Gleim et al. Journal of Biomedical Semantics            (2020) 11:6 https://doi.org/10.1186/s13326-020-00223-zRESEARCH Open AccessEnabling ad-hoc reuse of private datarepositories through schema extractionLars Christoph Gleim1* , Md Rezaul Karim1,2, Lukas Zimmermann3, Oliver Kohlbacher3,4,5,6,7,Holger Stenzhorn3,8, Stefan Decker1,2 and Oya Beyan1,2AbstractBackground: Sharing sensitive data across organizational boundaries is often significantly limited by legal and ethicalrestrictions. Regulations such as the EU General Data Protection Rules (GDPR) impose strict requirements concerningthe protection of personal and privacy sensitive data. Therefore new approaches, such as the Personal Health Traininitiative, are emerging to utilize data right in their original repositories, circumventing the need to transfer data.Results: Circumventing limitations of previous systems, this paper proposes a configurable and automated schemaextraction and publishing approach, which enables ad-hoc SPARQL query formulation against RDF triple storeswithout requiring direct access to the private data. The approach is compatible with existing Semantic Web-basedtechnologies and allows for the subsequent execution of such queries in a safe setting under the data providerscontrol. Evaluation with four distinct datasets shows that a configurable amount of concise and task-relevant schema,closely describing the structure of the underlying data, was derived, enabling the schema introspection-assistedauthoring of SPARQL queries.Conclusions: Automatically extracting and publishing data schema can enable the introspection-assisted creation ofdata selection and integration queries. In conjunction with the presented system architecture, this approach canenable reuse of data from private repositories and in settings where agreeing upon a shared schema and encoding apriori is infeasible. As such, it could provide an important step towards reuse of data from previously inaccessiblesources and thus towards the proliferation of data-driven methods in the biomedical domain.Keywords: Semantic web, Linked data, RDF, SPARQL, Schema extraction, Privacy, Data access, Distributed systems,Query design, Personal health train, FAIR dataBackgroundData-driven methods play an increasingly important rolefor cost-efficient and timely research results and effec-tive decision support [2] throughout numerous domainsuch as economics [3], education [4], manufacturing [5],healthcare and life sciences [68].At the same time, the data that build the founda-tion of these models oftentimes underlies strict sharing*Correspondence: gleim@cs.rwth-aachen.deThis work is an extended version of a paper previously published at theSeWeBMeDA-2018 workshop [1].1Informatik 5, RWTH Aachen University, Ahornstr. 55, 52062 Aachen, GermanyFull list of author information is available at the end of the articlerequirements. For example, in the sensitive healthcaredomain, although first responders, hospitals, and manyother stakeholders already collect valuable data for data-driven research and treatment today, large portions of thisdata remain inaccessible to the majority of stakeholders largely due to ethical, administrative, legal and politicalhurdles that render data sharing infeasible [9]. In prac-tice, this leads to an inability to access large amounts ofdata crucial for a variety of tasks such as the optimiza-tion of decision support systems, first response systemsand data-driven research. At the core of this issue lies thelack of an effective mechanism to allow for data accessin a legally certain, sustainable and cost-efficient mannerwithout extensive delays.© The Author(s). 2020 Open Access This article is licensed under a Creative Commons Attribution 4.0 International License,which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriatecredit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes weremade. The images or other third party material in this article are included in the articles Creative Commons licence, unlessindicated otherwise in a credit line to the material. If material is not included in the articles Creative Commons licence and yourintended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directlyfrom the copyright holder. To view a copy of this licence, visit http://creativecommons.org/licenses/by/4.0/. The CreativeCommons Public Domain Dedication waiver (http://creativecommons.org/publicdomain/zero/1.0/) applies to the data madeavailable in this article, unless otherwise stated in a credit line to the data.Gleim et al. Journal of Biomedical Semantics            (2020) 11:6 Page 2 of 15For example, learning health systems, allowing for data-driven research on sensitive data such as electronic healthrecords (EHRs), have long been said to bear the poten-tial to fill major knowledge gaps about health care costs,the benefits and risks of drugs and procedures, geo-graphic variations, environmental health influences, thehealth of special populations, and personalized medicine.[10]. While a variety of such systems have been proposed[1013], practical implementation has so far not becomea reality, likely due to the aforementioned hurdles.In order to enable data economy in privacy-sensitivedomains and effective reuse of existing data and research,novel approaches are emerging to overcome these limi-tations. One of those approaches is the Personal HealthTrain (PHT) framework [14], which aims to bring algo-rithms and statistical models to data sources, rather thansharing data with the third parties such as researchers.The main benefit of this approach is its ability of utilizingall the data, including the sensitive and private informa-tion, without data having to leave the original data source.A key challenge of this approach is that data users (such asresearchers) are required to develop their models withouthaving a grasp of the actual data. Unless there are univer-sally agreed information models and data set descriptions,there is a need to create and communicate a schema  thatis information about the structure of the data  to enablewriting queries for heterogeneous data resources.This work is embedded in our ongoing efforts support-ing data reuse in healthcare environments and conductedas part of the SMITH [15] and DIFUTURE [16] projects.The key contributions of this paper consist of an auto-mated approach for extracting task-relevant schema fromRDF data sources for the efficient formulation of dataselection and integration queries without direct access tothe data and a corresponding integration with an infor-mation system architecture that allows for the subsequentevaluation of that query in a secure enclave.In the following, we describes some related work andthe basic foundations of our approach. Subsequently, weoutline the motivation of our research, as well as the keychallenges of schema extraction from sensitive data with-out sacrificing privacy, followed by the description of ourproposed schema extraction approach from existing datain the methods section. We then present a number ofevaluation results of the proposed data selection and inte-grationmethodology, based on the schema extracted froma sample use case. After a discussion of our results, we fin-ish with a conclusion of our results and a short outlook ofdirections for future work.Related workIn order to facilitate knowledge discovery for bothhumans and machines, the FAIR data principles [17]have been proposed: A set of guiding principles to makeresearch and scientific data Findable, Accessible, Interop-erable, and Re-usable. These guidance principles promiseto help in the discovery, access, integration and analysis oftask-appropriate scientific data and associated algorithmsandworkflows. Thus, FAIR is gaining a lot of attention andincreasing adoption.Core to realizing these principles are Semantic WebTechnologies [18], which provide a framework for datasharing and reuse by making the semantics of datamachine interpretable. Particularly the directed, graph-based data model RDF [1921] (built entirely upon thenotion of statements, i.e. data in the form of subjectpredicate object triples) in conjunction with formalconceptualizations of information models, semantics andencoding conventions in RDF vocabularies and ontologiestakes an important role.As such, RDF Schema (RDFS) [22] and the Web Ontol-ogy Language (OWL) [23] provide a proven framework inorder to describe (but not necessarily enforce) the struc-ture and semantics of data. Substantially, RDFS introducesthe concepts of classes and properties as well as basic rela-tions between them. OWL  a computational logic-basedlanguage  extends upon these concepts in order to repre-sent rich and complex knowledge about things, groups ofthings, and relations between them.In the context of this work, we use the term schemato refer to the semantic and structural annotation of datausing especially these two vocabularies.On the other hand, the classical notion of schema asthe formal definition of the shape that data needs to com-ply with in order to be valid (i.e. schema validation andenforcement) also exists in the Semantic Web with theShape Expression Language (ShEx) [24] and the ShapesConstraint Language (SHACL) [25]. At this time, thereare however no established ways of sharing data shapesthrough public repositories and as such, in practice, theyare only adapted in isolated deployments.Nevertheless, using RDFS and OWL, it is possible tocreate domain-specific, optionally interoperable vocabu-laries and ontologies, which may declare e.g. term or con-cept equivalences and dependencies between each otherand subsequently enable interoperability across individualencodings.Key to realizing the semantics described in RDFSand OWL vocabularies is the inference or entailmentof implicit knowledge (inferred triples) that follow fromexplicit knowledge (dataset triples) via the semanticsdescribed in the corresponding vocabularies. Figure 1illustrates some of the inferred triples that follow fromthe formal RDFS and OWL entailment semantics [26].Here we assume the namespaces ex and snomed to bedefined1.1Likely the definitions would be http://example.org/ and http://purl.bioontology.org/ontology/SNOMEDCT/Gleim et al. Journal of Biomedical Semantics            (2020) 11:6 Page 3 of 15Fig. 1 Illustration of several effects of entailment support of a SPARQL endpointIn this example, only a small number of triples is con-tained in the actual dataset, while the majority of knowl-edge is inferred using RDFS and OWL semantics. Notablyeach resource is either a class, a property or an individual,i.e. either schema or data.Popular examples of RDFS and OWL vocabulariesinclude the Ontology for Biomedical Investigation (OBI)[27] in the biology and healthcare domain, the GoodRela-tions ontology [28] in eBusiness and theDCAT vocabulary[29], which is used for the general purpose metadataannotation of datasets and data catalogs.In the context of eHealth systems, support for theSemantic Web is becoming more and more promi-nent with candidates such as the multilingual thesaurusSNOMEDCT [30], ongoing research efforts into an RDFspecification of HL7 FHIR [31], as well as the establish-ment of clear guidelines for dataset descriptions such asthe HCLS Community Profile [32].Various high-quality catalogs of freely reusable vocabu-laries exist, allowing for the easy discovery of suitable ter-minology to semantically annotate data. Examples includethe Linked Open Vocabulary (LOV) [3335] and the Bio-Portal [3638] project.The related idea of using schema export and import forfederated data access date back to as early as 1985 [39] butit is only recently that the idea has receivedmore attentionin the context of the Semantic Web.Kellou-Menouer et al. [40] propose a schema discov-ery approach based on hierarchical clustering instead ofdata annotations thus leading to an approximate schema.Florenzano et al. [41], Lohmann et al. [42, 43] andDudá et al. [44] introduce approaches focused on schemaextraction for visualization of the data structure but donot consider publishing or reuse of the extracted schema.Benedetti et al. [45, 46] propose an interesting relatedapproach for schema extraction, visualization and querygeneration but do not consider interoperability issues andrely on custom mechanisms for schema storage.MotivationRecently, Jochems et al. [47] and Deist et al. [48]introduced two related promising Semantic Web-basedapproaches in the context of the PHT initiative, foundedon the key concept of bringing research to the data ratherthan bringing data to the research. As such the underly-ing information system architecture enables learning fromprivacy sensitive data without the data ever crossing orga-nizational boundaries, maintaining control over the data,preserving data privacy and thereby overcoming legal andethical issues common to other forms of data exchanges.The general approach of this underlying system can beoutlined as follows:1 Initially, both the client and data provider agree upona set of attributes or features, such that allparticipating data providers have correspondingsources of (privacy sensitive) data.2 Then each data provider encodes their data using an(also agreed upon) ontology or vocabulary,converting it into RDF representation. This processyields proper Linked Data [49] and thus enablessemantic interoperability [50].3 The resulting RDF data is deployed to a private triplestore at each location, providing a private SPARQL[51] query endpoint, which is not directly accessibleby the client.4 A SPARQL data query is then formulated based onthe previously agreed upon encoding and acorresponding distributable processing algorithmdefined.5 The shared query is then executed locally at eachdata provider against their respective triple storesGleim et al. Journal of Biomedical Semantics            (2020) 11:6 Page 4 of 15and the returned data processed using thecorresponding algorithm.6 The local results are then combined into a global one.7 Depending on the approach, steps 5 and 6 may befurther iterated.While these approaches  introduced in the contextof the PHT initiative  work well when multiple partiesagree on jointly collecting, encoding and evaluating datain advance  such as is the case for conducting individualcoordinated studies  they solve the issue of interoperabil-ity by agreeing on a single shared knowledge representa-tion and encoding methodology a priori (steps 1-3 in theabove process). In an optimal setting where agreeing on asingle shared and global information model and encoding,reuse of diverse and existing data could always be directlyaccomplished with this approach.However, to our knowledge, so far all correspondingefforts have been unsuccessful. At the time of writingthe popular https://fairsharing.org/ portal indexes 1084databases using 1183 standards, suggesting that in prac-tice, each collected dataset and domain much rather tendsto introduce its own encoding methodology.Additionally, RDF datasets de facto often combine termsfrom multiple vocabularies and ontologies, sometimesdeviating from the originally intended information mod-els and encodings.Thus when trying to reuse diverse existing data, a properunderstanding of the real structure of the available data i.e. the schema of the data  is indispensable. For a clientwithout direct access to the data, this information is how-ever typically not available, since its acquisition inherentlyrelies upon inspection of the structure of the data.Approaches, such as the PHT, depend upon ad-hocdata selection and integration facilities (step 4 of thePHT approach, corresponding to the first two steps ofthe classical Knowledge Discovery in Databases (KDD)process [52]) for the efficient and effective extraction ofknowledge from private data sources. In order to enablethe usage of such an approach with diverse existingdata, suitable methods for the extraction and distributiontask-specific schema, tailored specifically for the purposeof enabling ad-hoc data selection and integration, areneeded.MethodsIn this section, we propose an automated approach forextracting task-specific schema from RDF data sources inorder to enable the efficient formulation of SPARQL dataselection and integration queries without direct access tothe data. First, we describe basic requirements for theextracted schema, as well as the fundamental idea of theschema extraction technique before subsequently intro-ducing a number of extensions, in order to support formore generally applicable schema extraction methodol-ogy. We discuss the trade-offs to be made between differ-ent versions of the schema extraction approach and finallyshow how the extracted schema can be used further forthe data selection and integration.In the context of RDF data, the fundamental knowl-edge required for the creation of SPARQL queries fordata selection and integration consists of the variousrdf:type objects, the rdf:Property predicates and the struc-tural relations between them. This information can itselfbe represented using Semantic Web Standards, such asRDFS, OWL, ShEx or SHACL.While shape languages such as ShEx and SHACLare natural candidates for representing prescriptive dataschema, they are designed specifically for the validation ofclearly structured individual data shapes and to commu-nicate explicit graph patterns. As such they are howevernot equally well suited for the formalization of the flexibleschema of entire semi-structured datasets.RDFS on the other hand provides a simple and descrip-tive structural annotation of the relationships betweenproperties and classes and as such serves as a promisingcandidate for the task at hand.While OWL further extends RDFS with a pow-erful set of description logic-based modeling prim-itives, the corresponding semantic complexity addssignificant overhead to the schema extraction pro-cess. Especially since the extracted schema is onlymeant to be used for query authoring and explic-itly not for reasoning, in the context of this workwe generally restrict our effort to extracting schemausing RDFS and the OWL owl:equivalentClass,owl:equivalentProperty and owl:sameAs pred-icates, which we deem most relevant in order to enableinteroperability and the effective formulation of selectionand integration queries.Especially in order to ensure interoperability withexisting Semantic Web technologies and compatibilitywith standard Semantic Web tools, such as schema-introspection-assisted SPARQL query builders, theextracted schema should thus be available as a simpleRDFS and OWL vocabulary via a SPARQL endpoint.Schema-introspection refers to the process of examin-ing the schema definition to determine which types ofentities exist, which properties are defined upon them andsubsequently, what can be queried for. Since the schemaneeded to create data queries (e.g. using SPARQL) onlycontains basic structural information about the originaldata, it also conveys far less privacy critical informationthan exposing the actual data. As such it can be publishedpublicly without privacy concerns in many scenarios.In the following, we describe an automated approach forschema extraction fromRDF data which allows for the for-mulation of data selection and integration queries withoutGleim et al. Journal of Biomedical Semantics            (2020) 11:6 Page 5 of 15direct access to the data and the subsequent evaluation ofthat query in a secure enclave.Schema extractionWe propose an approach for schema extraction basedon exploiting key characteristics of RDF, RDFS, andOWL. RDF data encoded in compliance with correspond-ing vocabularies inherently include metadata about theirsemantics and structural relationships.For the schema extraction, the rdf:type relation playsthe key role, as it declares data points to be instances ofspecific data types or, according to RDFS terminology andsemantics [53], classes. Anything that is a type in the senseof occurring as the target of this relation should thus auto-matically becomes part of the schema as an entity of typerdfs:Class. Additionally, any property relation (thatis any identifier occurring in the predicate position of asubject-predicate-object triple) which occurs in the datashould be included as an entity of type rdf:Property.Finally all directly describing properties of these classesand properties should be included as well. For the scopeof this work, we assume that all data in the private datarepository is sensitive and should remain private.Entailment supported schema extraction Assumingperfect conditions, namely proper inclusion of all usedvocabularies into the triple store, correct usage of thosevocabularies, as well as OWL entailment [26] support ofthe SPARQL endpoint providing access to the data, theentire schema of a given RDF data set can be extractedusing a single simple SPARQL CONSTRUCT query asdepicted in Listing 1.CONSTRUCT {?s ?p ?o}WHERE {{[] ?s []}UNION {[] a ?s} .?s ?p ?o .} Listing 1 SPARQL schema extraction query relying on properentailment support of the endpoint.Note that we explicitly define the relevant subset of allavailable schema information to be that which is actuallyused in the data, i.e. the instantiated schema, and thus onlyextract that.The preceding query constructs an RDF graph (line 1)containing all the directly describing triples ?s ?p ?othat occur in the tripe store but having only the followingsubjects:1 Instantiated RDF properties ?s (line 3) whichaccording to RDF 1.1 Semantics [53] are any IRI usedin predicate position (c.f. rdfD2).2 Instantiated RDFS classes ?s (line 4) via theiroccurrence as the object of a triple with rdf:typeas the predicate. The fact that these are RDFS classesfollows directly from the RDFS axiomatic triplerdf:type rdfs:range rdfs:Class . inconjunction with RDFS entailment pattern rdfs3[53].According to the SPARQL entailment regime, all thesubclass relationships, transitive properties, equivalencesetc. used in the data are automatically materialized (i.e.included in the dataset as inferred knowledge as illus-trated in Fig. 1) and thus resolved and included too (c.f.[53, 54]).It should be noted that the query only extracts directproperties (i.e. triples ?s ?p ?o directly related to thesubject ?s) and as such, some complex constraints suchas OWL disjointness axioms are not included in theextracted schema. However, as stated before, for the taskof query formulation we consider this to be sufficient.Directly instantiated schema Since in practice fewSPARQL endpoints actually support any kind of entail-ment and usually do not materialize implicit triples, theapplicability of this basic approach is limited. While theoriginal query can theoretically also be executed with-out entailment support, it does not guarantee that allused properties and classes are annotated accordinglyas rdf:Property and rdf:Class and completelyignores any resource ?s that lacks further describingtriples ?s ?p ?o.Thus, in the following we introduce several revisionsof the initial extraction query 1 that allow us to reintro-duce the missing triples without relying upon entailmentsupport. Additionally, many datasets de facto employterms from a number of different vocabularies and ontolo-gies and deviate from the originally intended informa-tion model. Since the availability of information aboutdomain and range of the different properties employedin the dataset is especially relevant in order to assist thequery creation process, we further explicitly constructrdfs:domain and rdfs:range statements accordingto the propertys respective usage in the dataset.In scenarios where it is sufficient to consider only thosetypes and properties that are directly used in the datasetor where no information whatsoever about the employedvocabularies is available, it can be reasonable to disregardthe inference generalizations and equivalences entirely.Listing 2 proposes a SPARQL query for the extractionof a corresponding schema, which closely reflects thestructure of the underlying data and works even if thedefinitions of the employed ontologies are unavailable.For this and all further queries, we assume standardSPARQL namespace and prefix definitions as specified bythe World Wide Web Consortiums OWL and SPARQLspecifications [53, 55].Gleim et al. Journal of Biomedical Semantics            (2020) 11:6 Page 6 of 15CONSTRUCT {?predicate ?a ?b; a rdf:Property;rdfs:domain ?pDomain; rdfs:range ?pRange.?concept ?c ?d; a rdfs:Class.} WHERE {?s ?predicate ?o.OPTIONAL {?s a ?pDomain}OPTIONAL {?o a ?pRange}OPTIONAL {?predicate ?a ?b}[] a ?conceptFILTER(!isBlank(?concept))OPTIONAL {?concept ?c ?d}} Listing 2 Basic SPARQL schema extraction query which onlydiscovers RDFS classes and properties directly instantiated in thequeried dataset.Analogously to query 1, we detect predicates as anyInternationalized Resource Identifier (IRI) used in predi-cate position (line 5) and classes as IRIs used as objects ofRDF type triples (line 9). We also include any additionalinformation directly relating to those subjects that mightbe available in the dataset (lines 8 and 11). To explicitlyconstruct rdfs:domain and rdfs:range informationof the predicates, we further determine the rdf:typeof each subject (line 6) and object (line 7), if available.Additionally we filter out any class declarations withoutan own identifier (line 10) to avoid potential referenc-ing issues with the extracted schema. Lastly we constructthe schema graph as all discovered predicates (explicitlytyped as rdf:Property) and their related informa-tion (line 2) and all discovered classes (explicitly typed asrdfs:Class) and their related information (line 3).When applying this extraction approach to the datasetdepicted in Fig. 1, we end up with the schema depicted inFig. 2 where classes are highlighted in blue and propertiesin green (i.e. with implicit rdf:type triples).Subsequently, in this exemplary use case, following theextracted schema closely one could query for instancesof the ex:Patient class and their corresponding prop-erty ex:treatedAt, which however perfectly reflectsthe available dataset without inferred knowledge.It should be noted, that this extracted schema is explic-itly not suited for triple entailment according to RDFSsemantics, due to the conjunctive nature of multiplerdfs:domain and rdfs:range definitions on prop-erties (c.f. RDFS entailment patterns rdfs2 and rdfs3[53]). A semantically correct alternative would be theusage of Schema.orgs schema:domainIncludes andschema:rangeIncludes properties in line 2, insteadof their RDFS equivalents. However, since RDFS domainand range semantics are implemented in a variety of toolsfor schema exploration, visualization and assisted queryauthoring [5658], while schema.org semantics are notequally well supported, we deliberately defer semanticcorrectness to a closer representation of the underlyingdatas structure.Locally inferred schema In order to re-include previ-ously inferred information such as additional types andclasses due to sub-property, subclass, domain, range orequivalence relationships, we can extract the relevantschema directly from the data and the full definitions ofthe employed ontologies using the SPARQL 1.1 PropertyPaths [59] feature, independent of entailment support orstatement materialization on the endpoint.A corresponding SPARQL query is depicted in Listing 3.WHERE {?s ?x ?o. OPTIONAL {?s a ?pDomain}OPTIONAL {?o a ?pRange}?x (rdfs:subPropertyOf|owl:equivalentProperty|^owl:equivalentProperty|owl:sameAs|^owl:sameAs)* ?predicateOPTIONAL {?predicate ?a ?b}{?predicate (rdfs:range|rdfs:domain) ?y}UNION {[] a ?y}?y (rdfs:subClassOf|owl:equivalentClass|^owl:equivalentClass|owl:sameAs|^owl:sameAs)* ?conceptFILTER(!isBlank(?concept))OPTIONAL {?concept ?c ?d}} Listing 3 Extended WHERE clause of schema extraction query 2employing SPARQL 1.1 Property Paths to emulate RDFSspecialization, domain and range semantics, as well as OWLequivalence entailment.The query constructs a graph, which in addition to allinstantiated RDFS classes and RDF properties (and theirdirect properties) includes generalizations and equivalentresources of those via RDFS and OWL semantics.For both properties and classes, we resolve corre-sponding generalizations directly using the relevantRDFS entailment patterns (rdfs5, rdfs7, rdfs9, rdfs11)[53] and concept equivalences using OWLs owl:equivalentClass, owl:equivalentPropertyand owl:sameAs predicates [54] in lines 5 and 9. Whileowl:sameAs is only supposed to be used for the decla-ration of equivalence between individuals, it is commonlymisused in practice and as such deliberately included inthis query.rdfs:Class annotations are further inferred follow-ing RDFS entailment rules rdfs2 and rdfs3 [53] fromrdfs:domain and rdfs:range properties declaredon instantiated rdf:Property resources (line 7).When applying this extraction approach to the datasetdepicted in Fig. 1, we end up with the relevant schemadepicted in Fig. 3. As before, classes are highlighted in blueand properties in green.Following the extracted schema, it is now also possibleto query for instances of the hospital and person classes, asGleim et al. Journal of Biomedical Semantics            (2020) 11:6 Page 7 of 15Fig. 2 Directly instantiated schema extracted from Example 1well as a number of equivalent SNOMEDCT vocabularyterms.Employing terminology servicesIn practice, individual SPARQL endpoints providingaccess to individual datasets cannot be (and are not) bur-dened with serving all vocabularies and terminologiesused in the dataset and related to those. That is the pur-pose of specialized terminology services and vocabularycatalogs, such as the aforementioned LOV and BioPortalprojects.In order to resolve equivalences and generalizationsacross vocabularies, it is thus possible to make use of theSPARQL 1.1 Federated Query protocol [60, 61] in orderto entail additional schema triples using external termi-nology services. The query depicted in Listing 4 employsfederated queries to the SPARQL endpoint http://example.org/terminology in order to accomplishthis. The query further explicitly filters out all subject thatare blank nodes in order to avoid renaming and resolu-tion issues between blank nodes from different sources(c.f. [60]).While the approach follows the same principles as thepreviously introduced local inference (c.f. Listing 3), hereeach inference step also includes results from the exter-nal terminology service. As such, following the exam-ple from before, the extracted schema would now alsoinclude all inferred knowledge from the SNOMEDCTvocabulary as well as any vocabulary known to theterminology service that declares equivalences withSNOMEDCT.In some cases, such as with rare diseases, even thelimited communication with remote terminology servicesmight affect data privacy, since the instantiation of cer-tain very rare classes or predicates might in itself revealprivate data. In such cases a local terminology service canbe employed, i.e. by creating a local deployment of theLOV service or by providing local copies of the relevantfull vocabularies. Nevertheless, sharing of the extractedschema in such cases may still require additional consid-erations.Unfortunately, current implementations of federatedSPARQL queries still typically incur large performancepenalties by using suboptimal resolution strategies. Assuch, in practice, it is often helpful tomanually decomposethe single query into multiple query steps. An exem-plary four-step approach using the SPARQL 1.1 UPDATEconstruct [62, 63] can be found in the supplementaryFig. 3 Locally inferred relevant schema extracted from example 1Gleim et al. Journal of Biomedical Semantics            (2020) 11:6 Page 8 of 15materials2, which also includes performance optimizedreformulations of the other queries.WHERE {?s ?x ?o.OPTIONAL {?s a ?pDomain}OPTIONAL {?o a ?pRange}{?x (rdfs:subPropertyOf|owl:equivalentProperty|^owl:equivalentProperty|owl:sameAs|^owl:sameAs)* ?predicate}UNION {SERVICE < http://example.org/terminology> {?x (rdfs:subPropertyOf|owl:equivalentProperty|^owl:equivalentProperty|owl:sameAs|^owl:sameAs)* ?predicate}}{[] a ?y}UNION {{?predicate (rdfs:range|rdfs:domain) ?y}UNION { SERVICE < http://example.org/terminology> {?predicate (rdfs:range|rdfs:domain) ?y}}} FILTER(!isBlank(?y)){?y (rdfs:subClassOf|owl:sameAs|^owl:sameAs|owl:equivalentClass|^owl:equivalentClass)* ?concept}UNION {SERVICE < http://example.org/terminology> {?y (rdfs:subClassOf|owl:sameAs|^owl:sameAs|owl:equivalentClass|^owl:equivalentClass)* ?concept}} FILTER(!isBlank(?concept))OPTIONAL {{?predicate ?a ?b}UNION {SERVICE < http://example.org/terminology> {?predicate ?a ?b}}}OPTIONAL {{?concept ?c ?d}UNION {SERVICE < http://example.org/terminology> {?concept ?c ?d}}}} Listing 4 Extended WHERE clause of query 3 for entailing classand property equivalences and generalizations using an externalterminology service.Schema-aided data selection and integrationOnce the schema is extracted, the resulting schema canbe publicly or semi-publicly (e.g. with prior authentica-tion) exposed using a dedicated SPARQL endpoint. It isthen possible to use existing SPARQL query writing assis-tance tools (i.e. query builders) such as OWLPath [64],QueryVOWL [58] or VSB [57] together with the extractedschema for schema introspection aided design of dataselection and integration queries without direct access to2https://github.com/PersonalHealthTrainGermany/schemaExtractionthe private dataset. An overview of available tools can befound in [65].Figure 4 depicts a screenshot of the visual querybuilder VSB [57], configured to employ introspection ofa schema extracted using the locally inferred approach,as conducted in the following evaluation. Correspond-ing instructions for schema extraction and deploymentcan be found in the supplementary materials. This exam-ple illustrates how introspection of the public schemaallows for the automated suggestion and autocompletion-assisted search for available properties and classes, aswell as the relations between them, enabling easy querywriting through interactive schema exploration. In thedepicted case, the user is interested in instances of theschema:Person class and provided with a list of prop-erty suggestions for the search string fa, as available inthe original private data.Such tools may optionally also employ the providedschema in order to construct SPARQL 1.1 queries thatcan resolve term generalizations and equivalences follow-ing the semantics of the extracted schema. As such, theuser does not have to rely upon proper entailment sup-port of the dataset SPARQL endpoint but can constructexplicit queries that specify the relevant equivalences, fur-ther enabling ad-hoc data integration queries through theprovided resource equivalences.As such, e.g. in the example depicted in Fig. 3, it is likelythat the private data endpoint does not support entail-ment. Thus, the query must be constructed in a way toaccount for the semantic implications of the schema. Forexample, in order to find all persons, one would have toquery not only for all instances of the person class, but alsofor all instances of its equivalent classes, subclasses, theirequivalent classes, as well as those that occur as subject orobject of a property with corresponding domain or range,in this case subject of a triple with ex:treatedAt pred-icate. Query builders and query writing assistance toolscan however automatically construct queries accountingfor this without burdening the user. Such queries thusallow for the ad-hoc integration of data encoded withdifferent ontologies and standards, based only on thepreviously extracted schema.System architecture The workflow of the proposedarchitecture is illustrated in Fig. 5, which depicts the com-munication between client and data provider over a publicnetwork. In this scenario, the data providers internalcommunication within its private network is highlightedby the bounding box.In preparation for client usage, the schema of thesensitive data stored in the private triple storeis extracted in step 0 using the approach presentedabove and deployed to a publicly accessible schemaendpoint.Gleim et al. Journal of Biomedical Semantics            (2020) 11:6 Page 9 of 15Fig. 4 An example of a visual SPARQL query builder tool interacting with the schema introspection endpoint to enable assisted query designSince the private data store remains inaccessible fromoutside its private network at all times, the schemaextraction has to be conducted by the data providerherself. This could either be done by manually extract-ing the schema on-demand, e.g. using the four-stepLOV inferred schema extraction approach employingthe SPARQL Update construct, by automatically runninga corresponding extraction script in regular time intervalsor by creating a schema view for the data store, whichcan then directly be queried by data consumers.Once the schema endpoint is available, the client canstart to create a SPARQL query in step 1, using a querybuilder of their choice in conjunction with the schemaendpoint for introspection. The query is then sent to asubmission endpoint acting as the gateway betweenthe data provider and the client in step 2. For the scopeFig. 5Workflow of the proposed architectureGleim et al. Journal of Biomedical Semantics            (2020) 11:6 Page 10 of 15of this work, we assume that this requests includes algo-rithmic means of data anonymization, ensuring its resultsare no longer privacy sensitive and that validation is donemanually.Once validated, the request is scheduled in step 4 forprocessing within a secure enclave (processing), wherethe query and algorithm are evaluated (step 5). This isanalogous to the approach proposed by Jochems et al. [47]and Deist et al. [48] as detailed in the related work section.Finally, only the processing result is returned to the clientin step 6 without ever directly granting access to thedata.EvaluationIn order to evaluate the proposed approach, we extractschema information from a synthetic dataset of patientrecords (PRs), specifically generated in order to illus-trate the intended use case, as well as the three corporaGenDR, Orphanet and NCBI Homologene, as distributedthrough the third release of the interlinked life sciencedata repository Bio2RDF [66].The PRs dataset contains personal information of10,000 individuals such as name, birthday and phonenumber and is published in conjunction with this paper.The dataset was generated using the open source gener-atedata tool3 and converted to a corresponding dataset of15,0000 RDF triples using the SPARQL Generate exten-sion [67, 68]. Half of the records are encoded usingthe FoaF vocabulary [69] and half using the Schema.orgvocabulary [70].GenDR [71] is a database of genes associated withdietary restriction (DR), intended to facilitate researchon the genetic and molecular mechanisms of DR-inducedlife-extension.Orphanet[72] is a database of information on rare dis-eases and orphan drugs for all publics, intended for theimprovement of the diagnosis, care and treatment ofpatients with rare diseases.HomoloGene [73] is a database of homolog sequencerelationships between 20 completely sequenced and anno-tated eukaryotic genomes.GenDR, Orphanet and Homologene respectively pro-vide custom vocabulary definitions describing their dataencoding and semantics.All four datasets were separately deployed to a pri-vate triple store and relevant schema extracted using thethree presented direct extraction methods, i.e. extract-ing only directly instantiated properties and classesusing query 2, using local inference together with therespectively employed vocabularies (such as FoaF andSchema.org definitions for the PRs dataset) via query 3and finally using the LOV terminology server via query 4.3https://github.com/benkeen/generatedataThe employed data and scripts may be found in thesupplemental materials.ResultsIn order to evaluate the effectiveness of the schemaextraction process, we employ the HCLS core statisticalmeasures [32] to compare the characteristics of the vocab-ularies, datasets and the extracted schema. Table 1 listsresults for the entire Linked Open Vocabularies dataset(employed in the terminology service), the full datasetsPRs, GenDR, Orphanet and Homologene, the respectivecomplete vocabularies employed for coding the datasetsas well as the three extracted schemata per dataset.On first sight, the results clearly show that for all threeapproaches, the number of extracted triples is signifi-cantly lower compared to the respective combined sourcedata, thus reducing the cognitive and computational effortrequired for schema introspection.For the directly instantiated properties and classes, wehave to compare the extracted schema directly with thefull dataset, since there is no other available vocabularydefinition in the data source to compare it to. For thePRs dataset, only 47 instead of 15,0000 (i.e. about 0.03%of the number of triples contained in the full dataset) areincluded in the schema. Nevertheless, manual validationshows that the 23 subjects are exactly the 20 propertiesand three classes found in the full dataset.Similarly, with 361, 799 and 184 triples, the size of theextracted schema for GenDR, Orphanet and Homolo-gene datasets is about 3.11%, 0.21% and 0.03% of therespective full dataset. However, compared to the triplecounts of the corresponding authoritative vocabularies,there is a significant amount of additional informationin the extracted schema with 361:192 (?88% overhead),799:402 (?99% overhead) and 184:62 (?197% overhead)triples. This characteristic is proportionally reflected inthe number of typed entities and subjects extracted with37:20 (+85%), 67:40 (+67.5%) and 24:7 (+200%). Closerinspection reveals that the additional subjects in theextracted schema are in fact additional properties andclasses in the dataset, which are not included in therespective authoritative dataset vocabulary but stem fromusage of terms from additional vocabularies within thedataset. As such, reliance onto the data model specified inthe authoritative vocabulary when creating data queries,could actually hinder making proper usage of the fullavailable data, while the extracted schema more closelyreflects the actual data structure at hand.Manual validation (c.f. supplementary materials) showsthat for the GenDR and Homologene datasets all sub-jects of the authoritative vocabulary are also includedin the extracted schema. For Orphanet all but oneare included, the http://bio2rdf.org/orphanet_vocabulary:Disorder-Gene-Association class, which itself does notGleim et al. Journal of Biomedical Semantics            (2020) 11:6 Page 11 of 15Table 1 HCLS core statistics [32] of evaluated datasets, vocabularies and extracted schemataHCLSMetric 6.6.1.1 6.6.1.2 6.6.1.3 6.6.1.4 6.6.1.5 6.6.1.6 6.6.1.7number of unique triples typed entities subjects properties objects classes literalsLOV Vocabulary Corpus 833834 129827 171168 1209 145498 1469 180680PRs Dataset 150000 20000 20000 20 10003 3 70717Vocabulary schema.org (1) 8427 1617 1619 15 476 31 3193foaf (2) 631 84 86 15 38 9 154merge of (1), (2) 9058 1701 1705 23 508 38 3335Schema directly instantiated 47 23 23 3 5 2 0locally inferred 576 95 95 13 71 9 118LOV inferred 2345 208 208 87 379 16 850GenDR Dataset 11609 1123 1123 24 1232 13 5158Vocabulary GenDR Vocabulary 192 20 20 8 6 5 116Schema directly instantiated 361 37 37 10 16 7 105locally inferred 380 37 37 10 16 7 124LOV inferred 911 71 71 58 127 12 370Orphanet Dataset 377947 28871 28871 38 42891 29 144773Vocabulary Orphanet Vocabulary 402 40 40 9 7 5 239Schema directly instantiated 799 67 67 12 41 7 217locally inferred 840 68 68 12 41 7 256LOV inferred 1380 102 102 59 153 12 506Homologene Dataset 7189742 869981 869981 14 1420471 10 2865019Vocabulary Homologene Vocabulary 62 7 7 8 6 5 38Schema directly instantiated 184 24 24 10 13 7 40locally inferred 190 24 24 10 13 7 46LOV inferred 721 58 58 58 124 12 292occur in the dataset but is a superclass of 8 instantiatedand correctly included classes. This superclass is howeverincluded in the locally inferred version of the extractedschema and thus illustrates the proper functioning of therdfs:subClassOf inference. Since the validation fur-ther shows, that for all extracted schemata, the triplescontained in the directly instantiated schema are a sub-set of those in the locally inferred one, which are in turna subset of the LOV inferred schema, all subjects ocur-ring in the authoritative vocabulary are also contained inall other extracted schemata.With 576 triples, the locally inferred schema of the PRsdataset is about 6.36% of the size of the union of the fullemployed vocabularies and a superset of the previouslyextracted schema of directly instantiated properties andclasses. As intended, only the subset of the full vocabular-ies that actually describes the private dataset (and as suchis actually relevant to the data) is extracted, allowing forfocused query design based on only the relevant schema,thus saving cognitive as well as computational effort dur-ing schema introspection. Manual validation supports thecorrectness and completeness of the extracted schema.Similarly, the locally inferred schemata of GenDR,Orphanet and Homologene are extended versions of theirrespective locally instantiated variants, enriched by rele-vant semantically inferred knowledge from the respectivefull authoratative vocabularies, such as the entailment ofgeneralizations and equivalent classes and properties.Since these extracted schemata also contain explicitequivalence information (for example between thefoaf:Person and schema:Person, which is in thiscase only declared in the schema.org vocabulary) it ispossible to explicitly design queries considering the cor-responding implications at query design time withoutrelying upon inference support of the SPARQL endpoints.As such it may provide an additional building block forenabling efficient interoperability across different datacodings.Finally the schema inferred using the central LOV ter-minology service extends the locally inferred schemafurther by entailing additional schema equivalences, gen-eralizations and knowledge. The extracted schema for thePRs dataset consists of 2345 triples, which roughly equals0.28 percent of the entire LOV corpus and is yet againGleim et al. Journal of Biomedical Semantics            (2020) 11:6 Page 12 of 15a superset of the locally inferred schema. Overall it con-tains triples occurring in 265 of the 648 vocabularies thatmake up the entire LOV dataset. As such it provides avaluable source for semantic integration of data acrossvarious vocabularies used for coding data. Similarly, with911, 1380 and 721 triples, the LOV inferred schemata forthe GenDR, Orphanet and Homologene datasets weigh inat about 0.11%, 0.21% and 0.09% compared to the full LOVcorpus.While no in-depth evaluation of the runtime has beenconducted, it might be of interest that the extraction ofthe LOV inferred schema takes about one minute forthe largest evaluated dataset (Homologene) and under tenseconds for all other datasets, using two Fuseki4 SPARQLserver processes serving as triple store and terminologyserver on a single Intel i7-8700k desktop CPU. Herebythe runtime is largely dominated by the explicit construc-tion of rdfs:domain and rdfs:range properties, notby the SPARQL federation to the terminology service, asillustrated by the fact that the extraction of the locallyinstantiated schema took only between two to four sec-onds less extraction time in all evaluated datasets.DiscussionThe presented schema extraction and architecture striveto close a gap between owners and consumers of sensi-tive data. While related work has already provided us withbasic infrastructure in order to allow for the processing ofdata under the owners control, to our best knowledge, allexisting approaches relied upon a-priori agreement upona shared schema and data encoding.In contrast, the approaches presented in this work arecapable of extracting relevant (i.e. instantiated) schemafrom a given RDF dataset with a configurable amount ofinferred information based on RDFS and OWL semantics,which can subsequently be used for SPARQL query designwithout requiring access to the original data.As such, ongoing research efforts such as the PersonalHealth Train initiative could benefit significantly fromimplementing this or a similar approach in order to enableoptional interoperability and ad-hoc data integration andre-use. Especially given the challenges of trans-nationalstandardization efforts of vocabularies and data models,the evolution of such standards over time and the need ofindividual research to diverge from standards, we believea system such as the one presented in this work to beessential for the realization of effective data reuse.As illustrated in Fig. 4, the schema extraced usingour approach is suitable for usage with existing schema-introspection-assisted SPARQL query writing tools. Assuch it does enable the formulation of ad-hoc SPARQLdata-integration queries against RDF triple stores without4https://jena.apache.org/documentation/fuseki2/index.htmlrequiring direct access to the private data. The approachis compatible with existing Semantic Web-based tech-nologies and in can be employed in conjunction withthe presented system architecture for the subsequent exe-cution of such queries in a safe setting under the dataproviders control, i.e. in the context of the PHT initiative.Thus the presented approach can enable the ad-hoc reuseof private data repositories through schema extraction.While we believe the current approach to be universallyapplicable to any data domain (just as the underlying RDFdata and RDFS/OWL semantics model), many areas arecurrently lacking authoritative terminology servers withSPARQL endpoints and support for inference or SPARQL1.1 features required for any manual inference using ourmethodology. While the presented approaches work wellin conjunction with e.g the Linked Open Vocabulariesproject, compatibility with e.g. the important Bioportalproject is hindered by its SPARQL endpoint, which lacksentailment and SPARQL 1.1 support.Additionally, many vocabularies introduce customschema semantics that go beyond RDFS and the subsetof OWL that we consider in this work. Examples includeschema.orgs domainIncludes and rangeIncludesfor properties or Wikidatas own terms for class and prop-erty equivalences and concept generalization. While it iseasily possible to extend the presented schema extrac-tion mechanism to account for these additional terms,one may nevertheless wonder about the reasonableness ofthe redefinition of these basic schema concepts in vari-ous vocabularies. Nevertheless, as schema definition lan-guages, vocabularies with their own semantics and relatedrequirements evolve, we believe that a flexible solutionsuch as the one presented in this work will only growmorerelevant in practical applications in order to bridge the gapbetween competing systems and standards.Conclusion and outlookIn this paper, we proposed an automated way of schemaextraction from Linked Data in RDF format which enablesthe introspection supported development of SPARQLqueries without direct access to the actual data. Theapproach further allows for the extraction of a config-urable amount of semantically inferred schema and theresolution of equivalences across multiple vocabulariesand standards. As such, it could provide an importantbuilding block in order to enable optional interoperabil-ity across competing standards and data encodings. Basedon existing Semantic Web Technologies and inspired byrecently published work in the context of the PersonalHealth Train initiative, we further presented a systemarchitecture to realize reuse of data locked in privaterepositories without having to share the actual data. Fromthe users perspective, our approach enables straight for-ward query formulation against privacy sensitive dataGleim et al. Journal of Biomedical Semantics            (2020) 11:6 Page 13 of 15sources and successive evaluation of that request in asecure enclave at the data providers end.With this architecture, we can overcome the relianceof previous approaches on agreeing upon shared schemaand encoding a priori in favor of more flexible schemaextraction and introspection. While the methodology isdesigned specifically with the context of the PHT in mind,the approach is likely equally applicable to the broadercontext of semantic data exploration as well. As such,the presented method promises to provide a key buildingblock in enabling efficient reuse of data across a variety ofdomains. In conjunction with advanced distributed learn-ing and processing systems, the approach could be usedin order to overcome existing data sharing hurdles andunlock hidden value in existing data silos.Availability of data and supplementary materialsAll source code and all data generated or analyzed as part of this work aredocumented and publicly accessible on GitHub at https://github.com/PersonalHealthTrainGermany/schemaExtraction.AbbreviationsDR: Dietary restriction; EHR: Electronic health record; GDPR: EU general dataprotection Rules; IRI: Internationalized resource identifier; KDD: Knowledgediscovery in databases; LOV: Linked open vocabulary; OBI: Ontology forbiomedical Investigations; OWL: Web ontology language; PHT: Personal healthtrain; RDF: Resource description framework; RDFS: RDF schema; SHACL: Shapesconstraint language; ShEx: Shape expression language; SPARQL: SPARQLprotocol and RDF query languageAcknowledgementsThis paper is an extended version of our previous workshop paper [1]presented at the Extended Semantic Web Conference (ESWC2018) Workshopon Semantic Web Solutions for Large-scale Biomedical Data Analytics(SeWeBMeDA), in Crete, Greece, 3-4 June 2018. The authors would like tothank the anonymous reviewers for their helpful comments and improvementsuggestions.This work was conducted jointly by RWTH Aachen University, TubingenUniversity and Fraunhofer FIT as part of the PHT and GoFAIR implementationnetwork, which aims to develop a proof of concept information system toaddress current data reusability challenges of occurring in the context ofso-called data integration centers that are being established as part ofongoing German Medical Informatics BMBF projects (https://www.bmbf.de/de/medizininformatik-3342.html).Authors contributionsLG, MRK, LZ and OB participated in the project design and goal formulation.LG and LZ gathered requirements for the schema extraction. MRK contributeddata and ideas. LG drafted the paper, designed the schema extraction andconducted the evaluation. MRK, OB, OK, HS and SD contributed feedback andreviewed the manuscript. All authors read and approved the final manuscript.FundingThis work was supported by the German Ministry for Research and Education(BMBF) as part of the SMITH consortium (LG, MRK, OB and SD, grant no.01ZZ1803K) and the DIFUTURE consortium (OK, HS, and LZ, grant no.01ZZ1804D).Ethics approval and consent to participateNot applicable.Consent for publicationNot applicable.Competing interestsThe authors declare that they have no competing interests.Author details1Informatik 5, RWTH Aachen University, Ahornstr. 55, 52062 Aachen, Germany.2Fraunhofer FIT, Schloss Birlinghoven, 53754 Sankt Augustin, Germany.3Institute for Translational Bioinformatics, University Hospital Tübingen, Sand14, 72076 Tübingen, Germany. 4Applied Bioinformatics, Department ofComputer Science, University of Tübingen, Sand 14, 72076 Tübingen,Germany. 5Institute for Bioinformatics and Medical Informatics, University ofTübingen, Sand 14, 72076 Tübingen, Germany. 6Quantitative Biology Center,University of Tübingen, Auf der Morgenstelle 10, 72076 Tübingen, Germany.7Biomolecular Interactions, Max Planck Institute for Developmental Biology,Max-Planck-Ring 5, 72076 Tübingen, Germany. 8Institute for Medical Biometry,Epidemiology und Medical Informatics, Saarland University Medical Center,Kirrberger Str., Building 86, 66421 Homburg, Germany.Received: 25 October 2018 Accepted: 23 July 2019Nguyen et al. Journal of Biomedical Semantics            (2020) 11:5 https://doi.org/10.1186/s13326-020-00221-1RESEARCH Open AccessNeural side effect discovery from usercredibility and experience-assessed onlinehealth discussionsVan-Hoang Nguyen* , Kazunari Sugiyama, Min-Yen Kan and Kishaloy HalderAbstractBackground: Health 2.0 allows patients and caregivers to conveniently seek medical information and advice viae-portals and online discussion forums, especially regarding potential drug side effects. Although online healthcommunities are helpful platforms for obtaining non-professional opinions, they pose risks in communicatingunreliable and insufficient information in terms of quality and quantity. Existing methods in extracting user-reportedadverse drug reactions (ADRs) in online health forums are not only insufficiently accurate as they disregard usercredibility and drug experience, but are also expensive as they rely on supervised ground truth annotation ofindividual statement. We propose a NEural ArchiTecture for Drug side effect prediction (NEAT), which is optimized onthe task of drug side effect discovery based on a complete discussion while being attentive to user credibility andexperience, thus, addressing the mentioned shortcomings. We train our neural model in a self-supervised fashionusing ground truth drug side effects from mayoclinic.org. NEAT learns to assign each user a score that isdescriptive of their credibility and highlights the critical textual segments of their post.Results: Experiments show that NEAT improves drug side effect discovery from online health discussion by 3.04%from user-credibility agnostic baselines, and by 9.94% from non-neural baselines in term of F1. Additionally, the latentcredibility scores learned by the model correlate well with trustworthiness signals, such as the number of thanksreceived by other forum members, and improve credibility heuristics such as number of posts by 0.113 in term ofSpearmans rank correlation coefficient. Experience-based self-supervised attention highlights critical phrases such asmentioned side effects, and enhances fully supervised ADR extraction models based on sequence labelling by 5.502%in terms of precision.Conclusions: NEAT considers both user credibility and experience in online health forums, making feasible aself-supervised approach to side effect prediction for mentioned drugs. The derived user credibility and attentionmechanism are transferable and improve downstream ADR extraction models. Our approach enhances automaticdrug side effect discovery and fosters research in several domains including pharmacovigilance and clinical studies.Keywords: Online health communities, Drug side effect discovery, Credibility analysis, Deep learning, Naturallanguage processing*Correspondence: vhnguyen@u.nus.eduSchool of Computing, National University of Singapore, 13 Computing Drive,117417 Singapore, Singapore© The Author(s). 2020 Open Access This article is licensed under a Creative Commons Attribution 4.0 International License,which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriatecredit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes weremade. The images or other third party material in this article are included in the articles Creative Commons licence, unlessindicated otherwise in a credit line to the material. If material is not included in the articles Creative Commons licence and yourintended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directlyfrom the copyright holder. To view a copy of this licence, visit http://creativecommons.org/licenses/by/4.0/. The CreativeCommons Public Domain Dedication waiver (http://creativecommons.org/publicdomain/zero/1.0/) applies to the data madeavailable in this article, unless otherwise stated in a credit line to the data.Nguyen et al. Journal of Biomedical Semantics            (2020) 11:5 Page 2 of 16BackgroundSeeking medical opinions from online health commu-nities has become popular: 71% of adults aged 1829(equivalent to 59% of all U.S. adults) reported consultingonline health websites for opinions [1]. These opinionscome from an estimated twenty to one hundred thousandhealth-related websites [2], inclusive of online health com-munities that network patients with each other to pro-vide information and social support [3]. Platforms suchas HealthBoards1 and MedHelp2 feature users report-ing their own health experiences, inclusive of their self-reviewed drugs and medical treatments. Hence, they arevaluable sources for researchers [4, 5].Although patients use these platforms to access valuableinformation about drug reactions, there are challengesto their effective, large-scale use. There is lexical varia-tion where users describe the same side effect differently.For example, dizziness can be expressed as giddiness ormy head is spinning, posing difficulty to most feature-based or keyword matching approaches. Separately, thereare valid concerns regarding credibility of user-generatedcontents to be harvested at large in which research hasshown to be of variable quality and should be approachedwith caution [69]. One proxy indicator for informationquality is the authors trustworthiness [10]. In the con-text of social media or online forums, user trustworthinessis often approximated via ratings from other users, i.e.,number of thanks or upvotes [11], or via their consistencyof reporting credible information [12, 13]. In addition tocredibility, forum members also offer expertise thanks totheir own experience  with prescriptions in particular and facilitate responses to drug queries [14]. For instance,while reporting expected side effects for a specific treat-ment, patients with long-term use of certain drugs can bea complementary source of information:While my experience of 10 years is with Paxil, I expect that Zoloft will bethe same. You should definitely feel better within 2 weeks. One way I found tomake it easier to sleep was to get lots of exercize [sic]. Walk or run or whateverto burn off that anxiety.  User 3690.The above is an answer to a thread asking for expectedside effects for depression treatment with Zoloft.User 3690s history of active discussion on other anti-depressants such as Lexapro and Xanax lends credibil-ity to them being an authority on depression treatments.We noticed that Zoloft (mentioned in the thread)shares many common side effects with the other twoanti-depressants: changed behavior, dry mouth, andsleepiness or unusual drowsiness. as illustrated in Table 1.Many such examples suggest that drugs which are oftenprescribed together for the same treatment, such as anti-depressants, are likely to be discussed within a same1https://www.healthboards.com/2https://medhelp.org/Table 1 Side effects of anti-depressantsDrugs Side effectsLexapro chills, constipation, cough, decreased appetite, decreasedsexual desire, diarrhea, drymouth, joint pain, muscleache, tingling feeling, sleepiness or unusualdrowsiness, unusual dream, sweating, ...Xanax abdominal or stomach pain, muscle weakness , changedbehavior, chills, cough, decreased appetite, decreasedurine, diarrhea, difficult bowel movement, cough, drymouth, tingling feeling, sleepiness or unusualdrowsiness, slurred speech, sweating, yellow eye,..Zoloft changed behavior, decreased sexual desire, diarrhea,drymouth, heartburn, sleepiness or unusualdrowsiness, sweating,..The Drugs and Side effects columns respectively list the anti-depressants and theirside effects extracted from a drugside effect database. Side effects in commonamong those listed are boldthread and share common side effects. In addition, userswho have experienced certain drug reactions are moreoutspoken and active on those discussions involving drugsof similar side effects. These signals arise from the richcontext of online health information; hence, we expectsystems to explore beyond individual statements. Specif-ically, they should consider the complete discussion con-tent as well as the global experience of each involved users,in order to discover drug side effects or extract adversedrug reactions (ADRs).We argue that modeling user expertise from experi-enced side effects is more robust compared against gen-eral user profile and engagement features [13, 14], as userexpertise provides more meaningful signals for side effectdiscovery. To the best of our knowledge, there is no pre-vious work that incorporates user expertise in side effectdiscovery in discussion forums at either the thread orpost level. In this work, given online health discussions,we propose a novel end-to-end neural architecture thatjointly models each authors credibility, their global expe-rience and their posts textual content to discover theside effect of unseen drugs. We optimize the model ona self-supervised task of predicting side effect of men-tioned drugs for complete threads, where ground truthis accessible. Our key observation is that users can begrouped into clusters that share the same expertise orinterest in certain drugs, possibly due to their commontreatment or medical history. We incorporate this crit-ical observation into our user model in representing aposts content via a cluster-sensitive attention mechanism[15]. We also follow general definition of truth discov-ery and let the model learn a credibility score that isunique to every user and descriptive of their trustworthi-ness. Our experiments include an overall ablation studyto validate the significance of each model component.This paper extends our former work [16] by conductinga correlation study that analyzes the representativeness ofNguyen et al. Journal of Biomedical Semantics            (2020) 11:5 Page 3 of 16learned credibility scores and a comparison between ourself-supervised attention-based approach and traditionalsupervised sequence labeling approaches on side effectmention extraction.We summarize our contributions as follows: We propose a NEural ArchiTecture, NEAT, thatcaptures 1) user expertise and 2) credibility, 3) thesemantic content of individual posts and 4) thecomplete discussion thread, to improve side effectdiscovery from online health discussions. NEATsmain means of user credibility and experienceassessment can be easily adopted by various neuralattentional encoders [17, 18]. We formulate a self-supervised task of side effectprediction of mentioned drugs for the proposednetwork to jointly optimize its components. We conduct experiments to verify the validity of ourlearned credibility and the robustness ofself-supervised attention-based extraction,comparing against traditional supervised sequencelabeling baselines.Related workWe first review existing approaches to drug side effectdiscovery from health forums and social media. Next, weexamine how these works incorporate user credibility andexpertise in their learning objective. Finally, we justifyour choice of neural architecture by discussing its mod-eling capability of context-rich structures such as onlinediscussion.Drug Side Effect Discovery. Existing methods for drugdiscovery from online content extract drugs at post andstatement level. ADR mining systems typically include anamed entity recognition (NER) model and a relationshipor semantic role labeling model [19, 20]. Recent neu-ral approaches address lexical variation in user-generatedcontent  the difficulty faced by traditional keywordmatching and rule-based approaches  to improve recog-nition and labeling components [21, 22]. Distributed wordrepresentations [23, 24] constructed from context cancapture semantics based on the hypothesis that syn-onyms often share similar contextual words. For example,headache and cephalea will have close representationsif they share contextual words such as head or pain.Approaches to sub-word embedding [25, 26] model themorphology of words by leveraging sub-word or charac-ter information. These representations are naturally inte-grated into neural sequential models [17, 18, 27] that aresensitive to syntactic order. However, supervised sequencelabeling or mention extraction approaches require labo-rious annotations at the word (token) level, and areonly capable of discovering side effects that are explic-itly present in the text. Expert supervision or additionalsemantic matching models are also required to map suchrecognized text segments to standardized vocabularies orthesaurii [28]. In contrast, our proposed self-supervisedtask formulation discovers the aggregated side effects ofmentioned drugs for each community discussion by con-sidering the whole threads content. The list of discusseddrugs are tagged by forummoderators or obtained by pat-tern matching. This learning design not only effectivelyalleviates the need for expensive, finer-grained annota-tions but also allows for the prediction of side effects notexplicitly mentioned in the discussion.User Credibility and Expertise Integration. Credi-bility is of the utmost concern in large-scale knowl-edge harvesting [8, 29, 30]. Previous work on side effectdiscovery from individual statements or posts deriveinformation credibility by verifying a statements men-tioned side effects against ground truth drug side effectdatabases, and assess associated user credibility by mea-suring the percentage of a users credible statements[13, 31]. In contrast, our approach to side effect discov-ery from discussions by jointly modeling multiple postsand authors eschews the assessment of statement cred-ibility and derives user credibility differently. We assigneach user a positive score that is used to weight theirpost content in representing the discussions holistic con-tent. Suchweighted summation is detailedmathematicallyin Appendix 1 to conform to the general principle oftruth discovery, where sources providing credible infor-mation should be assigned higher credibility scores, andthe information that is supported by credible sources willbe regarded as true [10]. Although our dataset does notprovide any ground truth for user trustworthiness, we fol-lowed the previous usage of ratings or upvotes in onlineforums and adopted the number of thanks received fromother forum members [11] as our proxy for user trust-worthiness. Previous works have modeled user expertisebased on user profiles such as demographics; activityfeatures such as posting frequency and posting patternthrough time series and network analysis [13, 14]. Asshown in an earlier example in Section 1, modeling userexpertise from previously experienced side effects bettercaptures author authoritativeness for certain side effects.It is also universally applicable to any online platform.Modeling Online Discussion Content and StructureAs our work makes use of the rich topographical proper-ties of online communities, we briefly review approachesfor modeling textual content and post-thread discus-sion structure. Previous works use probabilistic graphicalmodels implicitly to represent textual content (especially,topicmodeling) as bags-of-words [28, 32] or inventories ofstylistic and linguistic features [13]. Such lightweight rep-resentation are well-suited in moderately short contexts,i.e., sentences or posts. However, in terms of modelingNguyen et al. Journal of Biomedical Semantics            (2020) 11:5 Page 4 of 16long discussions consisting of multiple posts, state-of-the-art models for Community Question Answering (CQA)feature hierarchical neural architectures [3335]. In termof encoding text, sequential encoders such as Long Short-TermMemory (LSTM) [36] or Convolutional Neural Net-works (CNN) [18] are capable of encoding long-termdependencies and semantic expressiveness by leverag-ing word embeddings. In terms of encoding hierarchicalstructures such as community discussions consisting ofpost- and thread-level features, neural architectures allowfor straightforward and efficient integration of multiplelearning objectives. In addition, our neural architecture,NEAT, incorporates attention mechanism that focuses onessential phrases while encoding post content, and jointuser credibility learning while optimizing for the sideeffect discovery objective.MethodsBasic Terminology. To ensure a consistent representa-tion, we define some terms and formalize them as follows: A drug d has a set of side effects,Sd = {s1, s2, . . . , s|Sd|} A post p is a message in online forums and contains asequence of words. Each post p belongs to the set ofall online forum posts P and is written by a user uand belongs to a thread t. A user u is a member of an online forum andparticipates in a list of threads, i.e.,Tu = {t1, t2, . . . , t|Tu|} by writing at least one post ineach thread. We use the terms user and author, aswell as user experience and user expertiseinterchangeably. Each user belongs to the set of allonline forum users U and is characterized by theircredibility and expertise. Credibility wu of user ureflects the probability of user u provide trustworthyor helpful information, and is approximated from thenumber of thanks given from other forummembers. A thread t (see Table 2) is an ordered collection ofpostuser pairs,Qt = {(p1,u1) , (p2,u2) , . . . ,(p|Qt |,u|Qt |)}.Each thread discusses the treatment for a particularcondition and entails a list of prescribed drugsDt = {d1, d2, . . . , d|Dt |}. Hence, every thread has a listof aggregated potential side effects defined asSt = Sd1 ? Sd2 · · · ? Sd|Dt | .Task Definition. Drug side effect discovery from discus-sions is the task of assigning the most relevant subset ofpotential side effects to threads discussing certain drugs,from a large collection of side effects. We view the drugside effect discovery problem as a multi-label classifica-tion task. In our setting, an instance of itemlabel is atuple(xt , y)where xt is the feature vector of thread tderived from its list of postuser pairs Qt and y is the sideeffect label vector i.e., y ? {0, 1}|S|, where |S| is the numberof possible side effect labels. Given training instances, wetrain our classifier to predict the list of drug side effects inunseen threads discussing unseen drugs.Formal Hypothesis. Given a thread t with Qt , wehypothesize that considering the credibility and experi-ence of user u ? (p,u) ? Qt improves the quality of featurerepresentation in thread t, resulting in better drug sideeffect discovery performance.Self-supervised Drug Side Effect Discovery. We pro-pose a self-supervised learning objective. Instead ofrelying on the identical and independently distributedassumption of fully supervised learning, we constructthe dataset from threads that can discuss a set of com-mon drugs. We look up the side effects of these men-tioned drugs via a drugside effect medical databaseobtained from Mayo Clinic portal. Our self-supervisedtask explores discussion-based side effect discovery whichalleviates the need for finer-grain annotation comparedagainst existing approach of statement-based side effectdiscovery. We also propose our neural architecture,Table 2 A sample discussion thread from an online health communityUser IDs Posts Mentioned drugs Aggregated side effects3690 While my experience of 10 years is with Paxil,I expect that Zoloft will be the same. Youshould definitely feel better within 2 weeks.One way I found to make it easier to sleepwas to get lots of exercize. Walk or run orwhatever to burn off that anxiety.Zoloft, Paxil changed behavior, decreased sexual desire,diarrhea, dry mouth, heart-burn, sleepinessor unusual drowsiness,...26521 Ive heard of people going cold turkey andhaving withdrawal at 6 months! Please, getin contact with a doctor ASAP! commonsymptoms include dizziness, electric shock-like sensations, sweating, nausea, insomnia,tremor, confusion, nightmares and vertigoThe User IDs and Posts columns respectively list the IDs of users involved in the discussions and their messages. The Mentioned drugs and Aggregated side effects columnsrespectively list the explicitly discussed drugs and their combined side effectsNguyen et al. Journal of Biomedical Semantics            (2020) 11:5 Page 5 of 16NEAT, that jointly models user credibility, expertise andtext content with attention while optimizing for the self-supervised objective. The network has three major com-ponents: 1) user expertise representation with rich multi-dimensional vectors; 2) cluster-sensitive attention beingcapable of focusing on relevant phases for post con-tent encoding improvement; and 3) credibility weightingmechanism which effectively learns to assign credibilityscore to each user, based on their content. We discuss itsimplementation in the following sections. Figure 1 showsthe detailed network architecture of our model.User Expertise Representation (UE). We embed eachuser u ? U as a vector vu so that the vector captures userus experience with certain side effects. As each user u par-ticipates in the threads Tu, entailing a list of experiencedside effects, we derive user side effect experience vectorv?u ? R|S| where S is the set of all possible side effectsand v?ui = nui where user u has discussed ith side effectin nui threads. We obtain a user drug experience matrixM? ? R|U|×|S| where jth row of M? denotes user sideeffect experience vector of jth user. To avoid learning fromsparse multi-hot encoded representations and to improveFig. 1 The neural architecture of our proposed NEAT. The wu and vu boxes denote Credibility Weight (CW) component and User Expertise (UE)component. The yellow boxes and blue boxes denote Cluster Attention (CA) component and neural text encoders with attention. The highlightedwords in red denoted the text segments that are being attended by the encoder. The ×, ?, and ? symbols denote the multiplication, summation,and sigmoid, respectivelyNguyen et al. Journal of Biomedical Semantics            (2020) 11:5 Page 6 of 16the models scalability with the number of side effects, weperform dimensionality reduction, specifically principalcomponent analysis (PCA) [37], to our experience matrixM? obtained from training set. Figure 2 shows percentageof variance explained versus number of included principalcomponents. Since our PCA plots do not show signifi-cant improved percentage of variance explained beyond100 components, we use g = 100 components, reduc-ing our original M? ? R|U|×|S| to user expertise matrixM ? R|U|×g .User Cluster Attention (CA).We make an assumptionvia observations that users in online health communitiescan be effectively grouped into clusters based on theirprevious side effect experience. The advantages of clus-tering users is twofold: First, since users in the sameclusters share certain parameters, they are jointly mod-eled and more active forum members leverage less activeones. Second, clustering efficiently reduces the numberof parameters to learn and improves optimization andgeneralization. We apply K-means  a distance-basedunsupervised clustering algorithm [38]  to binary-valueduser experience vectors v?u after normalization. By usingcosine similarity, the algorithm effectively groups userswith a high number of co-occurred side effects in the samecluster. To determine the number of clusters c, we plotthe silhouette scores against the number of clusters andobserve the sharp drop after c = 7 (Fig. 3). The averagesilhouette score is 0.57 for our choice of c = 7, indi-cating that users are moderately matched to their owngroups and separated from other groups. The top 5 mostcommon side effects in each clusters are shown in Table 3.In the larger domain of natural language processing,attention has become an integral part for modeling textsequences [39, 40]. By learning to focus on essential textsegments, attention allows text encoders to capture longterm semantic dependencies with regard to auxiliary con-textual information [41, 42]. In our related task of ADRmentions extraction, attention has been adopted recentlyin neural sequence labelling models [21, 43], resultingin promising improvement. Inspired by the concept, weenhance text encoding with user expertise attention. Eventhough the attention is adjusted to the non-extractive self-supervised task of thread-level drug side effect discovery,we hypothesize that our model learns to highlight thementioned accurate side effects, and can be used as aself-supervised baseline for side effect extraction. Basedon the previously obtained clustering results, we assign alearnable cluster attention vector for each user group andincorporate their expertise into the text encoding process.Post Content Encoding. NEAT takes the content of athread t as input, which is a list of postuser pairs Qt .Post pi of pair (pi,ui) ? Qt consists of a sequence ofwords xpi = {w1, . . . ,wn} with length n. We seek to rep-resent a post pi as a vector vp that effectively capturesits semantics through an encoding function f (xpi) mod-eled by a neural text encoding module (the blue boxesin Fig. 1). We embed each word into a low dimensionalvector and transform the post into a sequence of wordvectors {vw1 , vw2 , . . . , vwn}. Each word vector is initializedusing pre-trained GloVe [24] embeddings, and each out-of-vocabulary word vector is initialized randomly. Wemake use of modularity  a major advantage of neuralFig. 2 Principal component analysis on user experience vectors. The horizontal axis denotes the number of principal components chosen for PCA,while the vertical axis denotes their percentage of variance explained. We notice that the percentage of variance explained does not increasesignificantly after 100 principal componentsNguyen et al. Journal of Biomedical Semantics            (2020) 11:5 Page 7 of 16Fig. 3 Silhouette scores for User Clustering. The horizontal axis denotes the number of clusters chosen for K-means clustering, while the vertical axisdenotes their the silhouette scores. We notice that the silhouette scores drop sharply after 7 clusters.architectures  and design the post content encoder asa standalone component that can be easily updated withany state-of-the-art text encoder. In this work, we pro-vide two neural text encoders: long-short term memory(LSTM, see Fig. 4) [36] and convolutional neural net-works (CNN, see Fig. 5) [18], both of which incorporatesattention mechanism.A bi-directional LSTM encodes the word vectorsequence and outputs two sequences of hidden states: aforward sequence, Hf = hf1,hf2, . . . ,hfn that starts fromthe beginning of the text; and a backward sequence,Hb =hb1,hb2, . . . ,hbn that starts from the end of the text. Formanysequence encoding tasks, knowing both past (left) andfuture (right) contexts has proven to be effective [44]. Thestates hfi ,hbj ? Re of the forward and backward sequencesare computed as follows:hfi = LSTM(hfi?1, vwi), hbj = LSTM(hbj+1, vwj),where e is the number of encoder units, and hfi ,hbj are theith and jth hidden state vector of the forward (f ) and back-ward (b) sequence. We derive the cluster attention vectoras vai ? Re for each user ci, from which the weights ofeach hidden state hfj and hbj based on their similarity withthe attention vector are:waj =exp(vaihj)?nl=1 exp(vaihl). (1)The intuition behind Eq. (1), inspired by Luong et al.[39], is that hidden states which are similar to the atten-tion vector vai should be paid more attention to; henceare weighted higher during document encoding. vai isadjusted during training to capture hidden states that aresignificant in forming the final post representation. wajis then used to compute forward and backward weightedfeature vectors:hf =n?jwajhfj , hb =n?jwajhbj . (2)We concatenate the forward and backward vectors toobtain a single vector, following previous bi-directionalLSTM practice [45].Table 3 Most common experienced side effects for each usercluster ci (i = 1 to 7)Cluster Most common experienced side effectsc1 vision blurred, yellow skin, vision double, yellow eye,nose stuffyc2 headache, itch, stomach pain, weak, nauseac3 itch, irritate, headache, pain abdominal, stomachcrampc4 bad taste, nausea, tiredness, irritate, mouth ulcerc5 skin red, itch, rash skin, skin peeling, burning skinc6 sneezing, nose runny, nose stuffy, decrease sexualdesire, pain breastc7 nausea, stomach pain, vomit, diarrhea, painabdominalThe left column lists the names of 7 clusters, and the right column describes themost common experienced side effects of users in each clusterNguyen et al. Journal of Biomedical Semantics            (2020) 11:5 Page 8 of 16Fig. 4 LSTM-based encoder with cluster attention. The × and + cells denote the attention-weighted summation described in Eq. (2). The C celldenotes the concatenation of the forward, hf , and backward, hb , hidden statesOur choice of CNN-based encoder is based on priorwork [18, 46]. A convolution block k consists of two sub-components: a convolution layer and a cluster attentionlayer. In the convolution layer, a kernel of window s(0 < s < n) of weight W is used to generatethe hidden representation hkj for the word embeddingsNguyen et al. Journal of Biomedical Semantics            (2020) 11:5 Page 9 of 16Fig. 5 CNN-based Encoder with Cluster Attention. The × and + cells denote the attention-weighted summation described in Eq. 2. The C celldenotes the concatenation of the final hidden states of K convolution blocksNguyen et al. Journal of Biomedical Semantics            (2020) 11:5 Page 10 of 16{vwi?s+1 , · · · , vwi} as:hkj = CONV (W , {vwi?s+1 , · · · , vwi}) (3)where CONV (·) is the convolution operation describedin [18]. In the cluster attention layer, we first derive theattention weight waj for each hidden representation hkjsimilarly to the LSTM-based encoder. Attention weightedpooling is used to obtain the convolution block output asfollows:hk =n?jwajhkj (4)Since we use multiple convolution blocks of differentkernel sizes, the final post representation is the concate-nation of K block outputs hk .Thread Content Encoding with Credibility Weights(CW). For every postuser pair (pi,ui) at thread t, wefirst compute feature vector vpi for post pi. NEAT thenconcatenates this postuser representation with user uisexpertise vector vui to form postuser complex vector vpui .This postuser complex is weighted by a user credibil-ity ewui , where wui initially set to 0 per user and updatedwhile training for the self-supervised side effect discoveryobjective. We implement credibility learning according tothe general intuition from the truth discovery literature:users who give quality posts, on which the model cansolely base to make correct predictions, are given a highercredibility. We also exploit this credibility score to encodethe thread representation by placing emphasis on the con-tent of credible users. A representation of a thread thatmeets the above description is the weighted sum of eachpostuser complex vector:vt =n?i=1vp?ui =n?i=1ewui vpui (5)Multi-label Prediction:NEAT feeds the thread contentrepresentation vt through a fully connected layer whoseoutputs can be computed as follows:st = W tanh(vt) + b, (6)where W and b are weights and biases of the layer. Theoutput vector st ? R|S| is finally passed through a sigmoidactivation function ?(·), and trained using cross-entropyloss L defined as follows:L = 1|T ||T |?t=1{yt · log(? (st)) + (1 ? yt) · log(1 ? ?(st))}+ ?1??uv2u + ?2?i|wui |(7)We adopt regularization that penalizes the training losswith the user experience matrixs L2 norm by a fac-tor of ?1 and the user credibility vector wus L1 normby a factor of ?2. The loss function is differentiable,thus trainable with the Adam optimizer [47]. Duringour gradient-based learning, user uis credibility scorewui is updated by calculating ?L?wui by back-propagation(see Appendix 1).ResultsWe conduct experiments to validate the effectiveness ofour proposed model. We design an ablation study to high-light the effectiveness of each component of NEAT inour self-supervised side effect prediction. In addition, weexpand our previous work [16]. More specifically,1. We verify the representativeness of the learnedcredibility scores via correlation analysis and rankingmetrics using number of thanks received by otherforum members as the trustworthiness proxy.2. We compare the models performance in unseen drugside effect discovery against non-neural baselines.3. We examine the applicability of cluster attention inside effect mention extraction from user posts bothat the macroscopic and microscopic levels.Dataset and Experiment Settings. We conduct ourexperiments on the same dataset as [13] including 15,000users and 2.8 million posts extracted from 620,510HealthBoards[1] threads. The ground truths for self-supervised learning are defined as side effects of men-tioned drugs in the discussion. As annotating suchamount of posts is expensive, drug side effects areextracted from Mayo Clinics Drugs and Supplementsportal3 and are used as surrogates for potential drug reac-tions. From the original dataset, we only extract threadsthat are annotated with drugs and their side effects, alongwith the lists of contained posts and corresponding users.Table 4 shows some statistics of our dataset.For CNN encoder, we adopt the work by Kim (2014) [18]and use three kernels of sizes 3, 4, 5 with output chan-nel size = 100. For Bi-LSTM we use a single layer with ahidden state size = 32.We used Natural Language Toolkit 4 for tokenizationand stop-word elimination before representation mod-eling. We perform 10-fold cross-validation (with 8:1:1folds for training, validation, and testing, respectively).We perform PCA and K-means clustering on training set,using scikit-learns built-in modules [48], 100 prin-cipal components (g = 100). All models are trained usingPyTorch5 library. We have released our codes at 6.Ablation Study. We include each component inSection 1 to the architecture at a time and ver-ify the incremental enhancement. We implement both3https://www.mayoclinic.org/drugs-supplements4https://www.nltk.org/index.html5https://pytorch.org/6https://github.com/nguyenvanhoang7398/NEATNguyen et al. Journal of Biomedical Semantics            (2020) 11:5 Page 11 of 16Table 4 Some statistics on our dataset# Users 14,966# Threads 78,213Avg. words per post 67.45Avg. posts per thread 3.97Avg. participated threads per user 54.7# Side effects (SE) 315Avg. SEs per thread 74.25# Drugs 1869Avg. experienced side effects per user 128.12The left column contains the statistics descriptions while the right column containsthe statistics valuesCNN and LSTM-based text encoders to confirm theconsistent improvement across different neural encoders.The ablated baselines and the full models are as follows: Vanilla: We implement a neural text encoderbaseline without any proposed component. Weighted Post Encoder (WPE): We constructthread representation by summing each of itspostuser complex vector weighted by usercredibility. Weighted Post Encoder with User Expertise(WPEU): We concatenate user expertise and postvector to create postuser complex vector. NEAT: We incorporate all three components  UE,CW and CA  as described.Table 5 shows the precision, recall (sensitivity), and F1(the harmonic mean of precision and sensitivity) obtainedby our method and the four baselines. We also reportthe performance of baselines implementing UE and CAindividually in Table 11.User Credibility Analysis. We discuss how descrip-tive the credible users assigned by the model are to ourTable 5 Performance of CNN-based models and LSTM-basedmodels in Ablation StudySystems Components Evaluation MetricsCW UE CA Pre. Rec. F1LSTM-Vanilla 0.6173 0.407 0.4335LSTM-WPE  0.6376 0.4344 0.4503LSTM-WPEU   0.6064 0.5001 0.4896LSTM-NEAT    0.6197 0.5134 0.5064CNN-Vanilla 0.7214 0.5503 0.5637CNN-WPE  0.7423 0.5799 0.5804CNN-WPEU   0.6923 0.6350 0.5910CNN-NEAT    0.7066 0.6431 0.6139In the Components column, CW, UE, CA denote Credibility Weights, User Expertiseand Cluster Attention module components, respectively. In the Evaluation Metricscolumn, Pre., Rec. and F1 denote Precision, Recall, and F1 scorecommon notion of trustworthy users in online communi-ties. We employ the number of thanks received by othercommunity members as the proxy for a users credibility,at both global, forum-wise scope and local, thread-wisescopes. Specifically, at forum-wise scope, we measureSpearmans rank correlation coefficient to examine howour output user scores approximate the ordering of usertrustworthiness. Thread-wise, we examine how accurateour output user scores are in ranking trustworthy respon-dents within a single discussion by measuring both Spear-mans coefficient and nDCG@2 with regard to the order-ing provided by our credibility proxy. We find the forum-wise rankingmetrics meaningful as answer ranking, basedon user credibility in our case, is a well-formulated task inCQA [4951]. The measurement results are presented inTable 6.Drug Side Effect Discovery. We test the performanceof NEAT in the task of Drug Side Effect Discovery. Specif-ically, the model has to predict the side effects of one offive unseen drugs based on their discussions as a whole.Such task is necessary to verify that our self-supervisedobjective of predicting for side effects of discussed drugsgeneralizes well to drugs that have not been discussed intraining data. We highlight the performance of an end-to-end neural architecture against Random Forest (RF) a competitive, non-neural baseline trained on bag-of-word text representations of thread content. Additionally,we examine a baseline, uNEAT, where the user identitiesare randomized in order to verify that NEAT effectivelyconsiders both user credibility and expertise. The resultsof drug side effect discovery on Ibuprofen, Levothyrox-ine, Metoformin (Table 7), and Omeprazole, Alprazolam(Table 8) are reported.Side Effect Extraction with Cluster Attention. As dis-cussed in Section 1, our employed attention mechanismnot only offers a better textual encoding capacity butalso locates the informative segments of user-generatedcontent. This concept is well-aligned with ADR men-tion extraction, which is mainly modeled as a sequencelabeling problem. We conduct experiments to examineTable 6 Analysis of NEATs Credibility versus baselines inapproximating credibility proxyMethods ThreadnDCG@2ThreadSpearmanForumSpearmanRandom 0.7968 -0.0271 0.0Post frequency 0.8812 0.4223 0.1924Question frequency 0.8341 0.1773 0.0279NEATs Credibility 0.8856 0.4403 0.3055The Thread nDCG@2, Thread Spearman, and Forum Spearman columnsrespectively denote the values of Normalized Discounted Cumulative Gain at 2 atthread level, Spearmans rank correlation coefficient at thread level and forum levelof each method when using rankings by number of thanks as ground truthsNguyen et al. Journal of Biomedical Semantics            (2020) 11:5 Page 12 of 16Table 7 Performance of NEAT versus baselines in Side Effect Discovery of Ibuprofen, Levothyroxine, and MetoforminMethods Ibuprofen Levothyroxine MetoforminPre. Rec. F1 Pre. Rec. F1 Pre. Rec. F1RF 0.583 0.414 0.474 0.319 0.401 0.347 0.48 0.647 0.491uNEAT 0.859 0.371 0.487 0.505 0.349 0.404 0.798 0.361 0.497NEAT 0.845 0.427 0.536 0.549 0.385 0.443 0.814 0.365 0.504In the Methods column, RF denotes Random Forest baseline from Bag-of-word, and uNEAT denotes User permutation baseline from NEAT. Pre., Rec. and F1 denote Precision,Recall, and F1 score, respectively.the effectiveness of CNN-NEATs Attention in locatingthe text segments containing the correct side effects.We benchmark our results against a lexicon-based tag-ging using UMLS thesaurus for medical terms [52] anda state-of-the-art neural side effect extractor [21] whichwas supervisedly trained to identify side effect mentionsin social media contents. In this task, correctly predict-ing the positive side effects is of the utmost importance,hence, we benchmark the text segments extracted fromCNN-NEATs Attention against two mentioned baselineson precisionmetric. The experiment results on Ibuprofen,Levothyroxine,Metoformin, Omeprazole and Alprazolamare reported in Table 9.DiscussionAblation Study. Firstly, all of the three models that applycredibility weighting (CW)  WPE, WPEU, and NEAT outperform both LSTM-Vanilla and CNN-Vanilla base-lines. Specifically, in LSTM-Vanilla, solely weighting eachpost by its author credibility improves the performance ofthe naive post encoder by 2.03%, 2.74% and 1.68% on pre-cision, recall, and F1, respectively. We observe a similarmargin of improvement from CNN-Vanilla. These resultsdemonstrate the effectiveness of accounting for authorcredibility when encoding thread content, improving sideeffect prediction.Improvements by incorporating user experience (UE)are also testified in both neural encoders. In LSTM-based models, adding UE (LSTM-WPEU vs. LSTM-WPE) improves recall by 6.57% and 3.93% in F1. Again,the CNN-based counterpart, CNN-WPEU, shows simi-lar performance trends. On a macro scale, these statisticsindicate that our model successfully learns to includeTable 8 Performance of NEAT versus baselines in Side EffectDiscovery of Omeprazole and AlprazolamMethods Omeprazole AlprazolamPre. Rec. F1 Pre. Rec. F1RF 0.229 0.458 0.271 0.639 0.432 0.511uNEAT 0.534 0.393 0.394 0.981 0.551 0.663NEAT 0.522 0.421 0.41 0.977 0.596 0.704In the Methods column, RF denotes Random Forest baseline from Bag-of-word, anduNEAT denotes User permutation baseline from NEAT. Pre., Rec. and F1 denotePrecision, Recall, and F1 score, respectivelymore side effects in its prediction, where many arerelevant to the ground truth. This is consistent with ourhypothesis that considering author experience of eachpost is effective in predicting out-of-context side effects.Applying cluster-sensitive attention (CA) in combiningboth the LSTMs and CNNs hidden states also improvesthe performance. In LSTM-based systems, we observethat adding CA (LSTM-NEAT vs. LSTM-WPEU) uni-formly improves all retrieval metrics; our CNN-basedcounterpart, CNN-NEAT, also demonstrates similar per-formance improvements. Although CNN-NEAT and itsablated baselines obtain higher performance than theLSTM counterparts, when measuring relative improve-ment, the gains are comparable. This confirms the con-sistent improvement of our proposed components acrossdifferent neural encoders. According to the macroscopicanalysis of results in Table 5, we generally conclude thatall of the three components in our proposed architec-ture  namely, CW, UE, and CA  yield a positive impacton the overall model performance. We observe consis-tent improvements in F1 after adding each component,and this lends support our stated hypotheses. The signif-icance of these findings were verified by one-tail t-test ofp < 0.05.User Credibility Analysis. Results at both the threadand forum level show that user scores assigned by NEATreasonably approximate our credibility proxy, i.e. thenumber of thanks given by other forum users. Regardingranking users by their helpfulness within a thread, NEATscredibility improves heuristics such as post or questionfrequency marginally by 0.0044 in term of nDCG@2 andmoderately by 0.0180 in term of Spearmans coefficient.Regarding ranking users by their helpfulness in the wholeforum, we report a more significant improvement of0.1131 in term of Spearmans coefficient from the clos-est performing baseline of post frequency. These resultsverify the representativeness of the credibility scoresobtained in the self-supervised manner by our system.Drug Side Effect Discovery. Both neural meth-ods, namely uNEAT and NEAT, outperform non-neuralapproach based on bag-of-word vectors on all metrics andacross all drugs. Specifically, NEAT improves RF by 9.94%in F1 on average across five different drugs. This confirmsthemodeling capability of our neural network and justifiesNguyen et al. Journal of Biomedical Semantics            (2020) 11:5 Page 13 of 16Table 9 Performance of CNN-NEATs Attention versus baselines in Side Effect Extraction in term of PrecisionMethods Ibuprofen Levothyroxine Metoformin Omeprazole AlprazolamUMLS Tagging 0.6801 0.6145 0.8378 0.5218 0.614Neural Extractor [21] 0.6741 0.6259 0.8092 0.4665 0.6161CNN-NEATs Attention 0.7073 0.7119 0.8557 0.504 0.688The Methods column includes the two baselines, UMLS Tagging and Neural Extractor, and the extracted attention of our proposed NEAT  CNN-NEATs Attention. Wepresent the five evaluated drugs, Ibuprofen, Levothyroxine, Metoformin, Omeprazole, Alprazolam and the Precision of extracting their side effects for all three methods.its application to our task. We also observe a decrease inperformance while optimizing NEAT being user-unaware.This shortcoming is prevalent in all side effect discov-ery settings, ranging from a 0.7% F1 score decrease forMetformin to 4.9% decrease for Ibuprofen. Overall, beingaware of user experience and expertise improves drug sideeffect discovery by 3.04% in F1 on average across five dif-ferent drugs. This gives substantial indicative evidencecongruent with our hypothesis that considering the cred-ibility and experience of users improves drug side effectdiscovery performance in online health communities.Side Effect Extraction with Cluster Attention. Wenotice improvement of CNN-NEATs Attention fromboth baselines across most drugs with the exception ofOmeprazole. At a macro level, positive precision scoresconfirm CNN-NEATs emphasis on critical text segments,i.e. those containing correct drug side effects. The sig-nificant improvement in most cases also suggests theselectiveness of CNN-NEATs Attention. Unlike the twoproposed baselines which extract any side effect men-tions, CNN-NEATs Attention selectively emphasizes cor-rect ADRs. We also examine this hypothesis at the microlevel in Table 10. UMLS tagging identifies any phrasehaving a medical nuance, i.e. pain and back, and poten-tially forms side effects that are not actually mentioned,i.e. back pain, whereas both neural methods, NeuralExtractor and NEAT, that model textual semantics areable to dismiss such trivial mentions.Discomfort, althoughcorrect, is questionably an intentionally reported sideeffects and is also dismissed by both Neural Extractorand CNN-NEAT. Post-processing rules can arguably alle-viate the shortcomings of UMLSs matching strategy dueto missing context awareness. However, such rules are notefficient to engineer. On the other hand, unsupervisedcontext encoding for keyword-based extraction is chal-lenging, and the task is left open for future works. Weattempt to explain CNN-NEATs decision to dismiss rest-lessness based on its contextual awareness. The attentionwas derived from each clusters experienced side effects,in which there is the weak side effects being semanti-cally contradicting to restlessness. Although having notfully covered all side effects, all mentions extracted byCNN-NEAT are accurate, giving it the highest precisionamongst the three considered models. Specifically, CNN-NEATs Attention improves over neural ADR extractionmodel [21] by 5.502% and UMLS tagging by 3.974%on average in terms of precision across five differentdrugs. Despite being derived from a self-supervised objec-tive, CNN-NEATs Attention offers helpful indications forattention-based models and a strong baseline for ADRextraction.Limitations. We call attention to limitations from ourdesign choice of defining a users credibility by Eq. (5),as well as our choice of credibility proxy as defined bythe number of thanks. A users credibility can be dam-aged if their posts do not directly help with predictingthe correct side effects. This assumption is question-able when users are asking for some information insteadof giving answers without any intent to give mislead-ing information. In contrast, we also observe the caseswhere users receive thanks for giving helpful informationsuch as suggesting nutritious diet or healthy lifestyle with-out mentioning any relevant side effects. We recognizethe limitation of our model where users without mali-cious intent are possibly assigned a low credibility score.This case of failure can explain why some users areassigned low to moderate credibility despite their highnumber of thanks. However, our definition makes sureTable 10 A test example highlighting the extracted side effects obtained by CNN-NEATs Attention versus baselinesUser IDs Clusters side effects Post content8420 stomach pain, headache, itch, weak, nausea I wont´ commit suicide but the discomfort < U > is enoughto make me want to die right now [...] I feel like I havesever Akathisia (inner restlessness<U,X> that makes you feellike your body is electrified [...] I also have nausea<U,X,N>,but I can eat a little, sweating<U,X,N>/cold, and extremefatigue<U,X>, although I already have chronic fatigue [...] I alsoget anxious<U,X,N> if I take more oxycodone for breakoutpain< U > and then go right back< U > downIn the Post content column, the correct and incorrect side effects are highlighted in blue and red, respectively. The extracted side effects of UMLS Tagging, Neural Extractor andCNN-NEATs Attention are followed by < U >, < X >, and < N >, respectively. The Clusters side effects column shows the list of common side effects in user 8420s clusterNguyen et al. Journal of Biomedical Semantics            (2020) 11:5 Page 14 of 16that the credibility learning mechanism does not expressthe opposite adverse behavior of assigning high credibilityto untrustworthy users.Annotating a posts side effects solely from looking upthe mentioned drugs in theMayo Clinic database presentsanother limitation. To generalize the usability and ensurethe effectiveness of the learning framework to a broadercommunity such as medical informatics, we suggest tohave these annotations cross-checked with healthcareprofessionals or pharmacovigilance experts, in order toensure the correlation between Mayo Clinics annotationsand the posts actually described side effects.Overall, our analysis suggests that user credibilityscores, although learned in a self-supervised manner, cancapture the expected notion of credibility and are descrip-tive of trustworthiness. Every component of our archi-tecture is also shown to be vital in achieving the highestperformance.ConclusionWe have addressed the importance of user experience andcredibility in modeling thread contents of online commu-nities, specifically through the task of drug side effect dis-covery. Our proposed neural architecture, NEAT, suggestsa subset of side effects relevant to the mentioned treat-ment in the given discussion, while taking into accountthe each post content and its author side effect experiencevia attention mechanism to represent forum discussionsbetter. Mainstream models for drug discovery in onlinecommunities have not captured thread content and userexperience holistically inanend-to-end optimizable system.We modeled users expertise by examining their expe-rience with different side effects, and then grouped theusers with similar experience into clusters that share acommon attention representation. We also proposed anself-supervised method which assigns credibility scoresto users based on the correctness of their contents andoverall improves thread representations. Correlation anal-ysis testifies the representativeness of learned credibilityscores of trustworthiness approximated by number ofthanks received by other online community members.In addition, our integrated attention mechanism not onlyenhances textual encoding but also highlights essentialtext segments and benefits ADR extraction approaches.We believe that our model is applicable to otherdomains. We plan to generalize its application to main-stream CQA or expertise-based thread recommendationfor health forum members.AppendixA User credibility weighting and the general principle oftruth discoveryIn order to demonstrate the correlation between learneduser credibility scores and the general notion oftrustworthiness, we derive how user credibility scores areupdated after each turn of back-propagation via stochas-tic gradient descent. The overall loss function in Eq. (7)can be rewritten as logistic loss without regularization ona single training example and a single label s as follows:L = log(1 + exp(?ys(ws tanh(vt) + bs))), (8)where ys is the binary truth for label s, bs is a classificationbias, and ws ? Rg×1 is a row of W in Eq. (6). ws is theclassification weight vector of a single label s.In back-propagation, we update the score wui of user uibased on the gradient calculated by taking the derivativeof the loss L with regard to wui :?L?wui= (1 ? tanh(vt)2)ysws vpuiewui1 + exp(ys(ws tanh(vt) + bs))= ?wui L. (9)The user score wui is updated as follows:wt+1ui = wtui ? ??wtui L, (10)where ? is the learning rate.When the prediction is correct, ys and (ws tanh(vt)+bs)share the same sign and ys(ws tanh(vt) + bs)) is highlypositive, making the denominator highly positive and theoverall gradient small. The user score wui is minimallyupdated.When the prediction is incorrect, ys and (ws tanh(vt) +bs) have different signs and the denominator approaches1. In the nominator, ws vpui is the prediction if we solelyconsider the post vector vpui of user ui. If this prediction is correct, which fits our definitionof credible user, ysws vpui is positive, making theoverall gradient positive. Then, the user score wui isupdated in the positive direction and the credibilityscore ewui used to weight user uis content increases. On the other hand, when the prediction from solelyconsidering the post vector vpui of user ui is incorrect,indicating a not credible user, ysws vpui is negative,and the overall gradient is negative. wui is updated inthe negative direction and the credibility score ewuiused to weight user uis content decreases. The magnitude of the gradient is proportional to ewui .This indicates that users who are currently learned ascredible are most affected by back-propagation whenthe models prediction is incorrect.Algorithm performance for individual integration of UEand CA.Table 11 reports the performance of baselines imple-mented UE, and CA individually.Nguyen et al. Journal of Biomedical Semantics            (2020) 11:5 Page 15 of 16Table 11 Performance for individual integration of UE and CA inAblation StudySystems Components Evaluation MetricsCW UE CA Pre. Rec. F1LSTM-UE  0.6513 0.4204 0.4531LSTM-CA  0.6416 0.4293 0.4611CNN-UE  0.6738 0.6185 0.5743CNN-CA  0.7441 0.5616 0.5883In the Components column, CW, UE, CA denote Credibility Weights, User Expertiseand Cluster Attention module components, respectively. In the Evaluation Metricscolumn, Pre., Rec. and F1 denote Precision, Recall, and F1 scoreAbbreviationsAvg: Average; UE: User Expertise Representation; CA: Cluster-sensitiveAttention; CW: Thread Content Encoding with Credibility Weights; CNN:Convolutional Neural Network; LSTM: Long-short Term Memory; F1 score: Theharmonic average of the precision and recall; PCA: Principal ComponentAnalysis; #: Number of; NEAT: The neural architecture proposed in this work;uNEAT: The ablated version of NEAT where the user identities are randomized;ADR: Adverse Drug Reaction; RF: Random Forest; nDCG@2: normalizedDiscounted Cumulative Gain at 2.AcknowledgementsNone declared.Authors contributionsAll authors conceived of and planned the reported work. KS proposed theproblem statement and suggested literature for review. VHN mainly designedthe model architecture with the help from MYK and KH. VHN implementedthe experiments, and interpreted the results. VHN, KS, MYK took the lead inwriting the manuscript with support from KH. All authors discussed the resultsand commented on the manuscript.FundingThis research is supported by the National Research Foundation, Singaporeunder its International Research Centres in Singapore Funding Initiative. Anyopinions, findings and conclusions or recommendations expressed in thismaterial are those of the author(s) and do not reflect the views of NationalResearch Foundation, Singapore.Availability of data andmaterialsThe dataset analysed during the current study was first published in [13] and ispublicly available at https://www.mpi-inf.mpg.de/departments/databases-and-information-systems/research/impact/peopleondrugs/The source codes of the implementation of this study is publicly available athttps://github.com/nguyenvanhoang7398/NEATThe source codes used to generate the results of Side Effect Extraction inSection 1 is available at https://github.com/nguyenvanhoang7398/NEAT/blob/master/adr_extraction.py.Ethics approval and consent to participateNot applicable.Consent for publicationNot applicable.Competing interestsAll authors declare that they have no competing interests.Received: 2 May 2019 Accepted: 7 June 2020RESEARCH Open AccessDe-identifying free text of Japaneseelectronic health recordsKohei Kajiyama1, Hiromasa Horiguchi2, Takashi Okumura3, Mizuki Morita4 and Yoshinobu Kano1*AbstractBackground: Recently, more electronic data sources are becoming available in the healthcare domain. Electronichealth records (EHRs), with their vast amounts of potentially available data, can greatly improve healthcare.Although EHR de-identification is necessary to protect personal information, automatic de-identification of Japaneselanguage EHRs has not been studied sufficiently. This study was conducted to raise de-identification performancefor Japanese EHRs through classic machine learning, deep learning, and rule-based methods, depending on thedataset.Results: Using three datasets, we implemented de-identification systems for Japanese EHRs and compared the de-identification performances found for rule-based, Conditional Random Fields (CRF), and Long-Short Term Memory(LSTM)-based methods. Gold standard tags for de-identification are annotated manually for age, hospital, person, sex,and time. We used different combinations of our datasets to train and evaluate our three methods. Our best F1-scores were 84.23, 68.19, and 81.67 points, respectively, for evaluations of the MedNLP dataset, a dummy EHRdataset that was virtually written by a medical doctor, and a Pathology Report dataset. Our LSTM-based methodwas the best performing, except for the MedNLP dataset. The rule-based method was best for the MedNLP dataset.The LSTM-based method achieved a good score of 83.07 points for this MedNLP dataset, which differs by 1.16points from the best score obtained using the rule-based method. Results suggest that LSTM adapted well todifferent characteristics of our datasets. Our LSTM-based method performed better than our CRF-based method,yielding a 7.41 point F1-score, when applied to our Pathology Report dataset. This report is the first of studyapplying this LSTM-based method to any de-identification task of a Japanese EHR.Conclusions: Our LSTM-based machine learning method was able to extract named entities to be de-identifiedwith better performance, in general, than that of our rule-based methods. However, machine learning methods areinadequate for processing expressions with low occurrence. Our future work will specifically examine thecombination of LSTM and rule-based methods to achieve better performance.Our currently achieved level of performance is sufficiently higher than that of publicly available Japanese de-identification tools. Therefore, our system will be applied to actual de-identification tasks in hospitals.Keywords: De-identification, Electronic health records, Japanese languageBackgroundRecently, more electronic data sources are becomingavailable in the healthcare domain. Utilization ofelectronic health records (EHRs), with their vastamounts of potentially useful data, is an important taskin the healthcare domain. New legislation in Japan hasaddressed the treatment of medical data. The Act onthe Protection of Personal Information [1] was revisedin 2017 to stipulate that developers de-identify specialcare-required personal information. This legislation© The Author(s). 2020 Open Access This article is licensed under a Creative Commons Attribution 4.0 International License,which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you giveappropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate ifchanges were made. The images or other third party material in this article are included in the article's Creative Commonslicence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commonslicence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtainpermission directly from the copyright holder. To view a copy of this licence, visit http://creativecommons.org/licenses/by/4.0/.The Creative Commons Public Domain Dedication waiver (http://creativecommons.org/publicdomain/zero/1.0/) applies to thedata made available in this article, unless otherwise stated in a credit line to the data.* Correspondence: kano@inf.shizuoka.ac.jp1Faculty of Informatics, Shizuoka University, Johoku 3-5-1, Naka-ku,Hamamatsu, Shizuoka 432-8011, JapanFull list of author information is available at the end of the articleKajiyama et al. Journal of Biomedical Semantics           (2020) 11:11 https://doi.org/10.1186/s13326-020-00227-9further restricts the use of personal identification codesincluding individual numbers (e.g. health insurance cardnumbers, drivers license card numbers, and governmen-tal personnel numbers), biometric information (e.g. fin-gerprints, DNA, voice, and appearances), andinformation related to disability. This legislation can becompared with the Health Insurance Portability andAccountability Act (HIPAA) [2] of the United States, inthat the Japanese Act in 2017 includes additional codes,with abstract specifications such as you should strivenot to discriminate or impose improper burdens, andwith exclusion of birth dates and criminal histories, asstipulated by HIPAA. Another related act of Japanese le-gislation, the Act on Anonymously Processed MedicalInformation to Contribute to Medical Research and De-velopment [3] was established in 2018. This legislationallows specific third-party institutes to handle EHRs,thereby promoting wider utilization of medical data.De-identification of structured data in EHRs is easierthan that of unstructured data because it is straightfor-ward to apply de-identification methods to structureddata such as numerical tables. Although de-identificationof unstructured data in EHRs is necessary, it is virtuallyimpossible to de-identify the huge number of documentsmanually.Several earlier works have examined EHR de-identification. The Informatics for Integrating Biology &the Bedside (i2b2) task [4] in 2006 was intended forautomatic de-identification of clinical records to satisfyHIPAA requirements [2]. An earlier study prepared 889EHRs, comprising 669 EHRs for training and 220 EHRsfor testing. Their annotations included 929 patient tags,3751 doctor tags, 263 location tags, 2400 hospital tags,7098 date tags, 4809 id tags, 232 phone_number tags,and 16 age tags. The best performing method of i2b2 in-corporated diverse features such as a lexicon, part-of-speech identification, word frequencies, and dictionariesfor learning using an ID3 tree learning algorithm.Grouin and Zweigenbaum [5] prepared 312 cardiovas-cular EHRs in French, with 3142 tags annotated by twoannotators (kappa = 0.87). Their tags include 238 datetags, 205 last_name tags, 109 first_name tags, 43 hospitaltags, 22 town tags, 8 zip_code tags, 8 address tags, 8phone tags, 8 med_device tags, 3 serial_number tags. Ofthe person tags, 75% were replaced with other Frenchperson names. The other 25% were replaced with inter-national names. They also collected 10 photopathologydocuments, for which a single annotator assigned 29date tags, 68 last_name tags, 53 first_name tags, 17 hos-pital tags, 17 town tags, 13 zip_code tags, 14 addresstags, 1 phone tag, 1 med_device tag, and 7 serial_numbertags. They performed de-identification experimentsusing 250 documents as their training data and 62 docu-ments as their test data for the cardiology corpus. Theyobtained better F1-scores (exact match, 0.883; overlapmatch, 0.887) using conditional random fields (CRF)than they obtained using their rule-based method (exactmatch, 0.843; overlap match, 0.847). However, theirrule-based method was better for the photopathologycorpus (exact match, 0.681; overlap match, 0.693) thantheir CRF-based method (exact match, 0.638; overlapmatch, 0.638) because the data were fewer than those ofthe cardiology corpus.Grouin and Névéol [6] discussed annotation guidelinesfor French clinical records. After collecting 170,000 doc-uments of 1000 patient records from five hospitals, theyfirst prepared a rule-based system and their CRF-basedsystem from their earlier study [5], which we describedearlier. Their rule-based system relies on 80 patternsspecifically designed to process the training corpus, andlists which they gathered from existing resources fromthe internet. They randomly selected 100 documents(Set 1) from their dataset and applied both systems. Foreach document, they randomly showed one output ofthe two systems to the annotators for revision. They ap-plied their rule-based system to another set of 100 docu-ments (Set 2), which were further reviewed and revisedby a human annotator. They re-trained their CRF-basedsystem using the revised Set 2 annotations, which is fur-ther applied to the other set of 100 documents (Set 3).Annotators reviewed these annotations in subsets fordifferent agreement analyses. The study also comparedhuman revision times among different annotation sets,which was a main objective of their study. They anno-tated 99 address tags, 101 zip_code tags, 462 date tags,47 e-mail tags, 224 hospital tags, 59 identifier tags, 871last_name tags, 750 first_name tags, 383 telephone tags,218 city tags, in Set 1. They reported their rule-basedmethod as better (0.813) in terms of the F1-score thantheir CRF-based method (0.519) when evaluated with 50documents in Set 1. When trained with Set 2, the corpusof the same domain, their CRF-based system performedbetter, yielding 0.953 for Set 3 and 0.888 for Set 1 intheir F1-scores.From the Stockholm EPR [7], a Swedish database ofmore than one million patient records from two thou-sand clinics, Dalianis and Velupillai [8] extracted 100 pa-tient records to create gold standard for automatic de-identifications based on HIPAA. They annotated 4423tags, including 56 age tags, 710 date_part tags, 500 full_date tags, 923 last_name tags, 1021 health_care_unittags, 148 location tags, and 136 phone_number tags.They pointed out that Swedish morphology is morecomplex than that of English. It includes more inflec-tions, making the de-identification task in Swedish moredifficult.Jian et al. [9] compiled a dataset of 3000 documents inChinese. It comprises 1500 hospitalization records, 1000Kajiyama et al. Journal of Biomedical Semantics           (2020) 11:11 Page 2 of 12summaries, 250 consulting records, and 250 death re-cords. They extracted 300 documents from this datasetrandomly, discussed a mode of de-identification withlower annotation cost. They annotated their tags tothese 300 documents (kappa = 0.76 between two annota-tors for their 100 document subset). Then they appliedtheir pattern-matching module to these 300 documents,yielding a dense set of 201 sentences that include PHI(Protected Health Information). These 201 sentences in-cluded 141 name tags, 51 address tags, and 22 hospitaltags.Du et al. [10] conducted de-identification experimentsusing 14,719 discharge summaries in Chinese: two stu-dents annotated 25,403 tags. This dataset includes 6403institution tags, 11,301 date tags, 33 age tags, 2078 pa-tient_name tags, 3912 doctor_name tags, 326 provincetags, 310 city tags, 774 country tags, 917 street tags, 277admission_num tags, 21 pathological_num tags, 23 x-ray_num tags, 263 phone tags, 420 doctor_num tags, and13 ultrasonic_num tags (inter-annotator agreement was96%, kappa = 0.826). Their experiments demonstratedthat their method of combining rules and CRF per-formed best, yielding a 98.78 F1-score. The Chinese lan-guage shares some issues with the Japanese language:they both require tokenization because no spaces existbetween words. This issue makes de-identification tasksmore difficult than they are in other languages.The reports described above present a range of differ-ent evaluation scores. However they adopted differentannotation criteria, which make direct comparison diffi-cult. For instance, Grouin and Névéol used more de-tailed annotations than those used by Jian et al., asfollows. Jian et al. introduced Doctor and Patient tags,but evaluated both simply as Name. Grouin and Névéolintroduced ZipCode, Identifier, Telephone, and City tags,none of which is annotated in the work of Jian et al.Additionally, they assigned Last Name and First Nametags, where performance of First Name was better thanLast Name by around 10 points. However, both areworse than the results reported by Jian et al., probablybecause Jian et al. applied their pattern-matching algo-rithm to filter their training data. Regarding Addresstags, Jian et al. obtained a 94.2 point F-score, whereasthe Grouin and Névéol CRF method obtained scores offewer than 10 points. As Grouin and Névéol suggested,eliminating City tags in street names can greatly improvetheir results: their rule-based method yielded an 86 pointF-score.Unfortunately, automatic de-identification of EHRshas not been studied sufficiently for Japanese language.De-identification shared tasks for Japanese EHRs wereheld as tasks in MedNLP-1 [11]. Then named entity ex-traction was attempted in MedNLP-2 [12] tasks usingdatasets similar to MedNLP-1. We designate MedNLP-1simply as MedNLP hereinafter because we specificallyexamine de-identification tasks but not other tasks heldin the MedNLP shared task series.Regarding machine learning methods, Support VectorMachine (SVM) [13] and CRF [14] were used often inearlier Named Entity Recognition (NER) tasks inaddition to rule-based methods. Recent deep learningmethods include Long-Short Term Memory (LSTM)[15] with character-embedding and word-embedding[16], which performed best for the CoNLL 2002 [17](Spanish and Dutch) and CoNLL 2003 [18] (English andGerman) NER shared task data: these tasks require de-tection of personal, location, organization, andother tag types. Another LSTM model, which is similarto earlier work [16], was also applied to a task of NERfrom Japanese newspapers [19]. Although deep neuralnetwork models have been showing better results re-cently, rule-based methods are still often better than ma-chine learning methods, especially when insufficientannotated data are available.To evaluate the effectiveness of such different methodsfor the Japanese language, we implemented two EHR de-identification systems for the Japanese language in ourearlier work [20]. We used the MedNLP shared taskdataset and our own dummy EHR dataset, which waswritten as a virtual database by medical professionalswho hold medical doctor certification. Based on thisearlier work, we added a new dataset of pathology re-ports to this study, for which we annotated the followingtags. De-identification tags of age, hospital, sex, time,and person are annotated manually in all these datasets,following the annotation standard of the MedNLPshared task to facilitate comparison with earlier studies.We assume these annotations as our gold standard forour de-identification task. To these three datasets, weapplied a rule-based method, a CRF-based method, andan LSTM-based method. Additionally, we have anno-tated our own tags to these three datasets by three anno-tators to calculate inter-annotator agreement. We haveobserved the coherency of the original annotations ofthe datasets. Overall, this study differs from our earlierwork [20] in that we added a new pathology dataset andits annotations, trained and evaluated our machinelearning models using the new dataset, and evaluatedthe results using newly created annotations by three an-notators to observe characteristics of the original andour own annotations.DatasetsOur datasets were derived from three sources: MedNLP,dummy EHRs, and pathology reports. Irrespective of thedataset source, de-identification tags of five types are an-notated manually: age (numerical expressions of sub-jects ages including its numerical classifiers), hospitalKajiyama et al. Journal of Biomedical Semantics           (2020) 11:11 Page 3 of 12(hospital names), sex (male or female), time (subject re-lated time expressions with its numerical classifiers), andperson (person names). Characteristics of these datasetsare presented in Table 1. It is noteworthy that texts ofthe MedNLP and dummy EHRs are not actual texts, butthey were written by medical professionals, each ofwhom holds medical doctor certification. However, char-acteristics of the descriptions differ between these twosources, probably because of differences of the writers.The number of annotators is not described for theMedNLP dataset, but a single annotator created the an-notations of the dummy EHR dataset and the PathologyReport dataset, individually.MedNLP shared task datasetWe used the MedNLP de-identification task dataset forcomparison with earlier studies that have used the samedataset. This dataset includes the dummy EHRs(discharge summaries) of 50 patients. Although thetraining dataset and test dataset were provided from theshared task organizers, the test dataset of the formal runis not publicly available now. It is not possible tocompare results directly with earlier works in theMedNLP shared task formal run (Tables 2 and 3 showthe formal run results). However, both training and testdatasets were originally parts of a single dataset. There-fore, we can discuss their characteristics in comparisonwith those found in earlier works conducted using thetraining dataset only. We calculated inter-annotatoragreement by three annotators for the training dataset.The average F1-score of three pairs among these threeannotators was 86.1, in 500 sentences of this dataset.Dummy EHRsAnother source is our original dummy EHRs. Webuilt our own dummy EHRs of 32 patients, assumingthat the patients were hospitalized. Documents of ourdummy EHRs were written by medical professionals(doctors). We added manual annotations for de-identification following the guidelines of the MedNLPshared task. These annotations were originallyassigned by a single annotator. Additionally, we addedTable 1 Dataset characteristicsDataset name MedNLP Dummy-EHRs Pathology Reports# of documents 50 reports 32 pairs of records and summaries 1000 reports# of sentences 2244 8183 3012# of tokens 42,621 154,132 194,449# of all tags 490 3017 295# of age tags 56 39 0# of hospital tags 75 170 31# of person tags 0 135 224# of sex tags 4 16 0# of time tags 355 2657 40Example inoriginal Japanesetext????????<a > 64?</a >? < x >??</x >????????????<a > 86?</a > <x >??</x >????<<???? <h >??????????</h >? < p >???</p>Exampletranslated intoEnglishA < a > 64-year-old</a > <x >man</x > works in a factoryAn <a > 86-year-old</a > <x > woman</x >bedridden in a nursing home. Total assistancerequired<<Ex-hospital sample < h > ShizudaiDermatology Clinic</h > , < p > SatoshiKuwata</p>Table 2 Overall resultsP R F AC3 89.59 91.67 90.62 99.58B3 91.67 86.57 89.05 99.54B1 90.05 87.96 88.99 99.49B2 90.82 87.04 88.89 99.52C1 92.42 84.72 88.41 99.49A1 91.50 84.72 87.98 99.47C2 91.50 84.72 87.98 99.46A2 90.15 84.72 87.35 99.41D1 86.10 74.54 79.90 99.36G1 82.09 76.39 79.14 99.38D3 85.87 73.15 79.00 99.35D2 80.81 74.07 77.29 99.24H2 76.17 75.46 75.81 99.28H1 75.81 75.46 75.64 99.27H3 74.88 74.54 74.71 99.26P, R and F were calculated at the phrase level: P, precision; R, recall; F, F1-measure;and A, accuracy. A was calculated in the word level (the agreement ratio of B-*, I-*and O).The first column stands for participants team names, where the first letter standsfor a team ID and the second numerical value stands for a submission run IDKajiyama et al. Journal of Biomedical Semantics           (2020) 11:11 Page 4 of 12new annotations by three annotators to a part of thisdataset and calculated inter-annotator agreement. Theaverage F1-score of three pairs among these threeannotators was 76.1 for 730 sentences of the DummyEHR dataset.Pathology reportsThe other source is a dataset of 1000 short pathologyreports, that differ greatly from the EHRs above. Pathologyreports describe pathological findings by which personalinformation (names of patients, doctors, hospitals, andtime expressions) frequently appears, but for which tags ofsex and age rarely appear. Personal names, hospital names,and dates were manually de-identified beforehand by thedataset provider, and replaced with special characters. Formachine learning methods to support realistic trainingand evaluation, we replaced these special characters withrandomly assigned real entity names as follows. For thehospital names, we collected 96,167 hospital names whichcover most of the Japanese hospital names, published bythe Japanese government. For the person names, wemanually created 20 dummy-family names and 20dummy-first names using one of the last names only, orcombining one of the last names and one of the firstnames. Additionally, we calculated the inter-annotatoragreement by three annotators. The average F1-score ofthree pairs among these three annotators was 80.2 for 500sentences of this dataset. This Pathology Report dataset isthe only real (not dummy) dataset among our threedatasets. Because we received manually de-identifiedversion of the original real pathology reports, no ethicalreview was necessary.MethodsWe used a Japanese morphological analyzer, Kuromoji,1for tokenization and part-of-speech (POS) tagging. Weregistered our customized dictionary, derived fromWikipedia entry names and entries of the JapaneseStandard Disease-code master [21], to this morphologicalanalyzer in addition to the analyzers default dictionary.We implemented rule-based, CRF-based, and LSTM-based methods.Rule-based methodUnfortunately, the implementation of the best system forthe MedNLP-1 de-identification task [22] is not publiclyavailable. We implemented our own rule-based programbased on the descriptions in their paper, to replicate thesame system to the greatest extent possible. We presenttheir rules below for a target word x for each tag type.AgeIf xs detailed POS is numeral, then apply the rules inTable 4.HospitalIf one of following keywords appeared in x, then mark itas hospital: ?? (a near clinic or hospital), ?? (thisclinic or hospital), or ?? (same clinic or hospital).If xs POS is noun and if detailed POS is not non-au-tonomous word, or if x is either ?, ?, ? or ? (thesesymbols are used for manual de-identification because thedatasets are dummy EHRs), and if suffix of x is one of theTable 3 Detailed results for each privacy type in MedNLP-1 (De-identification task)<a > age <x > sex <t > time <h > hospital nameP R F P R F P R F P R FC3 90.32 87.5 88.89 100 100 100 87.16 91.49 89.27 97.30 94.74 96.00B3 90.00 84.38 87.10 100 50.00 66.67 91.30 89.36 90.32 97.06 86.84 91.67B1 93.33 87.5 90.32 100 100 100 90.65 89.36 90.00 89.47 89.47 89.47B2 90.00 84.38 87.10 100 100 100 91.24 88.65 89.93 91.89 89.47 90.67C1 96.67 90.62 93.55 100 50.00 66.67 91.18 87.94 89.53 93.55 76.32 84.06A1 92.86 81.25 86.67 100 50.00 66.67 91.04 86.52 88.73 91.89 89.47 90.67C2 96.67 90.62 93.55 100 50.00 66.67 89.13 87.23 88.17 96.77 78.95 86.96A2 92.86 81.25 86.67 100 50.00 66.67 89.05 86.52 87.77 91.89 89.47 90.67D1 92.31 75.00 82.76 100 50.00 66.67 82.84 78.72 80.73 96.15 65.79 78.12G1 80.65 78.12 79.37 100 50.00 66.67 84.56 81.56 83.03 72.73 63.16 67.61D3 88.89 75.00 81.36 100 50.00 66.67 83.08 76.60 79.70 96.15 65.79 78.12D2 92.31 75.00 82.76 100 50.00 66.67 75.86 78.01 76.92 96.15 65.79 78.12H2 83.87 81.25 82.54 100 100 100 73.79 75.89 74.83 77.78 73.68 75.68H1 80.65 78.12 79.37 100 100 100 75.86 78.01 76.92 70.27 68.42 69.33H3 83.87 81.25 82.54 100 100 100 73.79 75.89 74.83 70.27 68.42 69.33P, R and F were calculated at the phrase level: P, precision; R, recall; F, F1-measure; and A, accuracy. A was calculated in the word level (the agreement ratio of B-*, I-* and O).The first column stands for participants team names, where the first letter stands for a team ID and the second numerical value stands for a submission run ID1https://www.atilika.com/ja/kuromoji/Kajiyama et al. Journal of Biomedical Semantics           (2020) 11:11 Page 5 of 12following keywords, then mark it as hospital:?? (hospitalor clinic),????? (clinic), or?? (clinic).SexIf x is either ?? (man), ?? (woman), men, women,man, woman (in English), then mark it as sex.TimeIf xs detailed POS is numeral and if x consistsof four-digit-numbers+slash+two-or-one-digit-numbers(corresponds to yyyy/mm) or two-or-one-digit-numbers+slash+two-or-one-digit-numbers (corresponds tomm/dd), then mark it as time.Table 4 Rules used for our rule-based method, original Japanese with English translationsOption 1 main rule Option 2?(next)??? two years ago ?? (from)?(before)?? last year ?? (until)???(before hospitalization)?? last month ? (s)???(after hospitalization)?? last week ?? (early)????(after visit)?? yesterday ?? (last)??(a.m.)?? this year -- (from)??(p.m.)?? this month -- (from)????(after onset)?? this week ?? (over)??????(after onset)?? today ?? (under)??????(after care)?? today ?? (from)?? next year ? (when)?? next month ? (about)?? next week ?? (about)?? tomorrow ?? (about)??? the week after next ?? (early)??? day after tomorrow ?? (mid)?? same year ?? (late)?? same month ? (spring)?? same day ? (summer)?? following year ? (fall)?? the next day ? (winter)?? the next morning ? (morning)?? the previous day ? (noon)?? early morning ? (evening)??? after that ? (night)xx? xx (year) ?? (early morning)xx? xx (month) ?? (early morning)xx?? xx (week) ?? (before)xx? xx (day) ?? (after)xx? xx (oclock) ?? (evening)xx? xx (minutes) ?? (about)Kajiyama et al. Journal of Biomedical Semantics           (2020) 11:11 Page 6 of 12If xs detailed POS is numeral and followed by eitherof ? (old), ? (old), or? (s), then mark it as time.If x is followed further by either of ??, ??, ??, ??, ??, ??, ?, ?, ??, ??,??, ????, ????, ???, ????,or ????, then include these words in the span ofthe marked time tag.CRF-based methodWe implemented a CRF-based system because manyparticipants used CRFs in the MedNLP-1 de-identificationtask, including the second-best team and the baselinesystem. The best participant used a rule-based system, asdescribed previously. We used the MALLET2 library forCRF implementation. We defined five training features foreach token3: part-of-speech (POS), detailed POS, charactertype (Hiragana, Katakana, Kanji, or Number), a binaryfeature whether a token is included in our user dictionaryor not, and another binary feature whether a token isbeginning of its sentence or not.LSTM-based methodOur LSTM-based method combines bidirectional LSTM(bi-LSTM) and CRF, using character-based and word-based embeddings (Fig. 1) following earlier work thathad been reported as successful for other languages [16].For word-based embedding, we used the existingWord2Vec [23] model, which was trained using JapaneseWikipedia.4 We used bi-LSTM to embed characters;then we concatenated these two embeddings. Thisconcatenated output was fed to another bi-LSTM andthen sent to a CRF to output IOB tags.Our implementation has been made publicly availablein GitHub.5 Table 5 presents the parameter settings.ResultsExperiment settings and evaluation metricsWe followed the evaluation metrics of the MedNLP-1shared task using IOB2 tagging [24]. We used four-foldcross validation, whereas the rule-based method requiresno training data. We prepared five datasets: MedNLP(MedNLP), dummy EHRs (dummy), pathology reports(pathology), and MedNLP + dummy EHRs (MedNLP +dummy). We also prepared a dataset that comprisesthese three datasets (all). For each dataset, we appliedcross validation. The CRF and LSTM are trained withthree patterns of training data: the target dataset only,one of other datasets only, MedNLP + dummy, and all.Our evaluation uses a strict match of named entityspans, calculating F1-scores, precisions, and recalls.Table 6 presents the evaluation results.Results obtained using the MedNLP datasetIn this MedNLP dataset, the total number of sex is verysmall; that of person is zero. The rule-based system per-formed best in terms of the F1-score because its ruleswere tuned originally to the very MedNLP dataset.LSTM performed best for age and time, probably be-cause these tags exhibit typical patterns of less variation.LSTM is superior to Rule, except for sex and hospital.Regarding sex, we observe better performance whenLSTM uses more training data. Therefore, the data sizeis expected to have been the reason why LSTM was notgood in sex.Results obtained using the dummy EHR datasetLSTM (M + d) performed best in terms of the F1-score.CRF performed better when trained by M+ d datasetthan with the target dataset only. This performance in-crease consists of decrease of age and increase of allother tags, suggesting that these two datasets differ intheir age tag annotation scheme.The overall performance of this dummy EHR datasetis worse than the MedNLP dataset, suggesting that thedummy EHR dataset is more difficult to de-identify.Results obtained using the pathology report datasetThe LSTM-based method was better (81.67) than theCRF-based method (74.26), as shown by the 7.41 pointF1-score when applied to our Pathology Report dataset.Our rule-based system achieved very high recall, butvery low precision scores for time, exhibiting a differenceby 38 points. The pathology reports include many clin-ical inspection values written in an xx/yy format, whichmight engender confusion with dates expressed in anmm/dd format. We applied a workaround to limit[1 < = mm < = 12] and [1 < = dd < = 31], but it was insuf-ficient: we need contextual information, not just rules.In addition, hospital is better than time, with less differ-ence (15 points) of precision and recall.When trained with the Pathology Report dataset only,its performance is better than our rule-based system.When trained with the M+ d dataset, which does notcontain the pathology dataset, neither CRF nor LSTMworks fine because the pathology reports differ greatly interms of their styles of description and named entities.DiscussionThese results suggest that our datasets have quite differ-ent characteristics in what context and in what formtheir named entities appear, but LSTM adapted to thesedifferences well. Adding the Pathological Report dataset2http://mallet.cs.umass.edu/3Hereinafter, token means a morpheme of the Japanese language,which does not have any space between tokens. A morpheme is thesmallest meaningful unit in a language.4http://www.cl.ecei.tohoku.ac.jp/~m~suzuki/jawiki_vector/5https://github.com/johokugskKajiyama et al. Journal of Biomedical Semantics           (2020) 11:11 Page 7 of 12to the training data seems to degrade the system per-formance for other target test datasets because of thedifferent dataset characteristics (examples presented inTable 1). For example, when trained with the Patho-logical Report dataset, the hospital tags of the MedNLPdataset show lower performance because of the differentdescriptions of hospital names among these two data-sets. The Pathological Report dataset has full hospitalnames such as Shizudai Dermatology Clinic, but theother two datasets have more casual descriptions such asFig. 1 Conceptual figure of our LSTM-based model, showing embedding and NER in separate figures. + means concatenation. The first figureshows the embedding part, where Wx is an xth input word, Lx,i is an ith letter of the word Wx, r denotes right to left (forward) LSTM, l denotes leftto right (backward) LSTM, Vx is an intermediate node which corresponds to Wx. The second figure shows the NER part, where fl denotes forwardLSTM, bl denotes backward LSTM, c denotes concatenated vector, finally a CRF layer is shown with an example predicted named entities in theBIO annotation styleTable 5 LSTM parameter settingsWord embedding size 200Character embedding size 100Hidden layer of character 100Hidden layer of LSTM 300Learning rate 0.001Kajiyama et al. Journal of Biomedical Semantics           (2020) 11:11 Page 8 of 12Table 6 Evaluation results for each tag and in total, for different methods (rule, CRF, LSTM) and different evaluation datasets(MedNLP, dummy EHR, and pathology reports). M, d, and P respectively denote training data of MedNLP, dummy EHR, andPathology reports; M + d denotes that training data consist of MedNLP+dummy EHR, all stands for all of these three datasets; othermachine learning methods use the target evaluation dataset as its training data. In each cell, F1-score, precision, and recall areshown (in values multiplied by 100). The best scores for each tag type for each evaluation metric are presented in bold typeface. Allevaluations were done by four-fold cross validationsEvaluation Results on MedNLP datasettag type #of tags scores Rule CRF CRFdCRFPCRFM+ dCRFallLSTM LSTMdLSTMPLSTMM+ dLSTMalltotal 490 F1 84.23 82.62 43.85 0.71 26.40 67.34 83.07 41.26 0.43 67.35 57.03prec 78.90 85.63 46.20 2.50 21.51 66.54 81.33 41.07 0.48 66.98 57.94recall 90.42 79.95 42.33 0.41 59.76 68.38 86.12 41.57 0.38 68.17 56.34age 56 F1 93.43 71.12 30.00 0.00 32.55 53.04 95.83 71.11 0.00 84.72 87.50prec 96.00 78.24 37.50 0.00 26.93 56.85 95.83 71.11 0.00 84.72 87.50recall 91.16 65.47 28.13 0.00 46.05 50.00 95.83 71.11 0.00 84.72 87.50hospital 75 F1 84.73 87.09 43.25 0.00 26.02 70.04 66.67 13.33 13.89 66.67 41.67prec 80.75 93.52 66.67 0.00 20.55 91.67 75.00 11.11 10.67 70.83 45.83recall 89.90 81.71 27.50 0.00 53.06 60.42 62.50 16.67 20.00 63.89 38.89person 0 N/A N/A N/A N/A N/A N/A N/A N/A N/A N/A N/Asex 4 F1 50.00 16.67 16.67 0.00 14.65 25.00 0.00 20.00 0.00 25.00 25.00prec 50.00 25.00 12.50 0.00 8.68 25.00 0.00 20.00 0.00 25.00 25.00recall 50.00 12.50 25.00 0.00 50.00 25.00 0.00 20.00 0.00 25.00 25.00time 355 F1 50.00 16.67 47.43 0.98 14.65 70.57 96.14 67.22 42.98 89.78 82.67prec 50.00 25.00 45.16 2.50 8.68 65.46 95.00 66.26 39.46 88.68 81.53recall 50.00 12.50 50.19 0.61 50.00 76.50 97.41 68.30 47.94 91.00 82.67Evaluation Results on Pathology Report datasettag type #of tags scores Rule CRF CRFMCRFdCRFM+ dCRFallLSTM LSTMMLSTMdLSTMM+ dLSTMallall 71 F1 13.97 74.26 0.00 0.62 1.45 57.63 81.67 0.00 0.00 1.45 81.25prec 8.65 86.72 0.00 1.47 10.00 64.98 86.88 0.00 0.00 10.00 82.48recall 43.33 65.16 0.00 0.39 0.78 54.06 78.84 0.00 0.00 0.78 80.15age 0 N/A N/A N/A N/A N/A N/A N/A N/A N/A N/A N/Ahospital 31 F1 31.19 0.00 0.00 0.00 0.00 0.00 25.00 0.00 13.33 0.00 58.33prec 26.47 0.00 0.00 0.00 0.00 0.00 25.00 0.00 13.33 0.00 58.33recall 41.28 0.00 0.00 0.00 0.000 0.00 25.00 0.00 13.33 0.00 58.33person 224 F1 0.00 91.08 0.00 0.00 6.25 71.31 95.19 0.00 0.00 0.00 95.83prec 0.00 95.83 0.00 0.00 10.00 74.79 95.19 0.00 0.00 0.00 95.83recall 0.00 87.21 0.00 0.00 4.55 69.63 95.19 0.00 0.00 0.00 95.83sex 0 N/A N/A N/A N/A N/A N/A N/A N/A N/A N/A N/Atime 40 F1 9.25 10.57 0.00 2.00 0.00 18.82 25.00 3.81 0.00 6.25 19.44prec 5.25 16.67 0.00 1.79 0.00 20.83 25.00 6.67 0.00 10.00 19.44recall 43.09 9.09 0.00 2.27 0.00 19.32 25.00 2.67 0.00 4.55 19.44Kajiyama et al. Journal of Biomedical Semantics           (2020) 11:11 Page 9 of 12?? (hospital nearby) and ?? (our hospital). ThePathology Report dataset has different contextual pat-terns that could have learned by machine learningmethods such as ???? (ex-hospital sample) imme-diately before hospital tags, and a suffix/prefix such asxx hospital or xx clinic. These words, hospital andclinic, might have been learned as semantically similarby Word2Vec.Another difference of datasets is the coherence of an-notations. We compared the original annotations of thedatasets with our own new annotations created for thisstudy by three annotators. These new annotations werecreated to calculate inter-annotator agreement as de-scribed in the Dataset section. The original versus newinter-annotator agreement (and inter-annotator agree-ment of the three annotators) in average F1-scores were0.566 (0.861), 0.342 (0.761), and 0.772 (0.802), respect-ively, for the MedNLP, Dummy, and Pathology Reportdatasets. As these scores strongly suggest, the originalannotations were insufficiently coherent. By contrast,our new annotations are much more coherent becausewe have included more detailed annotation guidelines.For example, our guidelines include specifications ofprefixes, suffixes and classifiers.. Annotating larger data-sets with this coherent guideline is anticipated as a sub-ject for future work. It is particularly interesting that oursystem performance was better than the inter-annotatoragreement in the Pathology Report dataset. One reasonis expected to be the remaining vague part of the guide-line, such as inclusion of particles when assigning namedentities. We applied the automatic tagger for pre-annotation; then human annotators reviewed the results.However, annotators sometimes overly depend on auto-matically annotated parts-of-speech without consideringthe context and semantics; alternatively, the part-of-speech tagger can simply fail. Therefore, an annotationguideline including precise part-of-speech specificationswill be required.An earlier study that applied a similar LSTM-basedmethod to de-identify English medical data [25] foundlower F1-scores for LOCATION and NAME tags on thei2b2 2014 dataset and MIMIC-III dataset [26], whichincludes records of 61,532 patients in an intensive careunit (ICU); performance of naïve CRF was very low. ThisLOCATION tag corresponds to our hospital tag, exhi-biting similar characteristics among different languages.Table 6 Evaluation results for each tag and in total, for different methods (rule, CRF, LSTM) and different evaluation datasets(MedNLP, dummy EHR, and pathology reports). M, d, and P respectively denote training data of MedNLP, dummy EHR, andPathology reports; M + d denotes that training data consist of MedNLP+dummy EHR, all stands for all of these three datasets; othermachine learning methods use the target evaluation dataset as its training data. In each cell, F1-score, precision, and recall areshown (in values multiplied by 100). The best scores for each tag type for each evaluation metric are presented in bold typeface. Allevaluations were done by four-fold cross validations (Continued)Evaluation Results on Dummy EHR datasettag type #of tags scores Rule CRF CRFMCRFPCRFM+ dCRFallLSTM LSTMMLSTMPLSTMM+ dLSTMalltotal 3017 F1 43.74 66.97 44.01 19.67 67.13 65.79 63.99 20.33 1.60 69.82 68.19prec 42.89 66.77 67.35 56.72 67.60 68.27 68.76 26.68 2.22 72.79 80.26recall 44.75 67.34 33.28 12.34 66.69 63.63 60.20 17.03 1.25 67.24 60.04age 39 F1 51.13 48.46 29.35 0.00 38.87 33.82 50.00 22.38 0.00 50.00 41.67prec 51.97 65.25 28.85 0.00 41.56 35.72 50.00 19.05 0.00 50.00 45.83recall 50.46 53.74 30.00 0.00 36.71 32.50 50.00 32.38 0.00 50.00 41.67hospital 170 F1 15.98 47.85 33.19 0.00 48.62 35.73 22.22 35.79 0.00 40.00 43.33prec 10.07 53.18 38.75 0.00 44.91 35.90 28.33 34.48 0.00 37.50 45.83recall 39.06 43.73 29.42 0.00 53.60 37.81 29.17 37.33 0.00 43.75 41.67person 135 F1 0.00 26.96 0.00 0.00 28.36 15.48 50.00 0.00 0.00 45.83 37.50prec 0.00 26.79 0.00 0.00 29.91 19.64 50.00 0.00 0.00 45.83 37.50recall 0.00 30.71 0.00 0.00 27.99 13.39 50.00 0.00 0.00 45.83 37.50sex 16 F1 93.75 35.92 29.17 0.00 90.08 33.93 0.00 40.00 0.00 50.00 50.00prec 100.0 44.27 50.00 0.00 95.83 50.00 0.00 40.00 0.00 50.00 50.00recall 90.00 43.13 20.83 0.00 85.63 27.08 0.00 40.00 0.00 50.00 50.00time 2657 F1 49.48 71.28 42.14 21.20 70.60 68.33 83.93 51.97 48.89 85.70 88.20prec 51.81 71.44 64.94 59.35 71.24 70.94 84.82 52.59 48.89 86.51 89.24recall 47.38 71.15 32.08 13.58 70.00 66.08 83.29 51.46 48.89 84.93 87.23Kajiyama et al. Journal of Biomedical Semantics           (2020) 11:11 Page 10 of 12The LSTM-based method can be regarded as effective inJapanese medical de-identification tasks as well. If alarger dataset were available, then it would yield betterperformance.Japanese-specific issues include the following difficul-ties: Japanese (and Chinese) have no spaces between to-kens, which makes tokenization much more difficult andambiguous. The number of letter types is much greaterthan in other languages, including tens of thousands ofkanji letters, 50 hiragana letters, 50 katakana letters, nu-merals, and alphabets. The languages also have moresynonyms than in other languages.Our system performance almost reaches to the inter-annotator agreement, which can be regarded as upperbound of system performance. The current performancesare sufficiently high compared to other publicly availableJapanese de-identification tools. Therefore, we plan to applyour system to actual de-identification tasks in hospitals.ConclusionsWe implemented three de-identification methods forJapanese EHRs and applied these methods to three data-sets, which are derived from two dummy EHR sourcesand one real Pathology Report dataset. These datasetshave manually annotated de-identification tags, followingthe MedNLP shared task annotation guideline.Our best F1-scores over all the tag types are 84.23 (rule-based), 68.19 (LSTM), and 81.67 (LSTM) points, respect-ively, for the MedNLP dataset, the dummy EHR dataset,and the Pathology Report dataset. Our LSTM-basedmethod performed best in two datasets, whereas our rule-based method performed best in the MedNLP dataset.However, our LSTM-based method also achieved a goodscore of 83.07 points in the MedNLP dataset, which onlydiffers 1.16 points from the best score of the rule-basedmethod. Our results demonstrate that the bi-LSTM basedmethod with character-embedding and word-embeddingtends to work better than other methods, exhibiting morerobustness than CRF over different data sources. TheLSTM-based method was better than the CRF-basedmethod, exhibiting a 7.41 point F1-score difference whenapplied to our Pathology Report dataset. This report is thefirst describing a study applying this LSTM-based methodto any de-identification task of Japanese EHRs.Machine learning methods can extract named entitiesof de-identification comparable to a rule-based methodthat is tuned manually to specific target data. However,machine learning methods are still less adequate for ap-plication to expressions with low occurrence. Probablybecause of the insufficient data size, our methods yieldedworse evaluation scores than were obtained with theother languages when applied to the i2b2 task andMIMIC-III. Combinations of LSTM and rule-basedmethods are left as a subject for future work.The current performance is sufficiently high amongpublicly available Japanese de-identification tools. There-fore, we plan to apply our system to actual de-identification tasks in hospitals. Although it is still diffi-cult to make real EHRs publicly available, we could useour large amount of EHRs inside our hospitals. Increas-ing the size of annotated datasets for such internal usageis left as another subject for future work.AbbreviationsNLP: natural language processing; LSTM: Long Term Short Memory: a kind ofrecurrent neural network; CRF: Conditional Random Field: a kind of machinelearning method; POS: part-of-speech; EHR: electronic health recordAcknowledgmentsWe wish to thank the Research Center for Medical Bigdata at NationalInstitute of Informatics, Japan, for providing the anonymized pathologyreports. We thank the JP-AID/NII Research Group for their cooperation andfor providing clinical data.Authors contributionsKK designed and implemented all the systems. YK directed the research,especially that related to training and evaluation. TO and HH created thedummy EHRs. MM and YK created the MedNLP task series data. The authorsread and approved the final manuscript.FundingThis work was partially supported by Japanese Health Labour SciencesResearch Grant and JST CREST.Availability of data and materialsThe source code will be made available on the web; datasets will be madepartially available.Ethics approval and consent to participateThe Pathology Reports dataset was used under approval by the ethicscommittee and the research committee of the Japanese Society ofPathology under a research grant from the Japan Agency for MedicalResearch and Development (AMED), Japan Pathology AI Diagnostics Project(JP-AID).Consent for publicationAll the authors have agreed to publication of this manuscript.Competing interestsN/AAuthor details1Faculty of Informatics, Shizuoka University, Johoku 3-5-1, Naka-ku,Hamamatsu, Shizuoka 432-8011, Japan. 2National Hospital OrganizationHeadquaters, 2-5-21 Higashigaoka, Meguro-ku, Tokyo 152-8621, Japan.3National University Corporation Kitami Institute of Technology, 165,Koencho, Kitami, Hokkaido 090-8507, Japan. 4Graduate School ofInterdisciplinary Science and Engineering in Health Systems, OkayamaUniversity, 2-5-1, Kita-ku, Okayama, Okayama 700-8558, Japan.Received: 13 May 2019 Accepted: 7 August 2020RESEARCH Open AccessStructuring, reuse and analysis of electronicdental data using the Oral Health andDisease OntologyWilliam D. Duncan1,2* , Thankam Thyvalikakath2,3, Melissa Haendel4, Carlo Torniai5, Pedro Hernandez6, Mei Song7,Amit Acharya8, Daniel J. Caplan9, Titus Schleyer2,10 and Alan Ruttenberg11AbstractBackground: A key challenge for improving the quality of health care is to be able to use a common framework towork with patient information acquired in any of the health and life science disciplines. Patient informationcollected during dental care exposes many of the challenges that confront a wider scale approach. For example, toimprove the quality of dental care, we must be able to collect and analyze data about dental procedures frommultiple practices. However, a number of challenges make doing so difficult. First, dental electronic health record(EHR) information is often stored in complex relational databases that are poorly documented. Second, there is nota commonly accepted and implemented database schema for dental EHR systems. Third, integrative work thatattempts to bridge dentistry and other settings in healthcare is made difficult by the disconnect betweenrepresentations of medical information within dental and other disciplines EHR systems. As dentistry increasinglyconcerns itself with the general health of a patient, for example in increased efforts to monitor heart health andsystemic disease, the impact of this disconnect becomes more and more severe.To demonstrate how to address these problems, we have developed the open-source Oral Health and DiseaseOntology (OHD) and our instance-based representation as a framework for dental and medical health careinformation. We envision a time when medical record systems use a common data back end that would makeinteroperating trivial and obviate the need for a dedicated messaging framework to move data between systems.The OHD is not yet complete. It includes enough to be useful and to demonstrate how it is constructed. Wedemonstrate its utility in an analysis of longevity of dental restorations. Our first narrow use case provides aprototype, and is intended demonstrate a prospective design for a principled data backend that can be usedconsistently and encompass both dental and medical information in a single framework.(Continued on next page)© The Author(s). 2020 Open Access This article is licensed under a Creative Commons Attribution 4.0 International License,which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you giveappropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate ifchanges were made. The images or other third party material in this article are included in the article's Creative Commonslicence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commonslicence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtainpermission directly from the copyright holder. To view a copy of this licence, visit http://creativecommons.org/licenses/by/4.0/.The Creative Commons Public Domain Dedication waiver (http://creativecommons.org/publicdomain/zero/1.0/) applies to thedata made available in this article, unless otherwise stated in a credit line to the data.* Correspondence: wdduncan@gmail.comTitus Schleyer and Alan Ruttenberg are joint senior authors1National Center for Ontological Research, Buffalo, NY, USA2Center for Biomedical Informatics, Regenstrief institute, Inc., Indianapolis, IN,USAFull list of author information is available at the end of the articleDuncan et al. Journal of Biomedical Semantics            (2020) 11:8 https://doi.org/10.1186/s13326-020-00222-0(Continued from previous page)Results: The OHD contains over 1900 classes and 59 relationships. Most of the classes and relationships wereimported from existing OBO Foundry ontologies. Using the LSW2 (LISP Semantic Web) software library, we translateddata from a dental practices EHR system into a corresponding Web Ontology Language (OWL) representation basedon the OHD framework. The OWL representation was then loaded into a triple store, and as a proof of concept, weaddressed a question of clinical relevance  a survival analysis of the longevity of resin filling restorations. Weprovide queries using SPARQL and statistical analysis code in R to demonstrate how to perform clinical researchusing a framework such as the OHD, and we compare our results with previous studies.Conclusions: This proof-of-concept project translated data from a single practice. By using dental practice data, wedemonstrate that the OHD and the instance-based approach are sufficient to represent data generated in real-world, routine clinical settings. While the OHD is applicable to integration of data from multiple practices withdifferent dental EHR systems, we intend our work to be understood as a prospective design for EHR data storagethat would simplify medical informatics. The system has well-understood semantics because of our use of BFO-based realist ontology and its representation in OWL. The data model is a well-defined web standard.Keywords: Ontology, Dental health, Informatics, Electronic heath record, OWL, SPARQLBackgroundA key challenge for improving the quality of healthcareis to be able to use a common framework to work withpatient information acquired in any of the health and lifescience disciplines. The patient information collectedduring dental care exposes many of the challenges thatconfront a wider scale approach. Within dentistry, a keyaspect for improving the quality of care is the ability tocollect and analyze data about oral health conditionsand procedures, such as the longevity of fillings, the fre-quency of patient checkups, and incidence of tooth loss.Recent reports estimate that 73.8% of solo practitionersand 78.7% of group practitioners in the U.S. use a com-puter to manage some, and 14.3 and 15.9%, respectively,all patient information on a computer [1] . In conse-quence, we now have the opportunity to study dentalhealth services and perform outcomes research usinglarge amounts of secondary data obtained from geo-graphically dispersed dental practices [2].Large secondary datasets could help us more easilystudy diseases in a sizable samples with increased statis-tical power, track patients for an extended period oftime, provide valid and representative samples, supplycorrelates not commonly collected in an oral health set-ting, collect data in real time and ascertain potentialconfounders [2].Analyzing data from electronic health records (EHR),however, presents a number of challenges. First, dentalEHR information is often stored in relational databasesthat are poorly documented and have complex relationsbetween tables. This makes extracting and analyzingdata from even a single practices system difficult. Sec-ond, dental EHR database schemas vary depending onthe vendor who developed the system. This adds diffi-culty when integrating data from multiple practices.Third, information is not always encoded in the sameway. For example, a tooth encoded as number (e.g.,tooth 6) or as a character array in which the index pos-ition of a character represents the tooth (e.g., the Y inthe character array NNNNNYNNNNNNNNNNNNNNNNNNNNNNNNNN represents a right upper sec-ondary canine tooth, i.e., tooth 6). Last, dental EHR sys-tems are typically only loosely specified. So, outside of acommon core of structures for the oral cavity and itsparts, there is wide variation in how information such asspecific types of materials, details of methods, instru-ments, and general patient health is represented. Muchof this information is either semi-or unstructured text.While we focus here on dental EHRs, these same prob-lems are endemic in other EHR systems.To demonstrate how to address some of these problems,we have developed the Oral Health and Disease Ontology(OHD) as a common framework for representing dentalhealth information embedded in a larger framework ad-equate to accommodate structured representation thatgoes beyond that in current dental EHR systems and ex-tends into general medicine. The OHD contains terms forrepresenting anatomical structures (e.g., distal surface oftooth), dental procedures (e.g., tooth extraction), and oralconditions (e.g., caries), as well as relations between terms(e.g., distal surface is part of tooth). The OHDs structureprovides a common representation of the entities thatEHR data is about, without being designed in a way thatunintentionally limits it to only dental health data. Thismakes it possible to use the OHD as framework for inte-grating inhomogeneous data from disparate database sys-tems and support representations for future systems.Using the OHDs terms and relations, information frommultiple dental EHRs can now be translated into OWL 2[3] statements, stored in a semantic database or triplestore, and queried using SPARQL [4] to extract informa-tion for analysis.Duncan et al. Journal of Biomedical Semantics            (2020) 11:8 Page 2 of 19As a proof of concept, we have translated dental EHRdata from a single dental practice, and performed a sur-vival analysis of the longevity of resin filling restorations.The proof of concept demonstrates both aspects of theOHD that are specific to dentistry (e.g. teeth, restora-tions and other procedures) as well as aspects that wouldremain unchanged in a general medical context, such asdemographic correlates. The output of this analysis isdiscussed in the Results section. In the Discussion sec-tion we describe the potential for wider application.Related workThe work in this paper expands upon previous work de-veloping the OHD [5, 6], and provides a more detailedexplication of the OHDs structure. It differs from previ-ous ontology work, such as PeriO [7] and BigMouth [8],in two respects.First, it focuses on the domain of dental anatomy andprocedures rather than genomic information. Second,the OHDs use of the Basic Formal Ontology and Ontol-ogy of Biomedical Investigations as an upper-levelframework sets the stage for seamlessly extending it togeneral medical information. Moreover, the OHD is nota data repository, such as BigMouth [8], but a semanticframework for representing data that may be used in thedesign of repositories  such as our semantictechnology-based repository of information translatedfrom (for now) a single dental practice.We considered using SNOMED and its dental subsetSNODENT, but there are problems that make thesestandards, at the moment, unusable for our purposes.First, their licenses restrict modification of substantialparts of the standard. This prevents us from reorganiz-ing content according to realist principles, adding defini-tions, or adding or correcting axioms. Not all countrieslicense to use SNOMED, and this would prevent ourwork from being replicable worldwide.Second, there are serious quality issues withSNOMED, and SNODENT in particular [9]. A majorissue is the question of ontological commitment  whatterms mean. The vast majority of terms in SNODENTand SNOMED come without textual definitions [10],and the question of what SNOMED terms actually rep-resent is still up for debate.Third, use of these terminologies typically is within alayered framework that brings unnecessarily complica-tion [11]. In common usage these resources are boundto data models of medical records [12]. That means thatone needs to separately understand the data models andthe ontology. By contrast, in our approach the ingredi-ents for a representation are simple  an OWL ontologyand high-quality SPARQL, OWL and RDF W3C specifi-cations. Those logic-based specifications are substan-tially clearer than HL7 specifications.The Open Biological and Biomedical Ontology (OBO)Foundry approach is to have, for any given class, a singleidentifier, if necessary coordinating with developers ofother ontologies. The realism-based approach empha-sizes that classes are collections of instances, that the in-stances are things in the world, and that documentationshould make clear what those instances are. The OHDand the semantic technologies used to implement theontology make it relatively easy to merge data. The datais just added together, untransformed. It is possible todo this, in theory, because all parts of the representationare clearly understood, the types of entities are shared,and the choice to represent particulars using the stand-ard methods provided by semantic web standards allowfor little creativity in how concrete representations areconstructed. Because our focus is on showing how a uni-fied representation system works, we consider out ofscope general methods for harmonizing or interchangingdata with different representations, as is the focus ofHL7.Recently, authors AR and WD have started participat-ing in the review and development of SNODENT. It isentirely possible that in the future that SNOMED andSNODENT might be used in the same manner that weuse OHD here. The OHD and the source code used fortranslation and analysis are available in full at https://github.com/oral-health-and-disease-ontologies/ohd-ontology and in part in the Additional file 1.MethodsOntology developmentThe OHD was developed in a collaborative effort be-tween dental researchers, practicing dentists, statisti-cians, informatics experts, and ontologists. Our first taskwas to identify which dental entities would be repre-sented. To guide this process, we developed a set of re-search questions. For example, for the research question,What is the time from one restoration to its replace-ment on the same tooth?, we determined that we wouldneed to represent restoration procedures, the dates ofthe procedures, patients, patients teeth, surfaces ofteeth, and the restoration materials used to restore teeth.We provide the list of driving research questions inAdditional file 1.Once our domain of focus was identified, our nextstep was to catalog the terms1 we would need in theontology. We imported the Basic Formal Ontology(BFO) and the Ontology for General Medical Science(OGMS) as a whole and otherwise extracted terms fromexisting OBO Foundry ontologies that represented en-tities relevant to our dental health domain using custom1In this paper, we use the word term as a unique natural languageexpression for a class, instance, or relation in our ontology.Duncan et al. Journal of Biomedical Semantics            (2020) 11:8 Page 3 of 19programs as well as the OntoFox2 web tool [13]. TheOntoFox tool implements the Minimum Information toReference an External Ontology Term (MIREOT)principle [14]. MIREOT is a practice by which one im-ports a selected set of terms from another ontology ra-ther than including the whole ontology, as importing inOWL would do. Where relevant terms were not presentin an existing ontology, we created new terms. Each newterm was assigned an Internationalized Resource Identi-fier (IRI) [15], a human-readable label, a definition ordocumentation, and the name of the terms editor(s).When appropriate, other metadata was included, such asthe reference source for a definition and commentsabout a terms definition such as its rationale, scope, andusage. Throughout the ontology development process,the definitions were reviewed multiple times by teammembers. In the following sections, we discuss themethods for acquiring the necessary terms.Ontology architectureThe OHD is constructed in line with a number of OBOFoundry principles. The OBO Foundry [16] is a collect-ive of ontology developers who are committed to collab-oration and adherence to shared principles. The missionof the OBO Foundry is to develop a family of interoper-able ontologies that are both logically well-formed andscientifically accurate. OBO Foundry principles includeuse of the Basic Formal Ontology (BFO) [17], an upper-level ontology, use of a standard IRI identifier space, re-use, where possible, of other Foundry ontologies, andthe inclusion of a textual and, where feasible, logical def-inition for each class and relation.Ontology reuseThe OHD uses BFO as its upper-level ontology. BFO is de-signed as a domain-independent ontology based on princi-ples of ontological realism [18] As an upper-level ontology,BFO establishes categories such as material entities, pro-cesses, time, space, and realizable entities (properties), as wellas relations among them, such as the relation between a par-ticipant and a process they participate in.We reuse a number of classes and relations from exist-ing OBO Foundry ontologies, such as the FoundationalModel of Anatomy (FMA) [19] and the Ontology forBiomedical Investigations (OBI) [20].This construction methodology serves two purposes.First, it allows us to leverage the experience of the devel-opers of OBO ontologies. Second, adhering to OBOstandards and precedents makes the OHD more easilyinteroperable with other OBO ontologies [16], and thisallows developers to reuse our classes and providefeedback on how to improve the OHD. A summary ofthe reused ontologies is provided in Table 1.Classes from the ontologies listed in Table 1 are thenextended to encompass entities in the oral health do-main. At present, this includes classes for representingteeth and tooth surfaces, dental procedures, patients,providers, restoration materials, dental findings, and bill-ing codes. Each of these classes is discussed in the fol-lowing sections.Anatomical structuresWe use the FMAs classes to represent anatomical struc-tures, such as jaws, teeth, and tooth roots. However, inour initial construction of the OHD, we found that theFMA was not adequate for representing surfaces ofteeth. The FMAs class surface of tooth is used to repre-sent the two-dimensional curved plane that forms theouter boundary of a tooth. This is not suitable for repre-senting the portions of enamel into which restorationmaterial is placed. Thus, we added the class surface en-amel of tooth to represent the portions of enamel thatconstitute a tooths anatomical crown. The need for thisclass was reported to the FMAs curators, and the FMAnow includes the class surface layer of tooth3 to addressthis.Until recently, the FMA was authored in a representa-tion system called Protégé Frames. In order to use itwithin the OBO framework we needed to translate fromthe native frames version to a version that integrateswith OBO ontologies. As part of that translation, classesin FMA were placed as children of the appropriate BFOor OBO classes. Second, we needed to translate theframes expressions [25] to OWL before we could use itwith the other classes OBO classes.2http://ontofox.hegroup.org 3http://purl.org/sig/ont/fma/fma290055 (accessed August 2018)Table 1 Summary of ontology reuse in OHDOntology Classes/relations reused or specializedBasic Formal Ontology (BFO) upper-level ontology used tocoordinate other OBO ontologiesOntology for General MedicalScience (OGMS) [21]health care entities; e.g., patient role,visit, disorderFoundational Model ofAnatomy (FMA)anatomical entities; e.g., jaw, tooth,tooth surfaceOntology for BiomedicalInvestigations (OBI)relations between processes toentities; e.g., restoration procedure hasspecified input some toothInformation Artifact Ontology(IAO) [22]information entities in the dentalhealth care domain; e.g., billing codes,goals of dental proceduresOntology of Medically RelatedSocial Entities (OMRSE) [23]gender of patientCommon Anatomy ReferenceOntology (CARO) [24]male and female organismDuncan et al. Journal of Biomedical Semantics            (2020) 11:8 Page 4 of 19Patients and health care providersA given dental procedure (such as an oral evaluation orrestoration procedure) will minimally involve a patientand the dental health care provider. We define for thepatient and health care provider roles that characterizethe way in which patients and providers participate indental procedures.In BFO, roles are realizable entities which are inturn dependent entities. A dependent entity is onethat cannot exist unless the entity bearing the roleexists. For example, a particular patient role cannotexist unless the organism that bears the role (i.e., thepatient) exists. A role is optional in the sense that anentity may gain or lose a role without its physicalmakeup being changed. For instance, a person maycease to be patient at some practice due to the prac-tice going out of business. The practices going out ofbusiness is an event that is external to the person,and, thus, does not necessitate that the person issomehow physically changed. Roles are realizable inthe sense that their existence can be manifested in acorrelated process. For instance a dental hygienist roleis realized when the hygienist engages in processesrelated to their profession, such as plaque removaland application of fluoride treatment. Roles and otherdependent continuants inhere, or are borne by, mater-ial entities.Employing this distinction between roles and theirbearers, we define the types dental health care providerand human dental patient by first defining the appropri-ate roles for each kind of entity, and then defining pro-viders and patients as being bearers of the roles4:A dental health care provider role is a role thatinheres in a person who is licensed to provide den-tal health care and is realized in a health careprocess.A dental health care provider is a human being whobears a dental health care provider role.A patient role is a role that inheres in a person andis realized by the process of being under the care ofa physician or health care provider. (OGMS)A dental patient role is a patient role that is realizedby the process of being under the care of a dentalhealth care provider.A human dental patient is a human being whobears a dental patient role.In order to define the patients gender, we use the gen-der role types from the Ontology of Medically RelatedSocial Entities (OMRSE). The OMRSE is a realist repre-sentation of medically related social entities developedto cover demographics data and common roles of peoplein healthcare encounters for reuse in the context of theOBO Foundry. The gender role types are defined asfollows:A gender role is a human social role borne by a hu-man being that is realized in behavior which is con-sidered socially appropriate for individuals of aspecific sex in the context of a specific culture.(OMRSE)A female gender role is a gender role borne by a hu-man being that is realized in behavior which is con-sidered socially appropriate for individuals of thefemale sex in the context of the culture in question.(OMRSE)A male gender role is a gender role borne by a hu-man being that is realized in behavior which is con-sidered socially appropriate for individuals of themale sex in the context of the culture in question.(OMRSE)Female and male dental patients are then simply de-fined by relating the patient to the female and male gen-der roles:A female dental patient is a human dental patientwho bears a female gender role.A male dental patient is a human dental patientwho bears a male gender role.Using roles to define patients and dental health careproviders has two advantages. First, because roles areformally defined, they represent the semantics for howan entity participates in a procedure. That is, for a givendental procedure, the patient participant is the entitywhose participation realizes the dental patient role, andthe provider participant is the entity whose participationrealizes the dental health care provider role. In contrast,field names and values in relational databases are purelysyntactic.Second, by using gender roles instead of anatomicalsex to represent male and female dental patients, weallow for the possibility that the gender a patient assignsto himself or herself may differ from the patients ana-tomical sex (at birth), matching the common practice ofrecording patient-reported gender in clinical systems. Inthose cases in which biological sex needs to be4Classes/relations are defined in the OHD unless indicated otherwise.Duncan et al. Journal of Biomedical Semantics            (2020) 11:8 Page 5 of 19represented, the OHD includes CAROs types female or-ganism and male organism:A female organism is a gonochoristic organism thatcan produce female gametes. (CARO)A male organism is a gonochoristic organism thatcan produce male gametes. (CARO)Using these classes, a patients biological sex can thenbe defined according to biological criteria rather thangender selection.Dental proceduresWe define the class dental procedure as a subclass ofOGMS health care encounter class:A health care encounter is a temporally-connectedhealth care process that has as participants anorganization or person realizing the health care pro-vider role and a person realizing the patient role.The health care provider role and patient role arerealized during the health care encounter. (OGMS)A dental procedure is a health care encounter thatrealizes a dental patient role in which the patientundergoes a diagnostic or therapeutic process.As illustrated in Fig. 1, specific dental procedures arethen defined by specializing the dental procedure class.For instance, endodontic procedure, surgical dental pro-cedure, and tooth restoration procedure are defined asfollows:An endodontic procedure is a dental procedure thatis performed on the pulp chamber and/or root canalof a tooth, or a part thereof.A surgical dental procedure is a dental procedure inwhich there is structural alteration of soft tissue orbone in or around the oral cavity by incision ordestruction of tissues or by manipulation with in-struments causing localized alteration or transporta-tion of tissue, including lasers, ultrasound, ionizingradiation, scalpels, probes, and needles.A tooth restoration procedure is dental procedure inwhich either a whole tooth or a part of a tooth is re-placed by dental restoration material in order to re-establish the tooth's anatomical and functional formand function.More specific surgical and restoration procedures arethen defined as subclasses of these terms. For example, anon-exhaustive set of surgical and restorative proceduresdefined in the OHD include:A tooth extraction procedure is a surgical dentalprocedure that removes a tooth from the oral cavity.A crown restoration procedure is a tooth restorationprocedure whereby an artificial crown replaces all orpart of the natural dental crown.A direct restoration procedure is a tooth restorationprocedure in which the dental restoration material isplaced in the tooth via some direct dental materialinsertion process.An indirect restoration procedure is a tooth restor-ation procedure in which the dental restoration ma-terial is placed in the tooth via some dental materialtooth attachment process.An intracoronal restoration procedure is a tooth res-toration procedure in which a dental restoration ma-terial is placed into a site that is located in thecrown of the tooth.A veneer restoration procedure is a tooth restorationprocedure in which a thin layer of material (i.e., aveneer) is placed over one or more surfaces of theFig. 1 A portion of the hierarchy of health care encounters in OHD. Numbers represent the number of direct subclasses for a class, some notshown for reasons of spaceDuncan et al. Journal of Biomedical Semantics            (2020) 11:8 Page 6 of 19tooth for purposes such as improving the aestheticsof the tooth or protecting the tooth's surface fromdamage.Patients and providers are related to dental proceduresusing BFOs has participant and realizes relations. Thehas participant relation is a general way of relating pro-cesses to the entities involved in them. For example, anoral evaluation (minimally) has as participants the pa-tient undergoing the evaluation and the provider doingthe evaluation. The realizes relation holds between aprocess and a realizable entity such as a role. A role isdefined in terms of what bears it, what process realizesit, and the manner in which the bearer participates inthe process. As an example, consider the aforementioneddental patient role and dental health care provider role.When a dental procedure is performed, the procedurerealizes the roles of the patient and provider. The personupon whom the procedure is performed acts (or be-haves) as the dental patient and the person doing theprocedure acts (or behaves) as the provider. In this way,the dental procedure realizes the dental patient role ofthe patient and the dental health care provider role ofthe provider.BFO defines temporal regions and a relation occupiestemporal region that defines the temporal span of aprocess. However, we dont use this representation fortwo reasons. First, there isnt yet an established OBOpractice for specifying concrete dates. Second, the timeof a procedure is recorded only to the granularity of aday. Pending development of representations that ac-commodate these issues, we defined a date property, oc-currence date, that relates a process to an xsd:dateTimesome time during which the process occurred. Anotherdata property birth date was defined to relate a patientto their date of birth.To characterize the way in which a tooth participatesin a specific dental procedure, we define roles that areborne by the tooth and realized in the appropriate corre-sponding procedure. For example, in order to representthat a tooth undergoes a root canal treatment, we specifythat a tooth bears a particular tooth to undergo endodon-tic procedure role and this role is then realized in a par-ticular endodontic procedure.For procedures that involve restorative materials, we de-fine a dental restoration material role that is borne by (i.e.possessed by) the restoration material. The role helps de-fine the material in a domain-neutral way. All gold ismetal, but not all gold is used in dental restorations, justthose that bear the dental restoration material role.This role is then realized by the corresponding restor-ation procedure. For instance, an intracoronal restor-ation procedure (see above) realizes the dentalrestoration material role of the material that is placedinside the crown of the tooth. In procedures that involvea specific kind of material, we use OBIs has_specified_input relation to express that a procedure uses that ma-terial. For example, an amalgam filling restoration is de-fined as follows:An amalgam filling restoration is an intracoronalrestoration procedure that uses amalgam to restorethe tooth.As part of the logical framework of the OHD, we theninclude the axiom that an amalgam filling restorationhas_specified_input some portion of amalgam restor-ation material.Restoration materials, restored teeth, and prostheticsFor dental procedures that involve the use of restorationmaterials (e.g., amalgam), we define the restoration ma-terials in terms of the role the material has in replacingportions of the tooth. In general, dental restoration ma-terial has the role of serving as a prosthetic, that is, thematerial has the role of replacing a missing body part.However, not all prosthetics replace the function of themissing body part, for example, a prosthetic eye cannotsee, although it still functions to maintain the shape ofthe skull near the eyes. To address this, we define theterm functional prosthetic role to represent a prostheticthat performs the function of the replaced body part.Since dental restoration materials perform the functionof parts of the tooth they replace, we define dental res-toration material role as a subtype of functional pros-thetic role:A functional prosthetic role is a prosthetic role thatis realized by activities in which the material entity(bearing the role) is used a manner that is similar tohow the body part that the prosthesis replaceswould be used.A dental restoration material role is a functionalprosthetic role that is borne by a portion of dentalrestoration material and is realized in a tooth restor-ation procedure in which the restoration materialbecomes part of a restored tooth.Functional prosthetic role is not a term that is specificto oral health and so should lie outside the scope of theOHD. Our inclusion of it demonstrates a necessarilypragmatic approach in which we sometimes define gen-eral terms necessary to capture a term within our do-main when they are not yet present in a moreappropriate ontology. In this case, the term would moreproperly belong to OGMS.Duncan et al. Journal of Biomedical Semantics            (2020) 11:8 Page 7 of 19Outright replacements of teeth such as pontics or im-plants also have a functional prosthetic role. We do notconsider, however, restored teeth to be, as a whole, pros-thetic. We introduce the term functional tooth, as theunion of original teeth, restored teeth, and prostheticteeth.The restoration materials themselves are defined as akind of processed material that bears a dental restorationmaterial role:A processed material is a material entity that is cre-ated or changed during material processing. (OBI)A dental restoration material is a processed materialthat bears a dental restoration material role.Specific restoration materials are defined according tothe substance that constitutes them or how they areused. For instance, amalgam dental restoration materialand resin dental restoration material are defined asfollows:A metal dental restoration material is a dental res-toration material that consists mostly of metalatoms.An amalgam dental restoration material is a metalrestoration material that consists of a silver-colored,metallic alloy which is composed of a mixture ofmercury and other metals.A resin dental restoration material is a tooth-colored dental restoration material made from amixture of resin, silica and other materials used indirect restorations.By using the term dental restoration material role todefine dental restoration material, we are then able torelate the restoration materials to the tooth restorationprocess that use these materials by specifying that theprocedure realizes the dental restoration material roleborne by the dental restoration material.Finally, we relate a particular instance of a restor-ation material to the anatomical part it restores usingthe is dental restoration of relation. For example, anamalgam filling procedure that restores the occlusalsurface of the right upper first secondary molar (i.e.,ADA tooth number 3), is represented as an instanceof amalgam dental restoration material that is dentalrestoration of the particular occlusal surface which ispart of the patients tooth 3. We use a relation herebecause of an unusual temporal arrangement: the res-toration material and the tooth surface dont neces-sarily exist at the same time.Dental findingsIn the OHD, we make a clear distinction between infor-mation that is part of the patients medical record, andthe oral condition or treatment referred to by the infor-mation. To represent information, we define the classdental finding as a specialization of OGMSs clinicalfinding class:A clinical finding is a representation that is eitherthe output of a clinical history taking or a physicalexamination or an image finding, or some combin-ation thereof. (OGMS)A dental finding is a clinical finding that is a speci-fied output of a dental exam and is about the oralcavity, maxillofacial area, and/or the adjacent andassociated structures, or their parts, or pathologicalanatomical entities derived from them.We are then able to further specialize dental findingsas needed. For instance, a caries finding that a patienthas caries on some tooth is defined:A caries finding is a dental finding that indicates acarious lesion of a tooth.Findings are related to their targets using IAOs isabout relation. For example, a particular caries findinghas as its target a particular tooth in a patients mouth.This is represented as instance of a caries finding that isabout the patients particular tooth.For representing findings about missing teeth, we werefaced with the issue that, following the principles ofontological realism, one cannot have a finding about anon-existent entity. For instance, if a patient is missinghis right upper first secondary molar (i.e., tooth 5), youcannot have finding about this tooth because there is notooth that is the target of the finding. To address this,we defined a missing tooth finding to be about a patientsmouth, and we made use of the strategy put forth inHoehndorf et al. (2010) to represent anatomical entitiesthat lack a particular part [26]. In brief, Hoehndorf et al.represent such entities by negating the part of relationthat holds between an entity and one of its parts. A ma-ture red blood cell, for example, does not have a nucle-olus. Thus, a red blood cell is formally defined (i.e., =df)as follows:red blood cell =df blood cell and (not has part somenucleus)Extending this strategy to missing teeth findings, weformally define a missing tooth finding as being about amouth (i.e., is about some mouth), and a missing toothDuncan et al. Journal of Biomedical Semantics            (2020) 11:8 Page 8 of 19finding for a particular tooth as being about a dentitionthat lacks a particular tooth. For instance, a missingtooth 5 finding is formally defined as follows:missing tooth 5 finding =df missing tooth finding andis about some (secondary dentition and (not haspart some tooth 5))In natural language, this formal definition is rendered as:A missing tooth 5 finding is a missing tooth findingin which tooth 5 is found to be missing.The missing tooth findings for the other teeth are thendefined using the same approach as a missing tooth 5 find-ing, but with tooth 5 being replaced by the relevant tooth(e.g., missing tooth 6 finding, missing tooth 7 finding, etc.).Billing codesGiven the ubiquity of current dental terminology (CDT)codes in electronic dental record systems, we need torepresent these codes in the OHD. Since CDT codes area kind of information, we defined them as a subclass ofIAOs centrally registered identifier (CRID). A CRID is asymbol that is registered as part of some organization.For example, a social security number is a CRID this isregistered with the Social Security Administration. Simi-larly, CDT codes are registered and developed by theAmerican Dental Association [27], and thus, the currentdental terminology code class is defined as:A current dental terminology code is a centrally regis-tered identifier that is maintained by the American Den-tal Association and used for recording dental servicesprovided. It is typically used on the patient record, andwhen reporting procedures on a paper or electronicsubmission.To date, the OHD contains only a subset of total num-ber of CDT codes, and most of the represented codeslack definitions. This is because current dental termin-ology code subclasses were created by using computerprograms to extract information about CDT codes fromthe relevant ADA documentation [28].Translating dental EHR data into OHD-basedrepresentationsIn parallel with developing the OHDs class hierarchy,we developed methods to programmatically translatedental EHR data into OWL statements. For this, wewrote custom Common Lisp5 programs to extract andtranslate dental EHR data (data source described below)stored using Eaglesoft Dental Practice Management andImaging Software.6 This process consisted of three steps.First, we extracted data from the dental EHR systemusing SQL queries issued by our Common Lisp program.In order to facilitate access to the EHR data, we com-bined several of the Eaglesoft tables into a single tablenamed patient_history. This made queries simpler towrite and understand. That is, instead of having to do anumber of joins across multiple database tables, we werenow able to query just one table. For example, the fol-lowing query extracts data about patients who hadundergone single surface amalgam restorations:SELECT * FROM patient_historyWHERE ada_code LIKE 'D2140'Second, once extracted, the dental EHR data wastranslated into OWL statements about instances of theentities involved using the Lisp Semantic Web Library(LSW) [29], a Common Lisp library whose syntax issimilar to OWLs functional syntax [3]. For example, thefollowing OWL functional syntax statements declarethat a particular individual is an instance of a tooth:Declaration(NamedIndividual(obo:tooth_instance))ClassAssertion(obo:FMA_12516 obo:tooth_instance)In LSW, these statements are written as follows:(declaration (named-individual !obo:tooth_instance))(class-assertion !Tooth@ohd !obo:tooth_instance)7The close affinity of the LSW syntax to the OWLfunctional syntax, as well as its ability to reference clas-ses by name instead of IRI, allows us to write OWLstatements that we can easily understand and evaluate.This is in stark contrast to OWL statements representedas RDF/XML, which are not easily understood byhumans. The output of the Common Lisp program is anumber of OWL files that together contain an OWLrepresentation of the dental EHR data.Third, the OWL files are loaded into a semantic data-base, or triple store, that uses the OHD as the schemafor representing the data. This allows for data to be eas-ily queried and analyzed (discussed in the Results sec-tion). For this project, we used the GraphDB SE version7.2 triple store,8 a semantic database with integrated rea-soning that is built on Semantic Web standards. To ver-ify that data was translated correctly, we ascertained that5We use Armed Bear Common Lisp (https://abcl.org) forimplementation of Common Lisp.6https://www.pattersondental.com/eaglesoft (accessed January 2018)7LSW provides the means to retrieve the IRI for a term using thesyntactic form !<term label>@<ontology label>. In thisexample,!Tooth@ohd retrieves the IRI for the term Tooth (http://purl.obolibrary.org/obo/FMA_12516).8https://ontotext.com/products/graphdb/Duncan et al. Journal of Biomedical Semantics            (2020) 11:8 Page 9 of 19the number of entities in the triple store matched thenumber in the dental EHR relational database. For ex-ample, we queried the number of patients and dentalprocedures in the triple store and compared those re-sults to SQL queries used to extract the same informa-tion from the dental EHR.ResultsSummary of the OHDIn its present state, the OHD contains 1947 classes, and59 relationships. Tables 2 and 3 summarize the sourceof these classes and relations.In the above tables, it is important to point out therelatively low number of new classes and relations cre-ated specifically for the OHD. That is, 192 out of 1947classes and 3 out of 59 relations were specifically devel-oped for the OHD. This high amount of reuse demon-strates the effectiveness of the OBO Foundry principleof having distinct scientific communities develop rigor-ous interoperable ontologies. Without OBO Foundry on-tologies that follow these principles, we would have todraw upon other terminologies, such as SNOMED CT,9that dont provide the same sound basis, clarity, level ofdocumentation, or instance-orientation that character-izes the OHD.Translation of practice dataThe primary data source for this analysis was the rela-tional database from a dental EHR containing de-identified dental records for 7337 patients from a singledental practice spanning the years 19992011. Of thesepatients, approximately 4500 had treatment records. Thepractice used Eaglesoft (Patterson Dental, Effingham,IL), a leading dental EHR system in the U.S. In total, thedatabase contained 232,270 records that pertained to pa-tients dental health history.After receiving IRB approval, we used the methods de-scribed in Section 3.3 to translate the dental EHR datainto OWL. Where there were questions regarding whatcertain data meant, we consulted the vendor of the sys-tem and the practice clinician.The following kinds of procedures were translated: fill-ings, crowns, onlays, inlays, veneers, endodontic proce-dures, surgical extractions, and oral evaluations. Table 4summarizes the resulting number of translatedprocedures:The SPARQL query used to retrieve the number oftranslated procedures is provided in Additional file 1.The translated data were then loaded into a GraphDBSE (version 7.2) triple store using GraphDBs OWL2-RLautomated reasoner. Result sets for analysis were ob-tained by querying the triple store using SPARQL 1.1.A clinical use case: longevity of restorationsAs a proof of concept for using the OHD structured datato analyze dental EHR data we performed an analysis ofthe longevity of tooth restorations. For our study thesteps involved were1. define what would be considered a restorationfailure;Table 2 Summary of number of classes used in the OHDOntology Number of ClassesFoundational Model of Anatomy 1515Oral Health and Disease Ontology 192Current Dental Terminology codes 174Ontology for General Medical Science 74Basic Formal Ontology 32Information Artifact Ontology 14Ontology for Biomedical Investigations 13Common Anatomy Reference Ontology 3Ontology of Medically Related Social Entities 3NCBI Taxon 1Total 1947Table 3 Summary of number of relations used in the OHDOntology Number of RelationsBasic Formal Ontology 38Foundational Model of Anatomy 12Ontology for Biomedical Investigations 5Oral Health and Disease Ontology 3Information Artifact Ontology 1Total 59Table 4 Summary of the number of procedures translated inthe OHDProcedure TotalFillings 22,252Crowns 12,636Onlays 1269Inlays 365Veneers 877Endodontic procedures 1441Tooth extractions 999Oral evaluations 28,566Total 68,4059Systemized Nomenclature of Medicine  Clinical Terms, http://www.snomed.org/ (accessed January 2018).Duncan et al. Journal of Biomedical Semantics            (2020) 11:8 Page 10 of 192. define a set of correlates for the analysis: We lookat patient, gender, age, tooth position and numberof surfaces restored;3. design the queries to extract the relevantinformation;4. prepare the database for the sorts of queries wewould be making; and5. using the R statistics program to run the statisticsand plot curves.Defining restoration failureThere appears to not be a standard approach to studyingrestoration longevity. Prior studies have used a variety ofcriteria to define or categorize failure, and different cor-relates. We describe next a representative set.Bogacki et al. [30] defined failure as replacement of arestoration on the same surface. They censored caseswhere a larger restoration replaced the initial one (e.g., aone-surface restoration replaced by a two-surface restor-ation) or at the last known patient visit. Correlates in-cluded restoration type, prior history, provider andpatient age, tooth location, year of treatment, andwhether the provider changed.Gulambi et al. and Redman et al. [31, 32] categorizedfailures into major and minor based on United StatesPublic Health Services USPHS score, and analyzed majorfailures and total failures separately. Major failures weredefined as restorations that required complete replace-ment. Restorations were censored if there was no otherevent at last follow-up. Correlates included patient gen-der, provider, etiology of tooth wear, material, opposingdentition and incisal relationship.In Janus et al. [33] failure was defined as the tooth be-ing lost due to extraction, or the tooth requiring an add-itional restoration, crown, or other treatment such as anendodontic treatment. Only a single tooth from any pa-tient was chosen to minimize dependence. Restorationswithout further activity were censored as of last date thepatient was seen. Correlates were gender, race, age, site,type of restoration, and whether the initial restorationwas supervised by a specialist. We defined failure similarto Janus et al. A restoration was considered a failure ifthere was a subsequent restoration on any of the sur-faces that were initially restored. Cases were censored ifthere was no failure the last time the patient was seen. Ifthere was no encounter after the restoration, we did in-clude the restoration in our analysis.CorrelatesCorrelates were chosen for relevance and based on theiravailability in our data set. We considered the patientsage at restoration, gender, whether the tooth was anter-ior or posterior, and how many surfaces were initially re-stored. Age was broken into two groups: below andabove 40. When an initial analysis did not find signifi-cance using the exact number of surfaces restored, wechose to group the data into two categories  thosewhere a single surface was restored and those wheremore than one surface was restored.Etiology and condition at time of failure are likely tobe recorded in progress notes, but could not be easilyextracted from our source data. While provider informa-tion was ostensibly recorded, we were told it was notreliable.Database preparationAfter translation, we noted an issue. We had given den-tal visit an occurrence date, but not the processes thatoccurred during visit, such as the exams or restorations.Ideally we would add an OWL property chain has_parto occurrence_date - > occurrence_date, however OWL2only has object property chains. Instead we used aSPARQL Insert command to update this as shown inAdditional file 1.To make queries both efficient and clear we created arelation that linked, in chronological order, each patientencounter. For each patient, next_encounter relates eachencounter to the following encounter with the patient.Note that since encounters may be part of other encoun-ters, and that our time granularity is a day, there may beseveral next encounters after a single one. To create thechain of encounters, we used SPARQLs ability to testwhether a variable is bound in a solution, using thestrategy shown in Fig. 2. We did a query for triples ofevents in order, but we filtered any solutions in whichthe middle encounter was bound.subsequent_encounters is asserted as a transitive super-property of next_encounter, making relatively easy toconstruct queries looking for ordered pairs of type ofprocesses.QueriesThe general schema for the SPARQL queries for pairs ofevents for survival analysis was:?first_event rdf:type <type of restoration>:.<bind tooth and surface>?first_event subsequent_encounter: ?later_event.<constrain second event>?later_event occurrence_date ?date.<bind survival analysis correlates>Filter for minimal ?date of ?later_eventTable 5 lists the kinds of failures and conditions thatwere used as second events. A query retrievingrestorations whose second event is one of the fourconditions is captured in the query in Additional file 1.All queries returned information solely aboutsecondary teeth. Out first query retrieved the date of theDuncan et al. Journal of Biomedical Semantics            (2020) 11:8 Page 11 of 19restoration as well as the date of the last recordedencounter with the patient, the latter used as right-censored events in the survival analysis when there wasno recorded failure. In that case the constraint on thelater event is that there is no subsequent event, i.e. thereis no subsequent_encounter relation. When a restorationwas placed during the last patient visit on record, it wasnot included in the analysis.Table 5 Failure event type and constraintType of second event Second event constraintRestoration or inlay Same tooth and surfaceEndodontic procedure Same toothCrown replacement Same toothExtraction Same toothLast recorded encounter No later encounterFig. 2 Illustration showing instances used in representation of a two-surface resin restoration. Each box is an OWL individual. Arrows indicate therelations among the individuals, and box shape indicates the upper level BFO universal which it instantiates. In some cases, a proximatesuperclass is listed after a dash. In other cases, the label until the instance number or of names the proximate class. Where of is used it indicatesa functional relation. Underlined dates are data valuesDuncan et al. Journal of Biomedical Semantics            (2020) 11:8 Page 12 of 19The second query looked for pairs of restorations andfailures. The target restoration type here was resin fillingrestoration, and we considered as failure either arestoration or inlay on any surface of the firstrestoration, or replacement by a crown, or an extractionof the tooth, or an endodontic procedure on the tooth.It should be noted that we did not need to use anexplicit list of dental codes for our query, as iscommonly the case. Instead the dental procedurehierarchy provides us the ability to query all instancesof, e.g., endodontic procedures and its subclasses.Should they be necessary, queries can still be made interms of CDT codes since axioms relate CDT codes towhat they are about.Statistical analysisOur dataset included 13,922 resin restorations, of which12,704 had follow up. Table 6 provides a breakdown ofthe events by correlate, giving, for each group thenumber of patients, the number of events (failures +censored) and the number of failures.For analysis we used the R packages survival [34],simPH [35], and ggsurv from GGally [36] for theKaplan-Meier plots. The muhaz [37] package was usedto compute the hazard function. With a cutoff of .05 forp-value all correlates, all were statistically significant.Table 7 shows p value and relative hazard for significantcorrelates.Figure 3 shows Kaplan-Meier curves for overalllongevity and comparison curves for each correlate.Grayed area are 95% confidence intervals. Mediansurvival, overall, is somewhere in the range of 12years, falling to 10.5 years median survival for thoseolder than 40. Our results on longevity mostresemble Bogackiet et al. [30]. They dont seem toconcord with Redman et al. who found mediansurvival to be substantially less at under 5 years [31].The hazard rate was plotted once it was determinedthat there was a surfeit of early failures. The plot clearlyshows this with elevated hazard in the first 2 years. Codeto perform the analysis is available at https://github.com/oral-health-and-disease-ontologies/ohd-ontology/blob/master/src/analysis/survival.r.DiscussionWe have outlined the principles used to create the OHDclasses and relations, and discussed how data translatedinto OWL can be queried and analyzed. While therehave been recent efforts to use instance data in a clinicalsetting [38], this work represents the first example ofend-to-end use of BFO and OBO-ontology structuredinstance data for clinical research in healthcare. By usingpractice data and demonstrating how to answer a clinicalresearch question, we have demonstrated that the ap-proach is practical with current technology.Along the way to implementation we were faced witha number of situations where existing ontologies alonewere inadequate or where choices of how to use themwere not obvious. We chose to represent CDT codes asinformation artifacts beside, so to speak, representationsof the processes those codes refer to, to make room for,but not tie us to, a single coding system.The treatment of time in current OBO OWLontologies is inadequate [39]. In different cases wevariously ignored it, addressed it with an alternateontology pattern, or used a workaround. We use the ispart of relation without a time index despite BFOs partrelation being time-dependent. A common error inrepresenting processes is to define them in terms of par-ticipants having certain roles. The has role relationshould also be time-indexed and, importantly, entitieswith roles can and do participate in processes wherethose roles are not relevant. We use the role-realizationpattern to clearly relate roles, when they are relevant, toa process and this has an added benefit of having correcttemporal scope without specifying a time index. Our useof occurrence date is a workaround for the lack of a wayof specifying concrete times and also makes a choiceabout temporal granularity, something else not clearlyaddressed in current OBO.We needed to work with natural, restored and prostheticteeth. Anatomy ontologies are typically canonical, and so donot address these cases. There have been various efforts toaddress this, for example in understanding how non-canonical phenotypes relate to anatomy [40]. Here, we intro-duced a representation of prosthetics and introduced theTable 6 Breakdown by correlate of events for survival analysisCorrelate No. Patients No. Events No. FailuresGender female 1441 7114 1358Gender male 1117 5590 1251Anterior tooth 1195 3692 989Posterior Tooth 2234 9012 1620Age < 40 1082 5159 824Age over 40 1545 7545 1785Single surface 2016 6216 1346Multiple surface 2021 6488 1263Table 7 Significant correlates significance and effect sizeCorrelate p Hazard differenceposterior vs anterior <.001 23% decreaseMale vs female <.001 16% increaseAge 40+ vs < 40 <.001 40% increasemultiple vs single surface 0.0019 12% decreaseDuncan et al. Journal of Biomedical Semantics            (2020) 11:8 Page 13 of 19term functional tooth, to capture the necessary distinctions.Some of the terms are not specific to our domain and wehave proposed they be added to OGMS.It was not clear at the start how to have performantqueries that retrieved pairs of related encounters such asone in which a restoration is done and a later onerequiring a root canal because the first failed. Creatingthe next_encounter and subsequent_encounter relationsand using them for such queries proved to be effective,both computationally and cognitively.Ontologies sometimes did not have terms in theirdomain that we needed. While the FMA is incrediblydetailed, we discovered it did not give us arepresentation of the substantial (as opposed to two-dimensional) surface of teeth. We created the necessaryterms and worked with the developers of the FMA tohave them added, a success for the collaborative ap-proach espoused by the OBO Foundry.We see five benefits of the approach we used. Thefirst, which can be easily overlooked, is that building theOHD aided in understanding the domain and data byforcing us to use unambiguous terms. As an example,consider the term restoration. Depending on thecontext, a practitioner may mean the process ofrestoring a tooth or the material used to restore a tooth.These two uses of restoration are interrelated: Theprocess of restoring a tooth requires the use ofrestoration material. However, the process and thematerial are distinct types of entities.The second benefit is that we are not reliant upon aparticular coding system, but can still use one or moreeffectively. For instance, in the United States, teeth aredenoted according to the Universal Tooth NumberingSystem [41], which uses the numbers 132 forpermanent teeth and the letters A-T for primary teeth.But, other countries use the World Health Organization(WHO) notation system, which denotes teeth usingcombination of numbers to represent the quadrant ofthe mouth and the tooths position in the quadrant. TheOHD, in contrast, represents teeth using anatomicalclasses from the FMA. For example, the OHD representsa patients upper right wisdom tooth using the FMAclass Right upper third secondary molar tooth, which isalso denoted as 1 in the Universal Tooth NumberingSystem and 18 in the WHO system. Thus, differenttooth coding systems can be mapped to the same FMAclass. Similarly, whereas dental representations often useCDT codes, which also are used for billing, the OHDrepresents types of procedures and codes separately.When multiple codes are meant to refer to the samething, their meeting point can be, for example, a singleprocess type.The third benefit of our approach is that using theOHD allows for queries that leverage the logicalstructure of the ontology. Two examples of this arehierarchical queries and relational queries.By design, an ontology behaves such that if you queryfor instances of a class, instances which are only assertedto be of a subclass (or child class) are queried for aswell. That is because they are inferred to also be theparent type. For example, consider a query to retrieve allcrown procedures. Using the OHD, this query isstraightforward10:select (count(distinct ?procedure) as ?total_crowns)where { ?procedure rdf:type crown_procedure: }However, to do this in a relational database usingADA billing codes alone, you have to account for atleast 40 billing codes.11In addition to hierarchical queries, the OHD permitsqueries that make effective use of the relations betweenentities. For example, in the OHD, we specify that atooth restoration procedure must include restorationmaterial during the process. This permits us to query forall procedures that use a specific restoration materialinstead of having to recall which materials are denotedFig. 3 Construction of the next encounter relation10The prefix definitions have been excluded. The full query is given inAdditional file 1.11The exact number of billing codes needed depends on the version ofADA codes used.Duncan et al. Journal of Biomedical Semantics            (2020) 11:8 Page 14 of 19by ADA codes. The query below leverages the OHDspecification to find the number of restorationprocedures using resin broken down by the type ofprocedure.12 The result of this query is summarized inTable 8.select ?procedure_name (count(?procedure_type) as?total) where {?material_instance rdf:type resin: .?procedure_type rdfs:subClassOf dental_procedure: .?procedure asserted_type: ?procedure_type .?procedure has_participant: ?material_instance .?procedure_type rdfs:label ?procedure_name .} group by ?procedure_nameorder by desc(?total)The fourth benefit is easy generalization to wider domainsof medicine and clinical research, and is conferred by ourextensive use of instances and types. Consider therepresentation in Fig. 4. This representation contrasts withtypical representations from relational databases in that itmore explicitly tracks what happens and include typeinformation making it easier to discover and understandcontents. For example, the situation represented in Fig. 4might be represented in a single row in a relational database.PrimarykeyProvideridPatientidToothno.Surfaces CDTCodeXXXXX 21 17 19 MO D2392The relational representation provides economy ofspace and may be suitable for a self-contained applica-tion. However, this representation makes it difficultwhen it comes to integration in either a data warehouseor a system which records information that goes beyonddentistry. Information needed to interpret it, if evenavailable, typically lies outside the representation. Profes-sionals charged with integrating or querying such dataare typically not domain experts. For example, a personwho needs to understand the representation needs tounderstand that each letter in the surface column repre-sents one surface and find a reference for the letteringsystem. In addition, the representation provides littleguidance about how one might go about representingthe information in a way compatible with more generalmedical information about a patient. For example, theprovider id implicitly identifies a dentist. In a more gen-eral setting, there are a wide variety of types of providersand this information must be made explicit.By comparison, the representation in Fig. 4 might appearat first glance to be overkill. However, it has two importantqualities. First, it is easier to generalize to general medicine the same schema can easily accommodate procedures ofany sort, by providers of any sorts, on parts of the anatomyof any sort. Second, because it creates instances for theentities it removes ambiguities that might hinder carefulclinical analyses, a problem identified and addressed in thestrategy of referent tracking [42]. With this representationone can easily track the particular material used in a fillingeven when the filling is redone after failure or refer to thespecific usage of this CDT code in context, for example inan audit.The final benefit of our approach is that it allows us touse automated reasoning to infer information. That is,automated reasoners can use OHDs axiomatic definitionsto infer relations between entities that were not explicitlystated as being related. Two examples of this are theOHDs use of transitive relations and the functional toothclass. A transitive relation is a relation where if tworelationships have a common element that is object of thefirst relation and subject of the other, then the respectivesubject and object of those relations are also related. Forinstance, in mathematics the < (less than) operator istransitive. Given that 5 < 6 and 6 < 10, you are licensed toinfer that 5 < 10. In the OHD, we define the is part of astransitive, and use it relate a tooths surface to its toothand a tooth to a patient. Using these relations betweensurface and tooth, and between tooth and patient, we cannow easily query for patients tooth surfaces as follows13:select ?surface ?patient where {?patient rdf:type patient: .?surface rdf:type tooth_surface:; is_part_of:?patient . }In this query, the parthood relation between the toothsurface and patient is inferred, and not explicitly statedin the translated data.In the OHD, a functional tooth is defined to be either anatural tooth, a restored tooth, or a prosthetic tooth. ThisTable 8 Summary of the number of restoration proceduresusing resinProcedure Name Totalresin filling restoration 13,860resin laminate veneer restoration 135resin inlay restoration 13resin onlay restoration 11resin with predominantly base metal crown restorationprocedure2resin crown restoration procedure 1stainless steel with resin window crown restoration procedure 112The full query is provided in Additional file 1. 13The full query and results are provided in Additional file 1.Duncan et al. Journal of Biomedical Semantics            (2020) 11:8 Page 15 of 19Fig. 4 a-e: Survival plots f: Hazard rateDuncan et al. Journal of Biomedical Semantics            (2020) 11:8 Page 16 of 19allows us to easily query for all restoration proceduresperformed on a tooth regardless of whether the tooth isnatural or an implant. However, when translating the data,we do not explicitly state that a tooth or implant is afunctional tooth. Rather, we define the axioms that specifythe necessary and sufficient conditions for being afunctional tooth and let the automated reasoner do thework of classifying the instances. Our reason for classifyingan instance of functional tooth in this manner is that as thenumber of classes to which an instance can belong grows,the complexity of the ontology increases, which likewiseincreases the chance for misclassifying an instance. Byoffloading this task to the automated reasoner, we reducethe chance of introducing human error into the process ofclassifying instances of functional tooth.Conclusions & future workOur goal of developing the OHD was to leverage semanticweb standards to provide a common representation of thedental health care domain that exercises good ontologypractices and can be generalized to general medicine. Indoing this, we reused classes from OBO Foundryontologies when possible. The advantage benefit from thiswas twofold. First, we were able to effectively leverage workdone by others within the OBO community. Second, wewere then able to improve on the OBO ontologies whenwe found cases that were not yet represented, for instancethe surface enamel of tooth class that was added to theFMA as a result of our work. This has the added benefit ofenriching the OBO Foundry community in general.We only translated data from one practice, and whileour purpose was not to design a data integrationpipeline, building such a pipeline was necessary in orderto have data for analysis. Our translation method can beapplied to other practices with different dental EHRsystems, and efforts are currently under way to integratedata from 99 geographically dispersed dental practicesusing the OHD. One notable consideration to ourapproach is that in order to translate dental EHRrecords, one must learn the intricacies of the dentalEHR database schema. We had the advantage of havingan open line of communication with Eaglesoft, thepractices dental EHR vendor, but researchers wishing toadopt the OHD might not have this advantage. Thus,further work needs to be done on how to communicatethe necessary steps needed to query a vendors databaseto those who do not have contact with the vendor andto advocate that new systems use an ontology-basedrepresentation.Our use cases for this project primarily focused therepresentation of tooth restorations (e.g., fillings andcrowns), and dental procedures or conditions that wouldindicate a tooth restoration had failed. We recognizethat there are number of other procedures andconditions that need to be represented. Therepresentation of these other entities is part of ourongoing work, as is the application of the methodologyin the wider medical arena. The OHD and examples oftranslation code are available at https://github.com/oral-health-and-disease-ontologies/ohd-ontology.Finally, the OHD only contains a subset of CDTcodes. A more complete and formal representation ofthem and other coding systems relevant to oral health,such as SNO-DDS [43], remains future work.Supplementary informationSupplementary information accompanies this paper at https://doi.org/10.1186/s13326-020-00222-0.Additional file 1: Appendix A. Research questions used in developingthe OHD. Appendix B. Relate all questions to patient gender and age.SPARQL count by procedure query. Appendix C. SPARQL Constructpropagating occurrence date. Appendix D. SPARQL Query for patientsage at first dental encounter. Appendix E. Query to retrieve the totalnumber of crown restoration procedures. Appendix F. Query to retrieverestoration procedures that use resin. Appendix G. Query to retrievetooth surfaces and patients. Appendix H. Query to retrieve resinrestorations and failures.AbbreviationsBFO: Basic Formal Ontology; CARO: Common Anatomy Reference Ontology;CDT: Current Dental Terminology; EHR: Electronic Health Record;FMA: Foundational Model of Anatomy; IAO: Information Artifact Ontology;LSW2: LISP Semantic Web version 2; OBI: Ontology for BiomedicalInvestigations; OBO Foundry: Open Biological and Biomedical OntologyFoundry; OHD: Oral Health and Disease Ontology; OMRSE: Ontology ofMedically Related Social Entities; OWL: Web Ontology Language;RDF: Resource Description Framework; RDF/XML: RDF statementsrepresented using XML syntax; SPARQL: SPARQL Protocol and RDF QueryLanguage; SQL: Structured Query Language; XML: Extensible MarkupLanguageAcknowledgementsWe wish to thank Mantilla Rodriguez, Andres Alfredo and Werner Ceustersfor their assistance in editing this manuscript, Ted Fruchtl and Jim Garrett ofEaglesoft for their help in understanding the database structure, and thedental health provider who donated the data for this project.Availability of data and materialThe OHD, SPARQL queries, LSW2 source code for generating the OWLfiles, and R code executing the statistical analysis are available onGitHub: https://github.com/oral-health-and-disease-ontologies/ohd-ontology. The OHD is located in the src/ontology directory. The LSW2code is in the r21-study directory. The SPARQL queries and R code is inthe analysis directory.The data used to generate the OWL files is not available for download.Making such data publicly available would violate the study protocol. Weare, however, considering construction of a synthetic data set to enableexperimentation.Authors contributionsWDD composed, edited, and revised the manuscript, and served as the leaddeveloper for the OHD. AR edited the manuscript, performed the statisticalanalysis for, and wrote the section describing, the restoration longevity usecase. TPT, PH, MH, CT, MS, AA, and DC were instrumental in thedevelopment of the OHD and understanding dental health data. TS and ARdirected the work. The author(s) read and approved the final manuscript.Duncan et al. Journal of Biomedical Semantics            (2020) 11:8 Page 17 of 19FundingWe gratefully acknowledge support from National Institute of Dental andCraniofacial Research (NIDCR) grants R21-DE-19683, R21-DE-21178, and R03-DE-023358; the Lilly Endowment, Inc. Physician Scientist Initiative; the ClemMacDonald chair account; and start-up funds provided by the School ofDental Medicine, University at Buffalo.Ethics approval and consent to participateResearch for this study was conducted in accordance with Indiana UniversityIRB Protocol 1506009585 and University of Pittsburg IRB ProtocolPRO11040275. All data used was completely deidentified before delivery toinvestigators.Consent for publicationNot applicableCompeting interestsThe authors declare that they have no competing interests.Author details1National Center for Ontological Research, Buffalo, NY, USA. 2Center forBiomedical Informatics, Regenstrief institute, Inc., Indianapolis, IN, USA.3Dental Informatics Core, Indiana University School of Dentistry, Indianapolis,IN, USA. 4Translational and Integrative Sciences Lab, Oregon State University,Corvallis, OR, USA. 5Domino Data Lab, San Francisco, CA, USA. 6RepartoUniversitario, San Juan, PR, USA. 7Magee-Womens Research Institute,Pittsburgh, PA, USA. 8Marshfield Clinic Research Institute, Marshfield, WI, USA.9University of Iowa College of Dentistry, Iowa City, IA, USA. 10IndianaUniversity School of Medicine, Indianapolis, IN, USA. 11School of DentalMedicine, State University of New York at Buffalo, Buffalo, NY, USA.Received: 23 September 2018 Accepted: 9 June 2020RESEARCH Open AccessAn integrative knowledge graph for rarediseases, derived from the Genetic andRare Diseases Information Center (GARD)Qian Zhu1* , Dac-Trung Nguyen1, Ivan Grishagin1, Noel Southall1, Eric Sid2 and Anne Pariser2AbstractBackground: The Genetic and Rare Diseases (GARD) Information Center was established by the National Institutesof Health (NIH) to provide freely accessible consumer health information on over 6500 genetic and rare diseases. Asthe cumulative scientific understanding and underlying evidence for these diseases have expanded over time,existing practices to generate knowledge from these publications and resources have not been able to keep pace.Through determining the applicability of computational approaches to enhance or replace manual curation tasks,we aim to both improve the sustainability and relevance of consumer health information, but also to develop afoundational database, from which translational science researchers may start to unravel disease characteristics thatare vital to the research process.Results: We developed a meta-ontology based integrative knowledge graph for rare diseases in Neo4j. Thisintegrative knowledge graph includes a total of 3,819,623 nodes and 84,223,681 relations from 34 differentbiomedical data resources, including curated drug and rare disease associations. Semi-automatic mappings weregenerated for 2154 unique FDA orphan designations to 776 unique GARD diseases, and 3322 unique FDAdesignated drugs to UNII, as well as 180,363 associations between drug and indication from Inxight Drugs, whichwere integrated into the knowledge graph. We conducted four case studies to demonstrate the capabilities of thisintegrative knowledge graph in accelerating the curation of scientific understanding on rare diseases through thegeneration of disease mappings/profiles and pathogenesis associations.Conclusions: By integrating well-established database resources, we developed an integrative knowledge graphcontaining a large volume of biomedical and research data. Demonstration of several immediate use cases andlimitations of this process reveal both the potential feasibility and barriers of utilizing graph-based resources andapproaches to support their use by providers of consumer health information, such as GARD, that may strugglewith the needs of maintaining knowledge reliant on an evolving and growing evidence-base. Finally, the successfulintegration of these datasets into a freely accessible knowledge graph highlights an opportunity to take atranslational science view on the field of rare diseases by enabling researchers to identify disease characteristics,which may play a role in the translation of discover across different research domains.Keywords: GARD, Rare diseases, Ontology, Data integration, Knowledge graph© The Author(s). 2020 Open Access This article is licensed under a Creative Commons Attribution 4.0 International License,which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you giveappropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate ifchanges were made. The images or other third party material in this article are included in the article's Creative Commonslicence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commonslicence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtainpermission directly from the copyright holder. To view a copy of this licence, visit http://creativecommons.org/licenses/by/4.0/.The Creative Commons Public Domain Dedication waiver (http://creativecommons.org/publicdomain/zero/1.0/) applies to thedata made available in this article, unless otherwise stated in a credit line to the data.* Correspondence: qian.zhu@nih.govQian Zhu and Dac-Trung Nguyen contributed equally to this work.1Division of Pre-Clinical Innovation, National Center for AdvancingTranslational Sciences (NCATS), National Institutes of Health (NIH), Rockville,MD 20850, USAFull list of author information is available at the end of the articleZhu et al. Journal of Biomedical Semantics           (2020) 11:13 https://doi.org/10.1186/s13326-020-00232-yIntroductionAn estimated 30 million people in the United States areaffected by a rare disease, which is defined as a diseasethat affects fewer than 200,000 individuals in the UnitedStates [1]. The majority of rare disease are thought tohave a genetic etiology [2] with studies reporting themresponsible for almost 10% of adult and 30% of pediatrichospitalizations [3]. Despite the great heterogeneity ofdiseases included in this definition, many patients andtheir families share in common struggles, such as withdiagnostic delay leading to an average of 7.6 years frominitial onset of symptoms to receiving a diagnosis andrequiring the involvement of 7.3 physicians on average[4]. These shared challenges faced in the broader raredisease patient community are often due to a lack ofeither up-to-date information or awareness amongstproviders and the public at large. Efforts to tackle theseissues led to the passage of the Rare Disease Act of 2002and the establishment of several programs by theNational Institutes of Health (NIH) to improve researchactivities and public access to information on rare dis-eases. In particular, the Genetic and Rare Diseases(GARD) information center was charged with providingfreely accessible consumer health information in plainlanguage, and it has been investigating the challenge ofshifting from an entirely manual process to leveragingcomputational approaches to curate the accumulatedbiomedical and clinical research knowledge of over 6500rare diseases, and more rapidly make information ac-cessible 1) to educate patients, families, and health careproviders with more accurate and real-time knowledgeabout a rare disease, and 2) to support novel scientificresearch efforts and apply disease-agnostic translationalscience approaches to the field of rare diseases as awhole [5].Given the pace of ongoing scientific discovery, parsingthrough the accumulated research publications andconveying this knowledge in a plain language format ac-cessible to low-health literacy audiences presents a sig-nificant task for a single disease, let alone for over 6500rare diseases. Thus, a huge amount of effort to accumu-late and curate data for rare diseases has been made glo-bally. For instance, the GARD Information Centerprovides interpretable profiles in plain language for eachrare disease [5]; Orphanet focuses on expert manual cur-ation of a diseases clinical presentation [6]; and OnlineMendelian Inheritance in Man® (OMIM®) conducts asimilar expert-driven focus on defining genotype andphenotype relationships [7]. The discreteness of suchheterogeneous data, however, impedes their direct usefor consumer audiences. To overcome this barrier, inthis study, we integrated these well-known resources inone knowledge graph to semantically interconnect alldata together by means of the data points as nodes andtheir relationships as edges, as a first step in bridging theuse of these resources in consumer-facing healthinformation.Biomedical data integration is an important and tech-nical approach to tackling biomedical problems. Currentprogress in computational technology allows vast datastorages and powerful computational processes to bemore affordable and accessible. As a result, biomedicalscientists have gradually gained an awareness of the im-portance of pooling diverse types of data pertaining to aspecific medical entity to enhance their research under-standing [8]. Representing integrative data in the form ofa graph has attracted many interests, particularly in thebiomedical domain. Karczewski K, et al. have reviewedand discussed the potential and usage and challenges ofintegrating diverse types of omics data for human healthand disease [9]. Biomedical Informatics Research Net-work (BIRN) is an integrative resource by semanticallyintegrating data produced by multiple institutions fordata analysis on Neurosciences [10]. Similar efforts havealso begun to emerge with applications directed at thefield in rare disease, such as the semantic Diseasecard,which integrates rare disease data from distinct sourcesin a semantic web environment [11]. A similar EU plat-form, RD-Connect connects databases, registries, bio-banks and clinical bioinformatics to support research indiscovering new genes, biomarkers, and therapeutictargets more quickly and efficiently [12]. The MonarchInitiative as another analytic platform, semantically inte-grates genotype and phenotype data across differing spe-cies and sources [13], and has led to the establishmentof MONDO (Monarch Merged Disease Ontology) [14]as a cohesive ontology for connecting many of the dis-ease databases and resources. The integrative knowledgegraph we introduce in this study applies well-establishedrare disease data drawn from GARD, Orphanet, OMIMand MONDO as a backbone, and then expands to awide spectrum of additional biomedical data, includingphenotypes, genes and curated FDA approved drugs andFDA orphan drug designations.There are demonstrated merits and successes in usinggraph database to support the management of large bio-medical datasets. While relational databases excel at man-aging relationships between data, graph databases provideunique abilities to manage n-th degree relationshipsamong complex types of biomedical data. Furthermore,graph databases are particularly apt at representing hier-archical data, such as disease categories and complex se-mantic relationships among different types of data. Neo4jas a graph database management system [15], has beenwidely applied in such use cases within the biomedical do-main. Such as, Gratzl S, et al. demonstrated the utility ofNeo4j in developing integrated visual analysis platform forbiomedical data [16]; Himmelstein D, et al. constructedZhu et al. Journal of Biomedical Semantics           (2020) 11:13 Page 2 of 13Hetionet, an integrative Neo4j network that encodesknowledge from millions of biomedical studies toprioritize drugs for repurposing [17]. In this paper, weintroduce this rare diseases integrative knowledge graph,built in Neo4j as a backend graph database ingesting alarge variety of biomedical datasets. We detail data prepar-ation and entity resolution methodologies in generatinginitial insights and results, and the potential benefits forutilizing a knowledge graph-based approach to interpretbiomedical research at a scale and pace that would be un-sustainable when limited to the manual curation effortsthat define current processes used in curating consumerhealth information.MaterialsAt the time of writing, the knowledge graph integrates34 different biomedical datasets including GARD. Webriefly describe several primary resources as below.Rare disease related data resourcesBesides GARD data retrieved from our internal database,all other datasets were downloaded from NCBO Biopor-tal [18].GARD is currently managed by the Office of RareDiseases Research (ORDR) within the National Centerfor Advancing Translational Sciences (NCATS), hasremained an important portal for patients, health-careprofessionals, and researchers seeking to understand thecurrent state of genetic and rare diseases. GARD in-cludes curated disease information comprised of 15 dif-ferent sections, such as summary, diagnosis, inheritance,etc. Notably, not all of GARD diseases have a completelist of these 15 information sections, due to data unavail-ability at the time of curation and update. In this study,we extracted and applied disease specific informationsections, if applicable from our internal GARD database.Other sections, such as Resources, Organizations will beexplored in the future [5].Orphanet is a unique resource, gathering and improv-ing knowledge on rare diseases so as to improve thediagnosis, care and treatment of patients with rare dis-eases [6].Monarch Disease Ontology (MONDO) is a semi-automatically constructed ontology that merges multipledisease resources to yield a coherent merged ontology[14].Online Mendelian Inheritance in Man® (OMIM®) isa comprehensive, authoritative compendium of humangenes and genetic phenotypes. The full-text, referencedoverviews in OMIM contain information on all knownmendelian disorders and over 15,000 genes [7].Human Phenotype Ontology (HPO) provides a stan-dardized vocabulary of phenotypic abnormalities en-countered in human disease [19].FDA orphan drugsFDA orphan drug designation provides orphan desig-nations to drugs and biologics, which are defined asthose intended for the safe and effective treatment, diag-nosis or prevention of rare diseases/disorders [20]. Inthis study, we employed orphan drug designation datafrom the FDA [21], several examples of FDA orphandrug designations retrieved from the FDA are shown inTable 1. Specifically we utilized the associations betweenFDA designated drugs (the column of Generic Namein Table 1) and their designations (the column of Or-phan Designation in Table 1). Although the data is pre-sented in a structured form, orphan designation iscaptured in free text, such as examples shown in Table1. In that manner, additional curation was conducted inthis study to be able to map orphan designations toGARD diseases and designated drugs to UNII (UniqueIngredient Identifier).Inxight Drugs is a drug resource developed by NCATS. Inxight Drugs [22] incorporates the most comprehen-sive subset of substances and related biological mecha-nisms pertaining to translational research and connectsthem to the appropriate disease indications. As part ofInxight Drugs, explicit connections between drugs andconditions were manually identified from scientific arti-cles, press releases, FDA labels, and large-scale databases(e.g. AdisInsight [23]). For those identified associations,the curators manually matched conditions to MeSH,Disease Ontology (DO), and drugs to UNII (Unique In-gredient Identifier). For example, one association pre-senting in Inxight Drugs is as CYROMAZINE (withUNII: CA49Y29RA9) has indication of MYIASIS,CUTANEOUS MYIASIS OF SHEEP. In this study, weextracted associations between FDA approved drugs anddiseases, and integrated them into our integrative know-ledge graph.MethodsIn this paper, we detail the process of developing the in-tegrative knowledge graph for rare diseases with inclu-sion of multiple well-known biomedical datasetsincluding GARD. We also demonstrate the use of thisintegrative graph to support biomedical research for rarediseases. More details about this process is described asbelow.Data collectionGARD data is curated in two folds, manual curation byinformation specialists from GARD, and programmaticextraction from Orphanet. The curated data is stored ina relational database, from where we extracted GARDdata for this study. GARD provides comprehensive in-formation about rare diseases from different aspects,including summary, sign and symptoms, treatment,Zhu et al. Journal of Biomedical Semantics           (2020) 11:13 Page 3 of 13RESEARCH Open AccessTemporal information extraction frommental health records to identify durationof untreated psychosisNatalia Viani1*, Joyce Kam1, Lucia Yin1, André Bittar1, Rina Dutta1,2, Rashmi Patel1,2, Robert Stewart1,2 andSumithra Velupillai1AbstractBackground: Duration of untreated psychosis (DUP) is an important clinical construct in the field of mental health,as longer DUP can be associated with worse intervention outcomes. DUP estimation requires knowledge aboutwhen psychosis symptoms first started (symptom onset), and when psychosis treatment was initiated. Electronichealth records (EHRs) represent a useful resource for retrospective clinical studies on DUP, but the core informationunderlying this construct is most likely to lie in free text, meaning it is not readily available for clinical research.Natural Language Processing (NLP) is a means to addressing this problem by automatically extracting relevantinformation in a structured form. As a first step, it is important to identify appropriate documents, i.e., those that arelikely to include the information of interest. Next, temporal information extraction methods are needed to identifyRESEARCH Open AccessOntological representation, classificationand data-driven computing of phenotypesAlexandr Uciteli1,2* , Christoph Beger1,3, Toralf Kirsten2,4,5, Frank A. Meineke1,2 and Heinrich Herre1,2*AbstractBackground: The successful determination and analysis of phenotypes plays a key role in the diagnostic process,the evaluation of risk factors and the recruitment of participants for clinical and epidemiological studies. Thedevelopment of computable phenotype algorithms to solve these tasks is a challenging problem, caused by variousreasons. Firstly, the term phenotype has no generally agreed definition and its meaning depends on context.Secondly, the phenotypes are most commonly specified as non-computable descriptive documents. Recentattempts have shown that ontologies are a suitable way to handle phenotypes and that they can support clinicalresearch and decision making.The SMITH Consortium is dedicated to rapidly establish an integrative medical informatics framework to providephysicians with the best available data and knowledge and enable innovative use of healthcare data for researchand treatment optimisation. In the context of a methodological use case phenotype pipeline (PheP), a technologyto automatically generate phenotype classifications and annotations based on electronic health records (EHR) isdeveloped. A large series of phenotype algorithms will be implemented. This implies that for each algorithm aclassification scheme and its input variables have to be defined. Furthermore, a phenotype engine is required toevaluate and execute developed algorithms.Results: In this article, we present a Core Ontology of Phenotypes (COP) and the software Phenotype Manager(PhenoMan), which implements a novel ontology-based method to model, classify and compute phenotypes fromalready available data. Our solution includes an enhanced iterative reasoning process combining classification taskswith mathematical calculations at runtime. The ontology as well as the reasoning method were successfullyevaluated with selected phenotypes including SOFA score, socio-economic status, body surface area and WHO BMIclassification based on available medical data.Conclusions: We developed a novel ontology-based method to model phenotypes of living beings with the aimof automated phenotype reasoning based on available data. This new approach can be used in clinical context,e.g., for supporting the diagnostic process, evaluating risk factors, and recruiting appropriate participants for clinicaland epidemiological studies.Keywords: Phenotype definition, Phenotype classification, Phenotype calculation, Phenotype ontology, Phenotypereasoning© The Author(s). 2020, corrected publication 2020. Open Access This article is licensed under a Creative Commons Attribution4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, aslong as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence,and indicate if changes were made. The images or other third party material in this article are included in the article's CreativeCommons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's CreativeCommons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will needto obtain permission directly from the copyright holder. To view a copy of this licence, visit http://creativecommons.org/licenses/by/4.0/. The Creative Commons Public Domain Dedication waiver (http://creativecommons.org/publicdomain/zero/1.0/) applies to the data made available in this article, unless otherwise stated in a credit line to the data.* Correspondence: auciteli@imise.uni-leipzig.de; heinrich.herre@imise.uni-leipzig.de1Institute for Medical Informatics, Statistics and Epidemiology (IMISE),University of Leipzig, Leipzig, GermanyFull list of author information is available at the end of the articleUciteli et al. Journal of Biomedical Semantics           (2020) 11:15 https://doi.org/10.1186/s13326-020-00230-0BackgroundDespite its long ago introduction in 1909 by WilhelmJohannsen, the term phenotype still has no generallyagreed definition [1]. Usually, a phenotype is consid-ered as an observable characteristic or trait of an or-ganism, such as its morphology, function, behaviouror its biochemical and physiological properties [13].Scheuermann et al. define a phenotype as a (combin-ation of) bodily feature(s) (physical components, bod-ily qualities or bodily processes) of an organismdetermined by the interaction of its genetic make-upand environment [4]. From the medical perspective,clinical (clinically abnormal) and disease phenotypes(clinical phenotype characterising a single disease) areconsidered. According to Scheuermann et al., a dis-ease phenotype can exist without being observed. Ob-served bodily features that could be of clinicalrelevance are called Sign(  observed in a physicalexamination and is deemed by the clinician to be ofclinical significance) or Symptom (  observed bythe patient and is hypothesized by the patient to be arealization of a disease) [4].Correct determination of phenotypes plays a keyrole for diagnosis of diseases, evaluation of risk fac-tors and recruitment of patients for clinical and epi-demiological studies [5, 6]. One challenge is totranslate phenotype algorithms, which are most com-monly represented as non-computable descriptivedocuments and knowledge artifacts [7], intomachine-readable form. This paper focuses on devel-oping a general phenotype representation model thatcan be used for data-driven phenotype computing,i.e., software-supported determination of phenotypesbased on the data of an organism. The model to bedeveloped must support both the biological and themedical views of the phenotype notion. Recent at-tempts have shown that ontologies are suitable tohandle phenotypes and that they can support clinicalresearch and decision making [810].There is a large ongoing initiative in Germany, the socalled German Medical Informatics Initiative (MII) [11,12] that aims at making clinical data available for re-search. Most German university hospitals participate inone of four funded consortia. Smart Medical Informa-tion Technology for Healthcare (SMITH) is one of theseconsortia [13]. Within the ongoing SMITH project, aphenotyping pipeline (PheP) will be established to sys-tematically develop, evaluate and execute validated algo-rithms and models for classifying and annotating patientcare data. These annotations and derivatives will be pro-vided for triggering alerts and actions, data sharing anddeep analyses of patient care and outcomes. The generaldesign and concept of the SMITH phenotyping pipelineis presented in [14].In this article, we propose a novel ontology-basedmethod to model and compute phenotypes. Our ap-proach provides an extended reasoning combiningphenotypic data to derive complex phenotypes based oncalculations and classifications.MethodsPhenotypes can be derived from available data that mayhave been measured (quantitative data) or observed andqualitatively described (categorical data). The data can,for example, come from Electronic Health Records(EHR) (clinical data) or from a research database of aclinical/epidemiological study (research data). In SMITH, the required EHR data will be integrated into a cen-tral Health Data Storage (HDS) at each site. The inte-grated data is homogeneously represented in each HDSusing HL7 FHIR [15] and can be queried utilising FHIRSearch [16] (Fig. 1). Structured data from differentsource systems in hospitals as well as unstructured doc-uments will be extracted, transformed and loaded intothe HDS. Natural Language Processing (NLP) techniquesare used to extract and transform relevant data from un-structured EHR documents into structured form. InSMITH and the German Medical Informatics Initiative,the software tool ART-DECOR [17] is used to specify anoverarching global schema, the so-called core data set[18]. The core data subsumes the minimal set of data el-ements that each site (i.e., University Hospital) needs toprovide in a harmonised manner. In this way, data ele-ments are specified based on HL7 templates, their re-spective value sets, referenced terminologies, exemplifieduse scenarios and data. These specifications are the basisfor the ontology-based phenotype representation in ourapproach.Fig. 1 Integration of the PhenoMan. The Metadata Manager modelsbasic data elements using ART-DECOR. The Phenotype Designerimports the ART-DECOR specification and develops phenotypemodels (PheSO) utilising the PhenoMan Editor. The PhenoManrequests required input data from the FHIR Server, computesphenotypes and writes the results back to the FHIR ServerUciteli et al. Journal of Biomedical Semantics           (2020) 11:15 Page 2 of 17HL7 FHIR and FHIR SearchHealthcare records are increasingly digitised. TheEHR must be discoverable and understandable. Thepatient data must be structured and standardised tosupport machine-based processing and automatedclinical decision making. The FHIR (Fast HealthcareInteroperability Resources) specification is a HL7standard for modelling and exchanging healthcare in-formation [15]. FHIR provides a base set of resourcetypes representing relevant clinical concepts that canbe used to store and exchange data in order to solvea wide range of healthcare related problems. Foreach resource type, the corresponding informationcontents and structure are specified. The resourcescan be used either by themselves or combined tocomplex documents representing a coherent set ofhealthcare information [15]. The FHIR resource typesinclude, inter alia, Patient (Demographics and otheradministrative information about an individual oranimal receiving care or other health-related ser-vices.), Observation (Measurements and simple as-sertions made about a patient, device or othersubject.) and Condition (A clinical condition, prob-lem, diagnosis, or other event, situation, issue, or clin-ical concept that has risen to a level of concern.)[15].The FHIR Search Framework [16] is part of theHL7 FHIR standard and provides a range of opera-tions and parameters (series of name = value pairs) tosearch for existing FHIR resources in the underlyingrepository. In the simplest case, a search is executedby performing a GET operation in the RESTfulframework:GET [base-url]/[resource-type]?name = value&...{&_format = [mime-type]}}.e.g., GET [base-url]/Patient?gender =male.For numeric parameter types (number, date or quan-tity), a value range can be defined using a prefix to theparameter value (e.g., gt = greater than, le = less orequal).The & (AND) operator between single search criteria isused to search for the intersection of resources that matchall criteria specified by each individual search parameter(e.g., Patient?gender =male&birthdate = gt1970). To searchfor resources with one of the specified parameter values(OR), the values must be separated by a comma (e.g., Obser-vation?code= http://loinc.org?3141-9, http://snomed.info/sct?27113001, i.e., weight code from LOINC or SNOMED).The following query contains AND combinations of singlecriteria (code AND value-quantity) as well as OR linking ofcode values and can be used to search for weight observa-tions where the weight is greater than 75 kg:Observation?code= http://loinc.org?3141-9, http://snome-d.info/sct?27113001&value-quantity=gt75??kg.ART-DECORART-DECOR is an open-source tool suite that supportsthe creation and maintenance of HL7 templates, valuesets, scenarios and datasets [17]. To specify and hier-archically structure required data elements (items, con-cepts, variables) we use the Dataset Editor of ART-DECOR. Data elements can possess several attributes,such as name, description (in different languages) andvalue domain (including data type, unit and possiblevalue set) (Fig. 2a).One of the most important components of a dataelement is its terminology associations. A termin-ology association defines the binding of dataset con-cepts to relevant terminology [17]. To associate adata element with a terminology concept, the corre-sponding code (including the URI or ID of the ter-minology) must be specified. For instance, theconcept Fasting glucose [Mass/volume] in Serum orPlasma from LOINC (URI: http://loinc.org) has thecode 15586 (Fig. 2a).Furthermore, additional properties of data elementscan be defined as key-value pairs. We use this function-ality to specify the mapping between the data elementand the corresponding FHIR resource type (e.g., for fast-ing glucose, key: FHIR, value: Observation) requiredfor phenotype computing. Depending on the resourcetype, different FHIR Search parameters must be used toquery the relevant FHIR resources. Moreover, the differ-ent structure of the resulting resources must be consid-ered to extract required data.The resulting dataset specification is available in XMLor JSON and can be parsed by our software.Ontological architectureOur objective was to design the PhenoMan softwareaccording to the three-ontology method [19]. Thismethod is based on interactions of three differentkinds of ontologies: a task ontology (TO), a domainontology (DO) and a top-level ontology (TLO). TheTO serves as the conceptual model for the software,the DO provides the domain-specific knowledge,whereas the TLO integrates the TO and the DO andis used as foundation of them.In our case, the Core Ontology of Phenotypes (COP,see section 'Core Ontology of Phenotypes (COP)') func-tions as a TO. It describes the general structure of validphenotype specifications and thus enables the Pheno-Man to create such specifications and to use them forphenotype computing. Concrete phenotype specifica-tions (domain-specific knowledge) are represented inPhenotype Specification Ontologies (PheSO, see section'Phenotype Specification Ontologies (PheSO)') playingthe role of domain ontologies (DO) in our architecture.Uciteli et al. Journal of Biomedical Semantics           (2020) 11:15 Page 3 of 17For the foundation of the TO we used the GeneralFormal Ontology (GFO) [20] as TLO. GFO has alreadybeen successfully applied for a foundation of phenotype-related notions. For instance, a novel approach to repre-sent complex phenotypes in OWL was proposed im-proving the consistency and expressiveness of formalphenotype descriptions [10]. Another pillar of GFO for agrounding of phenotypes is the foundational ontology ofproperties, attributives and data (GFO-Data [21])providing an extensive classification of properties (andattributives). In the current paper, we especially refer-ence the property notion of GFO (including distinctionbetween single and composite properties [22]) in ourphenotype representation model supporting data-drivenphenotype computing.One of the advantages of the three-ontology method isthat the software only needs to implement the access toentities (classes, properties) of the TO (COP), whereasFig. 2 Mapping between ART-DECOR, PheSO, FHIR Subscription and FHIR Observation entities. a Specification of the data element fastingglucose in ART-DECOR. b Annotations of the corresponding class Fasting_Glucose after importing the ART-DECOR specification into the PheSO. cSubscription generated for the class Fasting_Glucose. The criteria (FHIR Search query) is encoded. The original URL part is Observation?code=http://loinc.org|1558-6. d Observation of fasting glucose provided by FHIR Server. The observation code, value, date and the referenced patientare specified. (The same colour of the border indicates the mapping between the entities)Uciteli et al. Journal of Biomedical Semantics           (2020) 11:15 Page 4 of 17the entities of the corresponding DO (PheSO) are proc-essed dynamically. The PhenoMan uses the COP as aninterface to access the PheSO entities.Additional requirements for the ontological modellingwere: Developing in OWL (using OWL API [23], HermiT[24] and Openllet [25]) Modelling all attributes and relations that arerelevant for reasoning as object or data properties Modelling all attributes and relations that are notrelevant for reasoning as annotations Usage of general class axioms (based on subclassof) instead of equivalence classes if only onedirection (is-a relation) is relevant for reasoning.Software designWe defined the following main requirements for theoverall system (Fig. 1): The system must support a phenotype specificationproviding a GUI tool (see section 'Specification ofphenotypes'). The phenotype specifications must be saved in astandardised ontology (see sections 'Core Ontologyof Phenotypes (COP)' and 'Phenotype SpecificationOntologies (PheSO)'). The system must be able to correctly computephenotypes based on a phenotype specification(ontology) and input data (see section 'Classificationand calculation of phenotypes'). The system must support an additionalimplementation of mapping components foraccessing required data and metadata repositories.Example components for metadata import fromART-DECOR as well as for interaction with FHIRservers (e.g., SMITH HDS) must be implemented(see sections 'Data procurement' and 'Transmissionof inferred phenotype classes to the FHIR Server').The PhenoMan accesses the FHIR Server, extractsphenotype-specific data, computes the specified pheno-types and writes the results back to the FHIR Server. Forthis purpose, the PhenoMan provides an API and acts asa web service (using Dropwizard [26]) (Fig. 1). The Phe-noMan is implemented in Java using OWL API [23] andtwo reasoners, HermiT [24] and Openllet [25]. For cal-culations we utilize the Java Expression Evaluator (Eva-lEx) [27], but the integration of other libraries (e.g., forexecuting R scripts) or rule systems (e.g., SWIRL orDrools) is also possible. The EvalEx enables evaluatingmathematical and Boolean (inter alia, Boolean operatorsand IF-THEN-ELSE structures) expressions and sup-ports defining custom functions and operators.The PhenoMan Editor1 is a desktop app, which is alsodeveloped with Java and bundled with the PhenoManAPI. It offers a graphical user interface based on JavaSwing to specify attributes of phenotype classes and cat-egories using appropriate form fields. On saving, formcontent is transmitted to the PhenoMan API and writteninto the ontology. The editor can be executed on a localmachine with a Java runtime environment 8 or higherand was developed with the aim of rapidly definingphenotype models.EvaluationAn evaluation of our approach was designed and con-ducted. The main objectives of the evaluation were toprove:1. Correct functioning of all software components2. Faultless communication of the software with theFHIR Server3. Correctness of all provided phenotype specifications4. Correct functioning of the overall system bycomparison with a corresponding SPSSimplementation of selected phenotypes.We evaluated the PhenoMan at different levels. Firstly,we tested all functionalities of the PhenoMan API (espe-cially read/write in the ontology and computing pheno-types) and the communication of the PhenoMan Servicewith the FHIR Server by a set of static JUnit tests usingfixtures (i.e., example PheSOs and patient data).Secondly, each phenotype specification is shipped witha structured representation (spreadsheet) of test data (in-put and output), such that the respective phenotype al-gorithm can be automatically tested. The criterion for asuccessful execution of the JUnit tests was a match be-tween the results calculated by PhenoMan based on pro-vided input data and the corresponding output data.Finally, we selected some test case algorithms/deriva-tives (such as socio-economic status [28], body massindex [29], waist circumference and waist-hip ratio [30])from the LIFE Adult study [31] running at the LIFE Re-search Centre for Civilization Diseases, University ofLeipzig. There, derivatives are usually implemented byepidemiologists, statisticians and other researchers usingthe statistics software SPSS [32] and R or are database(SQL) queries and functions, which are automatically ex-ecuted at night based on daily captured data. The result-ing data are directly stored within the LIFE researchdatabase in tabular form. More details about partici-pants, their invitation and consenting as well as1Source code and releases of the PhenoMan Editor are available onGitHub under the GPL-3.0 license: https://github.com/Onto-Med/Phe-noMan-EditorUciteli et al. Journal of Biomedical Semantics           (2020) 11:15 Page 5 of 17examinations, interviews, questionnaires and taken spe-cimen can be found in [31]. We reproduced selectedSPSS derivatives using the PhenoMan and developedparameterised JUnit tests to comparatively evaluate theaccuracy of the PhenoMan against the correspondingSPSS implementation at the LIFE Research Centre. Thecriterion for a successful comparison was a match be-tween the results calculated by PhenoMan and SPSSsoftware for each dataset. The performance of our ap-proach is not a critical issue in our use case (the pheno-type computing could run overnight).This evaluation included data of thousands of LIFEparticipants.ResultsCore Ontology of Phenotypes (COP)We developed the Core Ontology of Phenotypes(COP, Fig. 3) to model, classify and calculate pheno-types based on instance data sets (e.g., of a patient).In this article, we consider a phenotype as adependent individual (in the sense of General FormalOntology, GFO [20]), for example, the weight of aspecific person. Hereinafter, abstract instantiable en-tities that are instantiated by phenotypes are calledphenotype classes. For instance, the abstract propertyweight possesses individual weights as instances. Wedistinguish between single and composite properties,and correspondingly, between single and compositephenotypes. A composite property is defined as aproperty that has single properties as parts [22].Based on the definitions of single and compositeproperties [22], we define single phenotypes as singleproperties (e.g., age, weight, height) and compositephenotypes as composite properties (e.g., height andweight, BMI, SOFA score [33]) of an organism or ofone of its subsystems. Properties of an organism areconsidered as all documentable information about it,whereby the modeller is left to decide what is rele-vant to the current situation. These can be, for ex-ample, observable characteristics or traits of anorganism [13] or possible manifestations of clinicalphenotypes, such as signs, symptoms or dispositions[4]. The corresponding data can be modelled usingthe FHIR Observation or Condition resources.Composite phenotypes are divided into combinedand derived phenotypes. A combined phenotype isonly a combination of corresponding phenotypes (e.g.,a combination of height and weight), whereas a de-rived phenotype is an additional property (e.g., BMI)derived from the corresponding phenotypes (heightand weight). In the framework of GFO we modelledproperties using the class gfo: Property. In the presentarticle, composite phenotype classes are modelledusing a Boolean expression based on has_part relation(e.g., weight and height: has_part some height andhas_part some weight). Derived phenotype classesadditionally define a calculation rule/mathematicalformula (e.g., BMI = weight [kg] / height [m]2). Fur-thermore, combined phenotype classes can associatecertain conditions with specific predefined values(scores), which can be used, e.g., in further formulas.For example, if bilirubin value is greater than 12 mg/dL, then the value 4 is used for the calculation of theSOFA score [33].Additionally, we distinguish between restricted andnon-restricted phenotype classes, depending on whethertheir extensions (set of instances) are restricted to a cer-tain range of individual phenotypes by defined condi-tions or all instances are allowed. For example, thephenotype class age is instantiated by the ages of all liv-ing beings (non-restricted), whereas the phenotype classyoung age is instantiated by the ages of the young ones,e.g., if the age is below 30 years (restricted).Phenotype Specification Ontologies (PheSO)We consider a phenotype algorithm as a sequence of in-structions (1) to classify phenotypes (single or compos-ite) in phenotype classes or (2) to derive additionalproperties (derived phenotypes) from the phenotypes ofan organism. Phenotype algorithms can be implemented,for example, using a programming language or a statis-tics software (e.g., SPSS or R). Our approach is to separ-ate the specification of phenotypes (models) from theimplementation of corresponding algorithms. The COPprovides a basic model to specify phenotypes in a stan-dardised way, while the PhenoMan implements the gen-eral approach, common for all COP-based specifications.It is not our aim to completely model the EHR. Instead,our approach can support the modelling and calculationof selected phenotypes in a user-friendly standardisedmanner.Phenotypes are modelled in Phenotype SpecificationOntologies (PheSO) using the COP. The phenotype clas-ses and axioms (classification and calculation rules) con-tained in the PheSO are used by PhenoMan to executethe corresponding phenotype algorithm. PheSOs are em-bedded in the COP in such a way that the classes of thePheSO are subclasses of the COP classes. Every PheSOsubclass of the COP classes cop: Single_Phenotype, cop:Combined_Phenotype or cop: Derived_Phenotype is aphenotype class and is instantiated by phenotypes. TheFig. 3 Core Ontology of Phenotypes (COP)Uciteli et al. Journal of Biomedical Semantics           (2020) 11:15 Page 6 of 17direct subclasses are non-restricted (e.g., Fasting_Glu-cose, Fig. 4a), while the subclasses of the non-restrictedphenotype classes are restricted (e.g., Fasting_Glucose_ABNORMAL, i.e., fasting glucose is greater equal 125mg/dL, Fig. 4a3).Phenotype classes possess various common attributes(e.g., labels, descriptions and codes of external concepts).Other attributes vary depending on the type of thephenotype class. The following are examples of suchattributes: Non-restricted single phenotype (NSiP) class: unit ofmeasure and optional aggregate function. Restricted single (RSiP) and derived phenotype(RDeP) class: restriction. Restricted combined phenotype (RCoP) class:Boolean expression (based on RSiP, RCoP and RDePclasses) and optional score value. Non-restricted derived phenotype (NDeP) class:mathematical formula and Boolean expressionconsisting of AND-linked variables used in the for-mula (NSiP and non-restricted combined phenotype(NCoP) classes). If a NCoP class is used as a vari-able, the RCoP classes (subclasses) of the NCoP classmust have score values that should be used in theformula.Simple attributes of the phenotype classes are definedas annotations. The logical relations between phenotypeclasses as well as range restrictions are represented inOWL by anonymous equivalent classes or general classaxioms based on property restrictions.Phenotype Manager (PhenoMan)We developed the software Phenotype Manager (Pheno-Man), which implements a multistage reasoning ap-proach combining standard reasoners (e.g., Pellet orHermiT) and mathematical calculations. This sectionbriefly outlines the main functionality of our solution.Specification of phenotypesThe PhenoMan Editor is an interactive user interface formanaging and developing PheSOs. The user is able tocreate a new PheSO or to load an existing ontology. TheFig. 4 Parts of the T2DM PheSO in Protégé. Middle: Phenotype classes (a Single, b Derived, c Combined). Left: Example annotations of thephenotype classes. Right: Anonymous equivalent classes and general class axiomsUciteli et al. Journal of Biomedical Semantics           (2020) 11:15 Page 7 of 17PhenoMan Editor provides appropriate forms to browse,create and edit categories and phenotype classes of theontology. Value range restrictions, for example, are de-fined by selecting a comparison operator and enteringthe corresponding values (Fig. 5). Boolean expressionsare built by drag-and-dropping the phenotype classesfrom the left side into the expression form field and en-tering relevant operators (Fig. 6). After submission, theform data is transmitted to the PhenoMan API and isstored in the actual PheSO.Furthermore, an ART-DECOR specification (XML)of relevant data elements can be imported in thePheSO. For each data element, a NSiP class is gener-ated. All relevant attributes (name, codes, FHIR re-source type, data type, unit, etc.) specified in ART-DECOR are defined as annotations of correspondingclasses (Fig. 2a, b).Data procurementAfter starting the PhenoMan Service, FHIR subscriptions(rest-hooks) [34] are generated and transmitted to theFHIR Server. The structure of the subscription resourceis very simple. The main parts of the resource are thecriteria and the channel. The FHIR Server uses the cri-teria (FHIR Search query) to determine resources forwhich notifications have to be generated. When re-sources are identified (after creating or updating) meet-ing the criteria, a notification is sent to the address(endpoint) specified in the section channel.Fig. 5 Specification of the class Fasting_Glucose_ABNORMAL with the PhenoMan Editor form. We left out some of the metadata fields forbetter visibilityFig. 6 Specification of the class T2DM_Case_3 with the PhenoMan Editor formUciteli et al. Journal of Biomedical Semantics           (2020) 11:15 Page 8 of 17In the configuration file of the PhenoMan, a directorycontaining all available phenotype specifications (Phe-SOs) as well as the address (URL) of the PhenoMan ser-vice (including the PheSO name) are defined. For eachNSiP class of each available PheSO (in the defined direc-tory) a subscription is created. To generate the subscrip-tion criteria (FHIR Search query), the PhenoMan usesthe resource type and codes specified in the correspond-ing NSiP class as annotations (Fig. 2b, c). The endpointattribute is automatically filled with the URL of the Phe-noMan service defined in the configuration file. Theremaining parts of the subscription resource (status,type and payload) take default values (active, rest-hook and application/json) (Fig. 2c).After receiving a notification (including thecomplete resource, Fig. 2d), the PhenoMan Service re-quests further resources (for all other NSiP classes ofthe corresponding PheSO) using FHIR Search. Thegenerated FHIR Search queries are primarily basedupon the codes specified for the NSiP classes (simi-larly to subscription criteria), contain a reference tothe patient and can additionally support possible ag-gregate functions.Classification and calculation of phenotypesAfter receiving required resources, the PhenoMan startsinferring phenotypes.First, the relevant information is extracted from re-ceived resources and inserted into the ontology. On theone hand, the individual properties (single phenotypes)are inserted as instances of the direct subclasses of cop:Single_Phenotype and the values are modelled as prop-erty assertions based on the has_value relation. On theother hand, a composite phenotype is defined as an in-stance of the class cop: Composite_Phenotype, whichcombines all the single phenotype instances using prop-erty assertions based on has_part relation. Then, ourmultistage reasoning algorithm is executed. The algo-rithm consists of the following steps:1. Classification step. A standard reasoner classifies theexisting instances (assignment to classes).a. Single phenotype instances are classified in RSiPclasses based on property restrictions.b. The composite phenotype instance is classifiedin RCoP classes based on the specified Booleanexpression and inferred RSiP, RCoP and RDePclasses.c. The composite phenotype instance is classifiedin NDeP classes based on the specified Booleanexpression and corresponding NSiP and NCoPclasses. In this case, all variable values requiredfor calculating formulas are present.d. Available instances of NDeP classes(representing calculated values) are classified inRDeP classes based on property restrictions.2. If no new NDeP classes get an instance, theexecution of the algorithm stops. All inferredphenotypes (inferred classes including metadata andcalculated values) are returned.3. Calculation step. The formula of each NDeP classhaving an instance is calculated based on variablevalues (values of the corresponding singlephenotype instances or scores of the inferred RCoPclasses). A new instance of the NDeP classrepresenting the calculated value is created andassociated with the composite phenotype instance(using has_part).The algorithm goes back to step 1.In the case of complex phenotypes, the classificationand calculation steps can be executed several times (in aloop). That is the case if a NDeP class has subclasses,i.e., RDeP classes, which are in turn used in combinedphenotypes. Both steps are repeated until all formulasare calculated and all phenotypes are classified.The PhenoMan supports 4 primitive data types xsd:decimal, xsd:string, xsd:boolean and xsd:date. All othercomplex data types (e.g., FHIR code or quantity) aremapped to the primitive data types (e.g., code to xsd:string and quantity to xsd:decimal with additional unitattribute, Fig. 2a, b). Furthermore, the PhenoMan pro-vides, inter alia, aggregate functions, Boolean, date andmeasurement unit arithmetic, integration of external ter-minologies as well as reading and writing FHIRresources.Transmission of inferred phenotype classes to the FHIRServerPhenoMan returns all inferred combined and derivedphenotype classes as Observation resources and trans-mits them to the FHIR Server. The generated resourcescan have a numeric or a code data type. Numeric obser-vations are used for storing numeric values (i.e., calcu-lated values of derived phenotypes or score values ofcombined phenotypes), whereas the code observationsare intended for concepts of a terminology or a valueset. The specified codes of the non-restricted phenotypeclasses are utilised in the resulting resources to completethe code attribute. The calculated values, scores orcodes of the inferred restricted phenotype classes areused in valueQuantity or valueCodeableConcept attri-butes (Fig. 7).Export capabilitiesThe PhenoMan can export the complete PheSO or gen-erate reasoner reports (structured descriptions of allUciteli et al. Journal of Biomedical Semantics           (2020) 11:15 Page 9 of 17Fig. 7 T2DM case 3 Observation. For the Patient/103, an Observation resource was generated including the code (t2dm_case_calculated), thevalue (t2dm_case_3) and the observation method (generated by PhenoMan)Fig. 8 T2DM case 1 reasoner report. Left: Phenotype class types from the COP (single, combined, derived). Middle: Non-restricted classes of thePheSO (the NSiP classes contain the current input value, the NDeP classes the calculated value). Right: Restricted classes inferred by PhenoManbased on the input dataUciteli et al. Journal of Biomedical Semantics           (2020) 11:15 Page 10 of 17inferred phenotypes) in Excel format. A tabular rea-soner report contains three columns: Type, Non-re-stricted and Restricted. In the first column the type(single, combined or derived) of the inferred pheno-type is presented. In the next two columns, the speci-fied or derived information about the resultingphenotypes (restricted and non-restricted) is displayed(Fig. 8).Additionally, the PhenoMan can generate the graphicalrepresentation of combined phenotype classes in theform of decision tree (or flowchart) diagrams. The Phe-noMan translates the Boolean expressions of every RCoPclass into disjunctive normal form and considers eachconjunction as a possible path of the tree. Then, thepaths are grouped on shared nodes and form a treestructure (Fig. 9).ExampleWe illustrate our approach by means of an example al-gorithm for determining Type 2 Diabetes Mellitus(T2DM) cases presented by PheKB.org [37]. The T2DMalgorithm requires the following data elements to be ex-tracted from the EHR: Counts of T1DM and T2DM diagnoses (identifiedby ICD-9 billing codes), The earliest dates of T1DM and T2DM medications(identified by RxNorm codes), Laboratory values (fasting blood glucose, randomblood glucose and hemoglobin A1c, identified byLOINC codes) as well as Physician-entered diagnoses (derived fromencounter or problem list sources only).Modelling of single data elements using ART-DECORAs a first step, required data elements (items, concepts,variables, single phenotype classes) representing singlepatient characteristics relevant for determining theT2DM (T1DM and T2DM diagnoses, T1DM andT2DM medications, fasting blood glucose, random bloodglucose, hemoglobin A1c as well as physician-entereddiagnoses) must be modelled using ART-DECOR. La-bels, descriptions, codes from external terminologies,data types, units, etc. are specified. Additionally, everydata element must be associated (as property) with aFHIR resource type in order to ensure the correct searchand extraction of the instance values from the respectiveresource. Laboratory values are represented in FHIR asObservations, while diagnoses are usually specified usingthe Condition resource. The Fig. 2a shows the filledform of fasting glucose in ART-DECOR.The resulting specification is provided by ART_DECOR as a XML or JSON file.Modelling of phenotypes using PhenoMan EditorThe user imports the ART-DECOR specification inthe ontology (PheSO) utilizing the PhenoMan Editor.For each data element, a NSiP class (Fasting_Glucose,HBA1c, Random_Glucose, T1DM_Diagnosis, T2DM_Diagnosis, T1DM_Medication, T2DM_Medication andT2DM_Diagnosis_by_Physician) including relevant an-notations is generated (Fig. 4a, a1, a2).Furthermore, aggregate functions (e.g., COUNT, FIRST, LAST, MIN, MAX) can be defined for NSiP classes.For instance, the T2DM algorithm does not require toprocess the complete data of all diagnosis resources, it issufficient to count the resources. Therefore, the functionCOUNT is defined for the class T2DM_Diagnosis (Fig.Fig. 9 T2DM decision tree. The tree was generated by PhenoMan in GraphML format and was processed using an automatic layout [35] of theyEd Graph Editor [36]. Nonetheless, it is also possible to generate the complete tree as image in PNG formatUciteli et al. Journal of Biomedical Semantics           (2020) 11:15 Page 11 of 174a2). The both medication classes (T1DM_Medicationand T2DM_Medication) are associated with the functionFIRST, because only the earliest date of medications isrelevant for the algorithm.Next, the RSiP classes (Fasting_Glucose_ABNORMAL,Random_Glucose_ABNORMAL and HBA1c_ABNORMAL)for value range restrictions are defined as subclassesof the NSiP classes (Fig. 4a, a3, Fig. 5). For everyRSiP class, the anonymous equivalent class is createdthat represents the corresponding restriction. The re-strictions of other NSiP classes (e.g., T2DM_Diagnosisor T2DM_Diagnosis_by_Physician) are based on thecounts of the corresponding resources (e.g., T2DM_Diagnosis_NO: if the count of T2DM_Diagnosis = 0 orT2DM_Diagnosis_by_Physician_YES: if the count ofT2DM_Diagnosis_by_Physician > = 2, Fig. 4a4).Mathematical calculations are modelled using NDePclasses. The formula GT($T1DM_Medication, $T2DM_Medication) (GT stands for Greater Than) defined forthe class T2DM_precedes_T1DM_Medication expressesa comparison of the T1DM and T2DM medication dates(Fig. 4b, b1). The dollar sign in the variable name indi-cates that not the medication value itself but the entrydate of the medication is used in the formula. The for-mula returns ? 1, 0 or 1 depending on whether the firstoperand is less than, equal to or greater than the secondoperand. The value ? 1 is also returned if one of the op-erands is missing. The RDeP class T2DM_precedes_T1DM_Medication_YES and the corresponding restric-tion are specified similarly to RSiP classes (Fig. 4b, b2).The next step is to model the abnormal lab, i.e., if ei-ther random glucose or fasting glucose or HBA1c is ab-normal. For this purpose, we define the non-restrictedcombined phenotype (NCoP) class Abnormal_Lab andthe RCoP class Abnormal_Lab_YES with the corre-sponding Boolean restriction (disjunction) formalised asgeneral class axiom (Fig. 4c, c1).Finally, the T2DM case selection rules are modelledusing the NCoP class T2DM_Case as well as the fiveRCoP classes (one for each case type) including Booleanrestrictions (Fig. 4c, c2, Fig. 6). For instance, case 1 occurswhen the T1DM diagnosis is missing but a T2DM diagno-sis as well as both medications (T1DM and T2DM) arepresent and the first T2DM medication precedes the firstT1DM medication. The abnormal lab, the presence of aT2DM diagnosis and the absence of T1DM diagnosis andboth medications indicate the case 3.The resulting ontology and additional material (graph-ical and tabular representation, reasoner reports) arepublicly available [38].Execution of the PhenoMan ServiceThe PheSO (OWL file) created by the PhenoMan Editoris saved in the directory specified in the configurationfile. After starting the PhenoMan Service, subscriptionsfor each NSiP class of the T2DM PheSO are created.The subscription for the NSiP class Fasting_Glucose, forexample, is intended to identify Observation resourceswith the LOINC code 15586 (criteria) (Fig. 2c). Afterreceiving a fasting glucose resource, other required re-sources are queried. The query for T2DM diagnosis, forinstance, includes the additional FHIR Search parameter_summary = count to express the aggregate functionCOUNT:Condition?code=http://hl7.org/fhir/sid/icd-9-cm|250.00,http://hl7.org/fhir/sid/icd-9-cm|250.02&subject=Patient/103&_summary=count.In this case, the server returns a bundle with only thenumber of resources matching the query. To realise thefunction FIRST, the combination of _sort (sorting bydate) and _count (_count = 1) is used. The followingT2DM medication query returns only the first resourcematching the criteria:MedicationStatement?code=http://www.nlm.nih.gov/research/umls/rxnorm|25789,http://www.nlm.nih.gov/re-search/umls/rxnorm|10633&subject=Patient/103&_sort=effective&_count=1(Some codes were omitted in both queries).As soon as all required FHIR resources are present,the PhenoMan starts the phenotype computing. Sup-pose, the input resource set consists of only a fastingglucose (Fig. 2d) and a T2DM diagnosis resource. In thiscase, the single phenotype instances of the classes Fast-ing_Glucose and T2DM_Diagnosis are created and thevalues are modelled as property assertions based on thehas_value relation (e.g., has_value 130 for Fasting_Glu-cose and has_value 1 for T2DM_Diagnosis (due to theCOUNT function)). Then, a composite phenotype in-stance is defined, which combines both single phenotypeinstances using property assertions based on has_part re-lation. In the first step (classification step), a standardreasoner classifies the single phenotype instances in re-stricted classes. In our example, the instance of Fasting_Glucose is classified in the class Fasting_Glucose_AB-NORMAL (i.e., the fasting glucose value is > = 125 mg/dL, Fig. 4a, a3) and the instance of T2DM_Diagnosis inthe class T2DM_Diagnosis_YES (because the count ofthe T2DM diagnoses is > 0, Fig. 4a, a4). Next, the com-posite phenotype instance is classified in the RCoP clas-ses Abnormal_Lab_YES (because the fasting glucose isabnormal, Fig. 4c, c1) and T2DM_Case_3 (because allconditions of the corresponding Boolean expression arefulfilled, Fig. 4c, c2). In this case, further phenotypes cannot be derived or calculated.Let us consider another example. Suppose, the inputdata set contains a T2DM diagnosis, a T1DM and aT2DM medication (T2DM precedes T1DM medication).The classification step is similar to the first example.Uciteli et al. Journal of Biomedical Semantics           (2020) 11:15 Page 12 of 17The corresponding single phenotype instances are classi-fied in the classes T1DM_Diagnosis_NO, T2DM_Diag-nosis_YES, T1DM_Medication_YES and T2DM_Medication_YES. In the next step (calculation step), theformula of the NDeP class T2DM_precedes_T1DM_Medication (Fig. 4b, b1) can be calculated by PhenoMan.It inserts the variable values (the dates of the both medi-cations) in the formula and starts the calculation. Afterthe calculation step, the classification step must be per-formed again. The calculated instance of T2DM_pre-cedes_T1DM_Medication is classified in the classT2DM_precedes_T1DM_Medication_YES (because theformula returns 1, Fig. 4b, b2). Then, the compositephenotype instance is classified in the RCoP classT2DM_Case_1 (Fig. 4c, c2) and the PhenoMan finishesthe calculation.Finally, the PhenoMan generates the Observation re-source for the resulting T2DM case and transmits it tothe FHIR Server. In our example, we encode the possibleT2DM cases using a code system (https://www.smith.-care/phenoman/t2dm_case_selection_algorithm), onecode identifying the observation (t2dm_case_calculated)and five codes for possible values (t2dm_case_1, t2dm_case_2, t2dm_case_3, t2dm_case_4 and t2dm_case_5).The resulting Observation resource for case 3 is illus-trated in Fig. 7.Additionally, we can generate a tabular reasoner reportor a decision tree diagram.An example reasoner report for case 1 is shown in Fig. 8.The class T2DM_Case and its subclasses (T2DM_Case_1, T2DM_Case_2, etc.) are very suitable for therepresentation as a decision tree. The decision tree gen-erated by PhenoMan (Fig. 9) looks similar to the flow-chart specified by PheKB.org [37].Evaluation resultsThe evaluation has demonstrated that all components ofour solution function correctly. All JUnit tests were suc-cessful and showed no difference between specified andcalculated results. The comparison between the Pheno-Man and the SPSS calculation has also succeeded. Al-though the performance of our approach is not a criticalissue in our use case, we measured the execution time ofthe PhenoMan. The calculation of the socio-economicstatus (complex algorithm requiring multiple reasonerruns), for example, takes approximately 0.5 s per dataset.This performance is completely sufficient for our usecase.In summary, PhenoMan correctly computes pheno-types based on valid phenotype specifications (PheSO)and input data. Additionally, validating phenotype speci-fications (PheSOs) before deploying them in a product-ive environment is an extremely useful feature of thePhenoMan.Related workWe developed a novel approach to support onto-logical modelling and reasoning of phenotypes. Incontrast to [8, 9], our solution serves to determineand to classify phenotypes based on instance data(e.g., EHR). Moreover, the proposed reasoning processincludes calculation of mathematical formulas atruntime.Very similar to our approach, Fernández-Breis et al.[39] propose to take advantage of the best features ofEHR standards and ontologies. The authors developedmethods allowing a direct use of EHR data for the iden-tification of patient cohorts leveraging current EHR stan-dards and semantic web technologies. In [39], openEHR[40] archetypes were used as EHR standard. An onto-logical infrastructure was designed including differentontologies for representing domain entities (colorectal-domain), the rules for determining the risk level and thedata. The mappings between the phenotyping archetypeand the colorectal-domain ontology were defined andare automatically executed on the archetyped data in-stances to generate the OWL dataset. The data is thentransformed into OWL, where the classification isperformed.Pape et al. [41] evaluated OWL/RDF for enablingcomputable representations of EHR-driven phenotypingalgorithms. A proof-of-concept application using theOWL API and the HermiT reasoner was developed. Thephenotype algorithms are specified based on a rudimen-tary core ontology without the possibility to model andexecute mathematical calculations. The authors utiliseda simple diabetes phenotype algorithm as an exampleand validated their approach against a selected set of de-siderata proposed by Mo et al. [7]. The evaluationshowed that OWL/RDF is potentially sufficient to storephenotyping algorithms, as it is versatile enough to meetmost of the desiderata.We use HL7 FHIR as a standard for exchanginghealthcare information in the SMITH infrastructure. Butthe main difference to the both ontological approachesdescribed above lies in our three-level ontological archi-tecture. The COP is founded by GFO and provides aframework for developing PheSOs. In this way, each par-ticular phenotype model specified as a PheSO has thesame standardised structure and can be executed byPhenoMan in the same manner. A further advantage ofour solution is that the PhenoMan supports classifica-tion as well as calculation tasks and works directly withFHIR format, so that no further transformations are re-quired. The mapping between EHR data and ontology isperformed by PhenoMan automatically using termin-ology associations, which are defined for each data elem-ent in ART-DECOR (and imported into ontology) aswell as in FHIR resources (e.g., Observation).Uciteli et al. Journal of Biomedical Semantics           (2020) 11:15 Page 13 of 17The main objective of SHARPn [42] is to developmethods and modular open-source resources for enab-ling secondary use of EHR data for high-throughputphenotyping. The phenotype algorithms are specifiedbased on Quality Data Model (QDM) [43] and repre-sented in the HL7 Health Quality Measures Format(HQMF or eMeasure) [44]. According to the authors,there are two main challenges. Firstly, data elements inan EHR may not be represented in a format consistentwith the QDM. Secondly, an EHR typically does not na-tively have the capability to automatically consume andexecute eMeasure logic. To address these challenges, atranslator tool was developed that converts QDM-defined phenotyping algorithm criteria into executableDrools rules scripts.The Phenotype Execution and Modeling Architecture(PhEMA) [45] is an open-source infrastructure forstandards-based authoring, sharing, and execution ofphenotyping algorithms. Similarly to SHARPn, PhEMAuses QDM and HQMF to model phenotype definitions.Phenotyping algorithms are represented using thePhEMA Authoring Tool (PhAT), are exported from thePhAT into executable KNIME [46] workflows and areexecuted against data warehouses or data repositories.In contrast to the rule- or workflow-based descriptionof phenotyping algorithms, we use an ontology-basedone. Our approach is rather generic and enables a stan-dardised and structured modelling as well as the reuseof phenotyping algorithms and their parts (e.g., conceptsand restrictions). Furthermore, the PhenoMan is com-patible with the native representation of EHR data (HL7FHIR) in the SMITH infrastructure and does not needan additional import of the data into a data warehouse.In [47] a FHIR-compatible model was designed to sup-port capture of cancer clinical data. Our approach allowsthe modelling of different phenotypes based on a coreontology (COP) and is independent of the EHR repre-sentation standards. The interpretation of FHIR dataand the mapping to specified phenotypes using termin-ology associations are provided by PhenoMan.A method to enable automated transformation of clin-ical data into OWL ontologies is presented in [48]. Thedeveloped system generates OWL representations ofopenEHR archetypes and automatically transformsopenEHR data to OWL individuals. In our approach, thephenotypes are directly modelled in the ontology andare automatically mapped to the EHR data. Moreover,our solution supports classification as well as calculationof phenotypes.As described in section Phenotype Specification On-tologies, phenotypes can possess links to concepts of ex-ternal ontologies. For instance, they may be annotatedwith concepts of anatomic structures (e.g., FoundationalModel of Anatomy [49]), or situations, respectiveprocesses, where phenotypes are observed (e.g., electro-cardiographic monitoring). The linkage is similar to theEntity-Quality method [50] (entity: anatomic structureor process, quality: phenotype) and may improve com-parison of COP across multiple domains.Hoehndorf et al. [9] proposed the PhenomeNET forincorporation of phenotype ontologies from differentspecies. PhenomeNET can predict orthologous geneswith common pathways and common related diseases.Apart from the different interpretation of the termphenotype, the main focus of our attempt is to deducecomplex phenotypes from a set of basic phenotypes ofan individual.The Human Phenotype Ontology (HPO) [8] associatesphenotypic abnormalities with underlying diseases andparticipating genes, whereas COP can contain all sortsof properties of an organism (including non-abnormalities). Currently, COP does not offer weightsfor phenotype-disease relations, like HPO does to sortdiseases for a phenotype set by relevance. We will inves-tigate ways to add this functionality to COP in future.DiscussionMo et al. [7] propose 10 desired characteristics for aflexible, computable phenotype representation model. Inthis section, we discuss our implementation of the pro-posed desiderata.Structure clinical data into queryable formsIn the SMITH project, the patient data is structured andintegrated in a Health Data Storage (HDS) according toHL7 FHIR. FHIR Search is used as a query language.PhenoMan supports querying and writing FHIR re-sources to populate the PheSO respectively to write theinferred phenotypes back to the server. Additionally, weinvestigate the future application scenarios of more ex-pressive query languages, such as FHIRPath [51] andClinical Quality Language (CQL) [52].Recommend a common data model, but also supportcustomization for the variability and availability of EHRdata among sitesHL7 FHIR is used as a common EHR data model. TheFHIR specification supports adaptation to particularcontexts of use by means of profiling [53].Support both human-readable and computablephenotype representationsThe PheSOs are computable representations of pheno-type models. They are implemented in OWL and can beedited using the PhenoMan Editor or common ontologyeditors such as Protégé. The PhenoMan interprets Phe-SOs based on the COP and infers specified phenotypes.Additionally, the PhenoMan provides human-readableUciteli et al. Journal of Biomedical Semantics           (2020) 11:15 Page 14 of 17representations in graphic (diagrams) or tabular (spread-sheets) form.Implement set operations and relational algebraThe ontological representation supports intersection,union and negation operations as well as existential anduniversal quantifiers in accordance with OWL DL. Toextend the expression possibilities, First-Order Logic canbe considered in the future work.Represent phenotype criteria with structured rulesOur multistage reasoning approach supports structuredspecification of phenotype models from single pheno-types (non-restricted and restricted) through combinedphenotypes (Boolean expressions) to derived phenotypes(mathematical calculations). The PhenoMan iterativelyprocesses the individual steps (classification and calcula-tion rules) in the proper order until all specified pheno-types are inferred. It supports Boolean operations(conjunction, disjunction and negation), specification ofvalue ranges (as intervals or enumerations) and aggre-gate functions (for multiple values of single phenotypesas well as for values calculated based on differentdatasets).Support defining temporal relations between eventsAll FHIR resource types processed by PhenoMan possessone or more date attributes. The relevant date attributeswere implemented and associated with the correspond-ing resource types. When the PhenoMan receives re-sources from the FHIR Server, the dates of the resourcesare considered and can be used as variable values in for-mulas of NDeP classes (the dollar sign in the variablename indicates the resource date as variable value, Fig.4b1).Use standardised terminologies, ontologies, and facilitatereuse of value setsIn the SMITH project, the metadata (catalogue of items,data elements) is specified using the software ART-DECOR [17]. ART-DECOR is very suitable to specifyterminology associations (e.g., LOINC, SNOMED, ICD,RxNorm) and value sets. The PhenoMan integrates themetadata from ART-DECOR and uses the specified ter-minology associations and value sets (codes) to querythe HDS and to write the inferred phenotypes.Define representations for text searching and naturallanguage processingIn SMITH, a NLP module is upstream that extracts andtransforms relevant data from unstructured EHR docu-ments into structured form. The structured data is thenintegrated in the HDS, so that the PhenoMan can workonly with structured data.Provide interfaces for external software algorithmsWe use the Java Expression Evaluator (EvalEx) [27] formathematical calculations, but the integration of otherlibraries (e.g., for executing R scripts) or rule systems(e.g., SWIRL or Drools) is also possible and will be eval-uated in future work.Maintain backward compatibilityOur ontological phenotype representation model is ro-bust to changes in EHR data, used terminologies andstandards. If, for instance, in our T2DM example bothICD9 and ICD10 must be supported, the missing codes(ICD10) have to be completed in the correspondingPheSO. Additionally, we develop a component to specifyand automatically integrate required code mappings intothe ontology. The changes in the EHR data model haveno impact on the phenotype specifications (PheSOs).The PhenoMan contains a FHIR mapping moduleimplementing all required functionalities to extract rele-vant information from FHIR resources. Supported re-source types are offered for selection during thephenotype specification and are saved in the correspond-ing PheSO. If the EHR data model changes, it is only ne-cessary to re-implement the mapping module. Theswitch from FHIR r3 to r4 has already been done.ConclusionWe developed a novel ontology-based method to modelphenotypes of living beings with the aim of automatedphenotype reasoning based on instance data (e.g., patientdata from EHR). Our solution includes an enhanced it-erative reasoning process combining classification taskswith mathematical calculations at runtime. This new ap-proach can be used in clinical context, e.g., for support-ing the diagnostic process, evaluating risk factors orrecruiting appropriate participants for clinical or epi-demiological studies. About 20 phenotype models havealready been specified and the ontology as well as thereasoning method were successfully evaluated.Our approach has currently the following limitations:1. only structured data can be considered (a NLP mod-ule is upstream); 2. mathematical calculations are onlypossible for individual data sets (no statistical evalua-tions over multiple data sets).An integration of more complex algorithms into thereasoning process is possible and has to be investigatedin respect of accessing external libraries (e.g., R scripts).The current formalism will be extended in the future tooptimise the implementation of selected desiderataexpounded by Mo et al. [7].AbbreviationsCOP: Core Ontology of Phenotypes; PheSO: Phenotype SpecificationOntology; PhenoMan: Phenotype Manager; NSiP class: Non-restricted singlephenotype class; RSiP class: Restricted single phenotype class; NCoPUciteli et al. Journal of Biomedical Semantics           (2020) 11:15 Page 15 of 17class: Non-restricted combined phenotype class; RCoP class: Restrictedcombined phenotype class; NDeP class: Non-restricted derived phenotypeclass; RDeP class: Restricted derived phenotype class; TO: Task ontology;DO: Domain ontology; TLO: Top-level ontologyAcknowledgementsAn earlier version of the paper has been presented at JOWO 2019 (JointOntology Workshops) / ODLS (Ontologies and Data in Life Sciences) in Graz,Austria.This work was supported by the German Federal Ministry of Education andResearch as part of the projects SMITH (reference number: 01ZZ1803A) andLHA (reference number: 031 L0026).We acknowledge support from the German Research Foundation (DFG) andLeipzig University within the program of Open Access Publishing.Authors contributionsAU designed and implemented the COP, the PhenoMan API and thePhenoMan Service. CB developed the PhenoMan Editor and madesubstantial contributions to the design and implementation of COP andPhenoMan. HH was responsible for project management, conception andsemantic foundation of developed ontologies. TK and FAM focus on theSMITH, LHA and LIFE integration. The authors read and approved the finalmanuscript.FundingThis work was supported by the German Federal Ministry of Education andResearch as part of the projects SMITH (reference number: 01ZZ1803A) andLHA (reference number: 031 L0026). Open Access funding enabled andorganized by Projekt DEAL.Availability of data and materialsThe PhenoMan Editor, developed ontologies and generated phenotyperepresentations (diagrams, spreadsheets) [38] used in this paper are publiclyavailable. Further software components are available from the correspondingauthor on reasonable request. At the end of the SMITH project, theconsortium will take a final decision about licensing and usage of developedsoftware components.Ethics approval and consent to participateNot applicable.More details about LIFE Adult participants, their invitation and consenting aswell as examinations, interviews, questionnaires and taken specimen can befound in [31].Consent for publicationNot applicable.Competing interestsThe authors declare that they have no competing interests.Author details1Institute for Medical Informatics, Statistics and Epidemiology (IMISE),University of Leipzig, Leipzig, Germany. 2SMITH Consortium of the GermanMedical Informatics Initiative, Leipzig, Germany. 3Growth Network CrescNet,University of Leipzig, Leipzig, Germany. 4Faculty of Applied Computer andBiological Sciences, University of Applied Sciences Mittweida, Mittweida,Germany. 5LIFE Research Centre for Civilization Diseases, University of Leipzig,Leipzig, Germany.Received: 5 May 2020 Accepted: 3 November 2020Grabar et al. Journal of Biomedical Semantics            (2020) 11:7 https://doi.org/10.1186/s13326-020-00225-xRESEARCH Open AccessCAS: corpus of clinical cases in FrenchNatalia Grabar1,2*, Clément Dalloux3 and Vincent Claveau3AbstractBackground: Textual corpora are extremely important for various NLP applications as they provide informationnecessary for creating, setting and testing those applications and the corresponding tools. They are also crucial fordesigning reliablemethods and reproducible results. Yet, in some areas, such as themedical area, due to confidentialityor to ethical reasons, it is complicated or even impossible to access representative textual data. We propose the CAScorpus built with clinical cases, such as they are reported in the published scientific literature in French.Results: Currently, the corpus contains 4,900 clinical cases in French, totaling nearly 1.7M word occurrences. Someclinical cases are associated with discussions. A subset of the whole set of cases is enriched with morpho-syntactic(PoS-tagging, lemmatization) and semantic (the UMLS concepts, negation, uncertainty) annotations. The corpus isbeing continuously enriched with new clinical cases and annotations. The CAS corpus has been compared withsimilar clinical narratives. When computed on tokenized and lowercase words, the Jaccard index indicates that thesimilarity between clinical cases and narratives reaches up to 0.9727.Conclusion: We assume that the CAS corpus can be effectively exploited for the development and testing of NLPtools and methods. Besides, the corpus will be used in NLP challenges and distributed to the research community.Keywords: Medical area, Natural language processing, Corpus with clinical cases, Morpho-syntactic and semanticannotation, Sustainability, ReproducibilityBackgroundTextual corpora are central for various NLP applicationsas they provide information necessary for creating, set-ting, testing and validating these applications, the cor-responding tools, and the results. Yet, in some areas,due to confidentiality or to ethical reasons, it is compli-cated or even impossible to access representative textualdata typically created and used by the actors of theseareas. For instance, medical and legal areas are concernedwith these issues: in the legal area, information on law-suits and trials remains confidential, while in the medicalarea, medical confidentiality must be respected by themedical staff. In both situations, personal data cannotbe made publicly available, which prevents corpora from*Correspondence: natalia.grabar@univ-lille.frNatalia Grabar, Clé Dalloux and Vincent Claveau contributed equally to thiswork.1CNRS, UMR 8163, F-59000 Lille, France2Univ. Lille, UMR 8163 - STL - Savoirs Textes Langage, F-59000 Lille, FranceFull list of author information is available at the end of the articlebeing released and makes experiments non-reproducibleby other researchers and with other methods. To face suchsituations, Natural Language Processing (NLP) proposesspecific methods and tools. Hence, for several years now,anonymization and de-identification methods and toolshave been made available and provide competitive andreliable results [14] reaching up to 90% precision andrecall. But it may still be difficult to access de-identifieddocuments and use them for research. One reason is thatthere is a risk of re-identification of people, and moreparticularly of patients [5, 6] because medical historiescan be unique. In consequence, the application of de-identification tools on personal data often does not permitto make the data freely available and usable within theresearch context.Yet, there is a real need for the development of methodsand tools for several applications suited for such restrictedareas. For instance, in the medical area, it is impor-tant to design suitable tools for information retrieval andextraction, for recruiting patients for clinical trials, for© The Author(s). 2020 Open Access This article is licensed under a Creative Commons Attribution 4.0 International License,which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriatecredit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes weremade. The images or other third party material in this article are included in the articles Creative Commons licence, unlessindicated otherwise in a credit line to the material. If material is not included in the articles Creative Commons licence and yourintended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directlyfrom the copyright holder. To view a copy of this licence, visit http://creativecommons.org/licenses/by/4.0/. The CreativeCommons Public Domain Dedication waiver (http://creativecommons.org/publicdomain/zero/1.0/) applies to the data madeavailable in this article, unless otherwise stated in a credit line to the data.Grabar et al. Journal of Biomedical Semantics            (2020) 11:7 Page 2 of 10performing several other important tasks such as index-ing, study of temporality, negation, etc. [713]. Anotherimportant issue is related to the reliability of tools andto the reproducibility of study results across similar datafrom different sources. The scientific research and clin-ical communities are indeed increasingly coming undercriticism for the lack of reproducibility in the biomedicalarea [1416], but notice that, for instance, psychology isconcerned with this issue as well [1719]. The first steptowards the reproducibility of results is the availability offreely usable tools and corpora. In the current contribu-tion, we are mainly concerned with the construction offreely available corpora for the medical domain. Yet, weare aware that sharing tools and methods is also impor-tant. We assume that availability of corpora may boost thedesign and dissemination of other resources, methods andtools for biomedical tasks and applications.The purpose of our work is to introduce the CAS cor-pus, that contains clinical cases in French such as thosepublished in scientific literature or used in the educationand training of medical students. In what follows, we firstpresent some existing studies onmedical corpora creation(Existing work: freely available clinical corpora), high-lighting corpora which are freely available for research.We then present the methods used for building, annota-tion and analysis of the CAS corpus with clinical cases inFrench (Methods). The results are presented in Resultsand discussed in Discussion. We conclude with somedirections for future work (Conclusion sections). Thework presented in this article is an extended and updatedversion of our previous publication [20].Existing work: freely available clinical corporaWithin the medical area, we can distinguish two maintypes of medical corpora: scientific and clinical. Scientific corpora are issued from scientificpublications and reporting. Such corpora arebecoming increasingly available to researchers thanksto recent and less recent initiatives dedicated to openpublication, such as those promoted by the NLM(National Library of Medicine) through the PUBMEDportal1 and specifically dedicated to the biomedicalarea, and by the HAL2 and ISTEX3 initiatives, whichprovide generic portals for accessing scientificpublications from various areas, including medicine.Such corpora contain scientific publications thatdescribe research studies: motivation, methods,results and issues on precise research questions.Other portals may also provide access to scientificliterature aimed at specific purposes, namely indexing1https://www.ncbi.nlm.nih.gov/pubmed2https://hal.archives-ouvertes.fr/3https://www.istex.fr/reliable literature, such as proposed by HON [21],CISMEF [22], and other similar initiatives [23]. Someexisting scientific corpora also provide annotationsand categorizations, such as PoS-tagging [24] andnegation [25]. These are often built for the purposesof shared tasks [26, 27]. Clinical corpora are related to hospital and clinicalevents of patients. Such corpora typically containdocuments that describe medical history of patientsand the medical care they are undergoing. This kindof corpora is typically created and used in clinicalcontext as part of the healthcare process. Even afterde-identification, it is complicated to obtain freeaccess to this kind of medical data and, for thisreason, there are very few clinical corpora freelyavailable for research.In our work, we are mainly interested in clinical cor-pora: the proposed literature review of the existing workis aimed at clinical corpora that are freely available forresearch. We present here the main existing clinical cor-pora: MIMIC (Medical Information Mart for IntensiveCare), now available in its third version, provides thelargest available set of structured and unstructuredclinical data in English. MIMIC III is a single-centerdatabase comprising information pertaining topatients admitted in critical care units at a largetertiary care hospital. Those data include vital signs,medications, laboratory measurements, observationsand notes charted by care providers, fluid balance,procedure codes, diagnostic codes, imaging reports,hospital length of stay, survival data, and more. Thedatabase supports applications including academicand industrial research, quality improvementinitiatives, and higher education coursework [28].Those data are widely used by researchers, forinstance for predicting mortality [29, 30], fordiagnosis identification and encoding [31, 32], forstudies on temporality [33] or for identifying similarclinical notes [34], to cite just a few existing studies.Data from these corpora are also used in challenges,such as i2b2, n2c2 and CLEF-eHEALTH. i2b2 (Informatics for Integrating Biology and theBedside)4 is an NIH-funded initiative promoting thedevelopment and test of NLP tools forEnglish-language documents with the purpose ofhealthcare improvement. In order to enhance theability of NLP tools to process fine-grainedinformation from clinical records, i2b2 challengesprovide sets of fully de-identified clinical notesenriched with specific annotations [9, 11, 35], such as:4https://www.i2b2.org/NLP/DataSets/Main.phpGrabar et al. Journal of Biomedical Semantics            (2020) 11:7 Page 3 of 10de-identification, smoking status, medication-relatedinformation, semantic relations between entities, ortemporality. The clinical corpora and theirannotations built for the i2b2 NLP challenges areavailable now for general research purposes. n2c2 (National NLP Clinical Challenges),5 held in2018 and 2019, also address the processing ofEnglish-language clinical documents. Thesechallenges are dedicated to other typical tasks whenhandling clinical documents: inclusion of patients inclinical trials, detection of adverse-drug events,computing of textual semantic similarity, conceptnormalization, and extraction of family history. CLEF-eHEALTH challenges6 held in 2013 and 2014provide annotations for disorder detection andabbreviation normalization. In 2016 the focus was onstructuring Australian free-text nurse notes. Finally,in 2016 and 2017 death reports in French, providedby the CépiDc,7 have been processed for death causeextraction. eHealth-KD 2019 challenge8 targets human languagemodelling in a scenario in which electronic healthdocuments in Spanish could be machine readablefrom a semantic point of view. The two proposedtasks are: identification and classification of keyphrases, and detection of semantic relations betweenthese key phrases.Finally, medical data, close to those handled in the clini-cal context, can be found in clinical trials protocols. Oneexample is the corpus of clinical trials annotated withinformation on numerical values in English [36], and onnegation in French and Brazilian Portuguese [37, 38].MethodsWe first describe the specificity of the sources and clinicalcases from which the CAS corpus was created (Buildingthe corpus), then the annotation rationale (Annotationof the corpus), and the principles of its comparison withsimilar clinical narratives from Rennes University Hospi-tal (Comparison with clinical narratives sections).Building the corpusThe CAS corpus in French contains clinical cases aspublished in scientific literature, legal or training mate-rial. Hence, it is built using material freely availablein online sources. The collected clinical cases are pub-lished in different journals and websites from French-speaking countries in various continents. Those clinical5https://n2c2.dbmi.hms.harvard.edu/6https://sites.google.com/site/shareclefehealth/7http://www.cepidc.inserm.fr/8https://knowledge-learning.github.io/ehealthkd-2019cases are related to various medical specialties (e.g. cardi-ology, urology, oncology, obstetrics, pulmonology, gastro-enterology...).The purpose of clinical cases is to describe clinical sit-uations for real de-identified or fake patients. Commonclinical cases are typically part of education programsused for training medical students, while rare cases areusually shared through scientific publications to illustrateless common clinical situations. As for clinical cases whichcan be found in legal sources, they usually report on situ-ations which became complicated due to various reasonsemanating from different healthcare levels: medical doc-tor, healthcare team, institution, health system and theirinteractions.Similarly to clinical documents, the content of clinicalcases depends on the clinical situations that are illustrated,and on the disorders, but also on the purpose of the pre-sented cases: description of diagnoses, treatments or pro-cedures, evolution, family history, adverse-drug reactions,expected audience, etc.Data in published clinical cases are de-identified by theauthors prior to their publication. Besides, publicationis usually done with the written permission of patients.The case reports can be related to any medical situa-tion (diagnosis, treatment, procedure, follow-up...), to anyspecialty and to any disorder. The typical structure ofscientific publications with clinical cases starts by intro-ducing the clinical situation, then one or more clinicalcases are presented to support the situation. Schemes,imaging, examination results, patient history, lab results,clinical evolution, treatment, etc. can also be provided forthe illustration of clinical cases. Finally, those clinical casesare discussed. Hence, such cases may present an exten-sive description of medical problems. Such publicationsgather medical information related to clinical discourse(clinical cases) and to scientific discourse (introductionAlthubaiti et al. Journal of Biomedical Semantics            (2020) 11:1 https://doi.org/10.1186/s13326-019-0218-0RESEARCH Open AccessCombining lexical and context featuresfor automatic ontology extensionSara Althubaiti1,2, S¸enay Kafkas1,2 , Marwa Abdelhakim1,2 and Robert Hoehndorf1,2*AbstractBackground: Ontologies are widely used across biology and biomedicine for the annotation of databases. Ontologydevelopment is often a manual, time-consuming, and expensive process. Automatic or semi-automatic identificationof classes that can be added to an ontology can make ontology development more efficient.Results: We developed a method that uses machine learning and word embeddings to identify words and phrasesthat are used to refer to an ontology class in biomedical Europe PMC full-text articles. Once labels and synonyms of aclass are known, we use machine learning to identify the super-classes of a class. For this purpose, we identify lexicalterm variants, use word embeddings to capture context information, and rely on automated reasoning overontologies to generate features, and we use an artificial neural network as classifier. We demonstrate the utility of ourapproach in identifying terms that refer to diseases in the Human Disease Ontology and to distinguish betweendifferent types of diseases.Conclusions: Our method is capable of discovering labels that refer to a class in an ontology but are not present in anontology, and it can identify whether a class should be a subclass of some high-level ontology classes. Our approachcan therefore be used for the semi-automatic extension and quality control of ontologies. The algorithm, corpora andevaluation datasets are available at https://github.com/bio-ontology-research-group/ontology-extension.Keywords: Disease ontology, Embeddings, Neural networkBackgroundThe biomedical community has spent significantresources to develop biomedical ontologies which con-tain and define the basic classes and relations that occurwithin a domain. Biomedical ontologies are developed bydomain experts and are often developed in conjunctionwith the needs arising in literature-based curation ofbiological databases.Manual curation of databases based on literature is avery time-consuming task due to the massive amounts ofliterature, and automated methods have been developedearly on to aid in curation [1]. One of the key tasks incomputational support for literature curation is the auto-matic concept recognition of mentions of ontology classesin text [2]. An ontology class is an intensionally defined*Correspondence: robert.hoehndorf@kaust.edu.sa1Computational Bioscience Research Center, King Abdullah University ofScience and Technology, 23955-6900 Thuwal, Saudi Arabia2Computer, Electrical and Mathematical Sciences and Engineering Division,King Abdullah University of Science and Technology, 23955-6900 Thuwal,Saudi Arabiaentity that has a formal descriptionwithin an ontology andaxioms that determine its relation with other classes [3]. Innatural language, multiple terms and phrases can be usedto refer to an ontology class [4], and the formal depen-dencies within an ontology further determine whether aterm refers to a class or not (i.e., whether a term refers toa particular class may depend on background knowledge,in particular subclass relations, contained in an ontol-ogy). For example, the Disease Ontology (DO) [5] declaresPrediabetes syndrome (DOID:11716) to be a subclassof Diabetes mellitus (DOID:9351), and based on thisinformation we assume that any reference to, or mentionof, Prediabetes syndrome is also a reference to Diabetesmellitus (with respect to DO).There are several text mining systems designed forontology concept recognition in text. These methods areeither based on lexical methods and therefore applicableto a wide range of ontologies [6, 7] or they are domain-specific and rely on machine learning [8]. Text mining© The Author(s). 2020 Open Access This article is distributed under the terms of the Creative Commons Attribution 4.0International License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, andreproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to theCreative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver(http://creativecommons.org/publicdomain/zero/1.0/) applies to the data made available in this article, unless otherwise stated.Althubaiti et al. Journal of Biomedical Semantics            (2020) 11:1 Page 2 of 13based-methods can also be used to automatically or semi-automatically construct and extend ontologies [9, 10]. Forexample, Lee et al. [11] focus on text mining of relationsthat are asserted in text between mentions of ontologyclasses that has been used to refine ontology classes in theGene Ontology (GO) [12]. Text mining can also be used tosuggest new subclasses and sibling classes in ontologies,for exampleWächter and Schroeder [13] carried out a textmining based-system from different text sources which isused for extending OBO ontologies by semi-automaticallygenerating terms, definitions and parentchild relations.Xiang et al. [14] have developed a pattern-based systemfor generating and annotating a large number of ontologyterms, following ontology design patterns and providinglogical axioms that may be added to an ontology. Recently,clustering based on statistical co-occurrence measureswere also used to extend ontologies [15].Here, we introduce a novel method relying on machinelearning to identify whether a word used in text refersto a class that could be included in a particular ontol-ogy. Essentially, our method classifies terms to determineif they are usually mentioned in the same context as thelabels and synonyms of classes in an ontology (which areused as seeds to train the classifier); this classifier can thenbe applied to unseen terms. Furthermore, our method canalso be used to expand ontologies by suggesting terms thatare mentioned within the same context as specific classesin an ontology.We demonstrate the utility of our method in identi-fying words referring to diseases from DO in full textarticles. We select the DO because the labels and syn-onyms of DO classes are relatively easy to detect in textand a large number of computational methods rely onaccess to a comprehensive disease ontology [1619]. Ourmethod achieves highly accurate (F-score > 90%) androbust results, is capable of recognizing multiple differentclasses including those defined formally through logicaloperators, and combines dictionary-based and context-based features; therefore, our method is also capable offinding new words that refer to a class. We manuallyevaluate the results and suggest several additions to theDO.MethodsBuilding a disease dictionaryWe built a dictionary from the labels and synonymsof classes in the Disease Ontology (DO), downloadedon 5 February 2018 from http://disease-ontology.org/downloads/. The dictionary consisted of 21,788 termsbelonging to 6,831 distinct disease classes from DO. Weutilized the dictionary with the Whatizit tool [20] andannotated the ontology class mentions along with theiridentifiers in approximately 1.6 million open access full-text articles from the Europe PMC database [21] (http://europepmc.org/ftp/archive/v.2017.06/) and generated acorpus annotated with mentions of classes in DO. Wepreprocessed the corpus by removing stop words such asthe, a, and is as well as some punctuation characters.Generating context-based featuresWe use Word2Vec [22] to generate word embedding.Specifically, we use a skip-gram model which aims to findword representations that are useful for predicting thesurrounding words in a given sentence or a documentconsisting of sequence of words; w1,w2, ...,wK . The objec-tive is to maximize the average log probability using thefollowing formula:V (w) = 1KK?k=1K??c?j?c;j =0log p(wK+j|wK ) (1)where word vectors V (w) are computed by averaging overthe number of words K and c is the size of the trainingcontext. We generated the word embedding by using thedefault parameter settings of theWord2Vec gensim imple-mentation: vector size (dimensionality) of 100, windowsize 5, minimum occurrence count of 5, and we use askip-gram (sg) model.Supervised trainingWe carried out a set of experiments to choose the optimaltraining algorithm to design our model. In our experi-ments we used default parameters for the training algo-rithms but different hidden layers for Artificial NeuralNetworks (ANNs) [23]. Our experiments show that theANN model outperforms an SVM model [24] (see Addi-tional file 1: Table 1 for full details), and our modelperforms best with 200 neurons in a single hidden layer(we tested a single hidden layer with a size of 10, 50,100, and 200 neurons). We report results accordingly to amodel with 200 neurons in the remainder of this work. InANNs, multiple neurons are organized in layers. Typically,different layers perform different kinds of transforma-tions on their inputs [25]. In our experiments, we usedan ANN with an input layer of different sizes, a singlehidden layer that uses a sigmoid activation function, andan output layer that differs based on the experiment. Wetrain each classifier in a supervised manner, using 10-foldstratified cross-validation. Additionally, we report testingperformance on an independent 20% testing set whichwe generated by randomly removing data points beforetraining.Recognizing ontology classes in textWe used two approaches to recognize the mention ofontology classes in text. Our first approach relies solely onlabels and synonyms of the classes within a given ontol-ogy O and can be used to determine whether a word referAlthubaiti et al. Journal of Biomedical Semantics            (2020) 11:1 Page 3 of 13to a class in O. We first obtain an ontology O in the WebOntology Language (OWL) [26] format and extract a listof class labels and synonyms L from O; we further utilizea text corpus T as input to our method. Then, we gener-ate word embeddings (i.e., vector-space encodings of thecontexts in which a word occurs) for all words in our textcorpus T and train a supervised machine learning modelto classify whether a word refers to a class in O or not(using the Ls words as positive training instances and allothers as negative instances).Figure 1 illustrates the workflow of our first approach.Our method is generic and can, in principle, be appliedto any ontology as long as the ontology provides labels(or synonyms), these labels can be identified in text, andthe ontology from which the labels are extracted is moreor less limited to a single domain. For example, refer-ence ontologies in the OBO Foundry [27] are usuallysingle domain ontologies and therefore suitable for ourmethod. Ontologies that would not be suitable are appli-cation ontologies that cover multiple domains, such as theExperimental Factor Ontology (EFO) [28] (although ourmethods can be applied to parts of it). It is most useful toextend an existing ontology with new labels, synonyms, orclasses.In our second approach, we rely on annotations fromthe Whatizit tool [20] to identify the mention of ontologyclasses in text and determine their specific superclasses inan ontology. Our approach takes an ontology O in OWLformat, a set of ontology classes S = {C1, ...,Cn}, and acorpus of text T as inputs.This approach first uses Whatizit as a named entityrecognition and normalization tool to normalize classlabels and synonyms in text by replacing all mentionsof a class with the class identifier (i.e., the class URI).We annotate 15,183 distinct terms using Whatizit; thetotal dictionary consists of 21,788 terms (derived fromthe labels and synonyms of classes in DO). We then trainWord2Vec model that captures the context of the men-tion of the class and generates a vector space embeddingfor that class. Given such vector space embeddings fora set of classes in O, we use the vector space embed-dings as input to a machine learningmethod that classifieswhether another class appears in a similar context. Weuse this method to determine if a class should belong thesuperclass of C in O. Figure 2 illustrates the workflow ofthis approach.The main difference between the two approaches is thatthe first approach broadly identifies terms or words thatrefer to classes within a domain (as defined by the sumof classes within an ontology) while the second approachcan determine whether a term or word refers to a classthat should appear as a subclass of a more specific ontol-ogy class. Both methods generate seed words in text andthen use these seeds first to generate context-based fea-tures (through Word2Vec) and use these context-basedfeatures in a supervised machine learning classifier.Manual analysis processWe manually evaluate some of our findings. The manualevaluation is based on the medical expert knowledge ofthe evaluator who is a trained clinician, and supplementedby literature search to validate some findings or resolveconflicts. Mainly, results were confirmed by searchingfor review papers that characterize a condition. Overall,Fig. 1 Label-based workflow. The workflow describes how words (in red) are classified as disease or otherAlthubaiti et al. Journal of Biomedical Semantics            (2020) 11:1 Page 4 of 13Fig. 2 Annotation-based workflow. In this workflow, we first normalize the mentions of disease classes in the corpus and then apply Word2Vec togenerate embeddings for classes, not merely wordsmanual curation following the suggestions by our classi-fier took 10-15 min per sample (which included identify-ing related classes in the DO and drafting an explanationfor cases which disagree with the DO).ResultsBroad classification of domain-specific terms: applicationto diseasesOur method is a workflow that can be used to identifywhether a term or phrase commonly refers to a classthat may be included in a domain-specific ontology as alabel, synonym, or a new class. To achieve this goal, weuse the existing labels and synonyms within a domain-ontology as seeds to train a machine learning classifierthat determines whether a new term is sufficiently similarto an existing label or synonym and may therefore also beincluded in the ontology. We represent terms primarily bythe context in which they occur within a large corpus oftext; we useWord2Vec [22] for this purpose.We then trainan Artificial Neural Network classifier in a supervisedmanner to distinguish between the terms already includedwithin a domain ontology (and therefore expected to referto a particular kind of phenomena) and randomly chosenterms not included in the ontology (and therefore mostlikely not referring to a phenomenon within the domainof the ontology).We demonstrate our method using the Human Dis-ease Ontology (DO) [5] and applying it to the termsoccurring in a large corpus of full-text biomedical articles(see Methods). First, we tested whether our approach iscapable of identifying words that refer to the Disease class(DOID:4), i.e., whether our method can detect termsthat refer to a disease. We generated word embeddingsfor every disease terms and other words in our corpus offull-text articles.Figure 3 illustrates the distribution of the terms refer-ring to a diseases in DO and other words mentioned inour corpus which do not belong to DO using the t-SNEdimensionality reduction [29]. We can see that the termsare clearly different and should be separable through amachine learning system.Therefore, we trained a machine learning model torecognize whether a word refers to the disease or notusing the word embeddings as input. We split the vec-tor space embeddings into a training and testing datasetand consider all embeddings referring to disease as pos-itive instances and all others as negatives. We do notapply any filtering before selecting the positive or negativesamples. We randomly select negatives equal to the num-ber of positives (7,932 positives and 7,932 negatives). Wewithhold 20% of randomly chosen positive and negativeinstances for testing, train a model on the remaining 80%through 10-fold cross validation, and report the perfor-mance results on the 20% test set. Evaluated on the testingset, we can distinguish between disease and non-diseaseterms with an F-score of 95% and AUC of 96% (see Table 1and Figure 4).To better understand the source of errors and whetherour approach can be used to reliably extend ontolo-gies (either with additional labels and synonyms, or newAlthubaiti et al. Journal of Biomedical Semantics            (2020) 11:1 Page 5 of 13Fig. 3 a) The visualization of the embeddings using the t-SNE for binary-classification task b) The visualization of the embeddings using the t-SNEfor classifying infectious diseases. c) The visualization of the embeddings using the t-SNE for classifying anatomical diseases. d) The visualization ofthe embeddings using the t-SNE for classifying the combination of infectious and anatomical diseasesclasses), we performed a manual analysis on a set of 20false positive samples out of 197 which are not the label orsynonym of a disease class DO but are classified as diseaseby our classifier (see Table 2). We found that the majorityof the 20 false positive samples refer to either diseases orphenotypes (where phenotypes are the observable char-acteristics of an organism that may occur manifestations,or signs and symptoms, of a disease, but do not constitutea disease on its own). For example, Aphthosis is a pre-diction of our method which refers to a human disorderthat is not currently in the DO; the majority of false pos-itives are disease-related terms that do not explicitly referto a disease. For example, we predictedmal-absorption asa disease term which may refer to a phenotype in somecontexts. Our findings indicate that an ANN classifiercan identify known terms referring to diseases, and canfurther suggest novel terms which may prove useful forontology development and extension.Fine-grained classification: distinguishing between groupsof diseasesAs our method showed capability to identify terms refer-ring to a disease, we next tested whether our method canalso distinguish between different types of diseases. Forthis purpose, we used the embeddings generated from apre-processed corpus in which we normalize all mentionsTable 1 F-score and AUC for our four experiments using different hidden layer sizesClassification Hidden layer sizes 10 50 100 200Number of classes F-score AUC F-score AUC F-score AUC F-score AUCDiseases 2 94.65% 95.31% 94.83% 95.97% 95.32% 96.06% 94.49% 95.99%Infectious disease 5 95.65% 95.01% 96.01% 95.74% 95.43% 95.22% 95.68% 96.42%Anatomical disease 13 69.18% 77.22% 70.15% 80.24% 70.20% 76.98% 72.00% 85.11%Infectious + anatomical diseases 17 71.07% 84.75% 73.13% 84.03% 72.61% 84.98% 72.67% 83.66%The values in bold represent the highest AUC and F-score within each experimentsAlthubaiti et al. Journal of Biomedical Semantics            (2020) 11:1 Page 6 of 13Fig. 4 ROC curves for each experiment (Diseases, Infectious disease, Anatomical disease and a combination of Infectious disease + Anatomical disease)of a disease in our corpus using Whatizit tool. The dis-ease dictionary that we utilized with Whatizit includes atotal of 21,788 terms (labels and synonyms) from DO. Wefound that 15,183 of these 21,788 terms appeared in ourcorpus and we generate an embedding vector for each ofthem. We then first trained a neural network model torecognize whether a disease-term refers to the InfectiousDisease (DOID:0050117) class or not, and furthermorewhether our method is able to distinguish between thefour different types of infectious disease in DO (i.e., bac-terial, fungal, parasitic, or viral infectious disease). Astraining data, we used the word embeddings generated forDO classes, and we used the Elk reasoner to split theminto four types of infectious diseases, and an additionalclass for diseases that are not a subclass of Infectious Dis-ease in DO. We randomly select 20% of the disease inDO as validation set and train the neural network classi-fier using 10-fold cross-validation on the remaining 80%to separate diseases into one of the five classes (non-infectious, bacterial, fungal, parasitic and viral infections).Table 1 shows the performance achieved on the validationset.While the performance is less than predicting whethera term refers to a disease, our classifier can distinguishbetween specific disease classes.We manually analyzed a set of 20 false positive samplesout of 38 which are not a subclass of Infectious disease inthe DO but are classified as infectious by our classifier (seeTable 3). We found that 7 of these 20 cases can be sug-gested to be subclasses of the specific infectious diseasethey have been classified with but do not have a subclassrelation asserted or inferred in DO. For example, the termsyphilitic meningitis (DOID:10073) is a disease that ourmethod classify as a bacterial infectious disease but it isnot classified as infectious in the DO.Moreover, to test the strength of our method to distin-guish between disease classes, we further trained a neuralnetwork model to distinguish between the 12 differentsubclasses of Disease of anatomical entity (DOID:7), aswell as an additional class for diseases not classified assubclasses of Disease of anatomical entity. We used theAlthubaiti et al. Journal of Biomedical Semantics            (2020) 11:1 Page 7 of 13Table 2 Manually analyzed disease terms predicted as diseaseTerm Manual analysis result Explanation for the suggested diseasesFACTO other -leucoencephalopathy other -Aphthosis Disease A disease refers to a condition with repetitive mucosal ulcers[30, 31].Desmoid other -metapneumovirus other -Tracheobronchomalacia Disease A rare condition with abnormal flaccidity of both the tracheaand the bronchi which results in possibility of narrowing orcollapse of the airway [3234].RESLES Disease A rare condition characterized by transient lesions in the cen-tral part of the splenium of the corpus callosum (SCC), followedby complete reversibility on follow-up magnetic resonanceimaging (MRI) after a variable period. It coincides with differentdiseases [35, 36].mal-absorption other -acroparesthesias other -limb-shaking other -pineocytomas Disease A rare disease that has an Orphanet ID: ORPHA:251912. It isone of the pineal parenchymal tumors and is considered theleast aggressive one [37, 38].hypomineralisation other -neurognathostomiasis Disease It is a severe form of human gnathostomiasis, DOID:11379,which can lead to disease and death, it involves the nervoussystem [3941].Metastasis other -myelomatosis Disease A type of cancer that begins in plasma cells that produce anti-bodies. It could be one of the synonyms of multiple myelomaDOID:9538 [42, 43].AMRF Disease An OMIM disease, OMIM:254900 [44].arthralgia other -fibrodentinoma Disease Fibrodentinoma is a benign odontogenic tumor that occursin children and young adults. The disease name usually isrepresented as Ameloblastic Fibrodentinoma [45, 46].infantile-ataxia other -knowlesi other -The terms in bold represent the correctly validated terms (by a clinician) that classified as diseases terms using our method (in Diseases classification experiment).same method to split the classes in training and test set asbefore. Results are shown in Table 1 and demonstrate thatour method can also be useful to classify diseases in theiranatomical sub-systems.We manually analyzed a set of 20 false positive samplesout of 127 which are not a subclass of Anatomical dis-ease in the DO but are classified as being a subclass of aparticular anatomical system disease by our classifier (seeTable 4). We found that 12 of the 20 false positives can besuggested to be subclasses of the specific anatomical sys-tem disease they have been classified with but do not havesuch a subclass relation asserted or inferred in DO. Forexample, we classify Narcolepsy (DOID:8986) as a Ner-vous system anatomical disease, and this may be added asa new subclass axiom to DO.As it is often inconvenient to train separate classifiers,we also combined both tasks and trained a multi-classclassifier to classify disease classes either as infectious oranatomical, or as other disease. We evaluate the perfor-mance of this combined model (see Table 1), and ourmachine learning system achieves an AUC up to 84% (seeFigure 4). These results demonstrate it may be possible toidentify new subclasses, although the performance dropswhen we increase the complexity of the classificationproblem by distinguishing between more subclasses.DiscussionWe developed a method to automatically expand ontolo-gies in the biomedical domain with new classes, syn-onyms, or axioms. We demonstrate the utility of ourAlthubaiti et al. Journal of Biomedical Semantics            (2020) 11:1 Page 8 of 13Table 3 Sample of manually analyzed disease terms predicted as infectious diseaseDisease terms Ontology class assignedby ANNManual analysis result Suggested additionalclassificationDOID ExplanationPelizaeus-MerzbacherdiseaseViral infectious disease Non-infectious (inheriteddisorder)- - -Kaposis sarcoma Viral infectious disease Viral infectious disease herpes simplex DOID:8566 The disease is caused byHuman herpesvirus 8which is Herpesviridaeinfection.maxillary sinusitis Bacterial infectious disease Bacterial infectious disease(usually start viral andprogress to eitherbacterial or fungal)- - It is an infection in themaxillary sinuses whichcould be due to differentetiology, one of them isbacterial [47].keratosis follicularis Bacterial infectious disease Non-infectious (geneticdisease)- - -chronic rheumaticpericarditisViral infectious disease The condition is triggeredby autoimmune reactionto infection, mainly groupA streptococci.- - -gastroparesis Viral infectious disease In most cases the nerve isdamaged by diabetes orsurgery, however, a viralinfection might be a cause- - A condition in which thestomach suffers fromparesis that affects thefood movement to thesmall intestine [48, 49].osmotic diarrhea Bacterial infectious disease symptom - - -familial coldautoinflammatorysyndromeViral infectious disease Non-infectious (inheriteddisease)- - -angular cheilitis Fungal infectious disease Etiology is controversial,most commonly fungal orbacterial.- - Ambiguous.Binder syndrome Viral infectious disease Congenital disease - - -hypohidrosis Bacterial infectious disease Multi-causal - - -Sjogrens syndrome Viral infectious disease autoimmune disease - - -median rhomboidglossitisFungal infectious disease Etiology is controversial,however it is consideredas a variant of orallesionassociated with candidainfection [50].- - Ambiguous.Goodpasture syndrome Viral infectious disease autoimmune disease - - -syphilitic meningitis Bacterial infectious disease Bacterial infectious disease syphilis DOID:4166 Considering the sameconcept of etiology, bothdiseases are caused bybacterial infection(Treponema pallidum).acute diarrhea Viral infectious disease symptom - - -WHIM syndrome Bacterial infectious disease Congenital disease - - -erythrasma Fungal infectious disease Bacterial infection disease - - -chronic wasting disease Parasitic infectious disease Neurodegenerativedisorder- - -scarlet fever Bacterial infectious disease Bacterial infectious disease rheumatic fever DOID:1586 The disease is caused byGroup A bacteria of thegenus Streptococcus,same causative agent forRheumatic fever.The terms in bold represent the correctly validated terms (by a clinician) that classified as infectious diseases terms using our method (in Infectious disease classificationexperiment).Althubaiti et al. Journal of Biomedical Semantics            (2020) 11:1 Page 9 of 13Table 4 Sample of manually analyzed disease terms classified as affecting particular anatomical systemsDisease terms OntologyclassOntologyclassassigned byANNManual analysisresultSuggestedadditionalclassificationDOID ExplanationTimothysyndromegeneticdiseasecardiovascularsystemdiseaseCannot specify(affect multipleparts)- - -Familial periodicparalysisdisease ofmetabolismcardiovascularsystemdiseasemusculoskeletalsystem disease- - -Hyperprolactinemiadisease ofmetabolismendocrinesystemdiseaseendocrine systemdiseasepituitary glanddiseaseDOID:53 The pituitary gland isthe endocrine glandresponsible forsecreting prolactin.Angiokeratomacircumscriptumdisease ofcellularproliferationgastrointestinalsystemdiseasecardiovascularsystem disease- - -Zollinger-Ellisonsyndromesyndrome gastrointestinalsystemdiseasegastrointestinalsystem diseasepeptic ulcer disease DOID:750 It is a disease thataffects eitherpancreas, duodenum,or both of them. Bothorgans are pats of theGIT system. Thedisease pathologyis mainly excessivegastrin secretion withsubsequent pepticulcers.Polycystic liverdiseasegeneticdiseasegastrointestinalsystemdiseasegastrointestinalsystem diseaseliver disease DOID:409 It is a genetic disorderthat affects primarilythe liver.Bilirubinmetabolicdisorderdisease ofmetabolismhematopoieticsystemdiseasehematopoieticsystem diseasekernicterus due toisoimmunizationDOID:12043 Bilirubin disordercould be a result ofblood pathology,same as for thementionedclassificationDOID:12043.Alphathalassemiageneticdiseasehematopoieticsystemdiseasehematopoieticsystem diseasehemoglobinopathy DOID:2860 The disease is mainly ahemoglobindisorder withhematologicalphenotypes.Kabuki syndrome syndrome immune sys-tem diseaseNot anatomical- multisystems- - -Amyloidosis disease ofmetabolismimmune sys-tem diseaseNot anatomical -multisystems- - -Fatty liver disease disease ofmetabolismmusculoskeletalsystemdiseasegastrointestinalsystem disease- - -Renal-hepatic-pancreaticdysplasiaphysicaldisordermusculoskeletalsystemdiseaseCannot specify(affect multipleparts)- - -Radioulnar syn-ostosisphysicaldisordermusculoskeletalsystemdiseasemusculoskeletalsystem diseasebone developmentdisease/SynostosisDOID:0080006/DOID:11971There is already anentity in the DO forsynostosis underbone developmentdisease.Hypophosphatasia geneticdiseasemusculoskeletalsystemdiseasemusculoskeletalsystem diseasebone remodelingdiseaseDOID:0080005 We could suggestan additionalclassification basedon the main affectedsystem. Oursuggestiveclassification ismusculoskeletal sinceAlthubaiti et al. Journal of Biomedical Semantics            (2020) 11:1 Page 10 of 13Table 4 Sample of manually analyzed disease terms classified as affecting particular anatomical systems (Continued)the disease is mainlyaffectingmineralization ofthe bone withphenotypes similar tothose of RicketsDOID:10609.Narcolepsy disease of mentalhealthnervoussystemdiseasenervous systemdisease* * *Aceruloplasminemia disease of metabolism nervoussystemdiseasenervous systemdiseaseneurodegenerationwith brain ironaccumulationDOID:0110734 The disease mainpathophysiology iseither the absenceor dysfunction ofceruloplasmin withsubsequent ironaccumulation invarious organ, mainlythe brain.Glomangiomatosis disease of cellular pro-liferationnervoussystemdiseasecardiovascularsystem disease- - -Deafness-dystonia-optic neuronopathysyndromedisease of metabolism nervous sys-tem diseasenervous systemdiseasenervous systemdisease; since itcovers manysubclasses towhich we can mapmany aspects ofthis diseaseDOID:863 The diseasesphenotypes reflectneurological affectionofmultiple parts in thenervous system.Trophoblasticneoplasmdisease of cellularproliferationreproductivesystemdiseasereproductivesystem diseaseFemalereproductive organcancerDOID:120 The term refers to thegroup ofmalignant neoplasmsthat consist ofabnormalproliferation oftrophoblastic tissuessimilar tochoriocarcinomaDOID:3596 andgestationaltrophoblasticneoplasiaDOID:3590.Cryptorchidism physical disorder reproductivesystemdiseasereproductivesystem diseasetesticular disease DOID:2519 The term refers toundescended testicle.*Nacrolepsy: is classified as a sleep disorder which is correct, however, the class itself is a subclass to mental disorders. Since there are some neurological disorders that haveshown a strong association with sleep disorder such as: neurodenegrative disorders such as tauopathy which involve Alzheimers diseases (DOID:10652) [51],synucleinopathy which involve Parkinsonism (DOID:14330) [52], and Genetic neurodegenerative disorders such as Machado-Joseph disease (DOID:1440) [53] orHuntingtons disease (DOID:12858) [54]. We suggest a new classification in which sleep disorders may also be a subclass of nervous system diseases (neurodegenerativedisorder) [55] The terms in bold represent the correctly validated terms (by a clinician) that classified as anatomical diseases terms using our method (in Anatomical diseaseclassification experiment).approach on the DO [5] which is widely used in biomed-ical research [56]. As case studies, we focused on twohigh-level classes in the DO: Infectious Diseases andAnatomical Diseases. We have evaluated our method bothusing common performance measures in machine learn-ing as well as through manually investigating some of thepredicted false positives.When applying our method to the DO, our false positivepredictions often include phenotypes or, in some cases,pathogens. It is well-established that it is challenging todistinguish between diseases and phenotypes in litera-ture [5759], as evidenced by the large overlap betweendisease ontologies and phenotype ontologies [19]. Simi-larly, diseases and pathogens can often have very similarnames [60, 61], thereby making it challenging to distin-guish between them. While a disease is defined as thestructural or functional disorder that usually results insymptoms, signs and physical or chemical changes, phe-notype refers to observable characteristics of an organismand may be a part of a disease manifestation. PhenotypeAlthubaiti et al. Journal of Biomedical Semantics            (2020) 11:1 Page 11 of 13terms cover disease symptoms, signs and the investiga-tional results that might be related to that disease. Somephenotypic terms are more diverse; for example, con-genital hemolytic anemia is a form of hemolytic anemiawith congenital onset. The term is included in both theHuman Phenotype Ontology (HP) (HP:0004804) anddisease ontology (DOID:589). From a clinical point ofview, it could be a type of disease under the umbrellaof hemolytic disorders with a congenital onset; however,congenital hemolytic anemia may also be a phenotype forcertain diseases. For this reason, deciding on some termsto be identified either as phenotypes or diseases can becomplex, challenging, and context-dependent.Another limitation of our method is the use of theWha-tizit tool [20] to detect and normalize mentions of ontol-ogy classes in text. In our first use-case  the extensionof ontologies with new labels and synonyms  we classifyterms that occur in text without relying on any prior textprocessing which has some drawbacks such as consideringa word as disease name within a general context. We useWhatizit for our second use-case  the detection of sub-class axioms  while the performance of Whatizit is lessthan domain- and task-specific named entity recognitionand normalization tools [62], Whatizits key advantageis that it is a lexical, rule-based method that does notrequire any training and is able to recognize multi-wordterms.Whatizit can therefore be applied to a wide range ofontologies without the need to generate a training dataset.To evaluate the performance of Whatizit, we tested it onthe NCBI disease corpus [16] using their test set con-taining 100 abstracts. In our evaluation, Whatizit has aprecision of 75% and recall of 15% and an F-score of 26%with an accuracy of 90% (see Additional file 2). One of thereasons for the low recall is the number of diseases whichare included in theMedical Subject Headings (MeSH) [63]or the Online Mendelian Inheritance in Man (OMIM)[64] vocabulary but not in DO. Furthermore, Whatizitignores many disease abbreviations since they are notincluded in DO (and therefore in the vocabulary used byWhatizit).ConclusionsWe presented a general method for semi-automaticallyextending ontologies with new labels, synonyms, classes,or some general subclass axioms. Our approach is basedon machine learning algorithms utilizing vector repre-sentation of the ontology classes generated from full textarticles. We demonstrated the utility of our approach onthe Human Disease Ontology (DO), specifically by find-ing new candidate classes, labels, and synonyms to addto DO such as Aphthosis, and by identifying new axiomsthat relate disease classes to their infectious agent oranatomical systems. Our method can help to improvethe quality and coverage of ontologies in the ontologydevelopment process by automatically suggesting termsto include (either as labels of new classes or synonyms ofexisting classes) and suggesting missing subclass axioms.In the future, we plan to expand our study to otherontologies and to defined classes to further analyze itsrobustness.Supplementary informationSupplementary information accompanies this paper athttps://doi.org/10.1186/s13326-019-0218-0.Additional file 1: Different conducted experiments based on differentclassification tasks.Additional file 2: The evaluation of analyzing NCBI abstracts annotatedusing Whatizit tool.AbbreviationsANNs: Artificial neural networks; AUC: Area under curve; DO: Disease ontology;EFO: Experimental factor ontology; GO: Gene ontology; HP: human phenotypeontology; MeSH: Medical subject headings; OMIM: Online mendelianinheritance in man; OWL: Web ontology language; ROC: Receiver operatingcharacteristic; Sg: Skip-gramAcknowledgementNot applicable.Authors contributionsRH conceived of the study; S¸K, SA, and RH designed the experiments. SAconducted the experiments, implemented the software and evaluated theresults. MA manually evaluated the results. SA drafted the manuscript; S¸K andRH contributed to revising the manuscript. All authors have read andapproved the final version of the manuscript.FundingThis work was supported by funding from King Abdullah University of Scienceand Technology (KAUST) Office of Sponsored Research (OSR) under AwardNoU?RF/1/3454-01-01, FCC/1/1976-08-01, and FCS/1/3657-02-01.Availability of data andmaterialsAll source code developed for this study is available from https://github.com/bio-ontology-research-group/ontology-extension.Ethics approval and consent to participateNot applicable.Consent for publicationNot applicable.Competing interestsThe authors declare that they have no competing interests.Received: 2 October 2018 Accepted: 24 December 2019REVIEW Open AccessNatural language processing algorithmsfor mapping clinical text fragments ontoontology concepts: a systematic reviewand recommendations for future studiesMartijn G. Kersloot1,2* , Florentien J. P. van Putten1, Ameen Abu-Hanna1, Ronald Cornet1 and Derk L. Arts1,2AbstractBackground: Free-text descriptions in electronic health records (EHRs) can be of interest for clinical researchand care optimization. However, free text cannot be readily interpreted by a computer and, therefore, haslimited value. Natural Language Processing (NLP) algorithms can make free text machine-interpretable byattaching ontology concepts to it. However, implementations of NLP algorithms are not evaluatedconsistently. Therefore, the objective of this study was to review the current methods used for developingand evaluating NLP algorithms that map clinical text fragments onto ontology concepts. To standardize theevaluation of algorithms and reduce heterogeneity between studies, we propose a list of recommendations.Methods: Two reviewers examined publications indexed by Scopus, IEEE, MEDLINE, EMBASE, the ACM DigitalLibrary, and the ACL Anthology. Publications reporting on NLP for mapping clinical text from EHRs toontology concepts were included. Year, country, setting, objective, evaluation and validation methods, NLPalgorithms, terminology systems, dataset size and language, performance measures, reference standard,generalizability, operational use, and source code availability were extracted. The studies objectives werecategorized by way of induction. These results were used to define recommendations.Results: Two thousand three hundred fifty five unique studies were identified. Two hundred fifty six studiesreported on the development of NLP algorithms for mapping free text to ontology concepts. Seventy-sevendescribed development and evaluation. Twenty-two studies did not perform a validation on unseen data and68 studies did not perform external validation. Of 23 studies that claimed that their algorithm wasgeneralizable, 5 tested this by external validation. A list of sixteen recommendations regarding the usage ofNLP systems and algorithms, usage of data, evaluation and validation, presentation of results, andgeneralizability of results was developed.(Continued on next page)© The Author(s). 2020 Open Access This article is licensed under a Creative Commons Attribution 4.0 International License,which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you giveappropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate ifchanges were made. The images or other third party material in this article are included in the article's Creative Commonslicence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commonslicence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtainpermission directly from the copyright holder. To view a copy of this licence, visit http://creativecommons.org/licenses/by/4.0/.The Creative Commons Public Domain Dedication waiver (http://creativecommons.org/publicdomain/zero/1.0/) applies to thedata made available in this article, unless otherwise stated in a credit line to the data.* Correspondence: m.g.kersloot@amsterdamumc.nl1Amsterdam UMC, University of Amsterdam, Department of MedicalInformatics, Amsterdam Public Health Research Institute Castor EDC, RoomJ1B-109, PO Box 22700, 1100 DE Amsterdam, The Netherlands2Castor EDC, Amsterdam, The NetherlandsKersloot et al. Journal of Biomedical Semantics           (2020) 11:14 https://doi.org/10.1186/s13326-020-00231-z(Continued from previous page)Conclusion: We found many heterogeneous approaches to the reporting on the development and evaluation of NLPalgorithms that map clinical text to ontology concepts. Over one-fourth of the identified publications did not performan evaluation. In addition, over one-fourth of the included studies did not perform a validation, and 88% did notperform external validation. We believe that our recommendations, alongside an existing reporting standard, willincrease the reproducibility and reusability of future studies and NLP algorithms in medicine.Keywords: Ontologies, Entity linking, Annotation, Concept mapping, Named-entity recognition, Natural languageprocessing, Evaluation studies, Recommendations for future studiesBackgroundOne of the main activities of clinicians, besides providingdirect patient care, is documenting care in the electronichealth record (EHR). Currently, clinicians document clin-ical findings and symptoms primarily as free-text descrip-tions within clinical notes in the EHR since they are notable to fully express complex clinical findings and nuancesof every patient in a structured format [1, 2]. These free-text descriptions are, amongst other purposes, of interestfor clinical research [3, 4], as they cover more informationabout patients than structured EHR data [5]. However,free-text descriptions cannot be readily processed by acomputer and, therefore, have limited value in researchand care optimization.One method to make free text machine-processable isentity linking, also known as annotation, i.e., mappingfree-text phrases to ontology concepts that express thephrases meaning. Ontologies are explicit formal specifica-tions of the concepts in a domain and relations amongthem [6]. In the medical domain, SNOMED CT [7] andthe Human Phenotype Ontology (HPO) [8] are examplesof widely used ontologies to annotate clinical data. Afterthe data has been annotated, it can be reused by cliniciansto query EHRs [9, 10], to classify patients into differentrisk groups [11, 12], to detect a patients eligibility for clin-ical trials [13], and for clinical research [14].Natural Language Processing (NLP) can be used to(semi-)automatically process free text. The literature indi-cates that NLP algorithms have been broadly adopted andimplemented in the field of medicine [15, 16], includingalgorithms that map clinical text to ontology concepts[17]. Unfortunately, implementations of these algorithmsare not being evaluated consistently or according to a pre-defined framework and limited availability of data sets andtools hampers external validation [18].To improve and standardize the development and evalu-ation of NLP algorithms, a good practice guideline forevaluating NLP implementations is desirable [19, 20].Such a guideline would enable researchers to reduce theheterogeneity between the evaluation methodology andreporting of their studies. Generic reporting guidelinessuch as TRIPOD [21] for prediction models, STROBE[22] for observational studies, RECORD [23] for studiesconducted using routinely-collected health data, andSTARD [24] for diagnostic accuracy studies, are available,but are often not used in NLP research. This is presum-ably because some guideline elements do not apply toNLP and some NLP-related elements are missing or un-clear. We, therefore, believe that a list of recommenda-tions for the evaluation methods of and reporting onNLP studies, complementary to the generic reportingguidelines, will help to improve the quality of futurestudies.In this study, we will systematically review thecurrent state of the development and evaluation ofNLP algorithms that map clinical text onto ontologyconcepts, in order to quantify the heterogeneity ofmethodologies used. We will propose a structured listof recommendations, which is harmonized from exist-ing standards and based on the outcomes of the re-view, to support the systematic evaluation of thealgorithms in future studies.MethodsThis study consists of two phases: a systematic review ofthe literature and the formation of recommendationsbased on the findings of the review.Literature reviewA systematic review of the literature was performedusing the Preferred Reporting Items for Systematic re-views and Meta-Analyses (PRISMA) statement [25].Search strategy and study selectionWe searched Scopus, IEEE, MEDLINE, EMBASE, the As-sociation for Computing Machinery (ACM) Digital Library,and the Association for Computational Linguistics (ACL)Anthology for the following keywords: Natural LanguageProcessing, Medical Language Processing, Electronic HealthRecord, reports, charts, clinical notes, clinical text, medicalnotes, ontolog*, concept*, encod*, annotat*, code, and cod-ing. We excluded the words reports and charts in theACL and ACM databases since these databases also containpublications on non-medical subjects. The detailed searchstrategies for each database can be found in Additional file2. We searched until December 19, 2019 and applied theKersloot et al. Journal of Biomedical Semantics           (2020) 11:14 Page 2 of 21filters English and has abstract for all databases. More-over, we applied the filters Medicine, Health Professions,and Nursing for Scopus, the filters Conferences, Jour-nals, and Early Access Articles for IEEE, and the filterArticle for Scopus and EMBASE. EndNote X9 [26] andRayyan [27] were used to review and delete duplicates.The selection process consisted of three phases. In thefirst phase, two independent reviewers with a MedicalInformatics background (MK, FP) individually assessedthe resulting titles and abstracts and selected publica-tions that fitted the criteria described below.Inclusion criteria were: Medical language processing as the main topic ofthe publication Use of EHR data, clinical reports, or clinical notes Algorithm performs annotation Publication is written in EnglishFig. 1 PRISMA flow diagramKersloot et al. Journal of Biomedical Semantics           (2020) 11:14 Page 3 of 21Some studies do not describe the application of NLP intheir study by only listing NLP as the used method, insteadof describing its specific implementation. Additionally,some studies create their own ontology to perform NLPtasks, instead of using an established, domain-acceptedontology. Both approaches limit the generalizability of thestudys methods. Therefore, we defined the following exclu-sion criteria: Implementation was not described Implementation does not use an existing establishedontology for encodingTable 1 Induced objective tasks with their definition and an exampleInduced NLP task(s) Description ExampleConcept detection 1 Assign ontology concepts to phrases in freetext (i.e., entity linking or annotation)Systolic blood pressure can be represented as SNOMED-CTconcept 271649006 | Systolic blood pressure (observable entity) |Event detection Detect events in free text Patient visited the outpatient clinic in January 2020 is anevent of type Visit.Relationship detection Detect semantic relationships betweenconcepts in free textThe concept Lung cancer in This patient was diagnosed withrecurrent lung cancer is related to the concept Recurrence.Text normalization Transform free text into a single canonicalformThis patient was diagnosed with influenza last year. becomesThis patient be diagnose with influenza last year.Text summarization Create a short summary of free text andpossible restructure the text based on thissummaryLast year, this patient visited the clinic and was diagnosed withdiabetes mellitus type 2, and in addition to his diabetes, thepatient was also diagnosed with hypertension becomesLast year, this patient was diagnosed with diabetes mellitustype 2 and hypertension.Classification Assign categories to free text A report containing the text This patient is not diagnosedyet will be assigned to the category Undiagnosed.Prediction Create a predictive model based on free text Predict the outcome of the APACHE score based on the(free-text) content in a patient chart.Identification Identify documents (e.g., reports or patientcharts) that match a specific conditionbased on the contents of the documentFind all patient charts that describe patients with hypertensionand a BMI above 30.Software development Develop new or build upon existing NLPsoftwareA new algorithm was developed to map ontology conceptsto free text in clinical reports.Software evaluation Evaluate the effectiveness of NLP software The mapping algorithm has an F-score of 0.874.1.Also known as Medical Entity Linking and Medical Concept NormalizationTable 2 Induced objective categories with their definition and associated NLP task(s)Induced category Induced NLP task(s) DefinitionComputer-assisted coding Concept detection Perform semi-automated annotation (i.e., with a human in the loop)Information comparison Concept detectionEvent detectionRelationship detectionCompare extracted structured information to information available in free-text formInformation enrichment Concept detectionEvent detectionRelationship detectionText normalizationText summarizationExtract structured information from free text and attach this new information to the sourceInformation extraction Concept detectionEvent detectionRelationship detectionExtract structured information from free textPrediction ClassificationPredictionIdentificationUse structured information to classify free-text reports, predict outcomes, or identify casesSoftware developmentand evaluationSoftware developmentSoftware evaluationDevelop new NLP software or evaluate new or existing NLP softwareText processing Text normalizationText summarizationTransform free text into a new, more comprehensible formKersloot et al. Journal of Biomedical Semantics           (2020) 11:14 Page 4 of 21Table3Includedpublicationsandtheirfirstauthor,year,title,andcountryAuthorYearCountryChallengeInducedobjectiveDataoriginDatasetDatalanguageUsedsystemTerm.Sys.InuseSourcecodeRefAfshar2019USANoInformationextractionClinicalDataWarehouseDataOwnEnglishNew(+existing)UMLS(CPT,HCPCS,ICD-10,ICD10CM/ICD9CM,LOINC,MeSH,SNOMED-CT,RxNorm)NotlistedNo,onlylinkstocTAKESsourcecode[29]Alnazzawi2016UKNoInformationenrichmentPhenoCHFcorpus1ExistingEnglishExistingUMLSNotlistedNotapplicable[30]Atutxa2018SpainNoInformationenrichmentEHRdocumentsOwnSpanishNewICD(SNOMED-CTfornormalization)Notyet,aimtoembeditinhuman-supervisedloopNotlisted[31]Barrett2013USANoInformationextractionPalliativecareconsultlettersOwnEnglishNewSNOMEDCTNotlistedNo,butplanned[32]Becker2016GermanyNoInformationextractionShARe/CLEFcorpus(2013)2ExistingGermanExistingSNOMEDCT(English),UMLS(German)Notyet,stillunderdevelopmentNotapplicable[33]Becker2019GermanyNoInformationextractionClinicalnotesofpatientswithknowncolorectalcancerOwnGermanNew(+existing)UMLSYes,ledtoimprovedqualityofcareforcolorectalpatientsNotlisted[34]Bejan2015USANoInformationextractionDischargesummariesandi2b2/VAchallengedataset(2010)3Own+ExistingEnglishExistingUMLSNoNotapplicable[35]Castro2010SpainNoInformationextractionClinicalnoteswithmostrelevantinformationOwnSpanishExistingSNOMEDCTNotlistedNotapplicable[36]Catling2018UKNoSoftwaredevelopmentandevaluationMIMIC-IIIdataset4ExistingEnglishNewICD-9-CMNotlistedNotlisted[37]Chapman2004USANoInformationextractionEmergencydepartmentreportsOwnEnglishExistingUMLSNotlistedNotapplicable[38]Chen2016USANoInformationenrichmentDischargesummariesandprogressnotesOwnEnglishNew(+existing)UMLSNotlistedNotlisted[39]Chiaramello2016ItalyNoInformationextractionClinicalnotes(cardiology,diabetology,hepatology,nephrology,andoncology)OwnItalianExistingUMLSNotlistedNotapplicable[40]Chodey2016USASemEval(2014)InformationextractionICUData:Dischargesummaries,ECG,echo,andradiologyExistingEnglishNew(+existing)UMLSNotlistedNotlisted[41]Chung2005USANoInformationextractionEchocardiogramreportsOwnEnglishNew(+existing)UMLSNotyet,itwillbeusedtopopulatearegistryNotlisted[42]Combi2018ItalyNoInformationextractionVigiSegn(adversedrugreactions)reportsOwnItalian+EnglishNewMedDRAYes,implementedinVigiFarmacoPseudocode[43]DeBruijn2011Canadai2b2/VA(2010)InformationextractionHospitaldischargesummariesandprogressreportsExistingEnglishNew(+existing)UMLSNotlistedNotlisted[44]Deisseroth2019USANoInformationextractionSixsetsofrealpatientdatafromfourdifferentmedicalcenters.OwnEnglishNewHPONotlistedYes[45]Demner-Fushman2017USANoSoftwaredevelopmentandevaluationBioScope5 ,NCBIdiseasecorpus6 ,i2b2/VAchallengecorpus(2010)3 ,ShARecorpus7 ,LHCtestcollection(biological/clinicaljournalabstracts)ExistingEnglishNew(+existing)UMLSYes,usedinotherpapersidentifiedinliteraturesearchYes[46]Divita2014USAParts:i2b2/VASoftwareRandomlyselectedclinicalrecordsfromOwnEnglishNewUMLS(level0+9)Yes,usedbyVAYes[47]Kersloot et al. Journal of Biomedical Semantics           (2020) 11:14 Page 5 of 21Table3Includedpublicationsandtheirfirstauthor,year,title,andcountry(Continued)AuthorYearCountryChallengeInducedobjectiveDataoriginDatasetDatalanguageUsedsystemTerm.Sys.InuseSourcecodeRef(2010)developmentandevaluationthemostfrequentdocumenttypesInformaticsandComputingInfrastructureDuarte2018PortugalNoInformationenrichmentDeathcertificates,clinicalbulletins,andautopsyreportsOwnPortugueseNewICD-10Yes,usedbyPortugeseMinistryofHealthfornearreal-timedeathcausesurveillanceNotlisted[48]Falis2019UKNoInformationextractionMIMIC-IIIdataset4ExistingEnglishNewICD-9NotlistedNotlisted[49]Ferrão2013PortugalNoInformationenrichmentInpatientadultepisodesfromtheEHROwnPortugueseNewICD-9-CMNotlistedNotlisted[50]Gerbier2011FranceNoInformationextractionComputerizedemergencydepartmentmedicalrecordsOwnFrenchNewICD-10,CCAM,SNOMEDCT,ATC,MeSH,ICPC-2,DCRNotyet,willbeintegratedintoaCDSSNotlisted[51]GoicoecheaSalazar2013SpainNoInformationenrichmentDiagnostictextfrompatientrecordsOwnSpanishNewICD-9-CMNotlistedNotlisted[52]Hamid2013USANoClassificationNotesofIraqandAfghanistanveteransfromtheVAnationalclinicaldatabaseOwnEnglishExistingUMLSNotlistedNotapplicable[53]Hassanzadeh2016AustraliaNoInformationextractionShARe/CLEFcorpus(2013)2ExistingEnglishExistingUMLS,SNOMEDCTNotapplicableNotapplicable[54]Helwe2017LebanonNoComputer-assistedcodingMIMIC-IIIdatasetExistingEnglishNewUMLS,ICDNotlistedNotlisted[55]Hersh2001USANoInformationenrichmentRadiologyimagereportsOwnEnglishExistingUMLSNo,stillindevelopment/testingPseudocode[56]Hoogendoorn2015NetherlandsNoPredictionConsultationnotesofpatientsinaprimarycaresettingOwnDutchNewSNOMED-CT,UMLS,ICPCNotlistedNotlisted[57]Jindal2013USAi2b2(2012)Informationextractioni2b2challengecorpus(2012)8ExistingEnglishNew(+existing)UMLS,SNOMEDCT,MeSHNotlistedNotlisted[58]Kang2009KoreaNoInformationextractionDischargesummariesOwnKoreanNewKOMET,UMLSNotlistedNotlisted[59]Kersloot2019NetherlandsNoInformationextraction(Non-smallcell)LungcancerchartsOwnEnglishNew(+existing)SNOMEDCTNotlistedYes[60]König2019GermanyNoSoftwaredevelopmentandevaluationDischargelettersfromBASE-IIstudyOwnGermanNew(+existing)Wingert-NomenclatureNo,stillhastoproveitsvalueNotlisted[61]Li2015USANoInformationcomparisonClinicalnotesanddischargeprescriptionlistsOwnEnglishNew(+existing)UMLS,SNOMEDCT,RxNormNotyet,planstomovetoproductionPseudocode[62]Li2019USANoInformationextractionEHRnotesOwnEnglishNew(+existing)UMLS,SNOMEDCT,MedDRANotlistedNotlisted[63]Lingren2016USANoClassificationStructuredandunstructureddatafromtwoEHRdatabasesOwnEnglishNew(+existing)UMLS,ICD-9,RxNormNotlistedNotlisted[12]Liu2019USANoInformationextractionClinicalnotesfromdifferentinstitutions+PubMedCasereportabstractsOwn+ExistingEnglishExistingHPONotlistedNotapplicable[64]Kersloot et al. Journal of Biomedical Semantics           (2020) 11:14 Page 6 of 21Table3Includedpublicationsandtheirfirstauthor,year,title,andcountry(Continued)AuthorYearCountryChallengeInducedobjectiveDataoriginDatasetDatalanguageUsedsystemTerm.Sys.InuseSourcecodeRefLowe2009USANoInformationextractionSingle-specimenpathologyreportsOwnEnglishExistingUMLS,SNOMEDCTNotlistedNotapplicable[65]Luo2014USANoInformationextractionPathologyreportsOwnEnglishNew(+existing)UMLS,SNOMEDCTYes,currentlyworkingonprojectinmultiplehospitalsNotlisted[66]Meystre2006USANoInformationenrichmentClinicaldocumentsformadultinpatientsinacardiovascularunitOwnEnglishNew(+existing)UMLS(level0),SNOMEDCTNotyet,testinginpracticeNotlisted[67]Meystre2010USAi2b2(2009)Informationextractioni2b2challengedataset(2009)9ExistingEnglishNewUMLSNotyet,possibleintegrationinresearchinfrastructureNotlisted[68]Minard2011Francei2b2/VA(2010)Informationextractioni2b2/VAchallengecorpus(2010)3ExistingEnglishNew(+existing)UMLSNotlistedNotlisted[69]Mishra2019USANoInformationextractionClinicalnotesfromNIHClinicalCenterdatawarehouseOwnEnglishExistingUMLS,HPONotlistedNotapplicable[70]Nguyen2018AustraliaNoComputer-assistedcodingHospitalprogressnotesOwnEnglishNew(+existing)SNOMEDCT,ICD-10-AMNotlistedNotlisted[71]Oellrich2015UKNoInformationextractionPubMedabstracts,clinicaltrialinformation,i2b2/VAchallengecorpus(2010)3 ,SHARE/CLEF(2013)2ExistingEnglishExistingUMLSNotlistedNotapplicable[72]Patrick2011Australiai2b2/VA(2010)Informationextractioni2b2/VAchallengecorpus(2010)3ExistingEnglishNewUMLS,SNOMEDCTNotlistedNotlisted[73]Pérez2018SpainNoTextprocessingSpontaneousDTsrandomlyselectedentriesOwnSpanishNewICDNotlistedNotlisted[74]Reátegui2018CanadaNoInformationextractioni2b2challengecorpus(2008)10ExistingEnglishNew(+existing)UMLS,SNOMEDCT,RxNormNotlistedNotlisted[75]Roberts2011USAi2b2/VA(2010)Informationextractioni2b2/VAchallengecorpus(2010)3ExistingEnglishNew(+existing)UMLS,ICD-9NotlistedNotlisted[76]Rousseau2019USANoInformationcomparisonEDencountersforpatientswithheadacheswhoreceivedheadCTOwnEnglishExistingUMLS:SNOMEDCT,RadLexNotlistedNotapplicable[77]Savova2010USAi2b2(2006,2008)InformationextractionSubsetofclinicalnotesfromtheEMROwnEnglishNew(+existing)UMLS,SNOMEDCT,RxNormYes,usedinotherpapersidentifiedinliteraturesearchYes[78]Shivade2015USAi2b2/UTHealth(2014)Classificationi2b2challengecorpus(2014)11ExistingEnglishExistingUMLSNotlistedNotapplicable[11]Shoenbill2019USANoInformationextractionEHRnotesfromhypertensionpatientsOwnEnglishExistingUMLS,SNOMEDCTNotlistedNotapplicable[79]Sohn2014USANoInformationextractionClinicalnoteswithmedicationmentionsOwnEnglishNewRxNormNotlistedYes[80]Solti2008USANoInformationenrichmentCardiologyambulatoryprogressnotesOwnEnglishExistingUMLSNotlistedNotapplicable[81]Soriano2019SpainNoInformationextractionclinicalemergencydischargereportsOwnSpanishNewSNOMEDCTNotyetYes[82]Soysal2018USAParts:i2b2SoftwareDischargesummariesfromthei2b2/VAOwn+EnglishNewUMLSYes,usedbyvariousYes[83]Kersloot et al. Journal of Biomedical Semantics           (2020) 11:14 Page 7 of 21Table3Includedpublicationsandtheirfirstauthor,year,title,andcountry(Continued)AuthorYearCountryChallengeInducedobjectiveDataoriginDatasetDatalanguageUsedsystemTerm.Sys.InuseSourcecodeRef(2009+2010),ShARe/CLEF(2013),Sem-EVAL(2014)developmentandevaluationchallengecorpus(2010)3 ,outpatientclinicvisitnotes,mockclinicaldocumentsExistinginstitutionsandindustrialentitiesSpasi?2015UKNoInformationextractionMRIreportsofpatientsOwnEnglishNew(+existing)TRAK,UMLS,MEDCIN,RadLexNotlistedYes[84]Strauss2013USANoInformationextractionPathologyreportsofbreastandprostatecancerpatientsOwnEnglishNewSNOMEDCTNotlistedYes[85]Sung2018TaiwanNoInformationextractionCasesofadultpatientswithAISOwnEnglishExistingUMLSNotlistedNotapplicable[86]Tchechmedjiev2018FranceNoInformationextractionQuaero(FrenchMEDLINEabstracttitles+EMEAdruglabels)+CépiDC(ICD-10codingofdeathcertificates)ExistingFrenchNew(+existing)UMLSterminologies(ICD-10)Yes,availableinSIFRBioPortalYes[87]Ternois2018FranceNoClassificationEndoscopyreportswrittenbetween2015and2016OwnFrenchNewCCAMNotlistedNotlisted[88]Travers2004USANoInformationextractionChiefcomplainttextentriesforallemergencydepartmentvisitsOwnEnglishNewUMLSNotlistedNotlisted[89]Tulkens2019BelgiumNoInformationextractioni2b2/VAchallengecorpus(2010)3ExistingEnglishNew(+existing)UMLSNotlistedYes[90]Usui2018JapanNoPredictionElectronicmedicationhistorydatafrompharmacyOwnJapaneseNewICD-10Notyet,expecttouseitNotlisted[91]Valtchinov2019USANoClassificationRadiologyreports,emergencydepartmentnotes+otherclinicalreportsOwnEnglishExistingSNOMEDCT,RadLexNotlistedNotapplicable[92]Wadia2018USANoClassificationChestCTreportsOwnEnglishExistingSNOMEDCT,UMLSNotlistedNotapplicable[93]Walker2019USANoInformationextractionTreatmentsitesfromEMROwnEnglishNewUMLSNotlistedNotlisted[94]Xie2019ChinaNoInformationextractionMIMIC-IIIdataset4ExistingEnglishNewICD-9-CM,ICD-10NotlistedNotlisted[95]Xu2011USANoClassificationCRCpatientcasesfromtheSyntheticDerivativedatabaseOwnEnglishExistingUMLSNo,stillunderdevelopmentNotapplicable[96]Yadav2013USANoPredictionEmergencydepartmentCTimagingreportsOwnEnglishExistingUMLSNotlistedYes,commandlinecommand[97]Yao2019USANoPredictioni2b2challengecorpus(2008)10ExistingEnglishNew(+existing)UMLSNotlistedPart(Sorl)[98]Zeng2018USANoClassificationProgressnotesandbreastcancersurgicalpathologyreportsOwnEnglishNew(+existing)UMLSNotlistedNotlisted[99]Zhang2013USANoInformationextractioni2b2/VAchallengecorpus(2010)3andGENIAcorpus(MEDLINEabstracts)ExistingEnglishNewUMLSNotlistedNotlisted[100]Zhou2006USANoInformationextractionRecordsofpatientswithbreastcomplaintsOwnEnglishNewUMLSNo,stillunderdevelopmentNotlisted[101]Zhou2011USANoSoftwareCOPDandCADpatientsOwnEnglishNewSNOMEDCT,RxNorm,Yes,describedinotherNotlisted[102]Kersloot et al. Journal of Biomedical Semantics           (2020) 11:14 Page 8 of 21Table3Includedpublicationsandtheirfirstauthor,year,title,andcountry(Continued)AuthorYearCountryChallengeInducedobjectiveDataoriginDatasetDatalanguageUsedsystemTerm.Sys.InuseSourcecodeRefdevelopmentandevaluationUMLS,PPL,MDD,HL7valuesetspaper(103])Zhou2014USANoInformationextractionAdmissionnotesanddischargesummariesOwnEnglishExistingSNOMEDCT,HL7RoleCodesNotlistedNotapplicable[103]1.PhenoCHFcorpus:narrativereportsfromelectronichealthrecords(EHRs)andliteraturearticles2.ShARe/CLEFcorpus(2013):narrativeclinicalreports3.i2b2/VAchallengedataset(2010):dischargesummariesandprogressreports4.MIMIC-IIIdataset:demographics,vitalsignmeasurements,laboratorytestresults,procedures,medications,caregivernotes,imagingreports,andmortality5.BioScopecorpus:medicalfreetexts,biologicalfullpapersandbiologicalscientificabstracts6.NCBIdiseasecorpus:PubMedabstracts7.ShARecorpus:deidentifiedclinicalfree-textnotesfromtheMIMICIIdatabase8.i2b2challengecorpus(2012):dischargesummaries9.i2b2challengedataset(2009):de-identifiedhospitaldischargesummaries10.i2b2challengecorpus(2008):dischargesummariesofoverweightanddiabeticpatients11.i2b2challengecorpus(2014):longitudinallyorderedclinicalnotesfromthreecohortsofdiabeticpatientsKersloot et al. Journal of Biomedical Semantics           (2020) 11:14 Page 9 of 21Table 4 Included publications and their evaluation methodologiesAuthor Year Ref. std. Validation External Generalizability a RefAfshar 2019 Existing EHRdataHold-out validation (train,test, development)No No, validation is needed [29]Alnazzawi 2016 ExistingannotatedcorpusExternal ShARe/CLEF, NCBI disease,Heart failure and pulmonaryembolism corporaYes, achieves competitiveperformance on other corpora[30]Atutxa 2018 ManualretrospectivereviewHold-out validation (train,test, development)No Yes, easily portable to otherlanguages[31]Barrett 2013 Manualannotations10-fold cross validation Multiple datasets (differentprovider)Yes, expect that it is generalizable [32]Becker 2016 ExistingannotatedcorpusNot used No Not listed [33]Becker 2019 ManualannotationsHold-out validation (train,test, development)No Not listed [34]Bejan 2015 ManualannotationsExternal i2b2 data (2010) Yes, good performance on thei2b2 dataset, even though notoptimized on it[35]Castro 2010 ManualannotationsNot used No Not listed [36]Catling 2018 ExistingannotatedcorpusHold-out validation (train,test, development)No Not listed [37]Chapman 2004 ManualannotationsNot used No Yes, generalizable to other domainswithin and outside of bio surveillance[38]Chen 2016 Manualannotations10-fold cross validation No Not listed [39]Chiaramello 2016 ManualannotationsNot used No Not listed [40]Chodey 2016 ExistingannotatedcorpusHold-out validation (train,test)No Not listed [41]Chung 2005 ManualannotationsHold-out validation (train,test)Reports from a secondhospitalNot listed [42]Combi 2018 ManualannotationsNot used No Not listed [43]deBruijn 2011 Existingannotatedcorpus15-fold cross validation No Not listed [44]Deisseroth 2019 ManualannotationsHold-out validation (train,test)Data from a secondhospitalYes, it can be immediately incorporatedinto clinical practice[45]Demner-Fushman2017 ExistingannotatedcorpusExternal Multiple datasets Not listed [46]Divita 2014 ManualannotationsNot used No Not listed [47]Duarte 2018 ManualannotationsHold-out validation (train,test)Second dataset Not listed [48]Falis 2019 ExistingannotatedcorpusHold-out validation (train,test, development)No Yes, method is not specific to anontology, and could be used for a graphof any formation[49]Ferrão 2013 Existing EHRdataHold-out validation (train,test)No Not listed [50]Gerbier 2011 ManualannotationsHold-out validation (train,test)No Yes, it could also serve other types ofclinical decision support systems[51]Kersloot et al. Journal of Biomedical Semantics           (2020) 11:14 Page 10 of 21Table 4 Included publications and their evaluation methodologies (Continued)Author Year Ref. std. Validation External Generalizability a RefGoicoecheaSalazar2013 ManualannotationsHold-out validation (train,test)No Not listed [52]Hamid 2013 Manualannotations10-fold cross validation No Possible, the classifier may beapplicable in academic hospitalsamples[53]Hassanzadeh 2016 ExistingannotatedcorpusHold-out validation (train,test)No Not applicable [54]Helwe 2017 ExistingannotatedcorpusHold-out validation (train,test, development)No Not listed [55]Hersh 2001 ManualannotationsHold-out validation (train,test)No Not listed [56]Hoogendoorn 2015 Existing EHRdata5-fold cross validation No Not listed [57]Jindal 2013 ExistingannotatedcorpusHold-out validation (train,test)No Yes, broad applicability [58]Kang 2009 ManualannotationsHold-out validation (train,test)No Yes, extensible to other languages [59]Kersloot 2019 ManualannotationsHold-out validation(development, test)No Possible, but external validationis needed[60]König 2019 Existing EHRdataNot used No Still to be tested [61]Li 2015 Manualannotations10-fold cross validation No Not listed [62]Li 2019 ExistingannotatedcorpusHold-out validation (train,test, development)No Not listed [63]Lingren 2016 ManualannotationsHold-out validation (train,test, development)No Not listed [12]Liu 2019 ManualannotationsNot used No (but multiple datasets /non-trained)No, limited because of NYP/CUIMCand Mayo notes.[64]Lowe 2009 ManualretrospectivereviewHold-out validation (train,test)No Yes, has the potential to index otherclasses of clinical documents[65]Luo 2014 Existing EHRdata10-fold cross validation No No, challenging, not currently workingon it[66]Meystre 2006 ManualretrospectivereviewNot used No Not listed [67]Meystre 2010 ExistingannotatedcorpusHold-out validation (train,test)No Not listed [68]Minard 2011 ExistingannotatedcorpusHold-out validation (train,test, development)No Not listed [69]Mishra 2019 ManualannotationsNot used No Not listed [70]Nguyen 2018 Existing EHRdataNot listed No Not listed [71]Oellrich 2015 ExistingannotatedcorpusExternal Multiple datasets Not listed [72]Patrick 2011 Existingannotated10-fold cross validation No Yes, adaptable to different requirementsin clinical information extraction and[73]Kersloot et al. Journal of Biomedical Semantics           (2020) 11:14 Page 11 of 21Table 4 Included publications and their evaluation methodologies (Continued)Author Year Ref. std. Validation External Generalizability a Refcorpus classification by choosing relevant featuresetsPérez 2018 ExistingannotatedcorpusHold-out validation (train,test, development)No Yes, extensible to different hospital-sectionsand hospitals[74]Reátegui 2018 ExistingannotatedcorpusNot used No Not listed [75]Roberts 2011 ExistingannotatedcorpusHold-out validation (train,test)No Not listed [76]Rousseau 2019 ManualannotationsNot used No Not listed [77]Savova 2010 Manualannotations10-fold cross validation No Yes, implemented in several applications [78]Shivade 2015 ManualannotationsHold-out validation (train,test)No Not listed [11]Shoenbill 2019 ManualannotationsHold-out validation (train,test)No Yes, can allow further evaluation andimprovement in care delivery modelsand treatment approaches to multiplechronic illnesses[79]Sohn 2014 ManualannotationsHold-out validation (train,test, development)No Yes, with adaptions: create flexiblemechanism for adaptation process[80]Solti 2008 ManualannotationsHold-out validation (train,test)No Not listed [81]Soriano 2019 ManualannotationsNot listed No Not listed [82]Soysal 2018 ExistingannotatedcorpusHold-out validation (train,test)No Yes, can be used to quickly developcustomized clinical information extractionpipelines[83]Spasi? 2015 ManualannotationsHold-out validation (train,test)No Not listed [84]Strauss 2013 ManualannotationsNot used No Yes, can be shared between institutionsand used to support clinical +epidemiological research[85]Sung 2018 ManualannotationsNot listed No Not listed [86]Tchechmedjiev 2018 ExistingannotatedcorpusHold-out validation (train,test, development)No Yes, but not universally [87]Ternois 2018 Existing EHRdata5-fold cross validation +Hold-out validation (train,test)No Not listed [88]Travers 2004 ManualretrospectivereviewNot used No Not listed [89]Tulkens 2019 ExistingannotatedcorpusHold-out validation (train,test, development)No Not listed [90]Usui 2018 ManualannotationsNot used No Not listed [91]Valtchinov 2019 ManualannotationsNot used No No [92]Wadia 2018 ManualannotationsNot used No Not listed [93]Walker 2019 Manual Hold-out validation No Yes, it can be incorporated in [94]Kersloot et al. Journal of Biomedical Semantics           (2020) 11:14 Page 12 of 21 Not published in a peer-reviewed journal (except forACL and ACM publications)In the second phase, both reviewers excluded publica-tions where the developed NLP algorithm was not evalu-ated by assessing the titles, abstracts, and, in case ofuncertainty, the Method section of the publication. In thethird phase, both reviewers independently evaluated theresulting full-text articles for relevance. The reviewersused Rayyan [27] in the first phase and Covidence [28] inthe second and third phases to store the informationabout the articles and their inclusion. In all phases, bothreviewers independently reviewed all publications. Aftereach phase the reviewers discussed any disagreement untilconsensus was reached.Data extraction and categorizationBoth reviewers categorized the implementations of the foundalgorithms and noted their characteristics in a structuredform in Covidence. The objectives of the included studiesand their associated NLP tasks were categorized by way ofinduction. The results were compared and merged into oneresult set.We collected the following characteristics of the stud-ies, based on a combination of TRIPOD [21], STROBE[22], RECORD [23], and STARD [24] statement ele-ments (see Additional file 3): year, country, setting, ob-jectives, evaluation methods, used NLP systems oralgorithms, used terminology systems, size of datasets,performance measures, reference standard, language ofthe free-text data, validation methods, generalizability,operational use, and source code availability.List of recommendationsBased on the findings of the systematic review and ele-ments from the TRIPOD, STROBE, RECORD, andSTARD statements, we formed a list of recommenda-tions. The recommendations focus on the developmentand evaluation of NLP algorithms for mapping clinicaltext fragments onto ontology concepts and the reportingof evaluation results.ResultsThe literature search generated a total of 2355 uniquepublications. After reviewing the titles and abstracts, weselected 256 publications for additional screening. Out ofthe 256 publications, we excluded 65 publications, as thedescribed Natural Language Processing algorithms inthose publications were not evaluated. The full text of theremaining 191 publications was assessed and 114Table 4 Included publications and their evaluation methodologies (Continued)Author Year Ref. std. Validation External Generalizability a Refretrospectivereview(development, test) institutional data warehouseXie 2019 ExistingannotatedcorpusHold-out validation (train,test, development)No Not listed [95]Xu 2011 ManualannotationsHold-out validation (train,test)No Yes, generable approach to combineinformation from heterogeneous datasources in EHRs[96]Yadav 2013 ManualannotationsNot used No Yes, should be broadly applicate tooutcomes of clinical interest[97]Yao 2019 ExistingannotatedcorpusHold-out validation (train,test)No Not listed [98]Zeng 2018 Manualannotations5-fold cross validation +Hold-out validation (train,test)No Yes, potential to be replicated [99]Zhang 2013 ExistingannotatedcorpusExternal Two different sets withsame settingsYes, can be adapted to differentsemantic categories and text genres[100]Zhou 2006 Manualannotations5-fold cross validation No Not listed [101]Zhou 2011 ManualretrospectivereviewHold-out validation (train,test)No Not listed [102]Zhou 2014 ManualannotationsNot used No Not listed [103]a As reported by authorsKersloot et al. Journal of Biomedical Semantics           (2020) 11:14 Page 13 of 21Table 5 Characteristics of the included studiesRESEARCH Open AccessIdentifying disease trajectories withpredicate information from a knowledgegraphWytze J. Vlietstra1* , Rein Vos1,2, Marjan van den Akker3,4, Erik M. van Mulligen1 and Jan A. Kors1AbstractBackground: Knowledge graphs can represent the contents of biomedical literature and databases as subject-predicate-object triples, thereby enabling comprehensive analyses that identify e.g. relationships between diseases.Some diseases are often diagnosed in patients in specific temporal sequences, which are referred to as diseasetrajectories. Here, we determine whether a sequence of two diseases forms a trajectory by leveraging the predicateinformation from paths between (disease) proteins in a knowledge graph. Furthermore, we determine the addedvalue of directional information of predicates for this task. To do so, we create four feature sets, based on twomethods for representing indirect paths, and both with and without directional information of predicates (i.e.,which protein is considered subject and which object). The added value of the directional information of predicatesis quantified by comparing the classification performance of the feature sets that include or exclude it.Results: Our method achieved a maximum area under the ROC curve of 89.8% and 74.5% when evaluated withtwo different reference sets. Use of directional information of predicates significantly improved performance by 6.5and 2.0 percentage points respectively.Conclusions: Our work demonstrates that predicates between proteins can be used to identify disease trajectories.Using the directional information of predicates significantly improved performance over not using this information.Keywords: Knowledge graph, Disease trajectories, Predicates, Temporal relationships, Directionality of predicates,Protein-protein interactionsBackgroundKnowledge graphs can be used to represent the biomed-ical knowledge published in literature and databases [1].Knowledge is formalized as subject-predicate-object tri-ples, where pairs of entities are related to each other bypredicates [2]. By integrating triples from a variety ofsources, knowledge graphs can be used to perform com-putational analyses on the comprehensive body of bio-medical knowledge [3]. Previous work has used suchanalyses to identify new relationships between pairs ofentities, e.g., between drugs and diseases [4, 5], genesand phenotypes [6, 7], or between diseases [8, 9].Much research has been performed with knowledgegraphs that only consist of proteins, commonly referredto as protein-protein interaction networks. Through theinvolvement of proteins in metabolic, signaling, immune,and gene-regulatory networks, protein-protein inter-action networks can help to mechanistically explain dis-ease and physiological processes [1012]. Even thoughpredicates further specify the types of interactions be-tween proteins, thereby providing additional informationthat can be analyzed, protein-protein interaction net-works usually do not use them. Instead, most methodsanalyze the network topology of proteins [12]. However,© The Author(s). 2020 Open Access This article is licensed under a Creative Commons Attribution 4.0 International License,which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you giveappropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate ifchanges were made. The images or other third party material in this article are included in the article's Creative Commonslicence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commonslicence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtainpermission directly from the copyright holder. To view a copy of this licence, visit http://creativecommons.org/licenses/by/4.0/.The Creative Commons Public Domain Dedication waiver (http://creativecommons.org/publicdomain/zero/1.0/) applies to thedata made available in this article, unless otherwise stated in a credit line to the data.* Correspondence: w.vlietstra@erasmusmc.nl1Department of Medical Informatics, Erasmus University Medical Center, Dr.Molewaterplein 50, 3015 GE Rotterdam, the NetherlandsFull list of author information is available at the end of the articleVlietstra et al. Journal of Biomedical Semantics            (2020) 11:9 https://doi.org/10.1186/s13326-020-00228-8we have recently shown that analyses that are performedon protein knowledge graphs benefit from predicate in-formation [13].By using the predicates that specify the mechanismsby which proteins interact, temporal pathobiological re-lationships may also be identified, although this has notbeen demonstrated yet. A key application for such tem-poral analyses is the identification of disease trajectories,which are commonly occurring temporal sequences ofdiseases diagnosed in patients [14, 15]. An example of adisease trajectory found in a study by Jensen et al. [14] isrheumatoid arthritis-precedes-heart failure, where pre-cedes is defined as occurs earlier in time. [] [16]. Theoccurrence of the reverse, heart failure-precedes-rheumatoid arthritis, was found to occur significantlyless frequently in the same study, and therefore was notclassified as a trajectory.Identifying relationships between diseases is an im-portant and popular research topic for protein-proteininteraction networks (see Related work section). In suchanalyses diseases are represented by so-called diseaseproteins, which are proteins encoded by genes that areassociated with a disease [17, 18]. Often cited benefitsinclude an improved understanding of the biologicalmechanisms underlying disease interactions [8, 19, 20],and the ability to anticipate the next disease, therebyproviding the knowledge necessary to improve treatmentplans and interventions [14, 21]. However, the temporalaspects of relationships between diseases still requirefurther investigation. We therefore aim to automaticallydetermine whether a given sequence of two diseasesforms a trajectory. We do so by leveraging the predicateinformation from paths between (disease) proteins in aknowledge graph. We also determine whether there isadded value in using directional information of predi-cates for this task.Related workPrevious authors have mostly focused on identifying un-directed relationships between diseases with protein net-works [1923]. For example, Kontou et al. created adisease-disease graph, where an edge between diseasesindicated that they shared at least one disease gene [23].Sun et al. calculated the similarity between diseasesbased on their shared disease proteins, shared physio-logical processes associated with these proteins, or thegraph structures between the proteins [20]. Li and Agar-wal identified which biological pathways were associatedwith diseases via their disease proteins, and identified re-lationships between diseases based on the number ofshared pathways [19]. Menche et al. identified so-calleddisease modules, which are clusters of closely interre-lated disease proteins [22]. They found that short dis-tances between the modules of diseases were predictivefor pathobiological relationships. Contrary to Kontouet al., they demonstrated that sharing disease proteins isnot a requirement for diseases to be related to eachother.To our knowledge, Bang et al. were the only ones touse a directed protein-protein interaction network toidentify disease trajectories [21]. The disease proteins ofpairs of diseases were used to identify shared biomolecu-lar pathways, after which the locations of the diseaseproteins within these pathways were determined. Thedisease with most upstream disease proteins was classi-fied as the first within the sequence of diseases. Add-itionally, 13 million Medicare records were used tocalculate two relative risk scores for each pair of dis-eases, corresponding with the two possible temporal se-quences of the disease pair. If the sequence determinedwith the protein pathways concurred with the sequencethat generated the largest relative risk, that sequencewas identified as a trajectory. Between a total of 2604diseases, their method suggested 61 trajectories. Thesewere evaluated with the biomedical literature, where fur-ther leads were found for 16 of them. Because the au-thors only evaluated the trajectories that were suggestedby their method, it is unclear how many trajectories themethod failed to identify.Materials & methodsReference setsThe ability of our method to identify disease trajectorieswas evaluated with two reference sets, which have iden-tified disease trajectories by different means. The firstreference set consisted of statistically-derived disease tra-jectories from a large retrospective study of Danish hos-pital data, while the second set consisted of literature-validated disease trajectories that were based on a smallprospective study of Dutch general-practitioner data.Jensen reference setThe first reference set was based on a study of Jensenet al. [14]. They retrospectively identified 4014 diseasetrajectories from 6.2 million electronic patient records ofDanish hospitals based on diagnoses assigned over 14.9years. All diagnoses in these patient records were repre-sented as International Statistical Classification of Dis-eases and Related Health Problems 10th Revision (ICD-10) codes. Jensen used the hierarchy within the ICD-10to aggregate all diagnoses to a high abstraction level,resulting in 681 two-digit codes, such as Malignant neo-plasm of breast (C50) or Type 2 diabetes mellitus(E11).Jensen derived the disease trajectories from the Danishhospital data in a two-step process. First, they identifiedsequences of two diseases that were diagnosed within 5years from each other in at least 10 patients, and whichVlietstra et al. Journal of Biomedical Semantics            (2020) 11:9 Page 2 of 11had a relative risk higher than 1. Subsequently, the direc-tion of each sequence had to be corroborated by a bino-mial test that compared the frequency of the sequence tothe frequency of its reversed sequence. Sequences that ful-filled both criteria were classified as disease trajectories.To represent the diseases in the Jensen set on the pro-tein level, we used the expert-annotated associations be-tween proteins and diseases from the manually curatedsubset of DisGeNet [18]. The Unified Medical LanguageSystem (UMLS) MRCONSO table was used to map theICD-10 codes of the Jensen trajectories to the UMLSidentifiers that are used in DisGeNet. Two diseases, Ac-cidental poisoning by and exposure to other gases andvapours (E47) and Influenza due to identified zoonoticor pandemic influenza virus (J09), were lost becausetheir ICD-10 codes could not be mapped to a UMLSidentifier. Because only 25% of the high-level diseases inthe Jensen set were represented within DisGeNet, weused the narrower and child relationships from theUMLS MRREL table to identify subclasses of all diseases.By expanding the diseases with their subclasses, the per-centage of diseases to which disease proteins could beassigned was increased to 68% (465 of 679 diseases).From the 4014 disease trajectories in the Jensen set,there were 2530 trajectories where disease proteinscould be assigned to both diseases (63%). These 2530trajectories, which were used as positive cases in this ref-erence set, contained 453 of the 465 diseases to whichdisease proteins could be assigned (97%). On average,diseases had 90 disease proteins assigned to them (me-dian: 29, interquartile range: 794). Disease proteinswere on average assigned to 6.2 diseases (median: 3,interquartile range: 28).A set of 168,870 non-trajectories was constructed bycreating all possible sequences of the 453 included dis-eases, minus the trajectories that were described by Jen-sen. The set of non-trajectories thereby includedrandom pairs of diseases, the reversed temporal se-quences of these random pairs, as well as the reversedtemporal sequences of the trajectories. In the following,we will refer to the trajectories and non-trajectories aspositive and negative cases to align with common ter-minology in the machine learning field.Van den Akker reference setThe second reference set was based on a prospective co-hort study on disease susceptibility by Van den Akkeret al. [24]. They followed a Dutch cohort of 3460patients over 2 years, during which their general practi-tioner notes were examined for sequences of Inter-national Classification of Primary Care (ICPC) codesthat represent chronic, permanent, and recurrent dis-eases. In the Netherlands, each citizen is registered witha general practitioner, who acts like a gatekeeper forsecondary and tertiary medical care, and is responsiblefor maintaining a complete medical history of thepatient.A total of 473 unique sequences of diseases werefound in this cohort, containing 122 distinct diseases.Each sequence was manually evaluated using the pub-lished biomedical literature and medical handbooks.There were 65 sequences of diseases where the literaturestated that the first disease increased the susceptibility ofacquiring the second disease, and 408 sequences whereno evidence of increased susceptibility was found. Tomaintain consistent terminology, we will refer to se-quences with increased susceptibility as trajectories orpositives and to sequences without increased susceptibil-ity as non-trajectories or negatives.To assign disease proteins to these 122 diseases wefollowed the same procedure as for the Jensen set byusing the MRCONSO table to map the ICPC codes toUMLS identifiers, after which the MRREL table was usedto group them with their subclasses. Disease proteinscould be assigned to 97 diseases, which formed 55 tra-jectories and 316 non-trajectories. On average, diseaseshad 137 disease proteins assigned to them (median: 49,interquartile range: 17167). Disease proteins were onaverage assigned to 3 diseases (median: 2, interquartilerange: 14).To determine whether our method could also identifythe correct temporal sequence of the trajectories, 54additional non-trajectories were created by reversing thesequence of the diseases in the literature-supported tra-jectories (the reverse sequence of one trajectory wasalready included as a non-trajectory in the data from thegeneral practitioners).Knowledge graphThe predicates between proteins were extracted fromthe Euretos Knowledge Platform (EKP), a commerciallyavailable knowledge graph (http://www.euretos.com). Inthe EKP, information from more than 200 knowledgesources from a wide variety of domains in the life sci-ences is represented as triples. The biomedical entitiessuch as proteins, drugs, or diseases that form the sub-jects and objects of these triples are represented in theknowledge graph as vertices, each of which has one ormore identifiers associated with it from external data-bases. Mappings between the entities described in thedifferent knowledge sources underlying the knowledgegraph were made by matching their identifiers. Thepredicate and provenance of each triple are specified aspart of an edge between the two vertices that representthe subject and object. The direction of the predicategoes from subject to object. The predicates in the under-lying knowledge sources were matched to a standardizedset of 203 predicates. If an exact match was notVlietstra et al. Journal of Biomedical Semantics            (2020) 11:9 Page 3 of 11available, a predicate was manually mapped. If therewere no explicit predicates in a database that was usedas a knowledge source, the predicates were manually de-rived from the database schema. A path between twovertices is defined as a sequence of triples, or possibly asingle triple, connecting the vertices.The contents of the EKP are represented as documentsin a NoSQL database, which allows them to be flexiblymodelled and indexed. The EKP can be run on areasonably-powered server, requiring an 8-core proces-sor and 60GB of memory as a minimum. It has previ-ously been used in pre-clinical research for drug efficacyscreening [13], prioritizing existing drugs as repurposingcandidates for autosomal dominant polycystic kidneydisease [25], and pathway enrichment [26].Feature sets & machine learningThe paths between the disease proteins were extractedfrom the EKP. To keep our graph comprehensible, weonly extracted paths that consisted of one or two triples,i.e., paths where two disease proteins are connected byat most one intermediate protein. Within this range,three scenarios for the paths between the disease proteinsof two diseases A and B were distinguished (Fig. 1.):1) Overlap, where A and B share a disease protein,optionally with a path to itself, e.g. a disease proteinof which two copies bind with each other(homodimerization).2) Direct path, where a disease protein of A and adisease protein of B are part of one triple.3) Indirect path, where one intermediate proteinconnects the disease proteins of A and B, requiringa sequence of two triples.Two different methods to represent indirect paths be-tween disease proteins were compared. The first methodconstructed so-called metapaths [5], where the sequenceof predicates in an indirect path was used as single feature.The second method, which we refer to as split paths, con-sidered each predicate in the indirect paths as a separatefeature [13]. Each method was tested both with and with-out directional information of predicates. Predicates wereeither considered to all be undirected, or predicates werecategorized as being directed or undirected based on ex-pert assessment (described in the Assessment of predicatedirectionality section below), which we refer to as theMixed variation. In the overlap scenario, where the subjectand the object were the same protein, predicates were al-ways considered to be undirected.All features were binary. Figure 2 shows the fourfeature sets that are derived from the exampleshown in Fig. 1. We also experimented with featuresets where all predicates were directed as indicatedby the subject and object of the triple in the EKP.However, because some predicates are explicitly de-fined as being undirected, using any directional in-formation from triples with these predicates wouldcontradict these definitions. Nonetheless, for thesake of completeness we have chosen to presentthese results in Additional file 1.Random forests were trained to classify the sequences ofdiseases as positive or negative. Classification performanceFig. 1 Schematic overview of the overlap, direct, and indirect scenarios that were extracted from the knowledge graph. Both diseases A anddisease B have three disease proteins (DP) associated with them according to the manually curated subset of DisGeNet. DisGeNet describes thatDP1 is known to be associated with both diseases, while the knowledge graph describes that it has a binds with relationship to itself. DP2 andDP4 have a direct inhibits relationship, and DP3 and DP5 are connected through an indirect path, by an intermediate protein (IP). The arrowsbetween the proteins indicate which protein is the subject of the inhibits predicate, and which one its object. The binds with predicate wasconsidered to be undirected by the experts, and therefore does not have a direction. Based on the paths in the knowledge graph, four featuresets are created, based on two methods to represent indirect paths, and both with and without the directional information of predicatesVlietstra et al. Journal of Biomedical Semantics            (2020) 11:9 Page 4 of 11was measured with the area under the receiver operatorcharacteristic curve (AUC) of a 10-fold cross-validationexperiment [27, 28]. We report the mean and standard de-viation of the AUCs of 10 repeated cross-validation exper-iments. The same folds that were used in the experimentswith undirected predicates were also used in the experi-ments with directed predicates, after which the differencesbetween the test folds were tested for significance with atwo-sided, paired t-test.To control for the differences in prevalence and num-ber of cases between the two reference sets, we also re-port the classification performance after undersamplingthe number of positive and negative cases in the Jensenset to match those in the Van den Akker set.For the best performing classifiers we also report sensi-tivity and specificity at the probability cutoff for which theYouden index (sensitivity + specificity  1) is largest [29].Machine learning and evaluation of results were per-formed in R [30] with the packages caret [31], ranger[32], and pROC [33].Assessment of predicate directionalityThree experts with a strong biomedical background andfamiliarity with knowledge graphs assessed the direction-ality of 47 distinct predicates that were found in the ex-tracted paths. They were provided with definitions ofthese predicates which were obtained from the PathwayCommons resource [34]. If not available, definitionswere sought through the National Library of Medicine[35], or the OBO foundry [36]. The assessors couldcategorize each predicate as directed, undirected, ordont know. To establish directionality, a predicate hadto be categorized as directed or undirected by a majority(i.e., two or three) of the assessors. Predicates that con-tain a negation (e.g., does not interact with) were auto-matically categorized the same as the correspondingpredicate without negation (interacts with), and there-fore not presented to the assessors. For some predicatesthe categorization was straightforward. For example,Pathway Commons defines the predicate interacts withas This is an undirected relation between participantFig. 2 The four feature sets that were derived from the paths between the disease proteins in Fig. 1. All features are binary: Black fields indicate aTrue value, while empty fields indicate a False value. For the Mixed feature sets, the Binds with predicate is assessed to be undirected byexperts, while the Inhibits predicate is assessed to be directedVlietstra et al. Journal of Biomedical Semantics            (2020) 11:9 Page 5 of 11proteins of a molecular interaction. [] , and the predi-cate catalysis precedes as This relation defines di-rected interactions between proteins. [] [34]. Sixpredicates did not reach a majority in the first roundand were anonymously commented upon by the asses-sors to motivate their categorization. These commentswere shared between the assessors, after which theycould update their initial choice. Each predicate wasthen categorized with a majority.Table 1 shows the 12 predicates that were categorizedas undirected by the three experts. The other 35 predi-cates were categorized as directed. A complete overviewof the predicates can be found in Additional file 2.ResultsExtracted pathsIn total, 6859 distinct disease proteins were assigned tothe diseases in both reference sets, three of which couldnot be mapped to the EKP. Another 430 (6.3%) of thedisease proteins were not found in any of the extractedpaths. From these disease proteins, 314 had no relation-ship to any other protein in the EKP.The remaining 6426 disease proteins were involved in1,338,310 direct paths and 833,546,575 indirect paths,while 2581 disease proteins had 7354 paths to them-selves. All paths were based on 2,015,738 distinct triples,which contained 17,132 different proteins and 47 differ-ent predicates.The overlap scenario, where the two diseases in thetrajectory share at least one disease protein (scenario 1,Feature sets & Machine learning section), occurred in58% of the positive cases of the Jensen set, and 95% ofthe positive cases of the Van den Akker set. No indirectpaths (scenario 3, Feature sets & Machine learning sec-tion) were found between the disease proteins of 119positive cases (4.7%), and 18,217 negative cases of theJensen set (10.8%), and one positive case (1.8%) and 15negative cases (4.1%) of the Van den Akker set.Classification resultsThe classification performance for both reference sets isshown in Table 2. Mixed metapaths performed best,achieving mean AUCs of 89.8% for the Jensen set and74.5% for the Van den Akker set. Overall, classificationperformance on the Van den Akker set was 9.9 to 15.3percentage points lower than on the Jensen set, whilestandard deviations were 9.6 to 11.3 percentage pointshigher. Metapaths performed 4.1 to 7.0 percentagepoints better than split paths. The performance of themixed feature sets was 1.9 to 6.5 percentage pointshigher than the undirected feature sets. All differencesbetween mixed and undirected feature sets were signifi-cant (p-values for Jensen metapaths and split paths: <0.001; Van den Akker metapaths: 0.02, split paths 0.001).To quantify how much of the difference in AUC be-tween the two reference sets could be attributed to theirdifference in size, the Jensen set was undersampled tothe same number of positive and negative cases as theVan den Akker set. With the exception of the mixedmetapaths, performance dropped below the performancethat was achieved with the Van den Akker set. Thestandard deviations also increased from 0.91.7% to 8.412.3%. The latter values are comparable to the standarddeviations on the Van den Akker set.Figure 3 shows the receiver operating characteristic(ROC) curves of the mixed metapath classifiers that per-formed best. For the Jensen set, sensitivity and specificityat the maximum Youden index were 79.2% and 82.4%,respectively, while for the Van den Akker set these were73.6% and 64.3%.Error analysisFor our best classifier (mixed metapath features, trainedon the Jensen set), we analyzed the top-15 false-positiveand the top-15 false-negative cases, searching the litera-ture for information that might explain the errors. Theresults of our analysis of the false positives are shown inTable 3. Overall, the first 10 out of the top 15 false posi-tives appear to be omissions from the Jensen set ratherthan misclassifications. For two false-positive cases, po-tential mechanisms have been suggested, but the currentevidence is inconclusive on whether those mechanismsare valid. For the remaining three false-positive cases noliterature could be found, which may therefore be inter-esting leads for further investigation.Table 4 shows the results for the top-15 false nega-tives. For six false negatives, the second disease waslikely to be caused by the treatment of the first disease.For example, the radiation that is used to treat the ma-lignant neoplasm of the larynx may compromise theTable 1 Predicates categorized as undirected as a result of theassessment processUndirected Predicatesbinds withcoexists withdoes not coexist withforms protein complex withinteracts withdoes not interact withis associated withis compared withis functionally related tois spatially related tois the same asortholog is associated withVlietstra et al. Journal of Biomedical Semantics            (2020) 11:9 Page 6 of 11immune system around the throat and mouth, therebyincreasing susceptibility to oropharyngeal candidiasis[54]. Two false-negative trajectories are likely to havemechanical causes, rather than molecular pathways. Thetrajectory from malignant neoplasms of the ovary to nu-trient deficiency can be explained by the blocking of theintestines by the ovarian tumor, thereby blocking the en-tire digestive system [53]. For four of the false-negativetrajectories, no description could be found in the litera-ture, making their assessment impossible. Assessment ofthe three remaining false negatives is speculative. For ex-ample, the trajectory from transient ischemic attacks(TIA) to vitamin B12 deficiencies may be an artifact ofthe medical record keeping. Vitamin B12 is known toprotect against TIAs [52], so what may often happen isthat a vitamin B12 deficiency is only diagnosed after themore acute TIA has been treated in an emergency room.DiscussionOur work demonstrates that disease trajectories can beidentified with the predicates between proteins in a know-ledge graph. To do so, our machine-learning based meth-odology needed to successfully identify both the correctpairs of diseases, as well as their correct temporal se-quences. Overall, representing indirect paths as metapathsperformed superior as compared to representing them assplit paths. Using the directional information of predicatessignificantly improved performance over not using thisinformation. Undersampling the Jensen set to the samenumber of positive and negative cases as the Van denAkker set showed that its lower performance and higherstandard deviations could partially be explained by its smallsize.In previous work, Bang et al. [21] identified disease trajec-tories by calculating the relative risk between two diseasesand combining this with the relative position of disease pro-teins in biomolecular pathways. Their method is fullydependent on shared disease proteins between the two dis-eases, whereas our method also works when there are only(in) direct paths between disease proteins. In the Jensen set,this holds for 42% of the trajectories. Performance compari-son of the methods is difficult because Bang et al. only vali-dated the disease trajectories that were suggested by theirmethod, but did not validate the non-trajectories. Thus,only the precision of their method can be calculated but noinsight is provided in the number of false-negative trajec-tories. A final complication for the comparison between thetwo methods is the claim of Bang et al. to discover causalrelationships between diseases, rather than only temporalones. Unfortunately, they refer to an example to definecausal relationships between diseases, making it difficult topinpoint how these differ from disease trajectories.Although we do not foresee direct clinical applicationof our work, our high performance may persuade ex-perts to further examine the protein paths underlyingsome positively classified trajectories, either known orTable 2 Classification results for the four feature sets for both reference setsJensen set Jensen set - undersampled Van den Akker setMetapaths Split paths Metapaths Split paths Metapaths Split pathsUndirected 83.3 (1.7) 78.3 (1.7) 64.2 (12.1) 61.9 (12.3) 72.5 (11.8) 68.4 (13.0)Mixed 89.8 (0.9) 82.8 (1.2) 82.3 (8.4) 69.6 (13.1) 74.5 (10.5) 70.3 (11.4)The values in the columns indicate the mean AUC and its standard deviation in % of 10 cross-validation experimentsFig. 3 ROC curves of the mixed metapaths classifiers for the Jensen set and the Van den Akker setVlietstra et al. Journal of Biomedical Semantics            (2020) 11:9 Page 7 of 11newly suggested. Interpreting these protein paths mightprovide additional clues about the mechanism throughwhich the first disease leads to the second. Identifyingand understanding these mechanisms is likely to im-prove prevention, prediction of disease progression,intervention, and drug development, thereby indirectlysupporting clinical practice and health-care policy. Fornow, such detailed examinations of the protein pathswere beyond the scope of this project.A downside of working on the protein level was that notall disease trajectories could be studied. More than a thirdof the trajectories of the Jensen set, and a fifth of the Vanden Akker set was lost because disease proteins could notbe assigned to one or both of the diseases in a trajectory.Even when disease proteins could be assigned to both dis-eases, alternative explanations were sometimes moreplausible. For example, our analysis of the false-negativecases suggested that some trajectories could be explainedmechanically, or were likely due to a side effect of thetreatment for the first disease. To determine the true per-formance of our method, a validated set of trajectories thatare caused by biomolecular mechanisms would be needed.Alternatively, the range of trajectories that can be analyzedmay be broadened by linking diseases to other types ofdisease information available in the EKP, e.g., informationabout drugs or physiological processes.The two reference sets that were used in this researchwere both based on patient data, but differed in manyother respects. The sequences of diseases in the Jensenset were classified as trajectories based on statisticscalculated from 15 years of nationwide hospital data.Despite this large volume of data, our analysis of thefalse-positive cases showed that the set of trajectorieswas incomplete. The literature evaluation underlying theVan den Akker set ensures that such omissions are un-likely to occur there. Furthermore, the negatives in theVan den Akker set either were observed in patients, orwere reversals of literature-supported trajectories. Be-cause the negative cases in the Jensen set were based onrandomization, this set is likely to contain pairs of dis-eases that never co-occur within patients. Finally, thetypes of diagnoses within the trajectories differ betweenthe two reference sets. The hospital patients in theJensen set are more likely to suffer from more seriousand complicated diseases than patients visiting a generalpractitioner in the Van den Akker set. On the otherhand, the Van den Akker set only included chronic, per-manent, and recurring diseases, thereby excluding dis-eases that are acute and rapidly treatable.Only the definitions from Pathway Commons statedwhether the predicate was directed or not. The defini-tions of predicates from other knowledge sources,Table 3 Assessment of the top 15 false-positive trajectoriesFirst disease ICD-10 Second disease ICD-10 AssessmentMental and behavioural disorders due touse of alcoholF10 Alzheimers disease G30 Described in literature [37]Essential (primary) Hypertension I10 Alzheimers disease G30 Described in literature [38]Osteoporosis without pathological fracture M81 Alzheimers disease G30 Described in literature [39]Non-insulin-dependent diabetes mellitus E11 Alzheimers disease G30 Described in literature [40]Other disorders of pancreatic internalsecretionE16 Alzheimers disease G30 Described in literature [41]Schizophrenia F20 Other septicaemia A41 Described in literature, but commonlyoccurs via intermediate diseases suchas agranulocytosis and pneumonia [42]Lupus erythematosus L93 Other disorders ofurinary systemN39 Described in literature [43]Disorders of vestibular function H81 Alzheimers disease G30 Described in literature [44]Lupus erythematosus L93 Respiratory failure, notelsewhere classifiedJ96 Described in literature [45]Unspecified Dementia F03 Dementia in AlzheimersDiseaseF00 Further specification of diagnosisRetinal vascular occlusions H34 Cystitis N30 No relationship found in literatureChronic ischaemic heart disease I25 Other septicaemia A41 Cardiac troponins are suggested to bebiomarkers for sepsis [46]Hyperplasia of prostate N40 Alzheimers disease G30 No relationship found in literatureHyperparathyroidism and other disordersof parathyroid glandE21 Alzheimers disease G30 Suggested in literature (via calcium) [47]Asthma J45 Umbilical hernia K42 No relationship found in literatureVlietstra et al. Journal of Biomedical Semantics            (2020) 11:9 Page 8 of 11including the National Library of Medicine, left roomfor interpretation. As a result, six predicates required asecond round of assessment before a majority wasachieved between the assessors. With ontologies playingincreasingly important roles in data standardization andsharing [58], the directionality of predicates should al-ways be clear. The Relationship Ontology already sup-ports categorization of predicates as directed orundirected, which it refers to as asymmetric or symmet-ric predicates, but unfortunately is far from completeand did not cover the predicates in our set [59].A potential new application for our method would beto identify trajectories for rare and low-prevalence dis-eases, where insufficient patient data is available forstudies such as those performed by Jensen or Van denAkker. Because our method identifies trajectories basedon a protein network, it is independent of the prevalenceof a disease. Furthermore, many of the estimated 5 to 8thousand rare diseases have well known genetic causes[60], making them highly suitable to be analyzed withour method.A possible extension of our work would be the identi-fication of longer disease trajectories, e.g. the trajectoriesconsisting of sequences of four diseases that were alsodescribed by Jensen et al. [14]. However, as far as we areaware all available knowledge-graph methods limitthemselves to identifying relationships between two en-tities. Expanding the current methods to identify longersequences should therefore be a separate investigation.ConclusionsOur work demonstrates that disease trajectories can beidentified with the predicate information from a know-ledge graph. We also demonstrate and quantify theadded value of using directional information of predi-cates for this task. Our work thereby enables the discov-ery of temporal relationships with predicate informationfrom knowledge graphs.Supplementary informationSupplementary information accompanies this paper at https://doi.org/10.1186/s13326-020-00228-8.Additional file 1. Description and results of the directed variationfeature sets. This file describes the feature sets and classification results ofthe variation where all predicates in the feature sets have a direction asspecified by their triples in the knowledge graph. Their categorization asdirected or undirected by the assessors was not used in this variation.Figure S1 shows an example of the feature sets derived from Fig. 1, withTable 4 Assessment of the top 15 false-negative trajectoriesFirst disease ICD-10 Second disease ICD-10 AssessmentThyrotoxicosis [hyperthyroidism] E05 Other disorders of eyeand adnexaH57 Likely side effect of treatment [48]Irritable bowel syndrome K58 Spondylosis M47 No relationship found in literatureVitamin B12 deficiency anaemia D51 Other septicaemia A41 Vitamin B12 has been hypothesized as treatmentfor sepsis [49]Mental and behavioural disorders dueto use of alcoholF10 Acute and transientpsychotic disordersF23 Described in literature, but no clear role for proteininteractions [50]Gonarthrosis [arthrosis of knee] M17 Erysipelas A46 No relationship found in literatureSenile cataract H25 Other disorders of lens H27 Likely side effect of treatment [51]Transient cerebral ischaemic attacksand related syndromesG45 Vitamin B12 deficiencyanaemiaD51 Only reverse described in literature, that vitamin B12protects against stroke [52]Malignant neoplasm of ovary C56 Deficiency of othernutrient elementsE61 Likely mechanical cause [53]Malignant neoplasm of larynx C32 Candidiasis B37 Likely side effect of treatment [54]Other intervertebral disc disorders M51 Somatoform disorders F45 No relationship found in literatureGonarthrosis [arthrosis of knee] M17 Other local infectionsof skin and subcutaneoustissueL08 No relationship found in literatureBenign neoplasm of brain and otherparts of central nervous systemD33 Other septicaemia A41 Likely intermediate through infection, which followssurgery or weakening of the immune system after(radiation) treatmentInsulin-dependent diabetes mellitus E10 Other disorders of eyeand adnexaH57 Diabetes is a risk factor for many eye diseases [55],but it is not clear whether these fall under this ICD-10codeNoninflammatory disorders of ovary,fallopian tube and broad ligamentN83 Ventral hernia K43 Likely side effect of treatment [56]Other intervertebral disc disorders M51 Other polyneuropathies G62 Likely mechanical cause [57]Vlietstra et al. Journal of Biomedical Semantics            (2020) 11:9 Page 9 of 11the difference that in this variation the Binds with predicate also isdirected. Table S1 shows the classification performance of the directedfeature sets along with the performances of the undirected and themixed variations. Table S2 shows the p-values of the two-sided paired t-tests between all variations.Additional file 2. Overview of predicates that were found in the paths.This file contains Table S3, which shows the 47 predicates that connectproteins in the knowledge graph and were used to construct thefeatures.AbbreviationsAUC: Area under the receiver operator characteristic curve; DP: DiseaseProtein; EKP: Euretos Knowledge Platform; ICD-10: International StatisticalClassification of Diseases and Related Health Problems 10th Revision;ICPC: International Classification of Primary Care; IP: Intermediate Protein;ROC: Receiver Operating Characteristic curve; TIA: Transient Ischemic Attack;UMLS: Unified Medical Language SystemAcknowledgementsWe would like to thank Euretos B.V. for providing access to the EuretosKnowledge Platform, and Drs. Anneke M. Sijbers and Solène Grosdidier fortheir help in assessing the predicates.Authors contributionsWV, RV, EvM, and JK designed the study. WV created the feature sets,performed the error analysis, and drafted the manuscript. WV and RVperformed the data analyses. MvdA and RV supplied the Van den Akkerreference set. RV, EvM and JK supervised the study and critically revised themanuscript. All authors read and approved the final manuscript.FundingNo funding was received for this project.Availability of data and materialsThe datasets and scripts that are used in this study are available athttps://github.com/Wytz/DiseaseTrajectoriesEthics approval and consent to participateNot applicable.Consent for publicationNot applicable.Competing interestsThe authors declare that they have no competing interests.Author details1Department of Medical Informatics, Erasmus University Medical Center, Dr.Molewaterplein 50, 3015 GE Rotterdam, the Netherlands. 2Department ofMethodology & Statistics, Maastricht University, PO Box 616, 6200 MDMaastricht, the Netherlands. 3Institute of General Practice, Johann WolfgangGoethe University, Theodor-Stern-Kai 7, D-60590 Frankfurt, Germany.4Department of Family Medicine, Maastricht University, PO Box 616, 6200 MDMaastricht, the Netherlands.Received: 14 February 2020 Accepted: 12 August 2020RESEARCH Open AccessDisclosing Main authors and Organisationscollaborations in bioprinting throughnetwork maps analysisLeonardo Azael García-García1* and Marisela Rodríguez-Salvador2AbstractBackground: Scientific activity for 3D bioprinting has increased over the past years focusing mainly on fully functionalbiological constructs to overcome issues related to organ transplants. This research performs a scientometric analysis onbioprinting based on a competitive technology intelligence (CTI) cycle, which assesses scientific documents to establishthe publication rate of science and technology in terms of institutions, patents or journals. Although analyses ofpublications can be observed in the literature, the identification of the most influential authors and affiliations has notbeen addressed. This study involves the analysis of authors and affiliations, and their interactions in a global framework.We use network collaboration maps and Betweenness Centrality (BC) to identify of the most prominent actors inbioprinting, enhancing the CTI analysis.Results: 2088 documents were retrieved from Scopus database from 2007 to 2017, disclosing an exponential growthwith an average publication increase of 17.5% per year. A threshold of five articles with ten or more cites wasestablished for authors, while the same number of articles but cited five or more times was set for affiliations. Theauthor with more publications was Atala A. (36 papers and a BC = 370.9), followed by Khademhosseini A. (30documents and a BC = 2104.7), and Mironov (30 documents and BC = 2754.9). In addition, a small correlation wasobserved between the number of collaborations and the number of publications. Furthermore, 1760 institutions with amedian of 10 publications were found, but only 20 within the established threshold. 30% of the 20 institutions had anexternal collaboration, and institutions located in and close to the life science cluster in Massachusetts showed a strongcooperation. The institution with more publications was the Harvard Medical School, 61 publications, followed by theBrigham and Womens hospital, 46 papers, and the Massachusetts Institute of Technology with 37 documents.Conclusions: Network map analysis and BC allowed the identification of the most influential authors working onbioprinting and the collaboration between institutions was found limited. This analysis of authors and affiliations andtheir collaborations offer valuable information for the identification of potential associations for bioprinting researchesand stakeholders.Keywords: Network map analysis, Betweenness centrality, Bioprinting, Text mining, Collaboration analysis,scientometrics, competitive technology intelligence© The Author(s). 2020 Open Access This article is licensed under a Creative Commons Attribution 4.0 International License,which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you giveappropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate ifchanges were made. The images or other third party material in this article are included in the article's Creative Commonslicence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commonslicence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtainpermission directly from the copyright holder. To view a copy of this licence, visit http://creativecommons.org/licenses/by/4.0/.The Creative Commons Public Domain Dedication waiver (http://creativecommons.org/publicdomain/zero/1.0/) applies to thedata made available in this article, unless otherwise stated in a credit line to the data.* Correspondence: L.A.Garcia-Garcia@sussex.ac.uk1University of Sussex, School of Engineering and Informatics, Falmer,Brighton, UKFull list of author information is available at the end of the articleGarcía-García and Rodríguez-Salvador Journal of Biomedical Semantics           (2020) 11:3 https://doi.org/10.1186/s13326-020-0219-zBackgroundResearch articles are public documents that report scien-tific advancements to share knowledge and promote devel-opment in science. These documents contain fundamentalinformation regarding not only to research but also to theorganizations and authors involved. This data is of interestto identify leading organizations and to map scientificcollaborations.Scientometric tools such as co-citation analysis, biblio-graphic coupling, or co-author analysis can help to achievethese goals. Co-citation analysis and bibliographic couplingare mainly used to measure the flow of information basedon the documents selected by authors, while co-authoranalysis is more focused on the analysis of collaboration be-tween authors, taking into consideration the social aspectof the research collaboration. Furthermore, co-author ana-lysis has been proved to be useful to determine the multiand interdisciplinary of the institutions and their collabora-tions [1]. Co-author analysis requires information related toauthors aliases, affiliations, publications, areas of research,and their collaborations. This information can be obtainedfrom digital libraries (DL) aimed to create systems for theidentification of authors such as ORCID, which was createdby non-profit organizations, or ResearcherID, Scopus,PubMED or Web of Science, which are companies that aredeveloping their unique identifiers for authors [24]. Whenevaluating advances in science and technology, names ofauthors and affiliations become major indicators, as 1) theirnumber of citations by peers correlates to their acknow-ledgment as influential on their area of research [5] and 2)contributes to determining the specific disciplines involvedin the research [1], both are important elements to nurturethe decision-making process. In this sense, CompetitiveIntelligence (CI) acquires a relevant role, through the defin-ition, collection, analysis, and presentation of relevant infor-mation [6]. The CI process can be further enhanced byincorporating feedback form experts to validate the infor-mation obtained [7]. CI is fundamental to research and de-velopment (R&D), including products or processes withradical novelty, such as bioprinting.Bioprinting is an emerging technology, a variant of addi-tive manufacturing that involves the fabrication of 3D con-structs for living tissues and organs [8, 9]. This disciplineis growing at an accelerated pace, involving branches ofknowledge such as biology and engineering. Bioprintinghas been developed to assist the needs of a fast-growingpopulation. This technique has potential social and eco-nomic impacts [10, 11], including a huge effect in organtransplants, where one of the main objectives is the print-ing of functional biological structures to help in the short-age of organs, thus overcoming long waiting lists andissues related to the transplanted organs such as rejection[1012]. Although there have been significant signs of pro-gress in the past years, there are some areas of research tobe explored in this incipient technology [11]. Since acad-emy and industry have acknowledged that bioprinting willhave a significant impact on the health-care sector in thefollowing years, the identification of technology trends in3D bioprinting [13, 14], including potential printing tech-niques [15], becomes crucial to stay competitive and todevelop new technologies in this field. With this aim,Rodriguez-Salvador et al. [7] performed a patentometricand scientometric analysis in bioprinting to identify trendsand to explore the knowledge landscape of this technology.In addition, they also identified the most prolific institu-tions, being the MIT (113 publications) the number one,followed by Nanyang Technology University (103 publica-tions), and Tsinghua University (93 publications); Theyalso found that the three first countries with more publica-tions were USA with 1491, followed by China with 744,and Germany with 377 [7]. These analyses are mostlybased on the frequency of documents by affiliation andcountry, and no inclusion or exclusion terms were set. Theinsights obtained can be enhanced with the identificationof the leading scientists and their field of expertise, thusdistinguishing the principal areas of current research anddetermining potential opportunities for R&D.In order to unveil scientific and technological trends, it isimportant to face big volumes of information using textmining. This activity can be applied to identify and extractpotentially useful information from texts. It combines toolssuch as machine learning, artificial intelligence, and statis-tics to analyse large amounts of both structured and un-structured data. The information obtained can contributeto understanding patterns in data by making use of toolssuch as text categorization, text clustering, information ex-traction, among others [16]. Information retrieval, wordfrequency analysis, word distribution, pattern recognition,and visualisation techniques are some of the most frequentpractices [17]. As a conclusion, text mining adds importantvalue to the pattern recognition by structuring the contentof data from textual sources for research, data analysis,business or competitive intelligence (CI) [1719].A fundamental topic for the CI is the determination ofkey players, such as the main organizations and authors in-volved in scientific advancements. Network analysis can beused to identify the collaboration in a visual pattern, whereeither the authors or affiliations are represented by nodesand their collaborations can be seen as the connectionamong them. Moreover, the nodes with common attributesof interest for the analysis can be grouped using clusteriza-tion. Clusterization allows to group components with simi-lar characteristics, such as research topics or techniques.When clustering collaborations, the closer the nodes in au-thors or affiliations network maps, the more similaritiesthey share [5, 20]. Furthermore, collaboration analysis canbe strengthened with the assessment of the BetweennessCentrality (BC) to determine the level of association of theGarcía-García and Rodríguez-Salvador Journal of Biomedical Semantics            (2020) 11:3 Page 2 of 13nodes according to their position in the network. Astraightforward measurement of the association level canbe the connectivity, but it fails to disclose the importanceof a node. To overcome this, BC measure can be calculatedto evaluate the importance of a node and its social inter-action in a network as this measure counts the number ofregions in the map connected by each element, settingtheir importance in the flow of information [21, 22].Scientometric and patentometric techniques have beenused recently to analyse the number publications per year,the main authors, and organizations to determine the mainadvancements in bioprinting (methods, materials, etc.)[2325]. Scientometric and text mining can be used to de-tect the authors and affiliations with more publicationsand more influence in bioprinting. This information canbe an input for people looking for well-known experts inbioprinting or state-of-the-art developments in the field.To achieve the main goal of this paper, a customisedsearch query was used to gather documents from Scopus.The query included keywords highly used in the mostcited papers on bioprinting. Two network maps of collab-orations, one for authors and one for affiliations, weregenerated and analysed. Further analyses were carried outto estimate the BC measurement, and the relationship be-tween number of publications and the number of collabo-rations. These parameters were used for the identificationof the most prolific (those with more publications on thistopic) and important authors and institutions involved inthe publications of advances in bioprinting.This analysis is the first attempt to undertake a quantita-tive analysis using a network analysis approach and thecalculation of centrality measurements to strengthen theCI methodologies. The findings enhance the perception ofthe importance of collaborations among institutions forthe generation of high-quality scientific outcomes and forthe dissemination of the knowledge generated, helpingboth researchers and stakeholders in the identification ofpotential opportunities for research and collaboration.MethodsThis paper is focused on the network analysis of authorsand institutions from scientific publications in bioprinting.The analysis comprises both, a network analysis on thecollaboration among institutions and one that deals withthe collaboration among authors. The network maps weregenerated in Gephi, an open-source software for networkanalysis [2634]. Betweenness centrality was calculatedfor both, authors and institutions collaborations.The adequate identification of specific keywords on thetopic of interest is a determining step in the search strat-egy, as they contribute to the appropriate establishment ofthe search queries. A preliminary search in Scopus usingonly the term bioprinting with no period of time definedwas the first stage of this research. Scopus was selected forthe information retrieval as this is a major scientific data-base that includes information from more than 20,000 sci-entific journals [35]. The ten most cited papers identifiedthrough this search were selected, as they have beenacknowledged as referents for the topic. Table 1, García-García[36], shows the ten articles that formed the first setof documents. These papers were used to identify the key-words to form the search queries. A text mining programwas specially coded to carry out the text-mining of thesepublications, thus determining the most relevant keywordson the topic. With a broader range of terms and their syn-onyms we guarantee the inclusion of a wide range of pub-lications compared to searches performed using only theterm bioprinting. Three different types of keywords weresearched in the whole text of the papers, being 1) the mostfrequent terms, 2) terms containing the word bio, and 3)the collocations, which are the juxtapositions of two wordswith a greater frequency. A cleaning of terms was accom-plished manually afterward to sort them out according tospecialized language of the subject. The identified key-words were separated by subtopics (i. e. technology,process, and application) to form the search queries. A setof 23 searches were performed with the selected termin-ology prior to the development of the definite query.These searches were used to identify the correct groupingof terms and the exclusion terms.The search query was formed using the keywords previ-ously identified in combination with Boolean and proxim-ity operators, and exclusion terms. For this stage, thedefinite search was carried out by defining the period oftime, from 1 January 2000 to 15 November 2017 (whenthe information collection was concluded). The mainquery is observed in the appendix A1. The collection activ-ity involved the use of the query to search in title, abstractand keywords. A quick review of titles and abstracts of thedocuments found was carried out to discard those notrelated to bioprinting.The bibliographic information of the documents identi-fied in Scopus was retrieved and exported in a CSV formatto be cleaned and analysed. A cleaning process and thecomplete normalization of the data was carried out tostandardize authors and affiliations names. We performeda manual name disambiguation for both authors and affili-ations. The two authors analysed manually all the nameson each one of the publications gathered. Every time asimilar name was observed, name disambiguation was car-ried out by looking to the full name, affiliation, and e-mail.The level of agreement on the disambiguation performedby the authors was measured using Cohens kappa [37].Co-author analysis was limited exclusively to the informa-tion of the publications gathered and we did not requirefurther information from available DLs.The analysis to identify the most influential authorsand affiliations was carried out by setting a threshold forGarcía-García and Rodríguez-Salvador Journal of Biomedical Semantics            (2020) 11:3 Page 3 of 13Table1ComparisonofthetoptencitedpapersfromScopusobtainedfromthesearchof`bioprintingandthedevelopedsearchqueryintitles,abstracts,orkeywordsToptenresultsusingthekeywordbioprinting[36]ToptenarticlesusingthedevelopedsearchstringTitleAuthorsYearSourceCitesTitleAuthorYearSourceCites13Dbioprintingoftissueandorgans[38].Murphy,S.V.,Atala,A.2014NatureBiotechnology32(8),pp.77378514983Dbioprintingoftissuesandorgans[38].MurphyS.V.,AtalaA.2014NatureBiotechnology32(8),pp.773785.14982Scaffold-freevasculartissueengineeringusingbioprinting[39].Norotte,C.,Marga,F.S.,Niklason,L.E.,Forgacs,G.2009Biomaterials30(30),pp.59105917600Microscaletechnologiesfortissueengineeringandbiology[40].KhademhosseiniA.,LangerR.,BorensteinJ.,VacantiJ.P.2006Proc.Natl.Acad.Sci.U.S.A.,103(8),pp.24802487.116333Dbioprintingofvascularized,heterogeneouscell-ladentissueconstructs[24].Kolesky,D.B.,Truby,R.L.,Gladman,A.S.,Homan,K.A.,Lewis,J.A.2014AdvancedMaterials26(19),pp.31243130588Clinicaltransplantationofatissue-engineeredairway[41].MacchiariniP.,JungebluthP.,GoT.,AsnaghiM.A.,ReesL.E.,CoganT.A.,DodsonA.,MartorellJ.,BelliniS.,ParnigottoP.P.,DickinsonS.C.,HollanderA.P.,ManteroS.,ConconiM.T.,BirchallM.A.2008TheLancet372(9655),pp.20232030.10144Printingandprototypingoftissuesandscaffolds[23].Derby,B.2012Science338(6109),pp.921926510Mechanicalpropertiesandcellculturalresponseofpolycaprolactonescaffoldsdesignedandfabricatedviafuseddepositionmodelling[42].HutmacherD.W.,SchantzT.,ZeinI.,NgK.W.,TeohS.H.,TanK.C.2001JournalofBiomedicalMaterialsResearch55(2),pp.203216.9395Additivemanufacturingoftissuesandorgans[43].Melchels,F.P.W.,Domingos,M.A.N.,Klein,T.J.,Bartolo,P.J.,Hutmacher,D.W.2012ProgressinPolymerScience37(8),pp.10791104495Solidfreeformfabricationofthree-dimensionalscaffoldsforengineeringreplacementtissuesandorgans[44].LeongK.F.,CheahC.M.,ChuaC.K.2003Biomaterials24(13),pp.23632378.739625thanniversaryarticle:Engineeringhydrogelsforbiofabrication[45].Malda,J.,Visser,J.,Melchels,F.P.,Groll,J.,Hutmacher,D.W.2013AdvancedMaterials25(36),pp.50115028465Stemcell-basedtissueengineeringwithsilkbiomaterials[46].WangY.,KimH.-J.,Vunjak-NovakovicG.,KaplanD.L.2006Biomaterials27(36),pp.60646082.6577A3Dbioprintingsystemtoproducehuman-scaletissueconstructswithstructuralintegrity[47].Kang,H.-W.,Lee,S.J.,Ko,I.K.,Yoo,J.J.,Atala,A.2016NatureBiotechnology34(3),pp.312319466Scaffold-freevasculartissueengineeringusingbioprinting[38].NorotteC.,MargaF.S.,NiklasonL.E.,ForgacsG.2009Biomaterials30(30),pp.591059176008Printingthree-dimensionaltissueanalogueswithdecellularizedextracellularmatrixbioink[48].Pati,F.,Jang,J.,Ha,D.-H.,Kim,D.-H.,Cho,D.-W.2014NatureCommunications53,935412Organprinting:Tissuespheroidsasbuildingblocks[49].MironovV.,ViscontiR.P.,KasyanovV.,ForgacsG.,DrakeC.J.,MarkwaldR.R.2009Biomaterials30(12),pp.21642174.5949Tissueengineeringbyself-assemblyandbio-printingoflivingcells[50].Jakab,K.,Norotte,C.,Marga,F.,Vunjak-Novakovic,G.,Forgacs,G.2010Biofabrication2(2),0220012903Dbioprintingofvascularized,heterogeneouscell-ladentissueconstructs[24].KoleskyD.B.,TrubyR.L.,GladmanA.S.,BusbeeT.A.,HomanK.A.,LewisJ.A.2014AdvancedMaterials26(19),pp.31243130588103DBioprintingofheterogeneousaorticvalveconduitswithalginate/gelatinhydrogel[51].Duan,B.,Hockaday,L.A.,Kang,K.H.,Butcher,J.T.2013JournalofBiomedicalMaterialsResearch-PartA101A(5),pp.12551264244BindingandcondensationofplasmidDNAontofunctionalizedcarbonnanotubes:Towardtheconstructionofnanotube-basedgenedeliveryvectors[52].SinghR.,PantarottoD.,McCarthyD.,ChaloinO.,HoebekeJ.,PartidosC.D.,BriandJ.-P.,PratoM.,BiancoA.,KostarelosK.2005JournaloftheAmericanChemicalSociety127(12),pp.43884396.574García-García and Rodríguez-Salvador Journal of Biomedical Semantics            (2020) 11:3 Page 4 of 13each analysis. A threshold of five documents cited atleast ten times was set for authors, while for the institu-tions we selected those with five documents cited at leastfive times. These inclusion parameters were based onthe median number of cites for the whole set of docu-ments, which was 10.33, and the median number of pub-lications per author was 5.76. For institutions, the meannumber of publications was 10 with the same median ofcites for the documents, 10.33; however, only three affili-ations were within the threshold, hence the median forcitations and documents was reduced to 5 to includemore affiliations.To identify the most prolific authors, the top ten au-thors with more frequency within the threshold definedwere selected and a Pearson correlation was computed todetermine the relationship existing between the numberof publications and the number of co-authors. The au-thors were clustered by the similarity of areas of researchin the network maps and those with higher networkingwere identified by BC calculation. The number of times anode is taken as a connection for the shortest pathsbetween two other nodes can be estimated through BC,which measures the nodes connection to different groupson a network map, being of a higher value the one whoconnects more groups [53]. The BC is obtained using theequation [53]:CB vð Þ ¼Xv?s?t?st vð Þ?stWhere ?st is the total of shortest paths from node s tonode t, and ?st (v) is the number of those paths that gothrough v.The information within the threshold was importedinto VOSviewer, a software for data analysis and visual-isation [54, 55], to perform the network map analysis.The authors or institutions are represented by nodes orvertex in the network maps, and their connections arerepresented by links or edges; in this document, theterms are used indistinctly to refer to authors or affilia-tions and their connections. Two undirected networkmaps were constructed from two matrices, representingonly the correlation and not causality. A matrix of au-thors and a matrix of affiliations were generated usingthe visualisation of singularities (VOS) of the VOSviewersoftware [55]. The clustering was performed in VOS-viewer, computed using the default Field IndependentClustering Model (FICM) [55]. The statistical analysis todetermine the BC of the nodes forming both maps wasperformed in Gephi. The final step of the analysis wasthe consultation with experts in 3D bioprinting to valid-ate the results. Experts from UK and Asia were selectedbased on their international presence and impact in thefield considering elements such as their number of cites,publications, projects, and their availability. Instead ofproviding the experts with a list of authors found on theresults of this research, we asked them to provide a listof authors working on bioprinting according to theirown criteria. This method was used to reduce bias intheir selection, as they provided a list acknowledgingtheir peers based on their own experience. Is it worthmentioning that the experts requested anonymity, there-fore, we can only provide professional details of three ofthem at the time they were consulted. One of the ex-perts was affiliated to the School of materials at the Uni-versity of Manchester and had more than 10,000 Scopuscitations. A second expert was affiliated to the Faculty ofEngineering at the University of Nottingham and hadmore than 760 citations. A third one was affiliated to theSingapore Centre for 3D printing at Nanyang Technol-ogy University with more than 14,000 citations.ResultsFrom the initial search, where the ten most cited articles inbioprinting from Scopus were considered, the top-citedarticle is 3D bioprinting of tissue and organs [37]. This is areview of different techniques used in bioprinting cited1498 times, as seen in Table 1; the second most cited art-icle is Scaffold-free vascular tissue engineering using bio-printing [38]. This article describes a fully biologicalmethod to fabricate tubular vascular grafts and has beencited less than 50% of the first author, 600 times; the thirdpaper, entitled 3D bioprinting of vascularized heterogeneouscell-laden tissue constructs [24] was cited 446 times anddescribes methods to generate vascularized tissue con-structs. The second and third papers are focused on one ofthe biggest challenges faced to print fully functional organs,the fabrication of scaffold-free blood vessels with mechan-ical properties close to the naturally grown vessels. Five ofthe ten articles were published in journals related to mate-rials, four of them in general science journals (Nature Bio-technology, Nature Communications, and Science), andone in the journal of Biofabrication, as can be observed inTable 1. The results of the searches in Scopus using onlythe term bioprinting and those obtained using the searchquery developed are listed and compared in Table 1. It canbe observed that the paper entitled 3D bioprinting of tissueand organs still in first place in both results. The secondpaper listed in the results from the search string is Micro-scale technologies for tissue engineering biology by Khadem-hosseini et al. [39] with 77% of the cites of the most firstpublication, 1163, followed by the paper Clinical trans-plantation of a tissue-engineered airway by Macchiariniet al. [40], published in the Lancet. Interestingly, the firstthree papers are published in three major journals coveringbiology and medical-related science, and six out of the 10papers on this search were published in journals related tomaterials and one in chemical engineering.García-García and Rodríguez-Salvador Journal of Biomedical Semantics            (2020) 11:3 Page 5 of 13Using the previously defined search query a total of2088 publications were found from 2007 to November15 of 2017 (when information collection activity ended).Figure 1 shows the number of publications per year,there is a remarkable growth, where the highest numberof publications is 339 for 2017.After the data selection and cleaning, a total of 228authors were found within the threshold of at least 5 docu-ments with 10 or more citations. 89 of the authors werefound with repeated surnames. A Cohens kappa (?) of0.62 was obtained for the agreement on the author namedisambiguation. Values from 0.61 to 0.8 are ranked asGood [36]. A collaboration was observed in 93% of the au-thors, being 792 the total number of connections in themap. Regarding affiliations, a total of 20 organizations fallinto the inclusion threshold, from which only 30% had anexternal collaboration.From the analysis, only ten authors were found to havemore than 18 documents, as seen in Fig. 2, where thenumber of documents and the number of co-authors foreach of them are shown. The author with more documentsfalling in the threshold defined is Atala A. with 36 docu-ments and 13 co-authors. The following author, Khadem-hosseini A., had a total of 30 documents and more thandouble of collaborations for the first author, 27 co-authors,being the one with more connections. Mironov V. was inthird place with 30 documents, and 20 co-authors. A Pear-son correlation analysis was performed to determine therelationship between documents and co-authors, and aweak positive correlation was observed, as the Pearson cor-relation coefficient had a value r = 0.29 for the top ten au-thors, stating a lack of relationship between the number ofco-authors and the number of publications.Figure 3 shows the network map of the authors col-laboration, where the nodes size is proportional to theirBC value. The nodes representing the authors weregrouped in a total of 17 clusters. From the BC calcula-tion, the most prolific author, Atala A., was at the WakeForest Institute for Regenerative Medicine from theWake Forest University School of Medicine, WinstonSalem, United States when the information was gathered(15 November 2017). According to Scopus altmetrics,this author had an h-index of 89, 850 documents pub-lished, and a total of 17,376 citations working with 150co-authors at the time of the analysis (see Table 2). Onthe other hand, under the inclusion terms, this authorpublished a total of 36 documents on the topic analysed,having 13 connections, 2851 citations, and a between-ness centrality value of 370.9.The second most prolific author found is Khademhos-seini Ali L.I., affiliated with the Brigham and WomensHospital, Department of Medicine, Boston, United States,when the data was collected. This author had an h-indexof 88, a total of 645 papers, with a total of 16,704 citationsand 150 co-authors, as stated in the Scopus altmetrics.Considering the inclusion terms, this author accountedfor 30 documents, 27 connections, 3047 citations, and abetweenness centrality of 2104.9 (see Table 2).Fig. 1 Publications per year in bioprintingGarcía-García and Rodríguez-Salvador Journal of Biomedical Semantics            (2020) 11:3 Page 6 of 13The third author was Mironov V., from the Laboratoryfor Biotechnological Research 3D bioprinting solutions,Moscow, Russian federation. The Scopus altmetrics showedthat this author had 105 papers, 3231 cites, and an h-indexof 31, co-authoring with 150 people. In this analysis, the au-thor accounted for 30 documents, 20 links, 1009 citations,and a betweenness centrality of 2754.9 (see Table 2).According to the network map and the BC calculations,Mironov V. was stated as the author with a higher influ-ence in the knowledge flow of the collaboration network, asit had the higher BC, followed by Khademhosseini A. WhileMironov was affiliated to a biotechnological researchlaboratory, Atala and Khademhosseini were associated totwo of the top ten research departments in bioprintingfound on this analysis.The authors ranked by the experts were comparedwith the most influential authors disclosed in this study,as it can be seen from Table 3.Three of the ten top authors in this scientometric studywere considered as influential by the experts consulted,Atala A., Mironov V., and Wei Sun; who were listed amongthe top five authors in both cases. The top three authorsfrom this study, who are listed in Table 3, are also the maininfluential authors with a higher BC (see Table 2).Institutions research efforts can be better estimated bythe number and the quality of their publications, thereforethe affiliations with more publications on bioprinting arehere analysed. A total of 1760 affiliations were identifiedin the information obtained for the 2088 documents, witha median of 10 publications per institution and a standarddeviation of 7.8. The top ten affiliations with more publi-cations in bioprinting are presented in Fig. 4. An interest-ing fact is that seven of the top ten are based in theUnited States, two of them are in China and one inSingapore.Remarkably, four of the 7 affiliations in the UnitedStates are located in Massachusetts, and three of themhave a higher number of publications within the thresh-old. The Harvard Medical School is the institution withmore publications in the analysis here presented, with61 documents, followed by the Brigham and WomensHospital, with 46 documents. Both affiliations are lo-cated at the Longwood Medical and Academic Area, amedical campus in Boston with a strong life sciencecluster [56]. The Brigham and Womens Hospital, is aninstitution joint to the Harvard Medical School andholds the second largest hospital-based program in theworld, pioneering in the heart valve operation and theworlds first solid organ transplant [57].The Massachusetts Institute of Technology (MIT), lo-cated in Cambridge, MA, was found to be in third placeon papers related to the bioprinting, presenting 37 docu-ments within the threshold defined. This institute holdsthe fifth place in the World University Ranking 20162017 of the Times Higher Education [58]. The fourth in-stitution found with more publications is the Wake For-est University School of Medicine, an academic medicalcentre ranked among the best in the United States,Fig. 2 Number of documents and co-authors of the top ten authors in bioprintingGarcía-García and Rodríguez-Salvador Journal of Biomedical Semantics            (2020) 11:3 Page 7 of 13promoting research in medical areas [59]. This affiliationshows 35 documents. Tsinghua University is placed infifth place, with 33 publications. This institution was onthe 35th place on the Times Higher Education WorldUniversity Rankings 2017 [58].For the affiliations analysis, a total of 20 out of the 1760 in-stitutions met the inclusion requirements, which at least fivedocuments with at least five citations each. However, only sixaffiliations within this threshold were found to have a collab-oration with external institutions. Figure 5 depicts thecollaboration network between these institutions, the size ofthe nodes is proportional to their number of documents,while the thickness of the connection line is proportional tothe strength of the link, which is equal to the number of doc-uments they have co-authored. Within the inclusion limitsabove stated, the Harvard-MIT Division of Health Sciencehas the first position having 37 papers, followed by the WakeForest Institute for Regenerative Medicine with 28 docu-ments and the Biomaterials Innovation Research Centre fromthe Brigham and Womens Hospital with 26 documents.Fig. 3 Co-authors network map, the authors names were normalized with lower case lettersTable 2 Comparison of the Scientometric information between Scopus and the analysis performed to the top three authors with 5or more documents with 10 or more citationsAuthor Documents Connections Citations BC h-indexScopus Threshold Scopus Threshold Scopus ThresholdAtala A. 850 36 150 13 17,376 2851 370.9 89Khademhosseini Ali L.I. 645 30 150 27 16,704 3047 2104.9 88Mironov V 105 30 150 20 3231 1009 2754.9 31García-García and Rodríguez-Salvador Journal of Biomedical Semantics            (2020) 11:3 Page 8 of 13On the other hand, the network map shows four institu-tions with 5 collaborations. These institutions are theBiomaterials Innovation Research Centre, at the Brighamand Womens Hospital from the Harvard Medical School,United States, the Harvard-MIT Division of HealthSciences and Technology at the Massachusetts Institute ofTechnology, United States, the Department of Physics atthe King Abdulaziz University, Saudi Arabia, and the De-partment of Bioindustrial Technologies, Konkuk Univer-sity, South Korea. The remainder institutions have fourconnections, the Wyss Institute for Biologically InspiredEngineering, Harvard University, United States and theWake Forest Institute for Regenerative Medicine, WakeForest School of Medicine. Interestingly, three of the sixaffiliations are located in Massachusetts and two of themare associated to the University of Harvard, the second-best research university from the United States [60]. Thisinstitution has a close collaboration with the top institutein the United States, the Massachusetts Institute of Tech-nology [58]. Both institutions have founded the Harvard-MIT Division of Health Sciences and Technology, associ-ated to the Massachusetts Institute of Technology. Thisinstitute is the one with more citations, 1454, which alsohas a strong collaboration with the BiomaterialsInnovation Research Centre, which has 1099 citations.These affiliations are followed by the Wake Forest Schoolof Medicine with 858 citations.The low number of institutions and the high degree ofconnectivity among them is reflected on the computa-tion of the BC for each institution. The four affiliationswith five links each had the same BC centrality, 0.25, cal-culated with Gephis statistic tools; this low value meansthat all the affiliations share the same importance for thenetwork. On the other hand, the remaining two affilia-tions have four connections, and a BC equal to zero, notcontributing significantly to the network.Fig. 4 Top ten institution and number of publications in bioprintingFig. 5 Network map of the collaboration between affiliationsGarcía-García and Rodríguez-Salvador Journal of Biomedical Semantics            (2020) 11:3 Page 9 of 13DiscussionThe identification leading authors and affiliations and theircollaborations were the main factors to be determined inthis study. The use of the text mining software developedwas found to have a significant contribution to the identifi-cation of keywords to design the search queries. This stepwas crucial to include the complete set of publications dis-cussing the topic of bioprinting. The search queries createdincluded a wide range of terms and synonyms that areused in articles on topics related to bioprinting. An expo-nential growth of publications per year was observed fromthe data of the documents obtained. Furthermore, as oneof the main goals of this study was to identify the mostinfluential authors working in bioprinting, the analysis,including author disambiguation, was exclusively based onthe publications information specifically obtained from theScopus database. Although there are more scientific data-bases available, Scopus was selected because it also con-tains non-English coverage and its altmetrics tools wereused for a quick overview of the results. Although Data-bases such as Web of Science cover records back to 1900,we analysed only a specific period, which could be coveredby Scopus. Although results provide the appraisal of one ofthe most complete scientific databases available, Scopus,the information obtained can be further enhanced byanalysing data obtained from more databases to supportthe findings. The author disambiguation was performedmanually for the authors with good agreement; however,this procedure can be improved by including tools such assimilarity of pairs or features contribution. In this analysisit was observed that although a high number of authorswere engaged in the advancement of the scientific outputon bioprinting, only a small percentage have a remarkableproductivity on the topic. Furthermore, there was found aslight association between the number of documents andthe number of collaborations. Co-author analysis has con-tributed to the identification of the intellectual structure offields and specialties [2] and to identify research groups[3]. In this research, the network map analysis was en-hanced with the calculation of BC to identify the authorswith more publications and the most influential authorsand institutions working in bioprinting. Although some ofthe authors might be regarded as scientists with a higherrank or seniority, this classification was beyond the scopeof this study.The number of affiliations working in bioprinting wasfound to be high, as expected. However, only a smallportion of them fulfil the inclusion requirements for theanalysis. The most prolific institutions that came acrossin this study, such as Nanyang Technological University,MIT, and Tsinghua University, were also previously re-ported to be among the three most prolific in [15].Moreover, a reduced number of collaborations betweenthe institutions in the threshold was found, anunanticipated outcome for a multidisciplinary technol-ogy. The institutions with more publications, The Har-vard Medical School and the Brigham and Womenshospital, were two of the top ten Universities in theWorld University Ranking [58], which have established aresearch centre close to both institutions. Besides, thestrategic geographical position of the affiliations to pro-mote collaborations has been observed as important toencourage scientific production. But not only the institu-tions located closely, namely the Harvard MedicalSchool, Brigham and Womens Hospital and the Div-ision of Health Science, were found to have strong col-laborations, also the Department of BioindustrialTechnologies of the Konkuk University and the Depart-ment of Physics, of the King Abdulaziz University exhib-ited a high degree of collaboration. This illustrates thatgeographical positioning is an important factor to collab-orate, but it is not crucial.The method here presented involved the overall staticanalysis of collaborations over a ten-year period, as thechange in time for both kinds of collaboration, thoseamong authors and those among affiliations, were notanalysed for different periods. Furthermore, the resultshere shown concern the general approach of bioprintingdomain, where a wide range of methodologies and tech-nologies are involved without special emphasis on anyparticular methodology. In this sense, any agreement onthe most influential authors and institutions is more dif-ficult to reach. The threshold set in this study was usedto determine the most influential authors and institu-tions in bioprinting, taking into account also the depart-ments of affiliation, thus differing from the analyse madeby Rodriguez-Salvador et al. [7], where only countriesand institutions were considered. Regarding affiliations,insights obtained in the analysis are consistent with theinstitutions reported in by Rodriguez-Salvador et al. [7].Both analyses, this analysis and the one reported byRodriguez-Salvador et al. differ from the list provided bythe experts, shown in Table 3. The threshold was de-fined to include only those authors and affiliations withcites above the average, and this influenced the networkmap analysis, by reducing significantly the number ofnodes in the map. Another aspect that influenced the re-sults was the exclusion of those nodes with no connec-tions. These nodes were neglected in this study as zerolinks on the maps mean zero BC and do not have any ef-fect in the overall results. Furthermore, another possiblereason for the difference between the list provided byexperts and the results here disclosed, is that expert tra-jectories can have a subjective influence to define themost influential authors in bioprinting.In this research, we also disclosed the six main institu-tions working on bioprinting and their collaboration net-work. The use of network analysis and the calculation ofGarcía-García and Rodríguez-Salvador Journal of Biomedical Semantics            (2020) 11:3 Page 10 of 13the BC was decisive to find the authors with a higher de-gree of influence on the topic. However, the identifica-tion of research areas of both authors and affiliationswas out of the scope of this research, and this can be in-vestigated when looking for R&D opportunities forinnovation in bioprinting. This research set the basis todetermine collaborations and their position in a scien-tific network. The knowledge obtained in our researchcan provide support to researchers and stakeholderslooking for engagement in R&D projects on bioprinting.ConclusionsNetwork map analysis was used here to identify the mostprominent institutions and authors. A threshold was de-fined to disclose authors and organisations with a highernetwork of collaboration, identifying authors with morepublications. Moreover, the Betweenness Centrality cal-culation allowed us to identify the most influential au-thors and institutions working on bioprinting. Theoutcomes obtained can give strength to the perceptionof the collaborations in bioprinting technologies. Al-though the global research community in bioprintinghas grown, the most influential affiliations and authorsare located in the United States. The top three authorshave more than 29 articles each within the thresholdestablished. From the authors network map analysis, itwas observed that there is no direct correlation betweenthe BC, number of documents, and connections, as theone with more documents in the threshold was the onewith less connections and the lower BC value. The affili-ations with more publications are members of the topuniversities in the United States and are part of medicalresearch programs. Individuals interested in the develop-ment of bioprinting can benefit from the informationhere disclosed to perform a trend analysis on the institu-tions hereby mentioned. And identifying core technolo-gies that have led them to success. The findings of thisstudy can offer valuable information to be used insystematic approaches to support the decision making ofresearchers and stakeholders.AppendixSearch queryTITLE-ABS-KEY (((((3d OR 3-d OR three-dimensional)W/1 (bioprint* OR engineer* OR print* OR tech* ORfabricat* OR process* OR manufact* OR building ORbuilt)) OR ((bio-engineer* OR bioengineer* OR biofabri-cat* OR bioprint* OR biotech* OR biomanufact*)) OR(bioadditive W/1 manufact*) OR (3d AND bioprint*)))W/5 (scaffold* OR construct* OR spheroid* OR channel*OR structure* OR matr* OR crosslinking OR block* ORaggregate* OR sheet* OR biomim* OR bioactiv* OR bio-hybrid* OR bioresorbable OR bioscaffolds OR biosensorsOR bioassembl* OR bioartificial OR bioerodible OR bio-patterning OR biopaper OR microextrusion) W/5 (cell*OR tissue* OR stem OR multicellular OR organ* ORbiolog* OR embryonic OR vascular OR vessels OR cola-gen OR bone* OR osseo* OR adipose OR vascular ORcardiac OR heart OR cartilage* OR muscle) AND NOT(data storage OR photonic OR pcl OR social capital))AND (PUBYEAR > 2000 AND PUBYEAR < 2018).AbbreviationsBC: Betweenness Centrality; CI: Competitive Intelligence; CSV: CommSeparated Values; CTI: Competitive Intelligence; DL: Digital Libraries;FICM: Field Independent Cluster Model; MIT: Massachusetts Institute ofTechnology; R&D: Research and Development; VOS: Visualisation ofsingularitiesAcknowledgmentsThis research was supported by the research group in AdvancedManufacturing at the Tecnologico de Monterrey and by the CONACYTpostdoctoral fellowship program.Authors contributionL. A. G. G. Design the study, data collection, generation of maps, dataanalysis, drafting and editing of the final manuscripts. M.R. S. participated inthe study design and writing feedback. All authors read and approved thefinal manuscript and agreed on its submissionTable 3 Comparison of authors in bioprinting ranked by experts versus the most influential authors disclosed in this studyRank List of most influential authors provided by experts List of most influential authors found on this studyAuthor Institution Author Institution1 Atala A. Wake Forest Institute for Regenerative Medicine Atala A. Wake Forest Institute for Regenerative Medicine2 Mironov V. Laboratory for Biotechnological research Khademhosseini Ali L.I. Brigham and Womens hospital3 Malda J. Utrech University Mironov V. Laboratory for Biotechnological research4 Derby B. University of Manchester Sun W. Drexel University and Tsinghua University5 Sun W. Drexel University and Tsinghua University Wang X. Tsinghua University6 Lewis J. Harvard Cho D. W. Pohang University of Science and Technology7 Yoo J. Wake Forest Institute for Regenerative Medicine. Zhang L. G. George Washington University8 Woodfield T. University of Otago Okano T. Tokyo Womens Medical University9 Dalton P. University of Wurzburg Zhang Y. Brigham and Womens hospital10 M. Zanobi-Wong ETH Zurich Rezende R. A. Centre for information Technology Renato ArcherGarcía-García and Rodríguez-Salvador Journal of Biomedical Semantics            (2020) 11:3 Page 11 of 13FundingThis work was funded by Tecnologico de Monterrey through the Escuela deIngenieria y Ciencias and also supported by a postdoctoral scholarshipgranted by the Mexican National Council for Science and Technology(CONACYT). The funders had no role in study design, data collection andanalysis, decision to publish, or preparation of the manuscript.Availability of data and materialsThe datasets generated and/or analysed during the current study areavailable in the Open Science Framework repository, https://osf.io/ez7mv/ .Named bioprinting_scopus_data_10.csv,Ethics approval and consent to participateNot applicable.Consent for publicationNot applicable.Competing interestsThe authors declare that they have no competing interests.Author details1University of Sussex, School of Engineering and Informatics, Falmer,Brighton, UK. 2Tecnologico de Monterrey, Escuela de Ingeniería y Ciencias,Monterrey, Nuevo Leon, Mexico.Received: 6 March 2018 Accepted: 30 January 2020Keet Journal of Biomedical Semantics            (2020) 11:4 https://doi.org/10.1186/s13326-020-00224-yDATABASE Open AccessThe African wildlife ontology tutorialontologiesC. Maria KeetAbstractBackground: Most tutorial ontologies focus on illustrating one aspect of ontology development, notably languagefeatures and automated reasoners, but ignore ontology development factors, such as emergent modelling guidelinesand ontological principles. Yet, novices replicate examples from the exercise they carry out. Not providing goodexamples holistically causes the propagation of sub-optimal ontology development, which may negatively affect thequality of a real domain ontology.Results: We identified 22 requirements that a good tutorial ontology should satisfy regarding subject domain, logicsand reasoning, and engineering aspects. We developed a set of ontologies about African Wildlife to serve as tutorialontologies. A majority of the requirements have been met with the set of African Wildlife Ontology tutorial ontologies,which are introduced in this paper. The African Wildlife Ontology is mature and has been used yearly in an ontologyengineering course or tutorial since 2010 and is included in a recent ontology engineering textbook with relevantexamples and exercises.Conclusion: The African Wildlife Ontology provides a wide range of options concerning examples and exercises forontology engineering well beyond illustrating just language features and automated reasoning. It assists indemonstrating tasks concerning ontology quality, such as alignment to a foundational ontology and satisfyingcompetency questions, versioning, and multilingual ontologies.Keywords: Ontology engineering, Tutorial ontology, African wildlifeBackgroundThe amount of educational material to learn about ontolo-gies is increasing gradually, and there is material for dif-ferent target audiences, including domain experts, appliedphilosophers, computer scientists and software develop-ers, and practitioners. These materials may include a tuto-rial ontology to illustrate concepts and principles and maybe used for exercises. There are no guidelines as to whatsuch a tutorial ontology should be about and should looklike. The two most popular tutorial ontologies are aboutwine and pizza, which are not ideal introductory subjectdomains on closer inspection (discussed below), they arelimited to OWLDL only, and are over 15 years old by now,Correspondence: mkeet@cs.uct.ac.zaDepartment of Computer Science, University of Cape Town, 18 UniversityAvenue, Rondebosch, Cape Town, South Africahence, neither taking into consideration the more recentinsights in ontology engineering nor the OWL 2 standardwith its additional features.Considering subject domains in the most closely relatedarea, conceptual modelling for relational databases, thereis a small set of universes of discourse that are used inteaching throughout the plethora of teaching materialsavailable: the video/DVD/book rentals, employees at acompany, a university, and, to a lesser extent, flights andairplanes. Neither of these topics for databases lend them-selves well for ontologies, for the simple reason that thetwo have different purposes. It does raise the question asto what would be suitable and, more fundamentally, whatit is that makes some subject domain suitable but notanother, and, underlying that, what the requirements arefor an ontology to be a good tutorial ontology.© The Author(s). 2020 Open Access This article is licensed under a Creative Commons Attribution 4.0 International License,which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriatecredit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes weremade. The images or other third party material in this article are included in the articles Creative Commons licence, unlessindicated otherwise in a credit line to the material. If material is not included in the articles Creative Commons licence and yourintended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directlyfrom the copyright holder. To view a copy of this licence, visit http://creativecommons.org/licenses/by/4.0/. The CreativeCommons Public Domain Dedication waiver (http://creativecommons.org/publicdomain/zero/1.0/) applies to the data madeavailable in this article, unless otherwise stated in a credit line to the data.Keet Journal of Biomedical Semantics            (2020) 11:4 Page 2 of 11Table 1 Summary of main extant tutorial ontologiesOntology Year Stated aim Content Language Modelling issues AutomatedreasoningCurrent OE (e.g.,ODP, FO)wine 2001 novice all aspects(methodology,modelling, reasoning)for OEsomewhat generic,repetitive, limitedextensibilityframes; thewine.owl inOWL DL isbased on itmultiple (e.g., class vsinstance, hasX)yes nopizza 2004 Protégé user guide,also illustrate OWLand reasoningsomewhat generic,repetitive, limitedextensibilityOWL DL multiple (e.g., hasX,FO commitment, lackof domain & range)yes nouniversity 2005 illustrate OWL andreasoninggeneric, CDM (cf.ontology) scope,very small<OWL DL(ALCIN)multiple (e.g., XorY,naming ofindividuals)yes nozooAnimals 2011 illustrate DL&OWLand some GoodODmodelling guidelinesgeneric, a lot ofdetail, easilyextensible<OWL 2 DL(SHO)few yes partially(BioTopLite)familyhistory2013 illustrate OWL 2 DLand reasoningspecific to authorsfamily, not extensibleOWL 2 DL multiple (e.g., hasX,FO commitment, lackof domain & range)error noshirt 2015 illustrate the design ofthe FMAgeneric, structurespecific to FMA,repetitive, notextensible<OWL 2 DL(ALCIQ)few (lack of domain& range)none very limited(referenceontology)Abbreviations: OE: ontology engineering; ODP: ontology design pattern; FO: foundational ontology; CDM: conceptual data model; FMA: foundational model of anatomy;OWL DL is SHOIN(D) and OWL 2 DL is SROIQ(D) in DL notationIn this paper, we will first analyse existing tutorialontologies and highlight some issues. We then proceedto formulate a preliminary, first, list of requirements thattutorial ontologies should meet. The African WildlifeOntology (AWO) tutorial ontologies are then introducedbriefly and held against the requirements. The scope ofthis paper is thus to introduce the AWO tutorial ontolo-gies and to frame it in that context. Finally, we discuss andconclude.Tutorial ontologies: issues and comparisonThere are several tutorial ontologies, which are sum-marised in Table 1 and discussed in this subsection; thenext subsection that summarises the problems.Of the six tutorial ontologies considered in detail, twoare popular, being the Wine Ontology and the Pizzaontology, since they are part of the W3C OWL guideand designed for the most popular ontology developmentenvironment (Protégé), respectively. They have variousshortcomings as tutorial ontologies, however, especiallyconcerning modelling practices or styles (see also [1]).The Wine ontology in its current form emanates fromthe Ontology development 101 tutorial [2] with itsframes and slots that was subsequently transferred intoOWL1 and used in the OWL guide [3], which is a W3CRecommendation. While the guide contains some goodsuggestions, such as that Synonyms for the same con-cept do not represent different classes [2], there are also1http://www.w3.org/TR/2003/PR-owl-guide-20031209/winemodelling issues, notably that the ontology is replete withthe class-as-instance error that is promoted by the incor-rect statement in the tutorial Individual instances are themost specific concepts represented in a knowledge base.[2] (e.g., TaylorPort as instance of Port and MalbecGrapeas instance of Grape instead of as subclass of ), and thesub-optimal object property naming scheme of hasX ,such as adjacentRegion between two Regions rather thanthe reusable and generic adjacent. Further, it uses differ-ent desiderata in the direct subclassing of wine such as thelikes of Bordeaux and Loire (region-based) and Chardon-nay and Cabernet Sauvignon (grape-based), and thenthere are other criteria, like DessertWine (food pairing-based grouping) and wine descriptor ones (DryWine,RedWine, TableWine), This does make it interesting forshowing classification reasoning (except the undesirablededuction that DryWine ? TableWine), but is not idealfrom amodelling viewpoint. Further, from a tutorial view-point: there are many repetitions, such as very manywineries, which distract from the principles, and it lacksannotations.The Pizza ontology tutorial was created for the Pro-tégé user manual and OWL DL ontology language [4].It reflects the state of the art at that time, yet much hashappened over the past 15 years. For instance, there arenew OWL 2 features and there are foundational ontolo-gies that provide guidance for representing attributes (cf.Pizzas ValuePartition). Pizzas DomainConcept throws alearner straight into philosophical debates, which may notbe useful to start with, and, for all practical purposes,Keet Journal of Biomedical Semantics            (2020) 11:4 Page 3 of 11duplicates owl:Thing. Like the Wine ontology, it hasthe hasX naming scheme for object properties, such ashasTopping, including the name of the class it is sup-posed to relate to, which is a quirk that is a combinationof a workaround for not having qualified number restric-tions (anOWL 1 artefact) and of a sub-optimal ontologicalanalysis of the relation (in casu, of how the toppings reallyrelate to the rest of the pizza) that reduces chance ofontology reuse and alignment. Also, this propagates intostudents modelling approaches: students ontologies inearlier instances of the authors course on ontology engi-neering included, among others, a sandwich ontology withhasFilling, an electrical circuit board ontology with hasIso-lator, furniture with hasHeadboard. Modelling issuesare compounded by the statement we generally adviseagainst doing [domain and range declarations] in thetutorial documentation. When one aims to get novicesto use Protégé and OWL so as not get too many errorwith the automated reasoners, that might make sense,but ontologically, fewer constraints make an ontology lessgood because it admits more unintended models. Finally,it has repetitive content to show features, which may bedistracting, and, as with Wine, there is only one finalontology, despite that multiple releases are common inpractice.Other tutorial ontologies include Family History,zooAnimals, University, and Shirt. Family History [5] isdeveloped by the same group as Pizza and aims to teachabout advanced OWL 2 features and maximise the useof inferencing. Loading it in Protégé 5.2 results in threepunning errors, since it mixes three object properties withannotation properties (affecting 32 axioms), which is dis-allowed, and trying to classify it without the three anno-tation properties returned an OutOfMemoryError (on aMacBookPro, 2.6 GHz and 8GB of memory), which is notideal to start a tutorial with. Concerning modelling issues,ParentOfRobert illustrates one can use individuals in classexpressions, but just that the language allows it, does notmean it is ontologically a good idea that must be taught.It also has the hasX semantic weakness, very few anno-tations, DomainEntity being subsumed by owl:Thing,and multiple data properties. In contrast to Pizza andWine, all the declared instances are instances and theontology has different versions as one goes along in thechapters. It has some subject domain aspects descendinginto politics, which would render it unsuitable for teach-ing in several countries, such as stating that Sex? Femaleunionsq Male (enforcing a gender binary) and that Person ? 2 hasParent.Person (multiple constructions are possiblebiologically, societally, and legally).The remaining tutorial ontologies have been developedby different schools of views on ontology engineering(OE), which is readily apparent in their scope and con-tent. The zooAnimals tutorial ontology [6] comes closestto our aims for a versatile tutorial ontology, demonstrat-ing multiple OWL features, avoiding modelling issuessuch as class vs instance, and it is informed by a top-domain ontology (BioTop) as well as deep philosophicalnotions such as dispositions. It puts them all togetherinto one ontology instead of gradual extensions, how-ever, which is off-putting at a novice stage. One mayquibble about some of the content, such as simplifica-tions that Plant ? ?hasProperPart.Chloroplast (notably,some parasitic plants and all myco-heterotrophic plantsdo not have chloroplasts) and there are unintended unde-sirable deductionsi.e., logically implied, but incorrectontologicallysuch as marineAnimal  Omnivore sincenot all such animals are omnivores. Any simplified com-mon generic subject domain is likely to have some short-cuts that are not 100% scientifically accurate, and it may bea fine line between tutorial approximation and modellingmistake.The University ontology focuses on illustrating OWLfeatures and automated reasoning, rather than modelling.For instance, it has AcademicStaff with sibling NonAca-demicStaff where a non-X complement class is sub-optimal, especially when there is a term for it. The repre-sentation of Student  Person is an advanced modellingaspect that can be improved upon with a separate branchfor roles played by an object. The Computer ScienceOntology was based on the University Ontology tuto-rial and contains artificial classes, like unions of classes(ProfessorinHCIorAI) and underspecified or incorrect indi-viduals like AI and HCI (e.g., some course instance wouldbe CS_AI-sem1-2018 instead).The Shirt ontology is a tutorial ontology to explain thestructure and organisation of the Foundational Model ofAnatomy in a simpler way2 and therefore does not havethe hasX naming scheme for object properties, it has nodata properties and no instances. It has many annotationswith explanations of the entities. There are no inferences.Regarding suitability of the subject domains of theontologies assessed, they are mixed. Wine misses manywine-producing regions in the Americas (e.g., Chile), inEurope (e.g. Spain, Bulgaria), and elsewhere (e.g., SouthAfrica) and Pizza lacks varieties beyond Italian and Amer-ican ones, and both are served regularly in a relativelysmall part of the world, therewith reducing their appealinternationally. Family history and a university as subjectdomains veer too easily into the area of database design fora single application, rather than application-independentgeneric knowledge for an ontology. Shirts and zoo animalsdo not have these shortcomings.Finally, more or less related textbooks were consid-ered [711]. Only the Semantic Web for the working2http://xiphoid.biostr.washington.edu/fma/shirt_ontology/shirt_ontology_1.phpKeet Journal of Biomedical Semantics            (2020) 11:4 Page 4 of 11Ontologist (2nd ed.) has sample files for the books manysmall examples3 with two reoccurring subject domains,being English literature and products.Problems to addressThe previous section described several problems withexisting tutorial ontologies. Notably, the recurring short-comings are thati) good modelling practices are mostly ignored infavour of demonstrating language features,automated reasoning, and toolsii) when good modelling practices and at least somerecent ontology engineering advances are included, itfalls short on language features and gradualextensions.This has a negative effect on learning about ontologydevelopment, for tutorial ontology practices are nonethe-less seen by students as so-called model answers even ifit were not intended to have that function.The ontology survey does not reveal what may be thecharacteristics of a good tutorial ontology and, to the bestof our knowledge, there is no such list of comprehen-sive criteria for tutorial ontologies specifically. Schoberet al. [6] propose a partial list with seven high-levelcontent requirements indeed, such as a common senseknowledge subject domain that lends itself well to demon-strate the classic modelling challenges, but it omits theessential components of logic, reasoning, and engineeringrequirements. Scoping it more broadly, one could con-sider modelling guidelines and automated checkers forproduction level ontologies, such as [1215]. They caninform the development of tutorial ontologies, in partic-ular to avoid such issues as the class vs. instance error inthe provided sample ontology, but that is different fromeducating students about the foundations and reasons forsuch guidelines starting from a basic level of modellingto more advanced issues. For instance, disjointness andcovering constraints among subclasses of a parent class isindeed desirable together with coherent criteria to declarea taxonomy [15], but that does not let students observe orexperience mistakes, i.e., learn what is suboptimal or doesnot work and why. A tutorial ontology also would haveto be able to accommodate common pitfalls and grad-ual quality improvements, among other things, which arenot covered by the general guidelines. Also, general guide-lines tend to follow one commitment over anothere.g.,the GoodOD guidelines favour a realist approach withthe BFO foundational ontologybut for teaching OE ingeneral, students need learn to be cognisant of multiplepossible commitments, their consequences when choos-ing one or the other, and have at least one practical3http://www.workingontologist.org/Examples.zip; Last accessed: 26-11-2018.example of such a difference to illustrate it, which generalguidelines do not provide.Potential benefits of the African wildlife ontology tutorialontologiesIn order to address these problems, we introduce theAfrican Wildlife Ontology (AWO). The AWO has beendeveloped and extended over 8 years. It meets a range ofdifferent tutorial ontology requirements, notably regard-ing subject domain, use of language features and auto-mated reasoning, and its link with foundational ontologieson the one hand and engineering on the other. It aims totake a principled approach to tutorial ontology develop-ment, which thereby not only may assist a learner, but,moreover from a scientific viewpoint, it might serve as astarting point for tutorial ontology creation or improve-ment more broadly, and therewith in the future contributeto an experimental analysis of tutorial ontology qual-ity. This could benefit educational material for ontologydevelopment.Also, educationally, there is some benefit to reusingthe same ontology to illustrate a range of aspects, ratherthan introducing many small ad hoc examples, for thenlater in a course, it makes it easier for the learners to seethe advances they have made. This is also illustrated withoffering multiple versions of the ontology, which clearlyindicate different types of increments.Finally, the AWO can be used on its own or togetherwith the textbook An Introduction to Ontology Engineer-ing [16], which contains examples, tasks and exerciseswith the AWO.Construction and contentThe construction of the AWO tutorial ontologies has gonethrough an iterative development process since 2010. Thisinvolved various extensions and improvements by design,mainly to address the increasing amount of requirementsto meet, and maintenance issues, such as resolving linkrot of an imported ontology. Rather than describing theprocess of the iterative development cycles, we presenthere a digest version of it. First, a set of tutorial ontol-ogy requirements are presented together, then a briefoverview of the AWO content is described, and subse-quently we turn to which of these requirements are metby the AWO.OE tutorial ontology requirementsTutorials on ontologies may have different foci and itis unlikely that an ontology used for a specific tutorialwill meet all requirements. The ontology should meet theneeds for that tutorial or course, and that should be statedclearly. As such, this list is intended to serve as a set of con-siderations when developing a tutorial ontology. Each itemeasily can take up a paragraph of explanation. We refrainKeet Journal of Biomedical Semantics            (2020) 11:4 Page 5 of 11from this by assuming the reader of this paper is suffi-ciently well-versed in ontology engineering and seekinginformation on tutorial ontologies. For indicative purpose,the requirements are categorised under three dimensions:the subject domain of the ontology, logics & reasoning,and engineering factors.Subject domainThe tutorial ontologys subject domain, also called uni-verse of discourse, should be versatile to be able to caterplausibly for a range of modelling aspects. We specifyseven requirements for it, as follows.1. It should be general and commonsensical domainknowledge, so as to be sufficiently intuitive fornon-experts to be able to understand content andadd knowledge. Optionally, it may be an enjoyablesubject domain to make it look more interesting and,perhaps, also uncontroversial4 to increase chance ofuse across different settings and cultures.2. The content should be not wrong ontologically,neither regarding how things are represented (e.g.,no classes as instances) nor the subject domainsemantics (e.g., whales are mammals, not fish).3. It needs to be sufficiently international orcross-cultural so that experimentation with ascenario with multiple natural languages formultilingual ontologies is plausible.4. Its contents should demonstrate diverse aspectssuccinctly when illustrating a point (in contrast tobeing repetitive in content).5. It needs to be sufficiently versatile to illustrate themultiple aspects in ontology development (seebelow), including the use of core relations (e.g.,mereology).6. It should permit extension to knowledge thatrequires features beyond Description Logics-basedOWL species, so as to demonstrate representationlimitations and pointers to possible directions ofsolutions (e.g., temporal aspects, non-monotonicity,full first-order logic).7. The subject domain should be able to possibly beused in a range of use case scenarios (databaseintegration, science, NLP, and so on).Logics & reasoningSince a core feature of ontologies is their logic under-pinning, a tutorial ontology thus also will need to meetcriteria for the representation language and automatedreasoning over it. They are as follows.4Recent political issues include complaints with subject domains of exercisesthat perpetuate stereotypes and simplifications, such as, but not limited to, thegender binary, who can marry whom, and gendered subject domainsperceived to reside at the edges of the spectrum.I. The ontology should be represented in a logic that hastool support for modelling and automated reasoning.II. The ontology should be represented in a logic thathas tool support for debugging features thatexplain the deductions, meaning at least showingthe subset of axioms involved in a deduction.III. It should permit simple classification examples andeasy examples for showing unsatisfiability andinconsistency, such that it does not involve morethan 2-3 axioms in the explanation, and also longerones for an intermediate level.IV. The standard reasoning tasks should terminate fairlyfast (< 5 s) for most basic exercises with theontology, with the standard reasoning tasks beingsubsumption/classification, satisfiability, consistency,querying and instance retrieval.V. The representation language should offer some wayof importing or linking ontologies into a network ofontologies.VI. The language should be expressive enough todemonstrate advanced modelling features (e.g.,irreflexivity and role composition).VII. The logic should be intuitive for the modellingexamples at least at the start; e.g., if there is a need forternary relations, then the logic should permitn-aries with n ? 3 so that it can be represented assuch, rather than as an approximation with areification and a workaround pattern.Engineering and development tasksAn ontology is an artefact, which has to be built andmaintained. To this end, there are multiple approaches,methodologies, methods, and software tools of which atleast a subset will have to become part of an ontologiststoolbox. We identified eight broad requirements:A. At least some ontology development methods andtools should be able to use the ontology, be used forimprovement of the ontology, etc.B. The ontology needs to permit short/simplecompetency questions (CQs) and may permit longand complicated CQs, which are formulated for theontologys content and where some can be answeredon the ontology and others cannot.C. At least some of the top-level classes in the hierarchyshould be straight-forward enough to be easily linkedto a leaf category from a foundational ontology (e.g.,Animal is clearly a physical object, but the ontologicalstatus of Algorithm is not immediately obvious).D. It should be relatable to, or usable with, or else atleast amenable to the use of, ontology designpatterns, be they content patterns or other types.E. It is beneficial if there is at least one ontologysufficiently related to its contents, so that it can beKeet Journal of Biomedical Semantics            (2020) 11:4 Page 6 of 11used for tasks such as comparison, alignment, andontology imports.F. It is beneficial if there are relevant relatednon-ontological resources that could be used forbottom-up ontology development.G. It should be able to show ontology qualityimprovements gradually, stored in different files.H. It should not violate basic ontology design principles(e.g., classes and relations vs. implementationdecisions with data properties and data types whenrepresenting qualities of entities, such as an animalsweight).While this list may turn out not to be exhaustive in thenear future, it is expected to be sufficient for introduc-tory levels of ontology development tutorials and courses.Either way, this list of requirements are already hardto meet in one single ontology. For instance, simplicity(Items 3, III, and B) vs. complicated extensions and onto-logical precision (Items 6 and C) cannot be fully metat once. On the flip side, some requirements are closelyrelated or overlap, such as design principles (Item H) andnot being wrong ontologically (Item 2) since some of theformer are informed by the latter.Content of the AWO  at a glanceThe principal content of the AWO is, in the first stageat least, intuitive knowledge about African wildlife.This subject domain originated from an early SemanticWeb book ([8], Section 4.3.1) that was restructured andextended slightly for its first, basic version; see Table 2and Fig. 1. It has descriptions of typical wildlife animals,such as Lion and Elephant, and what they eat, includingImpala (a type of antelope), and Twig or Leaf, respectively.Basic extensions in the simple version of the ontology(v1) include plant parts, so as to demonstrate parthoodand its transitivity, and carnivore vs. herbivore, whichmake it easy to illustrate disjointness, subsumption rea-soning, and unsatisfiable classes, and carnivorous plantsto demonstrate logical consequences of declaring domainand range axioms 5. Most elements have been annotatedwith informal descriptions, and several annotations link todescriptions on Wikipedia.Like the aforementioned Family History ontology, thereare several versions of the AWO that reflect differentstages of learning. In the case of the AWO, this is notspecifically with respect to OWL language features, butone of notions of ontology quality and where one is inthe learning process. For instance, version 1a containsanswers to several competency questionsi.e., quality5in casu, declaring eats too restrictively with as domain only Animal: theneither it will result in an unsatisfiable CarnivorousPlant (if Animal and Plant aredeclared disjoint) or it will result in the undesirable deduction thatCarnivorousPlant  Animalrequirements that an ontology ought to meet [17]thatwere formulated for Exercise 5.1 in the Methods andmethodologies chapter of [16]. Versions 2 and 3, onthe other hand, have the AWO aligned to the DOLCEand BFO foundational ontologies, respectively, whose dif-ferences and merits are discussed in Chapter 6 of thetextbook, ensuring discussion of refinements in ontologi-cal precision with, e.g., processes and dispositions (e.g., anEating class with participating objects cf. an eats objectproperty). Their respective versions with the answers tothe related exercises have the name appended with an aas well. Version 4 has some contents cleaned up, par-tially based on what the OOPS! tool [14] detected; it usesmore advanced language features; and takes steps in thedirection of adhering to science more precisely with finergranularity, such as type of carnivores and distinguishingbetween types of roots.There are also four versions in different natural lan-guages, being in isiZulu, Afrikaans, Dutch, and Spanish,which mainly serve the purpose of illustrating issues withmultilingual settings of ontology use, which relates tocontent in Chapter 9 of the textbook.AWO against the requirementsThe AWO meets most of the requirements (see Table 3).Concerning the subject domain, the content is general,versatile, not wrong, sufficiently international, and notrepetitive (Items 1-4). The AWO includes the core rela-tion of parthood for, especially, plants and their parts, withoptional straightforward extensions with the participationrelation (e.g., animals participating in a Chasing event)and membership (animal collectives, such as Herd; see v4of the AWO), therewithmeeting Item 5. Representation ofrelevant domain knowledge beyond Description Logics-based OWL species (Item 6) could include informationabout temporal segregation of foraging or commensal-ism, inclusion of species with distinct successive phaseswith substantial morphological changes (e.g., Caterpil-lar/Butterfly), and the notion of rigidity between what anobject is and the role it plays (e.g., Lion playing the role ofPredator; see v4 of the AWO). The subject domain is alsofertile ground for exceptions that may be represented withnon-monotonic logics; typical examples are that, gener-ally, birds fly and plants have chlorophyl, but not all ofthem (e.g., the penguin and the dodder, respectively). Usecase scenarios (Item 7) may be, among others, scienceof African wildlife, activism on endangered species, andapplications such as a database integration and manage-ment system for zoos and for tourism websites.Regarding the logics and reasoning, the AWO is rep-resented in OWL [19], and thus has ample tooling sup-port for knowledge representation, reasoning, and basicdebugging/explanation, with ontology development envi-ronment tools such as Protégé (Items I-III). The AWOKeet Journal of Biomedical Semantics            (2020) 11:4 Page 7 of 11Table 2 AWO ontologies, with their main differencesFile name DifferenceAfricanWildlifeOntology.xml This is the file from http://www.iro.umontreal.ca/~lapalme/ift6281/OWL/AfricanWildlifeOntology.xml,that was based on the description in [8]AfricanWildlifeOntologyWeb.owl AfricanWildlifeOntology.xml + changed the extension to .owl and appended the namewith Web. This ontology gave at the time (in 2010) a load error in the then current version of Protégédue to the use of Collection in the definition of HerbivoreAfricanWildlifeOntology0.owl AfricanWildlifeOntologyWeb.owl + that section on Collection removedAfricanWildlifeOntology1.owl AfricanWildlifeOntology0.owl + several classes and object properties were added (up toSRI DL expressiveness), more annotations, URI updated (described in Example 4.1 in [16])AfricanWildlifeOntology1a.owl AfricanWildlifeOntology1.owl + new content for a selection of the CQs in Exercise 5.1 in[16] (its CQ5, CQ8) and awo_12 of the CQ dataset [18])AfricanWildlifeOntology2.owl AfricanWildlifeOntology1.owl + OWL-ised DOLCE (Dolce-Lite.owl) was importedand alignedAfricanWildlifeOntology2a.owl AfricanWildlifeOntology2.owl + answers to the questions in Example 6.2 in [16] onfoundational ontology alignmentAfricanWildlifeOntology3.owl AfricanWildlifeOntology1.owl + BFO v1 was imported and alignedAfricanWildlifeOntology3a.owl AfricanWildlifeOntology3.owl + answers to the questions in Example 6.2 in [16] onfoundational ontology alignmentAfricanWildlifeOntology3b.owl AfricanWildlifeOntology1.owl + BFO v2 + answer to Exercise 6.7 in v2 of [16] on refactoringthe AWO with dispositionsAfricanWildlifeOntology4.owl AfricanWildlifeOntology1.owl + some things cleaned up (e.g., consistent naming) andadded some science content, more OWL language features are used (up to SRIQ), and severaleducational explanations and questions for further exploration have been added in annotation fieldsAfricanWildlifeOntologyZU.owl Mostly AfricanWildlifeOntology1.owl but then in isiZulu, with IRI changedAfricanWildlifeOntologyAF.owl AfricanWildlifeOntology1.owl but then in Afrikaans, has some IRI issues to resolveAfricanWildlifeOntologyNL.owl AfricanWildlifeOntology1.owl in Dutch, with IRI changedAfricanWildlifeOntologyES.owl AfricanWildlifeOntology1.owl in Spanish, same IRI but different file namehas both simple deductions and more elaborate ones(Item III); e.g., compare Lion that is classified as aCarnivore, having one explanation involving three axioms,with Warthog that is classified as an Omnivore, for whichthere are three justifications computed that each use, onaverage, five axioms. Because the AWO is small, doesnot make extensive use of individuals and high numberrestrictions, the reasoner terminates fast under all stan-dard reasoning tasks (Item IV). OWL has the languagefeature to import other ontologies and it also can beFig. 1 The African Wildlife Ontology at a glance. The main classes and relations of the African Wildlife ontology (v1) and an illustrative selection of itssubclasses. (The relations drawn are existentially quantified.)Keet Journal of Biomedical Semantics            (2020) 11:4 Page 8 of 11Table 3 Summary of the evaluation of the AWO against therequirementsItem Eval. Item Eval. Item Eval.1 + I + A +2 + II + B +3 + III + C +4 + IV + D ±5 + V + E 6 ± VI + F ±7 + VII  G +H +The evaluation (Eval.) can be either + fully met, ± partially met (not implemented),or  not metused in other ontology network frameworks, notably theDistributed Ontology, Model, and Specification LanguageDOL [20] (Item V). While OWL contains expressive fea-tures such as role chaining (Item VI), it, arguably, fails onintuitiveness especially for novices (Item VII). Regardingthe latter, e.g., for as of yet unclear reasons, novices makeerrors in the use of existential and universal quantifica-tion [4, 13, 14], which is not known to be a problem assuch when modelling the equivalent in, say, UML ClassDiagrams, and there is the elaborate n-ary (with n ? 3)approximation issue.With respect to the engineering aspects, by virtue ofthe AWO being represented in OWL, there are tools thatcan process the ontology (Item A), and therewith ontol-ogy quality improvement methods can be used with theAWO. They include, e.g., the popular Protégé, and varioustools for methods and quality, such as test-driven devel-opment [21] and OOPS! [14], and ontology developmentsupport activities, such as visualisation and documen-tation (e.g., [22, 23]). There are also a few competencyquestions that can be answered and that can be easilymodelled to be answered, as included in AWO version1a (Item B), and there are examples and activities tolink it to foundational ontologies (AWO versions 2 and3) with easy examples (Item C) (see below, Utility andDiscussion). There are several versions demonstratingvarious quality improvements (Item G), avoiding vio-lating some basic design principles like data propertiesand punning hacks (Item H), and touching upon someadvanced engineering issues with multilingual ontologies(see Table 2).It falls short at the novice level on two requirements:an easy way to link it to another ontology (Item E) andbottom-up development from non-ontological resources(Item F). It is possible and feasible in a mini-projectassignment, however; e.g., one could use the freelyavailable wildlife trade data6 or relate it to the Biodiver-sity Information Standards7 for application scenarios, andlink it to the Envo Environment ontology [24] or take iteasier on the domain knowledge with one of the avail-able tourism ontologies to create an ontology network. Abottom-up approach to knowledge acquisition for ontolo-gies is demonstrated with cellfie8 that implements theM2 DSL [25] so that a modeller can add content in aspreadsheet and cellfie converts that into axioms in theontology, as demonstrated in Example 7.1 of the textbook.Regarding ODPs (Item D), a content ODP with the cur-rent contents is not immediately obvious, but other typesof ODPs, such as architectural ones, are easy to illus-trate, alike for BioTop [26] but then at the organism-levelwith an orchestration between foundation, top-domain,and domain-level ontologies, and what are dubbed excep-tion patterns in [6] to be used for the deviant cases whenremaining within a monotonic logic such as OWL (e.g.,penguins as non-flying birds).Utility and discussionThe principal utility of the AWO is to be a concretemachine-processable artefact for the related examples andexercises, which we shall turn to first, and subsequentlydiscuss the tutorial ontology.Use in exercises and examplesThe major utility of the AWO is its use in educationalactivities for ontology engineering exercises and examplesthat are described in the An Introduction to Ontol-ogy Engineering" textbook [16]. It is not intended as areal domain ontology, but it is explicitly designed as atutorial ontology that has a domain ontology flavour toit. Consequently, the subject domain knowledge aboutAfrican Wildlife has been kept simple, yet amenable toextensions.An example of an exercise is shown in Fig. 2, which fitswithin the broader scope of sensitising the student to thenotion of quality of an ontology, using the vehicle of com-petency questions that can be used in the validation stagewhen evaluating whether the ontology meets its statedgoals. It also offers a gentle acquaintance with founda-tional ontologies with some OWL classes that are eithereasy or fun to categorise or to elicitate lively debate. Forinstance, impalas die in the process of being eaten by alion, where both are straightforwardly subclasses of Phys-ical Object in DOLCE [27] or Independent Continuant inBFO [9], and Death is a type of Achievement or Processboundary, respectively. The exercises of aligning AWOto DOLCE is additionally assisted by the D3 decisiondiagram [28]. Death/dying also provides an entry point6https://www.kaggle.com/cites/cites-wildlife-trade-database7http://www.tdwg.org/8https://github.com/protegeproject/cellfie-pluginKeet Journal of Biomedical Semantics            (2020) 11:4 Page 9 of 11Fig. 2 Section of an exercise. Screenshot of the first part of Exercise5.1 in [16], which lets the student experiment with requirements forthe content of an ontology, trying to find that knowledge, and thetask of evaluating an ontology on its quality based on itsrequirements. The high-level notion of a good ontologycomparedto less good, bad, and worsehas been introduced earlier in thetextbook, which has to be recalled and applied hereto the alternate modelling styles of process-as-relationvs. process-as-class representation options. Another coredistinction in modelling styles are data properties vs. ahierarchy of qualities, for which a use case of elephantsweight in zoos across the world is used (Section 6.1.1 of[16]).While the emphasis in this paper is on modellingand engineering aspects, the AWO is still suitablefor teaching about OWL language features and auto-mated reasoning, as noted before regarding the deduc-tions (e.g., Lion  Carnivore), and use of languagefeatures such as transitivity and (ir)reflexivity withparthood. Straightforward examples for demonstratingunsatisfiability are multiple inheritance of Omnivoreto the disjoint Carnivore and Herbivore or to set thedomain of eats to Animal resulting in an unsatisfiableCarnivorousPlant.Additional variants of the AWO are in progress, whichzoom in on subject domains with corresponding exer-cises that are not yet covered in the introductory textbook.Among others, a future version 5 may be the engineeringaspects of importing, aligning, and integrating, anotherdomain ontology rather than a foundational ontology,such as a module of the Environment Ontology with thehabitat information or a tourism ontology, with a corre-sponding sample answer file. The former option wouldbe more suitable for ontology development in ecology,whereas the latter is a more practical option in a tuto-rial/course for people in other disciplines. Other themesthat have not been covered explicitly yet but easily canbe applied to the AWO are modularisation [29] andOntology-Based Data Access with its recent tools [30],and it could be assessed against the MIRO guidelines forreporting on ontologies [31].DiscussionThe AWO meets most of the tutorial ontology require-ments that evolved and extended over the years. TheAWO goes beyond extant tutorial ontologies that over-whelmingly focus only on demonstrating language fea-tures and automated reasoning, or how to use a specificversion of a specific tool. In particular, the AWO brings inontology development aspects, such as competency ques-tions and alignment to a foundational ontology, amongothers.The illustrations of gradual quality improvementscommon in ontology developmentgo beyond the notionthat a new version only uses more language features, asin Family History [5] and University9. In particular, thereare improvements on aspects regarding, among others,content, naming, annotations, and foundational ontologyalignment.Also, care has been taken in representing the knowl-edge, such as avoiding some common pitfalls like theclass-as-instance and certain naming issues like and, oror negation in a term [13]. Unlike other tutorial ontolo-gies, including the popular Pizza and Wine, it is richlyannotated with informal descriptions, pointers to intro-ductory domain knowledge, and questions for furtherexploration of a modelling topic.Tutorial ontology subject domains such as ones fam-ily history, a university, or ones pets are distinctlyfocussed on individual application scenarios that mayserve database development, but do not give an educa-tionally good flavour of typical scopes of domain ontolo-gies. In that regard, pizzas and wines fare somewhatbetter, which, however, have repetitive content, such aslisting all ingredients of pizza topping. Contrast this withanimal wildlife, where it suffices already to represent thata lion eats animals to have it classified automatically asa carnivore. The wildlife subject domain is generic ratherthan specific for one application scenario, and therewithless predisposed to a myopic my thing only thinking thatis prevalent when students encounter ontologies for a firsttime (a regular occurrence at least in the authors classes,carried over from software design). Last, but not least,besides its international appeal, African wildlife is obvi-ously relevant for South Africa, where the author andmost of her students are based, and it fits with the trend tomake curricula regionally relevant. This is also reflectedin an isiZulu and an Afrikaans version of the ontologyand introductory aspects on term use for ontologies ina multilingual setting, as Rockdassie is not a StandardEnglish word yet is widely accepted in South AfricanEnglish. Overall regarding the content of a tutorial ontol-ogy, however, it is a balancing act between simplicity andontological precision and correctness, as [6] also noted,and international and national relevance, as well as an esti-mation what may be assumed to be general common senseknowledge by novice ontologists.9http://owl.man.ac.uk/2005/07/sssw/university.htmlKeet Journal of Biomedical Semantics            (2020) 11:4 Page 10 of 11ConclusionsThe paper introduced the African Wildlife Ontologytutorial ontologies, which is a set of ontologies used for avariety of ontology development examples and exercises.Considering possible desirable educational outcomes, 22requirements were formulated that a tutorial ontologyshould meet. The AWO meets most of these require-ments, therewith improving over its predecessors espe-cially reading the notions of evolution of ontology qualityseveral ontology development tasks beyond getting theaxioms into an OWL file, such as alignment to a founda-tional ontology and satisfying competency questions.Both the 22 requirements and the AWO are relevantto the field of ontology engineering in particular, espe-cially for enhancing course material, which, it is hoped,will result in further quality improvements of the actualontologies that developers are building.AvailabilityThe AWO is freely available under a CC-BY licence through the textbookswebpage at https://people.cs.uct.ac.za/~mkeet/OEbook/.AbbreviationsAWO: African wildlife ontology; CDM: Conceptual data model; FMA:Foundational model of anatomy; FO: Foundational ontology; ODP: Ontologydesign pattern; OE: Ontology engineering; OWL: Web ontology languageAcknowledgementsThe author would like to thank previous ontology engineering courseparticipants on their feedback, which assisted in refining some of theexamples and exercises with the AWO, and Ludger Jansen for feedback thathelped improve the paper.Authors contributionsThe author contributed all aspects to the paper. The author(s) read andapproved the final manuscript.FundingThe author declares that she has not received project funding for this work.Publication charges were financially supported by the Hasso Plattner Institutefor Digital Engineering and the University of Cape Town.Ethics approval and consent to participateNot applicable.Consent for publicationNot applicable.Competing interestsThe author declares that she has no competing interests.Received: 13 December 2018 Accepted: 9 June 2020Moen et al. Journal of Biomedical Semantics           (2020) 11:10 https://doi.org/10.1186/s13326-020-00229-7RESEARCH Open AccessAssisting nurses in care documentation:from automated sentence classification tocoherent document structures with subjectheadingsHans Moen1* , Kai Hakala1,2, Laura-Maria Peltonen3, Hanna-Maria Matinolli3, Henry Suhonen3,4,Kirsi Terho3,4, Riitta Danielsson-Ojala3,4, Maija Valta4, Filip Ginter1, Tapio Salakoski1 and Sanna Salanterä3,4AbstractBackground: Up to 35% of nurses working time is spent on care documentation. We describe the evaluation of asystem aimed at assisting nurses in documenting patient care and potentially reducing the documentation workload.Our goal is to enable nurses to write or dictate nursing notes in a narrative manner without having to manuallystructure their text under subject headings. In the current care classification standard used in the targeted hospital,there aremore than 500 subject headings to choose from, making it challenging and time consuming for nurses to use.Methods: The task of the presented system is to automatically group sentences into paragraphs and assign subjectheadings. For classification the system relies on a neural network-based text classification model. The nursing notesare initially classified on sentence level. Subsequently coherent paragraphs are constructed from related sentences.Results: Based on a manual evaluation conducted by a group of three domain experts, we find that in about 69% ofthe paragraphs formed by the system the topics of the sentences are coherent and the assigned paragraph headingscorrectly describe the topics. We also show that the use of a paragraph merging step reduces the number ofparagraphs produced by 23% without affecting the performance of the system.Conclusions: The study shows that the presented system produces a coherent and logical structure for freely writtennursing narratives and has the potential to reduce the time and effort nurses are currently spending on documentingcare in hospitals.Keywords: Patient care documentation, Nursing documentation, Electronic health records, Text classification,Natural language processing, Neural networks, Model interpretation*Correspondence: hnsmoen@gmail.comHans Moen and Kai Hakala contributed equally to this work.1Department of Future Technologies, University of Turku, Vesilinnantie 5,20500 Turku, FinlandFull list of author information is available at the end of the article© The Author(s). 2020 Open Access This article is licensed under a Creative Commons Attribution 4.0 International License,which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriatecredit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes weremade. The images or other third party material in this article are included in the articles Creative Commons licence, unlessindicated otherwise in a credit line to the material. If material is not included in the articles Creative Commons licence and yourintended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directlyfrom the copyright holder. To view a copy of this licence, visit http://creativecommons.org/licenses/by/4.0/. The CreativeCommons Public Domain Dedication waiver (http://creativecommons.org/publicdomain/zero/1.0/) applies to the data madeavailable in this article, unless otherwise stated in a credit line to the data.Moen et al. Journal of Biomedical Semantics           (2020) 11:10 Page 2 of 12BackgroundCare documentation is important for supporting the con-tinuity of care in hospitals. According to literature, nursesspend up to 35% (with an average of 19%) of their workingtime on documentation [1]. Naturally, if we can reduce thetime that nurses spend on documentation, more time willbe available for direct patient care.To support tasks such as navigation, planning and sta-tistical analysis, nurses in many countries are requiredto perform structuring of the information they write [2].Such structuring approaches include the use of documen-tation standards, classifications and standardized termi-nologies [3]. However, this usually adds certain restric-tions and requirements to the documentation processcompared to writing the information in an unstruc-tured narrative manner. In Finland, nurses are nowa-days expected to structure the information they writeby using subject headings from the Finnish Care Clas-sification (FinCC) standard [4]. This includes selectingthe correct subject headings and writing the associatedinformation underneath. In this way, each subject head-ing forms a paragraph in the nursing note. As an example,if a nurse wants to write something about administratedwound care, he/she will first have to select an appropri-ate heading, e.g. Wound. FinCC consists primarily of twotaxonomy resources, the Finnish Classification of Nurs-ing Diagnoses (FiCND) and the Finnish Classification ofNursing Interventions (FiCNI), and both of these have athree-level hierarchy. For example, one branch in FiCNDis: Tissue integrity (level 1), Chronic wound (level 2)and Infected wound (level 3). Another example, a branchfrom FiCNI is: Medication (level 1), Pharmacotherapy(level 2) and Pharmaceutical treatment, oral instructions(level 3). However, FinCC consists of more than 500 sub-ject headings, covering both interventions and diagnoses.This makes it potentially challenging and time consumingfor nurses to use since they are required to memorize, useand structure the information they write according to alarge number of subject headings [5].What we are aiming for is to develop a system that canassist nurses in selecting suitable subject headings and instructuring the text accordingly.We hypothesize that sucha system has the potential to save time and effort requiredfor documentation and ultimately free up more time forother tasks. We see two use-cases for such a system: Oneis where the system assists nurses in selecting appropri-ate headings when they write, in a suggestive manner, e.g.,per sentence or paragraph; A second use-case is wherenurses are allowed to write or dictate (by voice to text)in a fully unstructured narrative manner, without havingto take into consideration the structure or the use of sub-ject headings. Instead the system assigns subject headingsafterwards and restructures the text into paragraphs. Inthis study we focus on the second use-case.This is the continuation of a previously reported studythat focused on assessing how an earlier version of thesystem performs on the level of sentences [6]. The mainconclusion of that study is that a sentence classificationmodel trained on semi-structured nursing notes can beapplied on unstructured free nursing narratives without asubstantial decline in accuracy.This time we focus on paragraph-level assessment,where we also explore a post-processing step aimed atreducing the number of paragraphs initially generatedby the system. To evaluate our system, a team of threedomain experts (aka evaluators) conduct a manual evalu-ation to assess both the grouping of sentences into para-graphs and the correctness of the assigned headings. Inaddition we analyze the classification model in an attemptto identify conflicts between the actual use of the sub-ject headings and the intended use according to the FinCCtaxonomy.At the core of our system is a text classification modelbased on a bidirectional long short-termmemory (LSTM)recurrent neural network architecture [7, 8]. As train-ing data we use a large collection of nursing notes froma Finnish hospital which contain subject headings andwhich are structured accordingly. Further, to acquire thetype of narrative text that we would like to use as inputto the system, without a bias towards a particular struc-ture and subject headings, we made a set of nursing notesbased on artificial patients that we use for testing.Related workAs we focus on classifying individual sentences, the workis closely related to other short text classification studies.However, most of the prior work focuses on texts col-lected from social media or other online sources [911].Interestingly, Zhang et al. [12] conclude that the optimaltext classification method is strongly dependent on theselected task, warranting domain specific research on thistopic.In the clinical domain, a common objective for textclassification has been the automated assignment of ICDcodes to the target documents [1315]. For instance Xie etal. [16] use a neural model for mapping diagnosis descrip-tions extracted from discharge notes to the correspondingICD codes. Similarly Koopman et al. [17] assign ICD-10codes to death certificates, but limit the scope to variouscancer types.For cases where available training data is scarce, Wanget al. [18] propose a system for producing weakly labeledtraining data, where simple rules are initially used tolabel a large set of unlabeled clinical documents andthese labels are subsequently used as training targets formachine learning based classifiers. The approach is eval-uated on smoking status and hip fracture classification,but shows mixed results, with a rule-based baseline beingMoen et al. Journal of Biomedical Semantics           (2020) 11:10 Page 3 of 12the strongest model in some cases. As our training datasetinherently contains the used classification labels, we havenot considered such weak supervision in our research.To our knowledge the most recent systematic reviewon clinical text classification was conducted by Mujtabaet al. [19]. In addition to comparing the classificationapproaches utilized in different studies, the review focuseson the differences in the selected datasets. Their studyindicates that along with the medical literature, clinicaltext classification research mostly focuses on pathology,radiology and autopsy reports, whereas other clinical doc-uments such as nursing care records are far less stud-ied. Moreover, the vast majority of the reviewed studiesonly evaluate their methods on English data, leading toMujtaba et al. suggesting wider range of languages to beincluded in these studies.As an additional note, Mujtaba et al. also conclude thatdeep learning methods are still relatively poorly studied inthis domain. However, lately neural approaches have beensuggested for a wide range of medical text classificationpurposes [2022].More related to our research are prior studies on clinicalnote segmentation. Denny et al. [23] present an approachfor detecting section headers in clinical notes based on thefree text. More precisely, they focus on history and phys-ical examination documents where the goal is to identifyand normalize section headers as well as to detect sectionboundaries. Li et al. [24] present a system that catego-rizes sections in clinical notes into one of 15 pre-definedsection labels for notes already split into sections. Theirapproach relies on modelling the dependencies of consec-utive section labels with Hidden Markov Models. In [25]coarse topics are assigned to the sections found in clin-ical notes. These topics are here seen as separate fromthe section headings used by the clinicians when writing,thus the section headings are considered as input to theclassifier along with the free text.A distinction between our study and the prior workis that we operate with an order of magnitude largerset of section labels. Additionally, we rely on semi-structured nursing notes as training data with the devel-oped method subsequently being applied on unstruc-tured notes. Thus, we do not utilize any prior knowledgeabout paragraphs/sections. Grouping the text into sensi-ble paragraphs is instead a task for the presented system together with assigning subject headings.MethodsOur ultimate goal is to develop a system that is ableto automatically identify and classify, on sentence level,interventions and diagnoses mentioned in nursing narra-tives, and further capable of grouping the text into sensibleparagraphs with subject headings reflecting their topics.In other words, we are aiming for a system that can letnurses simply write or dictate in a narrative manner with-out having to plan and structure the text with respect toparagraphs and subject headings. In pursuing this goalwe have implemented a prototype system with a neuralnetwork-based text classification model at its core. In thissection we describe the data and methods used in theimplementation and evaluation.DataThe data set used for training is a collection of approxi-mately 0.5 million patients nursing notes extracted from auniversity hospital in Finland. The selection criteria werepatients with any type of heart-related problem in theperiod 2005 to 2009 and nursing notes from all units vis-ited during their hospital stay are included. The data iscollected during a transition period between two classi-fication standards, the latter being the mentioned FinCCstandard. This means that our training data contains amixture of headings from these two. We only use sen-tences occurring in paragraphs with subject headings,which amounts to approximately 5.5 million sentences,133,890 unique tokens and approximately 38.5 milliontokens in total. We exclude all subject headings used lessthan 100 times, resulting in 676 unique subject headings,where their frequency count range from 100 to 222,984,with an average of 4,896. The individual sentences areused as a training example with the corresponding subjectheading as the target class to be predicted. The averagesentence length is 7 tokens1 and the average number ofsentences per paragraph is 2.1. The data set is split intotraining (60%), development (20%) and test (20%) sets andfurther used to train and optimize the text classificationmodel.Text classification modelThe classification task is approached as a sentence-levelmulticlass classification task, where each sentence isassumed to have one correct subject heading (label). Ourtext classification model is based on a bidirectional short-term memory (LSTM) recurrent neural network archi-tecture [7, 8]. The model receives a sequence of wordsas its input and encodes them into latent feature vectors(dimensionality 300). These vectors are subsequently usedas the input for a bidirectional LSTM layer (dimensional-ity 600 per direction). As the final layer a fully connectedlayer with the dimensionality corresponding to the num-ber of target subject headings is used. The word embed-dings are pretrained with Word2vec [26]. The model isoptimized for categorical cross-entropy with Adam opti-mizer [27], stopping early based on the development setperformance. As machine learning tools we primarily use1Space separated units.Moen et al. Journal of Biomedical Semantics           (2020) 11:10 Page 4 of 12the Keras deep learning library [28], with TensorFlowlibrary [29] as backend.We want to emphasize that the focus of this paper is notto find the optimal text classificationmethod and parame-ter settings for this task. This has instead been the focus ofanother study [30], where a range of different state-of-the-art and baseline text classification methods are tested andcompared. Results from the mentioned study indicate thata bidirectional version of LSTM networks performs bestwhen compared to other classification methods/models,including convolutional neural networks, support vectormachines and random forests [3133].On the test set, when the classifier is allowed to suggestone subject heading per sentence, it suggests the correctheading for 54.35% of the sentences according to auto-mated evaluation. When allowed to suggest 10 headingsper sentence, the correct one is among these 89.54% of thetime (see [30] for more details).Subject heading prediction and grouping into paragraphsSince our prototype system relies primarily on a sentence-level classification model, it starts by classifying each sen-tence individually before grouping them into paragraphs.However, this might arguably be the opposite order of howa human would approach this task. The systems opera-tion can be described as a four-step process. Step 1: Firstthe text is split into sentences. For this we rely on a com-bination of the NLTK tokenizers for Finnish [34] and a setof regular expressions tailored for the clinical text. Step 2:Next the classification model is used to classify each sen-tence individually and assign the top predicted heading(the one with the highest confidence value). Step 3: Asa third step the sentences with the same assigned sub-ject heading are grouped into paragraphs. Step 4: Thefourth step focuses on merging paragraphs whose contentand assigned headings are close to each other in terms ofmeaning. This fourth step is included to potentially reducethe number of paragraphs to more closely simulate hownurses document. Below we explain in more detail howthis fourth step is done.Paragraphmerging explained: In the previous study [6],the evaluators reported that the system showed a ten-dency to assign subject headings with a high level ofspecificity, and sometimes even too specific to be prac-tical. For example, for two or more sentences describingdifferent aspects of pain management in the same nurs-ing note, such as treatment and medication, the systemwould in some cases assign these to different subjectheadings, possibly headings of different level of speci-ficity/abstraction. This meant that, in some cases, unnec-essarily many unique headings, thus paragraphs, wereassigned to each nursing note.In an attempt to reduce the number of paragraphs cre-ated, to more closely simulate how nurses document, wehave implemented an experimental post-processing stepthat enables the system to merge paragraphs (within anursing note) that it finds to have similar subject head-ings. For this we primarily rely on the confidence valuesof the classification model, as well as extracted vec-tor representations of each subject heading. The LSTMlayer outputs 600 dimensional sentence encodings forboth directions of the input sequence, resulting in 1200dimensional vectors representations for the subject head-ings. These we use to calculate heading similarity byapplying the cosine distance metric. See the Data anal-ysis section for further description of these headingvectors.First a paragraph-to-paragraph similarity matrix isformed reflecting how each paragraph would consider thesubject headings from the other paragraphs (from step3) as a likely candidate heading. To this end we definea simple asymmetric similarity function which measureshow inclined a paragraph (source) is towards the head-ing of another paragraph (target) in the same nursingnote. For each sentence in a given source paragraph wetake the classifiers confidence of the sentence belong-ing to the target heading and subtract the difference inthe confidence between predicting the source headingand the target heading. The individual sentence scoresare averaged and further summed with the cosine dis-tance between the source and target headings and therelative size of the target paragraph (compared againstthe whole nursing note). The first component, relyingon the confidence values of the classifier, describes howwell the sentences fit in the target paragraph. The sec-ond component measures how semantically similar thecompared paragraph headings are, more similar headingsbeing more likely to be merged. The third componentincreases preference towards retaining the headings ofthe larger paragraphs. This scoring function producesvalues in the range 3 to minus 2. Note that it is notsymmetrical.To determine if two paragraphs are to be merged,we require that the similarity between these two para-graphs, in both directions, is above a given threshold.If the threshold is exceeded, the two most similar para-graphs are merged, keeping the heading of the para-graph with the lowest score out of the two. Subsequentlythe similarity matrix is recalculated, and the process isrepeated until no paragraph pairs can bemerged.We opti-mize this threshold on a sample of nursing notes fromthe test data where paragraph information and head-ings are removed. A threshold is found that enables thesystem to generate approximately the same number ofparagraphs as in the original versions of these nursingnotes.Moen et al. Journal of Biomedical Semantics           (2020) 11:10 Page 5 of 12System evaluationIn this experiment the focus is on evaluating how thesystem performs at the intended task. Two versions ofthe system are manually evaluated, NoMerging andWithMerging, where the difference is that NoMergingonly performs steps 13, while WithMerging also per-forms step 4. This comparison is done to see if the para-graph merging (step 4) can be done without reducingsystem performance according to the evaluators assess-ments. To perform the evaluation two domain expertswith nursing background first evaluated the paragraphsindividually. Then we consulted a third domain expertwho provided a third opinion for the instances where thetwo disagreed. Finally the three of them agreed on the finalconsensus version which we report here.The evaluation focuses on two aspects of the struc-tured notes produced by the system: 1) The correctness ofthe assigned subject headings at paragraph level. Table 1shows the classes used by the evaluators; 2) The quality ofthe formed paragraphs, i.e. sentence grouping. The classesused in this assessment are shown in Table 2.The nursing notes from the training data have beenplanned, structured and written with subject headings inmind. One could argue that by simply removing headingsand paragraph information, automated evaluation couldbe implemented. However, we found that the sentenceshere, which are structured under subject headings, have atendency to be biased towards the topic of their headings,and sometimes their meaning can only be interpreted inthe context of their headings. Also, this structuring forcesthe nurses to write very short and concise things, whereaswhen given the freedom to write in a narrative manner,more complex sentence structures are present. Thus, toobtain relevant nursing notes for evaluation of our usecase  notes written in a free narrative style without plan-ning for or considering the use of paragraphs and subjectheadings  we asked five domain experts with nursingbackground to write notes based on made up artificialpatients. In total, 40 nursing notes, each note representingone day of provided care for a patient, were generated. Thetop part of Fig. 1 shows an example of one such nursingnote.Table 1 Classes used by the evaluators when assessing theheadings assigned by the systemClass Description1 Correct: the subject heading suits the text in this paragraph.2 Partly correct: the subject heading only suits some of the text,not all.3 Incorrect: the subject heading does not seem to suit any ofthe text.4 Unable to assess: unable to asses whether or not this subjectheading is suitable.Table 2 Classes used by the evaluators when assessing theparagraphs formed by the systemClass Descriptiona Sensible grouping: it makes sense to have these sentencesgrouped together as a separate paragraph based on theirtopic(s) (even if the subject heading may not fit).b Inconsistent/problematic grouping  alt1: one or moresentences in this paragraph would fit better in other para-graph(s) in this note.c Inconsistent/problematic grouping  alt2: one or moresentences in this paragraph do not belong in this or any of theother paragraphs in this note.d Unable to assess: unable to evaluate this paragraph.These 40 nursing notes were fed to the two versions ofthe system, NoMerging and WithMerging. For eval-uation purposes the output was stored as spreadsheets,one for each system, each containing both the origi-nal and the generated/structured version of each nursingnote.Statistical analyzes were performed to investigate differ-ences in themanual evaluations of the two system versions(Pearsons chi-squared test), as well as to see if there isa possible correlation between manual evaluations andthe classification models confidence values (Spearmansrho).To gain some qualitative feedback on the system, we alsoasked the evaluators to answer the following open-endedquestions:Q1: Can you mention the main strengths that you foundwith the system(s)?Q2: Can you mention the main weaknesses that youfound with the system(s)?Q3: Do you, or do you not, think that this kind of asystem would be helpful when it comes to nursingdocumentation, and why?Data analysisWe hypothesize that the large amount of subject headingsin the FinCC classification standard may cause confusionamong the nurses in terms of what headings should beused in documenting the various aspects of the admin-istrated care. Thus, to obtain a deeper understanding ofthe evaluated sentence classification model and the caredocumentation conventions of the nurses, we analyzethe heading representations learned by the classificationmodel  reflecting how they have been used  and howthis may differ from their description and intended usebased on FinCC.The weights of the fully connected output layer of thetrained classifier can be seen as semantic representationsof the subject headings since the weights correspondingMoen et al. Journal of Biomedical Semantics           (2020) 11:10 Page 6 of 12Fig. 1 Nursing note example. Top: Without any particular structure or assigned subject headings. Input to the system. Bottom: Grouped intoparagraphs with assigned headings. Output from the system. This has been translated from Finnish to Englishto a given heading define how strongly the heading isactivated for a given input sentence, compared againstother possible headings. Thus, two headings with similarweights will have similar probabilities of being assignedto a given input sentence. Inversely, under the assump-tion that the model has learned the classification task well,it can be hypothesized that if two headings have similarweights, the sentences assigned under these headings inthe training data are also similar. Note that these represen-tations are not based on the names of the subject headings,but instead on the actual sentences written under theheadings.Our main goal in this analysis is to verify whether we areable to find subject headings which are semantically sim-ilar according to our classification model, but far apart inthe used FinCC taxonomy, or vice versa. This allows us toidentify conflicts between the actual use of headings andtheir intended use according to the taxonomy. To mea-sure the distances of the subject heading representationswe simply calculate the cosine distance across all headingpairs.The used FinCC classification standard is comprised of3 top level categories: nursing diagnoses, nursing inter-ventions and nursing outcomes, however the nursing out-Moen et al. Journal of Biomedical Semantics           (2020) 11:10 Page 7 of 12come headings are not present in the used data. Bothnursing diagnoses and interventions use a hierarchicalstructure with maximum depth of 3. To form a single tree,we connect the diagnoses and interventions categorieswith an artificial root node. This combined tree has amax-imum depth of 4. To measure the distances of headings inFinCC we calculate the shortest path between the head-ing nodes in the tree. Although simple, this approach hasshown strong performance in measuring concept similar-ities in other biomedical ontologies [35].Once we have the two distances calculated for all sub-ject heading pairs  cosine distance and distance in thetree  we rank each pair based on these two, resultingin two distinct rankings. The conflicting pairs that weselect for further analysis are the ones being furthest apartaccording to these two rankings.Since the nursing notes include the used subject head-ings as plain text, without containing the actual FinCCidentifiers, we use strict string matching to map the head-ings to the corresponding FinCC concepts. This leaves uswith 263 headings for this analysis out of the total 676headings in our data set. The excluded headings eitheroriginate from the older classification standard or containspelling variations.ResultsIn this section we first present the results from the sys-tem evaluation. Next we highlight some of the observa-tions from the analysis of subject heading representationsaccording to the classification model and the underlyingclassification standard.System evaluation resultsThis experiment provided insight into how the systemperforms at the intended task of assigning applicable sub-ject headings and grouping sentences into paragraphs.Table 3 shows how well the assigned subject headings fitthe text in the paragraphs. Table 4 reflects what the eval-uators think about the integrity of the paragraphs formedby the system.See Fig. 1 for an example showing a input note to thesystem (top) and the output (bottom) where the text isgrouped into paragraphs with assigned subject headings.Table 3 Subject headings evaluation results. See Table 1 for anexplanation of the classesClass NoMerging n(tot=396) WithMerging n(tot=305)1 70.45% 279 71.15% 2172 14.65% 58 16.72% 513 14.14% 56 11.80% 364 0.76% 3 0.33% 11+2 85.10% 337 87.87% 268Table 4 Paragraph (sentence grouping) evaluation results. SeeTable 2 for an explanation of the classesClass NoMerging n(tot=396) WithMerging n(tot=305)a 79.55% 315 79.02% 241b 15.66% 62 12.13% 37c 3.79% 15 8.52% 26d 1.01% 4 0.33% 1Overall these results show that the system is able toprovide suitable subject headings for about 71% of theparagraphs (class 1). They also indicate that about 79%of the paragraphs formed are sensible (class a). By sensi-ble paragraphs we mean that all the sentences within arerelated to the same topic and that none of them would fitbetter elsewhere in the corresponding nursing note.When using NoMerging the number of paragraphsformed is 396, with an average of 9.9 per note (min=3,max=19). When using WithMerging, which also per-forms the paragraph merging step, the number of para-graphs is reduced by 23%, down to 305, with the averageper note being 7.6 (min=2, max=17).We also calculated how many of the formed para-graphs were consistent (class a) while also having asuitable subject heading (class 1). The result is seen inTable 5 and shows that 66.67% (NoMerging) and 68.85%(WithMerging) of the paragraphs are both sensible andhave a correctly describing subject heading assigned tothem. These results show that the merging step results inbasically no loss in performance.Pearsons chi-squared tests were performed to seewhether there are statistically significant differencesbetween the evaluation results of NoMerging andWithMerging based on 1) the subject heading correct-ness evaluations, and 2) the paragraph (sentence merging)quality evaluation results2. The evaluation of 1) does notseem to be dependent on what system version was used(X2 (2, N = 697) = 1.20, p = 0.55). However, there is astatistically significant difference between the two whenlooking at 2) (X2 (2, N = 696) = 8.12, p = 0.02).It is possible that the confidence values of the classifiermay provide some indication of paragraph correctness inthat there is a correlation between the classifiers confi-dence value for an assigned heading and the paragraphbeing correct according to the manual evaluation results.Using Spearmans rho to compare the manual evaluationresults of WithMerging with the classifiers confidencevalues for each paragraphs assigned heading (averageacross sentences), we found there to be a negative correla-tion between classifier confidence values and the headingassignment ratings (Spearmans rho = -0.42, moderate);2Here we excluded classes 4 and d due to their low frequency (n<5).Moen et al. Journal of Biomedical Semantics           (2020) 11:10 Page 8 of 12Table 5 Results showing the percentage of sensible paragraphs(i.e. sentence groupings) with correct headings assignedClass NoMerging n(tot=396) WithMerging n(tot=305)1 and a 66.67% 264 68.85% 210as well as between classifier confidence values and the rat-ings of the quality of the formed paragraphs (Spearmansrho = -0.29, weak).Based on the open-ended questions posed to the evalu-ators, they reported the following.A1: As strengths they reported that the system does anoverall (surprisingly) good job and usually providesgood enough results.A2: Its main weakness and challenge is that people tendto write information about more than one topic intothe same sentence. This sometimes makes itchallenging for the system since it is tasked withclassifying the entire sentence. They suggest thatsome sort of smart sentence splitting, which has theability to split such sentences into two or morephrases, could help. Further, they also noticed thatthe basic sentence splitting performed by the systemwas not always correct, which sometimes resulted inthe main message of a sentence being lost. Onereported observation suggests that the system seemsto perform worse on the more atypical and complexnursing notes.A3: On the question regarding whether or not the systemcould be helpful, they report that they think it couldbe (very) helpful since nurses would not need toconsider where to write the information or whatsubject headings to choose. This would reduce timeand effort required for nurses documentation duties.It is also suggested that this kind of system wouldwork well when the documentation is done viadictation (speech to text). Another suggestedconsequence of using this system is that it couldincrease consistency in how headings are being usedfor similar information. However, it was alsomentioned that having the ability to first select a setof subject headings can sometimes be helpful toremember what to report. The evaluators suggestthat increased performance could be gained throughfine-tuning the model for the different units at thehospital, possibly by limiting the pool of headings toselect from.Data analysis resultsBefore looking in detail at the measured similaritiesbetween heading pairs, we examine the overall quality ofthe heading representations and the agreement betweenthe two used rankings. To visually inspect the representa-tions we form a dendrogram from a hierarchical clusteringof the headings. Figure 2 shows an example subtree of thedendrogram with two high level clusters. The first onefocuses on breathing, containing 10 headings overall, allof which are related to the topic. The second cluster con-tains 9 headings related to patients activity where most ofthe formed clusters are meaningful.Although the heading vectors seem to offer goodsemantic representations, and the shortest paths havebeen used for measuring semantic similarity with otherbiomedical ontologies, there seems to be a strong dis-Fig. 2 Heading Dendrogram. A subtree of the heading dendrogram formed with hierarchical clustering of the subject heading representationsderived from the neural network classification modelMoen et al. Journal of Biomedical Semantics           (2020) 11:10 Page 9 of 12agreement between these two approaches. For instancethe Spearmans rho between the two formed rankings isonly 0.12. To gain an insight into why these two rank-ings are heavily conflicted, we look at heading pairs thatthe classifier has identified as similar, but for which thecorresponding distance in FinCC is high. It turns outthat all top 1000 pairs with the largest difference in theranks in this setting are pairs where one of the headingsoriginates from the nursing diagnosis category and theother from the nursing interventions. The top conflictingpairs include headings such as Nursing Diagnosis: Uri-nary Incontinence  Nursing Intervention: Treatmentof Urinary Incontinence, Nursing Diagnosis: Changes inOral Mucosa  Nursing Intervention: Basic Care of Oraland Other Mucosa and Nursing Diagnosis: Swelling Nursing Intervention: Monitoring Swelling.To show that these headings are not similar accord-ing to our model only due to its incapability to distin-guish the semantic differences between diagnoses andinterventions, we look into the actual sentences writ-ten under these headings. For instance the NursingDiagnosis: Swelling heading is assigned by nurses tosentences such as Swelling of right arm. and Severeswelling of shins. whereas Nursing Intervention: Moni-toring Swelling heading contains sentences such as Shinssomewhat swollen. and Shins still swollen, feet not as much.In fact, sentences such as Legs swollen. occur identicallyunder both of these headings.Similar trend can be seen by just looking at the mostsimilar headings according to the classifier, ignoring theconflicting distance in the taxonomy. The most similarheading pair in the whole representation space is NursingIntervention: Providing Additional Nutrition  NursingIntervention: Offering Supplements. Both of these head-ings again contain identical sentences, such as Renilon1 can at 11 am and PreOp 2 cans, 6 oclock, yet theseheadings are not closely related in the FinCC taxonomy.In classification tasks it is often the case that theamount of training data have a clear correlation withclassification model performance, and that this can alsobe observed on the level of individual classes (i.e.,subject headings in our case). However, based on theautomated evaluation data, we do not observe a lin-ear dependence between heading-specific model accu-racy and the amount of training data for each head-ing (Pearsons r = 0.04), probably due to the relativelylarge number of training examples for most classes.There is neither a linear dependence between accuracyand heading specificity (depth) in the FinCC taxonomy(Pearsons r = 0.02).DiscussionOverall, the results suggest that the system is doing a rel-atively good job at the task of grouping nursing note textinto paragraphs and labelling them with subject headings.According to the manual evaluation, shown in Table 5,68.85% of the paragraphs formed by the WithMergingsystem variant are sensible and have been assigned subjectheadings that correctly describes the text therein. Eventhough the results are not yet perfect, we believe that thesystem could already be helpful by producing an initialstructured version that the users can correct afterwards ifneeded.We found that there is a correlation between theparagraph-level manual evaluation results and the classi-fiers confidence values for the assigned headings. Thus,for practical use, it could be helpful to the user to see theseconfidence values, for each paragraph and/or sentence,when assessing whether or not to retrospectively correctthe initial structured version of a nursing note. As a futurework we are considering training a separate model for thepurpose of classifying the quality of formed paragraphs e.g. as good or bad.In a previous study we conducted a manual evalua-tion of the same classification model as used here, butthis focused on sentence-level evaluation instead of para-graphs [6]. In that study the evaluation was conducted on20 nursing notes3 instead of 40, as in the present study.This previous evaluation showed that between 68.05% to88.40% of the sentences had been assigned a suitable head-ing. In the present study, focusing on paragraphs, theresults are similar, and equivalent to classes 1 (71.15%)and 1+2 (87.87%) in Table 3, accordingly.These similarities are as expected for the NoMergingvariant, since it merely groups together the sentenceswith the same assigned subject headings. More interest-ing is the observation that WithMerging has about thesame performance as NoMerging (0.70 percentage pointincrease for class 1 and 2.77 for class 1+2). This indi-cates that the merging step performed by WithMergingdoes not result in less suitable headings being assignedto the paragraphs. We also observe that there is not astatistically significant difference between these evalua-tions. Further, by looking at Table 4, we see that thedifferences between the two system versions in terms ofparagraph (sentence grouping) quality are small (e.g., only0.53 percentage point decrease for class a when com-paring WithMerging to NoMerging). However, thePearsons chi-squared test shows that these differences canbe considered as being statistically significant.We observethat the main differences between the assessments of thetwo system versions are found in classes b and c, indi-cating that the paragraphs produced by WithMerginghas fewer sentences which should be moved to otherformed paragraphs within a nursing note (b), but insteadmore sentences do not group well with any of the para-3These 20 nursing notes are a subset of the 40 ones used in the present study.Moen et al. Journal of Biomedical Semantics           (2020) 11:10 Page 10 of 12graphs it produces (c). Whether this difference is ofpractical relevance is something that requires furtherinvestigation.As already mentioned, this system has the potentialto save nurses time and effort when it comes to docu-mentation. As suggested by the evaluators, this systemcan be helpful when the documentation is performed viaspeech-to-text dictation  which alone has been shown todecrease documentation time [36, 37].With amicrophonebeing the main interface for the user (instead of a key-board), it will be evenmore difficult tomanually select andinsert subject headings and structure the resulting textaccordingly. Thus, with the use of such a system, nursingdocumentation could potentially be done, e.g., at the pointof care and still produce nursing notes that follow theruling documentation standard. The use of the proposedsystem also has the potential to increase the consistencyin the use of subject headings for similar information and,as a consequence, improve the documentation quality.Regardless of how the text is produced, a classification-based model like we use here could additionally serve asa reminder system that reminds the user about possiblemissing information in the nursing notes being written.For example, if a unit requires that certain topics shouldbe mentioned in the nursing notes, the system will beable to detect (with a certain confidence) if somethinghas not been reported yet. Similarly, the system could beused to notify users if a sentence already written underone heading/paragraph might better fit under anotherheading.We did not put any limitations on the units and wardsfrom where the nursing notes used in this study comefrom. Still, it is difficult to say how this system generalizesto the various units at the hospital. However, asmentionedin the answers from the evaluators, performance of sucha system is likely to improve if it were to be tailored forindividual units at the hospital. We believe that separateversions of the system could be used at the different unitsand wards at the hospital. In this way, the training data andwhat the classification model learns would more closelyreflect the local documentation practices.In the classification model used in our system, all train-ing examples contained a sentence as input and a subjectheading from the classification standard to predict as out-put. However, we have also observed that some of thetext that the nurses document may not necessarily belongunder a specific subject heading. Examples include metainformation regarding the unit/ward, dates and names. Asa future work we plan to also include such information astraining examples for the model, and thus allow the sys-tem to suggest that some text does not need to be assigneda subject heading.The paragraph merging step used here is rather prim-itive. Further, the system (WithMerging) is currentlyonly allowed to merge the initially formed paragraphs. Asa future work we plan to develop this merging algorithmfurther, where initially formed paragraphs may be split upto form new ones, and with the possibility of introducingnew headings in the process. One idea could be to applysome sort of centrality-based algorithm.The exploration of the heading representations formedby the classification model reveals a drastic discrepancybetween the FinCC taxonomy and the actual use of thesubject headings. The most prominent observation is thatneither the classification model nor the nurses differen-tiate between diagnosis and intervention headings, butinstead the same textual content is often documentedunder both variants of otherwise similar headings, e.g.Swelling (diagnosis) and Monitoring Swelling (inter-vention). Similar indistinguishable heading pairs can bedetected within the main categories.We believe these observations can be beneficial in devel-oping future versions of FinCC as they provide a semi-automated method for identifying problematic taxonomydefinitions based on a large collection of nursing notes,whereas the prior development has relied on small-scalequestionnaires [38]. Since FinCC is derived from the inter-national Clinical Care Classification (CCC) System [39],these issues are most likely not specific to FinCC, but alsopresent in other patient care frameworks.ConclusionsIn this study we have described the evaluation of a sys-tem aimed at assisting nurses in documenting patient care.The aim is to allow nurses to write the information theywant to document without having to manually structurethe text under subject headings which they select from alarge taxonomy. Instead, the system automatically groupssentences into paragraphs and assigns subject headings. In68.85% of the paragraphs formed by the system, the topicsof the sentences are coherent and the assigned headingscorrectly describe the topics. Further, we show that the useof a paragraph merging step reduces the number of para-graphs produced by 23% without affecting the quality ofthe patient documentation, resulting in a more coherentoutcome.Finally, we show that interpreting the internal work-ings of the used neural classifier provides insights into theactual use of the subject headings in care documentationand can be used to pinpoint where the documentationpractices deviate from the intended use of the care clas-sification standards. Such observations can be utilizedin improving the usability of the underlying clinical caretaxonomy.This study shows that the use of text classificationapplied to clinical nursing notes has the potential toreduce the time and effort that hospital nurses are cur-rently spending on care documentation.Moen et al. Journal of Biomedical Semantics           (2020) 11:10 Page 11 of 12AbbreviationsFinCC: Finnish Care Classification standard; FiCND: Finnish Classification ofNursing Diagnoses; FiCNI: Finnish Classification of Nursing Interventions; LSTM:Long Short-Term Memory recurrent neural network; ICD: InternationalClassification of Diseases; CCC: Clinical Care ClassificationAcknowledgementsWe would like to thank the anonymous reviewers for their valuable commentsand suggestions which led to improvements to the originally submittedmanuscript.Authors contributionsHM initiated the study and was, together with KH, LMP and SS, responsible forthe overall design. HM and KH conducted the system implementations,performed the machine learning experiments, data preprocessing andautomated evaluations under the supervision of FG and TS. LMP, HMM, HS,RDO, KT and MV developed the data set used for testing the system and,together with SS, provided the required domain expertise. LMP, HMM, HS wereresponsible for the manual evaluations of the system. HM and KH outlined thefirst draft of the manuscript. All authors contributed to editing and revising themanuscript. All authors read and approved the final manuscript and there areno other persons who satisfy the criteria for authorship but are not listed. Theorder of authors listed in the manuscript has been approved by all authors.FundingThis research was supported by Academy of Finland (315376). The Titan XpGPU used in this research was donated by the NVIDIA Corporation.Availability of data andmaterialsThe datasets generated and/or analysed during the current study are notpublicly available due to their sensitive nature but more information areavailable from the corresponding author on reasonable request.Ethics approval and consent to participateEthical approval for using the data was obtained from the hospital districtsethics committee (17.02.2009 §67) and research approval was obtained fromthe medical director of the hospital district (02/2009).Consent for publicationNot applicable.Competing interestsThe authors declare that they have no competing interests.Author details1Department of Future Technologies, University of Turku, Vesilinnantie 5,20500 Turku, Finland. 2University of Turku Graduate School, University ofTurku, Hämeenkatu 4, 20500 Turku, Finland. 3Department of Nursing Science,University of Turku, Joukahaisenkatu 3-5, 20520 Turku, Finland. 4TurkuUniversity Hospital, Kiinamyllynkatu 4-8, 20521 Turku, Finland.Received: 19 May 2019 Accepted: 14 August 2020Wolff et al. Journal of Biomedical Semantics           (2020) 11:12 https://doi.org/10.1186/s13326-020-00226-wRESEARCH Open AccessMethodologically grounded semanticanalysis of large volume of chilean medicalliterature data applied to the analysis ofmedical research funding efficiency in ChilePatricio Wolff1, Sebastián Ríos1, David Clavijo1, Manuel Graña2* and Miguel Carrasco3AbstractBackground: Medical knowledge is accumulated in scientific research papers along time. In order to exploit thisknowledge by automated systems, there is a growing interest in developing text mining methodologies to extract,structure, and analyze in the shortest time possible the knowledge encoded in the large volume of medical literature.In this paper, we use the Latent Dirichlet Allocation approach to analyze the correlation between funding efforts andactually published research results in order to provide the policy makers with a systematic and rigorous tool to assessthe efficiency of funding programs in the medical area.Results: We have tested our methodology in the Revista Médica de Chile, years 2012-2015. 50 relevant semantictopics were identified within 643 medical scientific research papers. Relationships between the identified semantictopics were uncovered using visualization methods. We have also been able to analyze the funding patterns ofscientific research underlying these publications. We found that only 29% of the publications declare funding sources,and we identified five topic clusters that concentrate 86% of the declared funds.Conclusions: Our methodology allows analyzing and interpreting the current state of medical research at a nationallevel. The funding source analysis may be useful at the policy making level in order to assess the impact of actualfunding policies, and to design new policies.Keywords: Data science, Machine learning, Latent Dirichlet allocation, Healthcare management, StrategyBackgroundDue to the speed of innovation and change of researchtrends in the medical community, research topic tax-onomies published by governmental agencies for fundingcalls often diverge from the reality of the research practice.Our working hypothesis is that semantic topic analysisprovides an unbiased and accurate portrait of the actualresearch topics that are generating published results. Inthis paper we exploit the information from a national*Correspondence: manuel.grana@ehu.es2Computational Intelligence Group, University of Basque Country, P. ManuelLardizabal 1, 20018 San Sebastián, SpainFull list of author information is available at the end of the articlemedical publication, described below, to identify the areasof active research, correlating them with the acknowl-edged funding sources, and non-funded personal effortbacking these scientific results. This analysis provides thepolicymaker with a systematic, unbiased, and automatedtool for the evaluation of the results of funding programs,allowing to assess the coherence of the national researchfunding policies with the actual research outcomes.Methodology background