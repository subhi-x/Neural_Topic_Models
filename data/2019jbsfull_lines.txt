RESEARCH Open AccessOntology-based specification andgeneration of search queries forpost-market surveillanceAlexandr Uciteli1*, Stefan Kropf1*, Timo Weiland2, Stefanie Meese2, Klaus Graef2, Sabrina Rohrer2, Marc O. Schurr2,Wolfram Bartussek3, Christoph Goller4, Philipp Blohm4, Robin Seidel5, Christian Bayer5, Manuel Kernenbach5,Kathrin Pfeiffer5, Wolfgang Lauer5, Jörg-Uwe Meyer6, Michael Witte6 and Heinrich Herre1*AbstractBackground: The vigilant observation of medical devices during post-market surveillance (PMS) for identifyingsafety-relevant incidents is a non-trivial task. A wide range of sources has to be monitored in order to integrate allaccessible data about the safety and performance of a medical device. PMS needs to be supported by an efficientsearch strategy and the possibility to create complex search queries by domain experts.Results: We use ontologies to support the specification of search queries and the preparation of the documentcorpus, which contains all relevant documents. In this paper, we present (1) the Search Ontology (SON) v2.0, (2) anExcel template for specifying search queries, and (3) the Search Ontology Generator (SONG), which generatescomplex queries out of the Excel template. Based on our approach, a service-oriented architecture was designed,which supports and assists domain experts during PMS. Comprehensive testing confirmed the correct execution ofall SONG functions. The applicability of our method and of the developed tools was evaluated by domain experts.The test persons concordantly rated our solution after a short period of training as highly user-friendly, intuitive andwell applicable for supporting PMS.Conclusions: The Search Ontology is a promising domain-independent approach to specify complex searchqueries. Our solution allows advanced searches for relevant documents in different domains using suitable domainontologies.Keywords: Ontology, Information retrieval, Search queries, Spreadsheet-based ontology specification, Ontologygeneration, Post-market surveillanceBackgroundAccording to the provisions of the current EuropeanMedical Device Directive 93/42/EEC [1, 2] and the newEuropean Medical Device Regulation (applicable as fromMay 2020) [3], each manufacturer of medical deviceshas to set up a comprehensive system in order to iden-tify, evaluate and integrate clinical data derived from thefield application of a medical device after market accessduring post-market surveillance (PMS). Small andmedium-sized enterprises in the field of medical devicesare in need for operable systems for post-market data re-trieval in order to enhance their PMS strategies and tobe prepared for the growing requirements of the newEuropean Medical Device Regulation.A wide range of both internal (own quality manage-ment and compliant system) and external (scientific da-tabases, medical congresses, internet-based knowledge &experiences, PMS by competent authorities) sourceshave to be monitored in order to integrate all accessibledata about a medical devices safety and performance.Currently, these detailed, continuous searches are stillperformed manually with a high input of time andpersonnel resources, making PMS a daunting task.© The Author(s). 2019 Open Access This article is distributed under the terms of the Creative Commons Attribution 4.0International License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, andreproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link tothe Creative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver(http://creativecommons.org/publicdomain/zero/1.0/) applies to the data made available in this article, unless otherwise stated.* Correspondence: auciteli@imise.uni-leipzig.de; stefan.kropf@imise.uni-leipzig.de; heinrich.herre@imise.uni-leipzig.de1Institute for Medical Informatics, Statistics and Epidemiology (IMISE),University of Leipzig, Leipzig, GermanyFull list of author information is available at the end of the articleUciteli et al. Journal of Biomedical Semantics            (2019) 10:9 https://doi.org/10.1186/s13326-019-0203-7Literally, an employee has to type all search queries (e.g.,safety AND coronary stent) into the input fields of alarge number of different databases, congress sites andpublic search engines in order to gain a broad, unspecifichit list, interspersed with single, relevant content. Thisstrategy of data retrieval reaches its limits assuming thatseveral search strings have to be applied in order to moni-tor a whole range of medical devices, each featured by avariety of decisive search questions.Additionally, each notable medical database uses itsown, inherent syntax to specify search queries. This in-compatibility between databases and the amount of differ-ent search tasks combined with the manual application toa multitude of databases results in low efficiency and ahigh potential for human error.Setting up more complex queries in a simple mannerby domain experts enables the definition of the topic ofinterest in a more specific way and circumvents theproblem of retrieving irrelevant content.In the OntoVigilance project (predecessor project ofOntoPMS), we developed the Search Ontology (SON)v1.0 [4], a promising approach for an ontology-basedspecification of complex search queries. The modulararchitecture of the SON enables the re-use of ontologyparts in different use cases as well as a quick and easyadaptation and extension of the ontology according tothe specific requirements.The developed Search Ontology and its application wasevaluated in the OntoVigilance project by domain experts.This previous study has proven that the SON is a suitablemethod for modelling complex queries, but it needed tobe optimized to face further requirements of domain ex-perts. On the one hand, the structure of the Search Ontol-ogy can be simplified to improve the usability by domainexperts. On the other hand, certain extensions are neces-sary to model all relevant query types. Based on thesefindings, we further developed and optimized the SearchOntology in the OntoPMS project. The Search Ontologyv2.0 is presented in this paper. The SON is generic andcan be used in any domain. For the application of theSON in a particular domain, it has to be extended by a do-main ontology, such that the classes of the domain ontol-ogy are subclasses of the SON classes. We call suchdomain ontologies Domain-specific Search Ontologies(dSON). Whereas SON stands for exactly one ontology(namely the Search Ontology presented in this paper),dSON represents a class or a type of ontologies. VariousDomain-specific Search Ontologies can be developed,such as dSON-PMS for the whole PMS domain or dSON-Niti for modelling queries regarding the material Nitinol.In addition, we developed an Excel template to specify theinformation required to create a dSON, which signifi-cantly simplifies the ontology development by domain ex-perts. For the automatic generation of a dSON from theExcel template, we implemented the Search OntologyGenerator (SONG). In contrast to the OntoQueryBuilder(OQB) [4], the SONG generates the complete dSON in-cluding all specified queries in the correct query syntaxfrom the Excel template and provides it for external tools(e.g., the search engine). In this way, the search engine canget the complete dSON by accessing the SONG servicewithout any requests or generating queries at search time.MethodsIn Europe, market access of a medical device based on aCE-mark is granted after a successful so-called con-formity assessment process, which includes passing anextensive series of tests, risks analyses and evaluations ofclinical data on the medical devices safety and efficacy.Nevertheless, the behaviour of a medical device overtime in broad application can be investigated a priorionly in a limited manner. Thus, PMS strategies are setup in order to retrieve and summarize application dataof medical devices and to identify residual risks. Expres-sive search queries are needed to precisely define thetopic of interest. The problem is that the manual cre-ation of complex queries requires knowledge of the cor-rect query syntax and is time-consuming and error-prone. This paper focusses on developing the SearchOntology Generator (SONG), a framework for ontology-based specification and generation of powerful searchqueries by domain experts with less effort and withoutknowing the query syntax.Example PMS questionReports on unfavourable interactions between implantmaterial and patients tissue have to be identified andevaluated in order to a) control residual and/or unex-pected risk, b) determine vulnerable patient subpopula-tions and c) improve the respective medical implant ormaterial, respectively.An example PMS question could be to find out the un-expected side effects of the metal alloy Nitinol used forconstruction of endoscopic clipping systems. A searchquery has to be constructed covering the different aspectsof the PMS question such as unexpected complication,type of medical device (endoscopic clipping system) andused material (Nitinol) by suitable search terms (e.g.,Nitinol, Nickel Titanium and NiTi as synonyms ofNitinol or unexpected complication, unforeseeable risk,adverse event, etc. to describe the complication). Further-more, it can be necessary to specify terms that should notappear in the text (negation), for instance, to exclude de-scriptions of preclinical tests or studies (e.g., terms likeanimal, study and preclinical). Finally, the desiredterms have to be assembled to a valid search query usingsupported operators and brackets.Uciteli et al. Journal of Biomedical Semantics            (2019) 10:9 Page 2 of 13This example is used in the paper for furtherexplanations.ApproachFigure 1 illustrates the overall architecture of theSONG environment.The Domain Expert specifies information required togenerate a dSON (including search queries) using aneasily applicable Excel template.The SONG Manager uploads/downloads files and teststhe service using the SONG Config App. The SONGservice generates the dSON (in our example the dSON-Niti) in OWL and JSON format out of the Excel tem-plate, allows adding new entities to the ontology andprovides the generated dSON for external tools, espe-cially for search apps. After each file upload (Excel orOWL) or after an adding of a new entity, the new ontol-ogy (OWL and JSON) is generated.The SONG manages the generation of OWL andJSON from Excel as well as JSON from OWL. TheOWL format is used for a possible optimization of thegenerated ontology with an ontology editor or for an in-tegration of external ontologies. Any ontology that con-tains concepts and their labels can be considered as adSON and can be easily integrated with our approach.JSON is utilized for communication with external tools.The Searcher uses the SONG Search App, which visu-alizes the dSON, and can select desired concepts orqueries for the execution by a search engine.The next sections introduce the two additional com-ponents, search engine and Corpus Builder that wereused in the OntoPMS project in combination withSONG.Search engineThe SONG can be used with any Lucene-based searchengine for the generation of queries in the Lucene querysyntax out of the Excel template. In addition, new ex-pressive query operators were implemented in theOntoPMS project, which significantly extend the Lucenequery syntax.To identify risks or complications (for PMS) in un-structured documents, complex patterns have to be de-tected. Such patterns go beyond the standard capabilitiesof state-of-the-art search engines such as Elasticsearch[5]. Therefore, we extended these capabilities by creatingour own search plugin, providing the required function-alities and improving search quality. The extension wasrealized as an Elasticsearch plugin and contains, amongFig. 1 SONG and its application. The Domain Expert specifies the dSON in Excel. The SONG Manager uploads/downloads files and tests theservice. The SONG Service generates the dSON (including complete search queries) and offers different methods for external applications. TheSearcher uses the SONG Search App and can select desired concepts or queries for the execution by a search engineUciteli et al. Journal of Biomedical Semantics            (2019) 10:9 Page 3 of 13others, the following additional features: improved toke-nization, lemmatization and word decomposition; build-in support for several normal forms / term types; im-proved quality for ambiguous searches; named entity,date and measurement recognition; additional searchmodes; NEAR operators.In particular, the search modes and new search opera-tors are extensively used in our dSONs to produce moreprecise queries. The search modes correspond to the dif-ferent types of terms (exact [E], diacritics-normalized[D], lemmatized baseforms [B], compounds-parts [C])that we use in our index. For example, with the queryMODE/E (SafeSet) we only search for SafeSet with twoupper case S. Words within a NEAR/n query must nothave a token-distance greater than n. With NEAR/S andNEAR/P, words must occur within one sentence or oneparagraph. These new NEAR-Operators can be com-bined and nested with other queries in an arbitrary way.Corpus BuilderPMS requires information from several types of sourcesincluding proprietary manufacturer data and informationfrom the web. Getting information from the web re-quires some knowledge on what to look for, how to lookfor it, how to access it and which parts to extract. Add-itionally, following the links found on a page identifiedby a given URL quickly turned out to be a potential trap,since the referenced pages may be completely out ofscope. Therefore, we concluded that an ontology wouldhelp to define the scope and thereby control the auto-mated data acquisition process.For data acquisition, we developed the Corpus Builder[6, 7]. Its input component, the Prospector, metaphoric-ally speaking, roams the internet in order to identifysuitable data to feed the OntoPMS Corpus. To achievethis, it uses a set of special corpus queries, which arepart of our dSON. Currently, the Prospector delivers itsdocuments to a NLP pipeline, which analyses the con-tents to identify documents that are important to the re-spective projects and rejects (i.e. blacklist) documentsthat shall not be included into the OntoPMS corpus.This processing is done by a kind of control circuit. Theplant of the feedback loop is controlled by a seed list,produced by the prospector and by the feedback compo-nent. It does the crawling and gathering of new URLs byfollowing forward and backward links and reading thecontents identified by the URLs. Then, the output ischecked by the sensor. The sensor is controlled by thecorpus queries and allows a deep analysis of the content.After that, questionable content is fed back to a splittercomponent which sorts out garbage (blacklist) andboosts domains with a high amount of documents wewant to include (whitelist). URLs, based on those whitelisted domains are then included if not yet part of theseed list. If the output contains unwanted documents,we have to improve the corpus queries. Hence, we havea semi-supervised learning component, with which themanual part of supervision is made on the abstract levelof ontologies. This enables us to change the behaviour ofthe corpus builder by changing the underlying ontologyinstead of changing the software.ResultsSearch Ontology (SON) v2.0The Search Ontology (SON) provides a general structurefor all dSONs (the classes of the dSONs have to be sub-classes of the SON classes; only relations and propertiesdefined in the SON are allowed). This section presents theoptimized Search Ontology v2.0, which contains some im-provements compared to the v1.0. One of the advantagesof the new version is that the SON-based dSONs can bespecified in a specially developed Excel template ratherthan with an ontology editor. Furthermore, the keywordsfor the search (search terms) are directly associated withsearch concepts as annotations. In the v1.0, the searchterms had to be defined as instances of the search termclasses (with different labels) and linked to the search con-cepts using the property restrictions (based on the prop-erty described_by). Both aspects simplify the structure ofthe ontology. Other extensions include negated conceptsand direct storage of queries in the ontology. The ontol-ogy contains 9 classes and 13 properties.The SON models three types of entities: search con-cepts, search terms, and search queries (Fig. 2). Thesearch concepts are concepts (in the sense of GeneralFormal Ontology, GFO [8, 9]), whose descriptions ordesignations have to be found in texts. The other twoentities are symbolic structures (gfo: Symbolic_Struc-ture) and serve to model single keywords or phrases ofthe concept description as well as queries.Search termsThe search terms are descriptions or designations ofsearch concepts. A distinction is made between sim-ple and composite terms. The simple terms are ei-ther single words (e.g., clip, Nitinol) or fixed(defined by the user) phrases (e.g., endoscopic clip-ping system). The composite terms are combina-tions (has_part) of simple terms of two searchconcepts (has_terms_of_concept_as_part). They aredefined by the user by choosing the two concepts(e.g., Unexpected and Complication) and are gener-ated by the generator as an AND-connection of theOR-linked simple terms of the selected concepts(e.g., (unexpected OR unforeseeable OR unknown)AND (complication OR failure OR incident)).Uciteli et al. Journal of Biomedical Semantics            (2019) 10:9 Page 4 of 13Search conceptsThe search concepts are described or designated bysearch terms (described_by, simple_term, composite_term). We distinguish between standard (e.g., Complica-tion) and negated (e.g., No_Preclinical) concepts. Whilethe terms of the standard concepts (e.g., complication,failure, incident) have to be contained in the result-ing documents, the terms of the negated concepts (e.g.,animal, study, preclinical) have to be excluded/ne-gated. Each concept is additionally associated with aFig. 2 SON. The SON models three types of entities: search concepts, search terms, and search queries as well as several relations between themFig. 3 Excel template (excerpt). The different aspects of the PMS question such as unexpected complication, type of medical device and usedmaterial were modelled within the easily applicable Excel templateUciteli et al. Journal of Biomedical Semantics            (2019) 10:9 Page 5 of 13single concept query (see Search queries), which is usedfor the search for descriptions of the concept.Search queriesThe single concept query is an OR-connection of allterms (simple and composite) for a standard concept ora negated OR-connection of all terms for a negated con-cept. The query can additionally contain specified searchoperators and brackets. The multiple concept query isan AND-connection of single concept queries of selectedconcepts (has_query_of_concept_as_part).Excel templateThe design of the Excel template was derived from theSON structure. Sheets, tables and fields were createdallowing the specification of all the information requiredfor generating a valid dSON (including search queries).Figure 3 illustrates our example by screenshots of theseveral sheets.The Excel template consists, on the one hand, of thepredefined data sheets (Negated_Concept, Composite_Term and Multiple_Concept_Query) and, on the otherhand, of the user-defined sheets (facet sheets) for thespecification and classification of the search conceptsand simple terms. For the observation of medical devicesduring PMS, we introduced among others the followingfacets: Medical_Device, Medical_Area, Medical_Prob-lem, Incident, Material and Risk. In our example, the dif-ferent facets of the search are represented by the Excelsheets Material, Medical_Device and Incident.In every facet sheet, a subclass structure represents acategorization of the knowledge within the appropriatearea. For instance, we subdivided medical devices in clip,stent, occluder and implant; moreover, these device cat-egories can be subdivided into special types, e.g., endo-scopic clipping system, PFO occluder, PDA occluder,and so on. Next to the nodes of the subclass hierarchy,the domain expert can enter simple terms; two columns(Simple Terms (en) and Simple Terms (de)) are usedfor enabling the separation of English and German sim-ple terms. Several types of query operators, such as thewildcard or boost (e.g., incident^5), can be applied tosimple terms in order to refine the search query.For excluding documents that contain descriptions ofcertain concepts (e.g., complications in preclinical tests),the Negated_Concept sheet is used. The concept is spe-cified (e.g., No_Preclinical) and described by simpleterms to be excluded (e.g., animal, study, preclin-ical) in the column Excluded Simple Terms.The Composite_Term sheet is used for the specifica-tion of terms based on other concepts. The compositeterms for describing the search concept Unexpected_Complication (column: Concept) are combined fromthe simple terms of Unexpected (column: part1) andComplication (column: part2).For the creation of complex (multiple concept) quer-ies, which are based on the conjunction of queries ofmultiple search concepts (e.g., Unexpected_Complica-tion, Nitinol, Endoscopic_Clipping_System and No_Pre-clinical), the Multiple_Concept_Query sheet is used. Thename of the query is specified in the column Query.The definition of the improved MODE or NEAR (e.g.,NEAR/S) operators (columns: MODE and NEAR) ispossible for both, composite terms and multiple conceptqueries. Concepts that should be combined to a multipleconcept query are specified in the columns Concept.Generating a dSON by SONGBy the generation of the ontology from the Excel tem-plate, the model presented in Fig. 2 is not applied one-to-one, but rather simplified. For example, simple termsand single concept queries are defined as annotations ofthe search concept classes.Firstly, the SONG generates the class hierarchy. Thesearch concept trees from the user-defined sheets (facetsheets) are placed under Search_Concept and the ne-gated concept tree under Negated_Concept. Next, thesimple terms (from the columns Simple Terms (en)and Simple Terms (de)) are linked to their conceptsusing the annotation property simple_term.For each row in the Composite_Term table, a compos-ite term class is generated as subclass of Composite_Term. The annotation properties has_term_of_concept_as_part_1 and has_term_of_concept_as_part_2 (shortly:part_1 and part_2) are used to specify the two searchconcepts whose simple terms have to be put together. Inaddition, the specified MODE or NEAR operators aregenerated as annotations. Then, for each composite termclass, the corresponding term is generated as an AND-connection of the OR-linked simple terms of the se-lected concepts, and is associated to the composite termclass using the annotation property query. The possiblyspecified query operators for composite terms are takeninto account in the correct syntax. The composite termclasses are referenced in the search concept classes bythe annotation property composite_term.After that, the single concept queries of all search con-cepts are generated as an OR- connection for standardconcepts or a negated OR-connection for negated con-cepts from all their terms, and are associated with the re-spective concept using the annotation property query. Fornegated concepts, the standard concepts can also be speci-fied, whose terms have to be excluded (excluded_concept).The multiple concept queries specified on the Mul-tiple_Concept_Query sheet are generated as subclassesof Multiple_Concept_Query. The multiple concept queryclasses are associated with the concepts whose singleUciteli et al. Journal of Biomedical Semantics            (2019) 10:9 Page 6 of 13concept queries are to be combined using the annotationproperty has_query_of_concept_as_part (shortly: search_concept). The single concept queries are AND-linked andstored using the annotation property query. Similar tocomposite terms, the possibly specified operators for quer-ies are taken into account during the generation process.In Fig. 4, some parts of the generated dSON-Niti areillustrated. The upper part shows the search conceptUnexpected_Complication, which is described by thecomposite term Unexpected__Complication (with twounderscore characters), and the search concept Nitinol.In the lower left corner, the search concept Endoscopic_Clipping_System is presented. The lower middle partdemonstrates the negated concept No_Preclinical, whichis used for the exclusion of several simple terms. In thelower right corner, the complete (multiple concept)query is illustrated, which consists of different searchconcepts. In the annotation property query is the gener-ated query, which can be executed by a search engine.The query parts (single concept queries) of the multipleconcept query are highlighted.SONG Search AppThe SONG Search App accesses the SONG service andreceives the generated dSON in JSON format (using thegetDSON method of the service). The search conceptsand multiple concept queries are visualized on the GUIof the app as a tree with checkable nodes (Fig. 5). Thesearcher can select desired concepts or multiple conceptqueries by checking the corresponding checkboxes. Theoverall query appears in the boxes English Query orGerman Query (depending on which language wasused for specifying simple terms). The user can enter asearch engine URL directly or can select an availablesearch engine via the dropdown list. In Fig. 5, theOntoPMS search engine was selected. After pressing thebuttons Run English Query or Run German Query,the query is forwarded to the search engine URL as GETparameter. On the website of the OntoPMS search en-gine (Fig. 6), the search results are displayed. Matchingterms are highlighted. When minor changes are needed(e.g., deleting the NEAR or boost operators), thesearcher can modify the query in the input field. How-ever, the important changes of the query that should beavailable for further searches have to be made in Excel(see Modifying dSON in Fig. 7).Additionally, the app supports the creation of newmultiple concept queries. To achieve that, the user hasto select desired concepts, to define the query name andto press the Create Query button. The app sends thisFig. 4 Parts of the dSON-Niti in Protégé. The upper part shows the search concept Unexpected_Complication, the composite termUnexpected__Complication and the search concept Nitinol. In the lower part, the search concept Endoscopic_Clipping_System, the negatedconcept No_Preclinical and the complete (multiple concept) query are illustratedUciteli et al. Journal of Biomedical Semantics            (2019) 10:9 Page 7 of 13information to the SONG service (using the methodaddQuery). After that, the SONG adds the new query tothe ontology und transmits the updated dSON back to theGUI. The query is then available for further searches.Figure 7 summarizes the different steps of the ontology-based search.EvaluationComprehensive testing confirmed the correct executionof all SONG functions. The applicability of our methodand developed tools was evaluated by domain experts.In the OntoVigilance project, development and editingof specific ontologies was conducted in Protégé [10]. Forcommercial use (in our case post-market surveillancepurposes for medical devices), ontologies are rather dy-namic constructs with a constant pace of re-editing toreact upon changing search parameters. Designated keyoperators are Regulatory Affairs and/or Quality man-agers positioned at the respective departments of med-ical device manufacturers. Hence, the prototypicaldomain expert will be rather untrained in deep informat-ics/ontology processing. It turned out that Protégésbasic functionality can be learned by a domain expert.However, the ontology editor was considered cumber-some and complex to operate. Consequently, in theOntoPMS project, an Editor easy to learn and at onceapplicable was formulated as an essential requirement.Due to the broad application of MS office in businessapplication, an Excel-based platform was highly appreci-ated by domain experts involved in the project. Threenaïve domain experts were shortly instructed in thestructure and function of the SON as well as the SON-based Excel template and equipped with a manual writ-ten by the SON developers.Then each domain experts had to fulfill seven pre-defined tasks using the Excel template: Specification of a new facet Equivalent product(task 1.1) Specification of a new search concept Clip XY inthe respective facet (task 1.2) Linking the search concept with pre-defined searchterms in form of several simple terms (task 1.3) Specification of a new facet Safety (task 2.1)Fig. 5 SONG Search App. The searcher clicks the checkboxes of desired concepts or multiple concept queries, selects a search engine andsubmits the generated queryUciteli et al. Journal of Biomedical Semantics            (2019) 10:9 Page 8 of 13 Specification of a new search concept UnexpectedSide Effect in the respective facet (task 2.2) Linking the search concept with pre-defined searchterms in form of composite terms (adjective-noun-phrase) (task 2.3) Specification of a negated concept NoPreclinical with simple terms to be negated inthe query (task 3)Afterwards the test persons were introduced to theSONG and asked to generate a query to search for unex-pected side effects of the Clip XY that are not related topreclinical tests (task 4).Each test was accomplished successfully in a reason-able time. Table 1 provides the results of processing thetasks; Table 2 shows the time expenditure. Afterwardsthe test persons were briefly interrogated by preformedFig. 6 OntoPMS search results page. The search results of the OntoPMS search engine are displayed. Matching terms are highlighted. The querycan be modified in the input fieldFig. 7 Ontology-based search pipeline. The figure summarizes the different steps of the ontology-based search. A recursive optimization of thequery is possibleUciteli et al. Journal of Biomedical Semantics            (2019) 10:9 Page 9 of 13questions and asked to provide a general statement(Table 3). The test persons congruently rated the SON-based Excel template as clearly structured, featured byintuitive operator control logic and highly user-friendly.The Excel platform appears familiar. By application ofthe SONG, also complex queries can be generatedquickly, transparent and reproducible. In comparison toa conventional periodic, manual data search, relevantcontent was identified by SONG-based data retrieval ina more convenient and comprehensive way.In conclusion, the SONG framework significantly facil-itates the creation of search queries. According to thedomain experts in charge of the testing, the system is in-tuitive. Queries once generated can be saved and reused.This feature fosters transparency of a systematic searchand repeatability, which is a legal imperative in the post-market surveillance of medical devices.Additionally, BfArMs Research group Safety of Med-ical Devices evaluated the applicability of SONG from aregulatory perspective giving a direct feedback from anassessors point of view. The evaluation was conductedbased on the FDA coding system for medical deviceproblems, which is implemented at BfArM to classify re-ported incidents. The evaluated tasks included not onlyadding, editing and deleting facets, concepts, simple andcomposite terms within an existing template but alsogenerating complex queries, a task to be considered ashighly important from a regulatory perspective. Sincenone of the assessors had been trained on the conceptof ontologies before participating, the initial test resultsshowed some minor but expected difficulties at first.Thereafter a fast learning process was observed, leadingto desired performances within a very short period oftime. Table 4 shows, that no help of any kind wasneeded (intuitional), whenever the complete informationrequired for a given task was presented in one facet.Tasks including working with more than one facet oradding new information sometimes lead to mistakes,which could be corrected quickly and only by use of de-bug output (easy). Additional information was only re-quired (explanation needed), when new concepts orcomposite terms had to be added. These kind of mis-takes occurred only if it has been necessary to add newinformation while also consider consequences of this ac-tion to other facets. Notably no task needed to be ex-plained more than once. Generating complex queriesbecomes a very easy task using this tool. One of the ad-vantages of the current implementation is that it al-lows quick and easy modification of specified queries(e.g., by adding new simple terms) if the ontologyneeds to be altered due to a better understanding ofthe subject. The evaluation showed the fast increasein understanding the concept of search ontologies aswell as the applicability of SONG to model the riskclassification and to generate powerful search queriesin a very systematic and efficient way.Table 1 Successful task managementtask1.1task1.2task1.3task2.1task2.2task2.3task3task4Proband12 2 2 2 2 2 2 2Proband22 2 2 2 2 2 1 2Proband32 2 2 2 2 1 2 20 = task not fulfilled1 = task fulfilled; additional support required (Minor support was necessary inform of short explanations of the template structure while processing thetasks 2.3 and 3)2 = task fulfilled without further supportTable 2 Expenditure of time in secondstask 1completetask 2completetask 3completetask 4completeProband172 60 13 20Proband247 60 20 19Proband361 89 16 22Mean 60 70 16 20SD 13 17 4 2Table 3 Interview resultsYes No Prefer not tosayDo you have any previous experiences withOntology Editors?0 3 0Is Excel a common standard in regular workenvironment?3 0 0Is the structure of the ontology transparent inthis set-up?3 0 0Do you rate Excel as feasible for ontologyediting?3 0 0Is this set-up helpful for query generation? 3 0 0Table 4 BfArMs evaluation resultsAdd Edit DeleteFacet Easy Intuitional IntuitionalSimple terms Easy Intuitional IntuitionalConcept Explanation needed Intuitional IntuitionalComposite terms Explanation needed Easy IntuitionalMultiple concept query Intuitional Intuitional IntuitionalIntuitional = no help of any kind neededEasy = quick correction of mistakes only by use of debug outputExplanation needed = additional information required (Explanation wasneeded only if it has been necessary to add new information while alsoconsider consequences of this action to other facets. Notably no task neededto be explained more than once)Uciteli et al. Journal of Biomedical Semantics            (2019) 10:9 Page 10 of 13Related workOntology-based information retrievalSince finding meaningful and intelligent information isdifficult, there are different ontology information re-trieval techniques and methods available [11]. In thewide world of semantic searches, the approach of thispaper can be classified as Research Search [12], becausewe denoted search queries by concepts. Semanticsearches are usually executed not on plain documentsbut on ontologies, which requires expensive manual an-notation or natural language processing steps (NLP) forextracting semantic data out of the documents. Afterthat step, the information of the documents is stored ina semantic knowledge base [13] or in a semanticallyenriched enhanced document index [14], on which se-mantic searches can be applied by using semantic re-trieval languages such as SPARQL [15] or SeRQL [16].The early TAMBIS project [17] provides a foresightedsemantic search approach for accessing multiple bio-informatics databases, using a complex biological con-cept model for query formulation. Despite of semanticknowledge bases or structured data sources, the ap-proach of this paper builds up on indexed documentswhich can be retrieved by complex Boolean expressions,which are difficult to construct [18]. Using ontologies asnavigation tree structure in form of a Concept-based In-formation Retrieval Interface (CIRI) seems to be moreeffective than a direct interface (input field) [19].GoPubMed [20] uses the Gene Ontology for search onPubMed. In contrast to our approach, the user is not ableto increase the precision of the search by simply develop-ing and using his own dSON, exactly tailored to his needs.Textpresso [21] is a text-mining system for scientificliterature. It implements categories of terms (an ontol-ogy) which can be used for a search on a database of ar-ticles. Regular expressions have to be created for eachcategory to match the corresponding terms in the textand the documents have to be labelled according to thelexicon of the ontology. The documents are thenindexed with respect to labels and words. Our solutiondoes not use any in the ontology contained informationfor pre-processing or indexing of the documents. Theontology is constantly under development and is adaptedby the domain experts to meet their current needs. Ourapproach does not require any additional pre-processingsteps (e.g., labelling) as well as re-indexing the documentcollection when the ontology changes.Excel-based ontology developmentSince ontology engineering is difficult for non-ontologists, there is a need for a rapid and collaborativeontology engineering methodology and easy to use tools[22]. The transformation of spreadsheets in OWL isalready used in life science projects [2325]; tools andplugins enable the population of OWL ontologies out ofspreadsheet templates [26]. The template we developeddiffers in that way, that it is not intended for the ontol-ogy development in general based on modelling certainOWL constructs. Instead, our template is exactly tai-lored to the SON-based specification of dSONs in orderto make its use by domain exerts as intuitive as possible.DiscussionThe specification of complex search queries is a recur-ring task in different domains. The search for complica-tions in the usage of medical devices within the post-market surveillance or the classification of the incidentreports are only two examples in this area. Other exam-ples are the patent examination or the search for rele-vant information in medical documents (e.g., dischargeletter). Our solution is domain-independent and thus al-lows advanced search for relevant documents in differ-ent domains using suitable dSONs. The SON approachwas also already successfully exploited for another usecase in the medical domain to generate complex XPathexpressions for querying archetype-based EHRs [27].On the other hand, our approach is also generic re-garding the used search engine. In the OntoPMS project,an Elasticsearch [5] based search engine was used, whichwas extended by developed plugins to provide novel ex-pressive query operators. In addition, the document cor-pus was specially prepared and optimized for the PMSissue. However, other search engines can also be inte-grated relatively easily with our approach. The corre-sponding query syntax only needs to be implemented.For instance, scientists could use our solution to searchin PubMed [28]. Nevertheless, not only scientists canbenefit from our work. An office employee could modelqueries, which are relevant in his daily work and usethem for the Google or Bing search.Additionally, our solution supports the classification ofdocuments (search results). When a query of a searchconcept delivers certain documents, they can be classi-fied in this concept. The whole taxonomy of search con-cepts (part of the dSON) can then be considered as aclassification of the entire result document set.Classification of search resultsFrom the regulatory perspective of the German compe-tent authority for risk assessment for medical devices,the Federal Institute for Drugs and Medical Devices(BfArM), there is an increasing demand to have the riskassessment process of critical incidents supported by in-telligent IT solutions. With respect to the exponentialincrease in reported incidents with medical devices inGermany, specific dSONs for different aspects of the in-cident must be developed. These specific dSONs willallow the identification of similar incidents and therebyUciteli et al. Journal of Biomedical Semantics            (2019) 10:9 Page 11 of 13an automatic recommendation of classification of newincidents will become possible. The aspects currently infocus include dSONs for the resulting health problem,device problem, root cause and components, all of whichare at present being developed on the basis of the FDAcoding system, which is currently revised by the IMDRFworking group on Adverse Event Terminology and Cod-ing [29]. Using the SONG approach allows domain ex-perts to easily create and modify the subsequent searchconcepts for each of the FDA/IMDRF Codes. Our ap-proach will allow for accelerated risk classification,which in turn allows to create individual views ofdevice-specific problems as well as to monitor the per-formance of different manufacturers within certain de-vice groups such as hip implants, cardiac pacemakers,instruments for bone surgery or insulin pumps.Future workFuture work includes the application of our approach toother domains, especially the search for relevant infor-mation in medical documents as well as the integrationof further search engines including the implementationof the corresponding query syntax. Since the PubMedsearch engine can process GET parameters, we can for-ward the generated query strings directly to PubMed. Infuture work, we planned to integrate fields such as au-thor, journal and title as well as the MeSH termin-ology [30], including the subdivision in main and subheadings.After the definition of a sufficiently extensive knowledgebase in form of dSONs, ontology learning can be exploitedfor supporting a semi-automatic query creation.ConclusionWe presented the improved Search Ontology, a promisingdomain-independent approach to specify complex searchqueries. Our solution allows advanced search for relevantdocuments in different domains using suitable dSONs andsupports an automatic classification of search results. Thesecond version of the Search Ontology includes enhance-ments such as the inclusion of new search operators, ne-gated concepts and direct storage of generated queries inthe ontology. For easier handling by non-ontologists, wedeveloped an Excel template, which facilitates a SON-basedspecification of dSONs without the usage of ontology edi-tors or knowing the query syntax. A service-oriented archi-tecture was introduced; in the core of the architecturestands the Search Ontology Generator (SONG), which pro-vides methods for an access by search engines as well asdSON administration methods. By the enhancement of theSON, the Excel template, the SONG Search App and theservice-oriented architecture, we improved the access tothe Search Ontology for domain experts and external tools.AbbreviationsdSON: Domain-specific Search Ontology; PMS: Post-market surveillance;SON: Search Ontology; SONG: Search Ontology GeneratorAcknowledgementsAn earlier version of the paper has been presented at JOWO 2017 (JointOntology Workshops) / ODLS (Ontologies and Data in Life Sciences) inBozen-Bolzano, Italy.This work has been funded by the German Federal Ministry of Education andResearch (BMBF) in the KMU-innovativ funding program as part of theOntoPMS project (reference number 01IS15056B).We acknowledge support from the German Research Foundation (DFG) andLeipzig University within the program of Open Access Publishing.Authors contributionsAU developed the search ontology method for modelling and generation ofsearch queries, designed and implemented SON and SONG. SK madesubstantial contributions to the design and implementation of SON andSONG, analyzed the recent related works. HH was responsible for projectmanagement, conception and semantic foundation of developed ontologies.TW, SM, KG, SR, MOS, acting as domain experts, set up the content design ofthe SON, created the evaluation plan and conducted the evaluation. Themain contribution of WB was the designing and implementing the CorpusBuilder with the Prospector component including the integration of theontology to control developed components. CG and PB created anElasticsearch plugin providing advanced functionalities such as additionalsearch modes and NEAR operators. RS, CB, MK, KP and WL implemented arisk classification on the basis of the FDA coding system and performed theevaluation of the system from the regulatory perspective of the GermanFederal Institute for Drugs and Medical Devices (BfArM). JUM and MWcontributed to the design of the overall system. All authors read andapproved the final manuscript.FundingThis work has been funded by the German Federal Ministry of Education andResearch (BMBF) in the KMU-innovativ funding program as part of theOntoPMS project (reference number 01IS15056B). The aim of the fundinginitiative is the strengthening of innovation capacity of small and mediumsized enterprises in Germany. Nevertheless, the funding body played no rolein the design of the study and collection, analysis and interpretation of dataand in writing the manuscript.Availability of data and materialsThe datasets generated and/or analyzed during the current study as well asthe tools developed and further material used in the OntoPMS project arenot publicly available. They contain information that could compromiseresearch participants consent and contrast with the projects fundingobjective with the aim of strengthening the innovation capacity of small andmedium sized enterprises in Germany. However, are available from thecorresponding author on reasonable request.Ethics approval and consent to participateNot applicable.Consent for publicationNot applicable.Competing interestsThe authors declare that they have no competing interests.Author details1Institute for Medical Informatics, Statistics and Epidemiology (IMISE),University of Leipzig, Leipzig, Germany. 2novineon Healthcare TechnologyPartners GmbH, Tübingen, Germany. 3OntoPort UG, Sulzbach, Germany.4IntraFind Software AG, München, Germany. 5Federal Institute for Drugs andMedical Devices (BfArM), Bonn, Germany. 6MT2IT GmbH & Co. KG, Ratzeburg,Germany.Uciteli et al. Journal of Biomedical Semantics            (2019) 10:9 Page 12 of 13Received: 5 September 2018 Accepted: 22 May 2019Lithgow-Serrano et al. Journal of Biomedical Semantics            (2019) 10:8 https://doi.org/10.1186/s13326-019-0200-xRESEARCH Open AccessSimilarity corpus on microbialtranscriptional regulationOscar Lithgow-Serrano1,2* , Socorro Gama-Castro1, Cecilia Ishida-Gutiérrez1, Citlalli Mejía-Almonte1,Víctor H. Tierrafría1, Sara Martínez-Luna1, Alberto Santos-Zavaleta1, David Velázquez-Ramírez1and Julio Collado-Vides1,3AbstractBackground: The ability to express the same meaning in different ways is a well-known property of naturallanguage. This amazing property is the source of major difficulties in natural language processing. Given the constantincrease in published literature, its curation and information extraction would strongly benefit from efficientautomatic processes, for which corpora of sentences evaluated by experts are a valuable resource.Results: Given our interest in applying such approaches to the benefit of curation of the biomedical literature,specifically that about gene regulation in microbial organisms, we decided to build a corpus with graded textualsimilarity evaluated by curators and that was designed specifically oriented to our purposes. Based on the predefinedstatistical power of future analyses, we defined features of the design, including sampling, selection criteria, balance,and size, among others. A non-fully crossed study design was applied. Each pair of sentences was evaluated by 3annotators from a total of 7; the scale used in the semantic similarity assessment task within the Semantic Evaluationworkshop (SEMEVAL) was adapted to our goals in four successive iterative sessions with clear improvements in theagreed guidelines and interrater reliability results. Alternatives for such a corpus evaluation have beenwidely discussed.Conclusions: To the best of our knowledge, this is the first similarity corpusa dataset of pairs of sentences forwhich human experts rate the semantic similarity of each pairin this domain of knowledge. We have initiated itsincorporation in our research towards high-throughput curation strategies based on natural language processing.Keywords: Corpus, Similarity, Transcriptional-regulation, GenomicsBackgroundExpressing the same approximate meaning with differentwording is a phenomenon widely present in the everydayuse of natural language. It shows the richness and poly-morphic power of natural language, but it also exhibits thecomplexity implied in understanding the conveyed mean-ing. Due to these characteristics, paraphrase identifica-tion is necessary for many Natural Language Processing(NLP) tasks, such as information retrieval, machine trans-lation, and plagiarism detection, among others. Althoughstrictly a paraphrasis refers to a rewording that states*Correspondence: olithgow@ccg.unam.mx1Computational Genomics, Centro de Ciencias Genómicas, UniversidadNacional Autónoma de México (UNAM). A.P., 565-A Cuernavaca, 62100Morelos, México2Instituto de Investigaciones en Matemáticas Aplicadas y en Sistemas (IIMAS),Universidad Nacional Autónoma de México (UNAM), Mexico City, MéxicoFull list of author information is available at the end of the articlethe same meaning, i.e., its evaluation should only result intrue or false, frequently a graded paraphrasing is needed.This graded paraphrasing is often called Semantic TextualSimilarity (STS).Textual similarity depends on particular text features,domain relations, and the applied perspective; therefore,textual similarity has to be defined according to the con-text. This context specification presupposes the delin-eation of the kind of textual similarity desired, e.g., assign-ing grades of importance to the syntactic parallelism, tothe ontological closeness, to the statistical representationslikeness, etc.It is not a simple endeavor to explicitly state these gradesof importance. The difficulty stems from the fact that it isvery complicated to envisage all possible language featurevariations to express the same idea, and so to have a broadperspective and to identify which features or relations are© The Author(s). 2019 Open Access This article is distributed under the terms of the Creative Commons Attribution 4.0International License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, andreproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to theCreative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver(http://creativecommons.org/publicdomain/zero/1.0/) applies to the data made available in this article, unless otherwise stated.Lithgow-Serrano et al. Journal of Biomedical Semantics            (2019) 10:8 Page 2 of 14important. It is for these steps that a paraphrase corpusis a very useful instrument, because it implicitly capturesthose nuances.There are several paraphrase corpora available, both forgeneral and specific domains. However, as stated before,these corpora are very sensitive to the aimed task and tothe targeted domain. Hence, when a task or domain is veryspecific and the available corpora do not fit, an ad hoccorpus has to be built. This is the case for the biomedicalcuration of the literature about the regulation of transcrip-tion initiation in bacteria, a specific domain of knowledgewithin the biomedical literature.RegulonDB1 [1] is a manually curated standardresource, an organized and computable database, aboutthe regulation of gene expression in the model enterobac-teria Escherichia coli K-12. It aims at integrating within asingle repository all the scattered information in the lit-erature about genetic regulation in this microorganism,including elements about transcriptional regulation, suchas promoters, transcription units (TUs), transcription fac-tors (TFs), effectors that affect TFs, active and inactiveconformations of TFs, TF binding sites (TFBSs), regula-tory interactions (RIs) of TFs with their target genes/TUs,terminators, riboswitches, small RNAs, and their targetgenes. We are capable of keeping up to date with the lit-erature thanks to constant manual curation in an effortinitiated close to 20 years ago. However, the pace ofcuration tends to lag behind the number of publications,motivating the implementation of automatic curation pro-cesses2. Certainly, biocuration typically accelerates withthe emergence of novel technologies, and furthermore,we believe that the depth and detail of the description ofwhat is extracted from the literature could be increasedsignificantly. As shown in the most recent publicationof RegulonDB [2], the number of curated objects hasincreased over the years. Finally, another major motiva-tion stems from the fact that microbial genomes have beenconstructed under similar evolutionary principles as E.coli; thus, the methods that can be trained with literaturefor E. coli should be very well applicable to the litera-ture on gene regulation in other microbial organisms, forwhich the literature has not been subject to curation. Reg-ulonDB plays an important role in scientific research: ithas been cited in more than 1700 scientific publications.As an ongoing effort to enrich the already curated infor-mation and to improve the curation process, we are devel-opingNLP tools, some of which rely on STS. The goal withthese STS assessment tools is to discover statements, indifferent publications, connected by their meaning. Oneof the direct contributions to the curation process couldbe to facilitate the discovery of supporting evidence fora piece of curated information. Table 1 shows a pair ofsentences, from different publications, that express verysimilar meanings and that provide supporting evidenceTable 1 Examples of sentences of different publications thatexpress very similar meaningsSentence Publication titleThere is, however, some evidencethat increased rob expression occursin glucoseand phosphatelimitedmedia in the stationary phase of cellgrowth, attributable to activation byfactor rpoS.MarA-mediated transcriptionalrepression of the rob promoter.(PMID: 16478729)A similar rpoS dependency wasobserved for glucose-limited orphosphate-limited growth in whichrob::lacZ transcription increased 5-fold.Posttranscriptional activation ofthe transcriptional activator Robby dipyridyl in Escherichia coli.(PMID: 11844771)for each other. These pairs of sentences exemplify whatis intended to be annotated within our corpus and, thus,the kind of annotations that we expect to produce throughmachine learning models trained with this corpus. Dueto the very specific nature of our domain, we built the adhoc graded paraphrase corpus to be used as a training andevaluation source of truth for our NLP tools.In the following sections, we first describe the method-ology followed to build our corpus, then we analyze itquantitatively, and finally we briefly mention the immedi-ate foreseen uses of the corpus.Related work andmotivationSTS aims to measure the degree of semantic equivalencebetween two fragments of text. To achieve this, it triesto unveil the meaning conveyed by a textual expressionand compare it with the meaning conveyed by anotherone. The comparisons result is a graded similarity scorethat ranges from an exact semantic match to a completelyindependent meaning, passing through a continuous scaleof graded semantic parallelism. This scale intuitively cap-tures the notion that a pair of texts can share differentaspects of meaning at different levels [3], i.e., they coulddiffer in just some minor details, they could share a com-mon topic and important details, or they could share onlythe domain and context, etc. Another characteristic ofSTS is that it treats similarities between two texts as bijec-tive, setting this task apart from textual entailment, wherethe relation is directed and cannot be assumed true in theinverse direction.Many NLP tasks, such as machine translation, questionanswering, summarization, and information extraction,potentially benefit from this quantifiable graded bidirec-tional notion of textual similarity. Building this kind ofcorpus is difficult and is labor-intensive, and that is whythere are not as many corpora of this kind as might beexpected, given their usefulness.In recent years, the most notorious efforts on theSTS task and their corresponding corpus constructionswere tackled by the Semantic Evaluation WorkshopLithgow-Serrano et al. Journal of Biomedical Semantics            (2019) 10:8 Page 3 of 14(SEMEVAL) [3]. The SEMEVAL corpus consists of 15,000sentence pairs from different sources, with the MicrosoftResearch Paraphrase (MSRP) and PASCAL VOC [4] cor-pora among them. The SEMEVAL corpus was annotatedthrough crowdsourcing, using a scale from 5 (identical) to0 (completely unrelated).Another corpus that is useful for STS is the User Lan-guage Paraphrase corpus (ULPC) [5]. This corpus wasbuilt by asking students to rephrase target sentences. Asa result, 1998 sentence pairs were annotated with rat-ings ranging from 1 to 6 for 10 paraphrasing dimensions;entailment and lexical, syntactic, and semantic similaritieswere among those dimensions.The SIMILAR corpus [6] is the product of a qualita-tive assessment of 700 pairs of sentences from the MSRPcorpus; in addition to providing word-to-word semanticsimilarity annotations, it also supplies a qualitative simi-larity relationshipidentical, related, context, close, worldknowledge, or nonebetween each pair of sentences.Among corpora that do not rely on graded similaritybut instead on binary paraphrases, there are importantcorpora, such as the MSRP corpus [7]. It is one of thefirst major public paraphrase corpora, comprising 5801new sentence pairs, of which 67% were judged seman-tically equivalent by two human judges. In the Q&Afield, another corpus,TheQuestion Paraphrase corpus [8],was built by collecting from WikiAnswers 7434 sentencesformed by 1000 different questions and their paraphrases.All these corpora target general domains and weresourced mainly from the news, making it very difficultto fit them into a specific topic such as ours: bacterialtranscriptional regulation. Closer to our domain is theBIOSSES corpus [9]. It is formed by 100 pairs of sentencesfrom the biomedical domain which were rated followingthe guidelines of the STS SEMEVAL task. The candidatesentences were collected from the set of articles that citedat least 1 of 20 reference articles (between 12 and 20 citingarticles for each reference article). Those sentence pairsthat cited the same reference article were selected. Articleswere taken from the Biomedical Summarization TrackTraining Dataset from the Text Analysis Conference.Due to the extension of the biomedical domain andthe small size of the BIOSSES corpus, most likely it doesnot capture the nuances of our subject of study. For thisreason, we decided to build our own corpus of naturallyoccurring non-handcrafted sentence pairs within the sub-ject of regulation of gene expression in E. coli K-12. Thesemantic similarity grade of each pair was evaluated byhuman experts of this field.MethodsCorpus designA corpus is a collection of pieces of language text inelectronic form, selected according to external criteriato represent, as far as possible, a language or languagevariety as a source of data for linguistic research [10].Before building a corpus, the textual source set, the evalu-ation rules, the corpus size, and other characteristics mustbe defined. This design should be, as much as possible,informed and principled so that the resulting corpus ful-fills the desired goals. The decisions involved within theaxes of consideration [10] for the corpus construction arethe following.The sampling policy defines where and how the candi-date texts are going to be selected, following three maincriteria: the orientation, in this case a contrastive corpuswith the aim of showing the language varieties that expressthe same meaning (semantic similarity); the selection cri-teria that circumscribe candidates to written sentences(origin and granularity) in English (language) taken fromscientific articles (type) on the topic of genetic regulation(domain), where the sentence attitude3 is irrelevant and aspecific content is not required; finally, the sampling cri-teria consists of preselection of sentence pairs through avery basic STS component followed by a filtering processto keep the same number of exemplars for each similaritygrade, i.e., a balanced candidate set.The corpus representativeness and balance refer to thekind of features and to the distribution of those featuresin the exemplars; hence, these characteristics determinedthe usage possibilities of the corpus. In this sense, sen-tences containing any biological element or knowledgewere preferred. It was more important that all similaritygrades were represented within the corpus and prefer-ably in equal proportions. Our main analysis axis was thesemantic similarity between pairs of sentences and not thetopic represented by each sentence, the sentences special-ization or technical level, nor the ontological specificity ofthe terms in the sentence.The orientation of a corpus topics impacts directlythe variety and size of the resulting vocabulary. Whereasembracing more topics can broaden the possibilities foruse of the corpus, this can also have negative conse-quences in the semantic similarity measures due to theincreased chances of the same term having differentmeanings for different topics (ambiguity). Consequently,a limited set of topics was preferred. We intended forthe corpus to be representative of the genetic regulationliterature. It is worth noting that it was not limited tothose sentences specifically about genetic regulation butall kinds of sentences present in the corresponding litera-ture. The corpus homogeneitywas tackled by stripping outthose sentences considered too short (less than 10 words)[11] and those sentences that were not part of the mainbody of the article4.Finally, a corpus size should be dependent on the ques-tions that it is aimed to answer and the type of tasks whereit can be applied [12, 13]. However, in practice it is largelyLithgow-Serrano et al. Journal of Biomedical Semantics            (2019) 10:8 Page 4 of 14restrained according to available resources (time, money,and people). Our main goals are to train our STS systemand to measure its performance. Because our STS systemis based on the combination of several similarity meth-ods, it is difficult to estimate the required number of casesthat would make it a significant training source, becausethis varies for each type of metric. For example, one of themost demanding methods on training data is neural net-works, whose complexity can be expressed based on thenumber of parameters (P), and it is common practice tohave at least P2 training cases. This would result in thou-sands of training cases, which is out of our reach. Thus,we focused on the second goal, to measure the STS sys-tem performance. We planned to measure the Pearsonscorrelation between the computed system similarity andthat generated by human experts (corpus). According to[14], considering a medium-size effect (r = 0.30), a sig-nificance level of 0.05, and a power of 80%, 85 sampleswould be enough. However, [15] and [16] suggested amin-imum sample size of 120 cases in order to allow not only aPearsons correlation analysis but also a regression analy-sis. With this in mind, we decided to generate a corpus of170 sentence pairs, i.e., a number of pairs just above thosethresholds.Lastly, as a validity exercise, we compared our designdecisions versus those taken in other corpora, for exam-ple, the MSRP corpus. In the construction of the MSRPcorpus [7], several constraints were applied to narrow thespace of possible paraphrases. However, in our opinionand for our specific purpose, these guidelines limit theaspects of semantic similarity that the corpus could cap-ture. For example, only those pairs of sentences with atleast 3 words in common and within a range of Leven-shtein edit distance were considered, but these parametersconstrain similarity, at least to a certain extent, to a tex-tual one; it was required that for a pair to be a candidate,the length in words of the shorter sentence be more than66% of the length of the longer sentence, thus limiting thepossibility for the corpus to represent cross-level semanticsimilarity [17], a phenomenon of sentences with differentlengths. It is also noteworthy that theMSRP corpus has anagreed consensus that 67% of the proposed sentence pairsare paraphrases, meaning that the majority of sentencesare semantically equivalent and, therefore, other grades ofsimilarity and even nonsimilarity are underrepresented.Compiling the corpusAs stated in the sampling criteria of the corpus design,the selection of candidate pairs was performed using abasic STS process that automatically assigned continuoussimilarity scores between 0 and 1 inclusive, where 1 rep-resented exact semantic equivalence5 and 0 indicated atotally unrelated meaning. The referred basic STS processwas performed by a tool that we developed to comparethe semantic similarity of two sentences using only theirword embeddings. The strategy consisted of averaging theembeddings of the sentence words to produce a sentenceembedding and compute the cosine between both sen-tence embeddings as a measure of their similarity. Thisstrategy is well known as a good baseline for this kindof task. It is worth noting that the embeddings weretrained on RegulonDBs literatureTranscriptional Reg-ulation domain (further details of this strategy and theword embedding training are presented in [18]). Next,the final candidate sentences were selected by a balancedstratified random sampling from those prerated sentencepairs.This process was applied to two different sets: theanaerobiosis FNR (Fumarate and Nitrate Reductase reg-ulatory protein) subset formed by articles about anaero-biosis; and the general set, consisting of sentences takenby randomly sampling of all of RegulonDBs articles (5963publications). The former subset was manually built by anexpert curator who selected, from anaerobiosis articles,sentences that she considered relevant within the subject.To generate the latter subset, we first extracted the textualcontent (sentences) from the 5963 publications (PDFs)found in the literature of RegulonDB by using a tool thatwe built for this purpose. Then, as a naive approach toonly focus on sentences belonging to the articles mainsections (e.g., methods, results, discussion), we discardedthe first 30% and the last 30% of sentences from each arti-cle. Finally, we randomly chose two sentences from eacharticle.The resulting corpus is formed by pairs of sentences,of which 40% come from the anaerobiosis FNR subsetand 60% from the general subset. A big picture of thedescribed pipeline is shown in Fig. 1.Annotation designIn addition to the corpus design, it was necessary to delin-eate the semantic similarity rating process. We followeda similar rating scale to the one used in SEMEVAL. Thisis an ordinal scale ranging from 0 to 4, where a SentencePair Similarity Score (SPSS) of 0 represents a totally dis-connected semantic relation between two sentences and4 conveys an exact semantic match, with the three middlescores indicating similarity shades, as shown in Table 2.Seven human experts, who are coauthors of the presentarticle, comprised the set of annotators for the task.We decided to apply a non-fully crossed study design6in which different sentence pairs were rated by differ-ent subsets of 3 annotators, i.e., each sentence pair wouldbe rated by 3 annotators selected by chance from theset of the 7 human experts. Some studies have shownthat 2 evaluations per item can be enough [19], butwe considered that 3 annotators per item would allowevaluation of a larger number of exemplars, and alsoLithgow-Serrano et al. Journal of Biomedical Semantics            (2019) 10:8 Page 5 of 14Fig. 1 Corpus compilation pipeline. This pipeline, from bottom to top, shows the steps that were taken to compile the corpus (171 sentence pairs)that was later evaluated by annotators regarding the semantic similarity between the sentence pairs. First, two subsets, the anaerobiosis-FNR andthe more general one, were compiled using different strategies. Then, a basic STS process was applied to both subsets in order to have a preliminarysemantic similarity evaluation. This preliminary evaluation was used to select candidate sentences, creating a corpus that ended up with 40% ofsentences from the anaerobiosis subset and 60% from the general subsetthat 3 is the smallest number to provide a medianwhen there is no consensus and a discrete final score isdesired.Due to the fact that what is considered semanticallyequivalent is prone to be biased by personal subjectiveconsiderations, it was necessary to homogenize the anno-tation process among raters. This was done by a trainingperiod of 4 iterative sessions to help annotators becomefamiliar with the annotation guidelines and the corpora tobe rated, and also to refine annotation guidelines. Duringthis training, each session consisted of evaluating a smallsubset of sentence pairs, and at the end of each session,disagreements were discussed and solved and annota-tion guidelines were more precisely defined. This train-ing period was considered concluded when a minimumannotator interagreement was achieved or the annota-tors considered that they fully understood the annotationguidelines.General guidelinesIn order to make the annotation process less subjective,some general guidelines were initially given to raters.These were collected from other corpus-building experi-ments [20] and from our own observations, including: Order. Clauses in a compound sentence can bearranged in a different order without implying achange in its meaning. Missing clauses. In complex or compound sentences,if a clause is present in one and missing in the other,it does not automatically result in a zero similarity. Itdepends on the grade of importance of the sharedinformation. Adjectives. Missing adjectives in principle do notaffect similarity. Enumerations. Missing elements can produce aminor decrease in the similarity score unlessTable 2 Rating scaleSPSS Description4 The two sentences are completely ormostly equivalent, as theymean the same thing.3 The two sentences are roughly equivalent, but some importantinformation differs/is missing.2 The two sentences are not equivalent but share some details.1 The two sentences are not equivalent but are on the sametopic.0 The two sentences are on different topics.Lithgow-Serrano et al. Journal of Biomedical Semantics            (2019) 10:8 Page 6 of 14enumeration conveys the main sentence meaning.Reordering is considered equivalent. Abbreviations. Abbreviations are consideredequivalent, e.g. vs and versus. Hypernyms and hyponyms. The two forms share agrade of similarity, e.g., sugar substance vs honeyvs bee honey. Compound words. Some terms are semanticallyequivalent to multiterm expressions, e.g.,anaerobiosis and in the absence of oxygen,oxidative and nitrosative stress transcriptionalregulator and oxyR, or hemorrhage and bloodloss. Generalization or abstractions. Consider that twotextual expressions share some grade of semanticsimilarity if one is a generalization or abstraction ofthe other, e.g., 8 vs one-digit number.Consensual refinementGeneral guidelines were subsequently refined andenriched during the consensus sessions.As a first approximation to clarify the rating scale in ourcontext, it was decided we would use the class of Regu-lonDB objects as topic markers within the sentences. Reg-ulonDB contains objects of the following classes: Gene,Gene Product, Protein, Motif, Promoter, TranscriptionUnit (TU), Regulatory Interaction (RI), Reaction, Tran-scription Factor (TF), and Growth Condition (GC). Next,we provide example cases for each score that help toclarify our similarity scale.SPSS of 4. Both sentences have in common the sameobjects and express the same meaning. i.e., they are para-phrases of each other. The following pair of sentencesserve to illustrate this grade: This would mean that the IS5 element is able toprovide FNR regulatory sites if inserted atappropriate positions. In any case, insertion of an IS5 element is able toincrease FNR-dependent expression or to place genesunder FNR control.SPSS of 3. Both sentences share the same objects andother elements of their meaning. However, one of the sen-tences lacks relevant elements, does not refer to the sameobjects, or arrives at different conclusions. Some cases wecould envision are that both sentences refer to the sameGene and share all other information, except that in onethe gene is activated and in the other it is repressed; sen-tences referencing the same RI but that differ in termsof the RIs conditions; both sentences almost paraphraseeach other, but one has more details.The relation between the next pair of sentences exem-plifies the last case: These results confirm that the N-terminal domain ofNikR is responsible for DNA recognition. In preliminary experiments, we have also found that asubset of mutations within the DNA region protectedby the N-terminal domain reduce the affinity of NikRfor the operatordata not shown.SPSS of 2. Both sentences share at least one specificobject and some other similarities, for example, a pair ofsentences that refer to the same TF (see example (a)). Aninteresting singularity from the expert evaluation was theobservation that aerobic and anaerobic conditions arerelated, since they both refer to oxygen availability. There-fore, in this corpus, contrasting conditions like these havea certain degree of similarity (see examples (a) and (b)). Example (a) The fnr mutant was thus deficient in theanaerobic induction of fumarate reductaseexpression. Aerobic regulation of the sucABCD genes ofEscherichia coli, which encodeK-ketoglutarate dehydrogenase and succinylcoenzyme A synthetase: roles of ArcA, Fnr,and the upstream sdhCDAB promoter. Example (b) Aerobic regulation of the sucABCD genes ofEscherichia coli, which encodeK-ketoglutarate dehydrogenase and succinylcoenzyme A synthetase: roles of ArcA, Fnr,and the upstream sdhCDAB promoter. Transcription of the fdnGHI and narGHJIoperons is induced during anaerobic-growthin the presence of nitrate.SPSS of 1. Both sentences have the same object class incommon, but the specific object is different. Since Geneand GC objects are highly common in RegulonDBs litera-ture, it was decided that sharing only these classes is not asufficient condition for sentences to be rated with an SPSSof 1. When comparing a sentence that mentions a TF withanother one that mentions any other object (or GC) thatrefers to the same process in which the TF is involved, anSPSS of 1 has to be assigned to the sentence pair. An SPSSof 1 was also considered in cases when both sentencesreferred to sequences and genes, even when neither thesequences nor the mentioned genes were the same. Thefollowing pair of sentences is an example of this grade: The fnr mutant was thus deficient in the anaerobicinduction of fumarate reductase expression. To test whether the formate induction of the cyxpromoter could be mediated by the fhlA geneLithgow-Serrano et al. Journal of Biomedical Semantics            (2019) 10:8 Page 7 of 14product, the expression of the cyx-lacZ fusion wasexamined in an fhlA deletion strain in the presenceand in the absence of formate.SPSS of 0. Sentences do not even share objects class. Apossible case is that sentences share Gene and GC class(the exceptions of SPSS 1 grade) but not the same specificobjects; the following pair of sentences is an example ofthis case: Carbon metabolism regulates expression of the pfl(pyruvate formate-lyase) gene in Escherichia coli. Later work showed that most mutants lacking eitherACDH or ADH activities of the AdhE proteinmapped in the adhE gene at 27.9 min [1,4].It was clarified that sentences do not necessarily have tocontain biological content or refer to RegulonDBs objectsto be annotated and have an SPSS above 0. The annotationassesses the similarity inmeaning irrespective of the topic.Table 3 is a summary of the above-described guidelines.Annotation processTo facilitate the annotation process, we decided to pro-vide annotators with a spreadsheet template (see Fig. 2).The template was designed so that all needed informa-tion would be self-contained and the rater did not have toswitch to other files. It consisted of a list of all sentencepairs that the annotator had to rate; for each sentence pair,the IDs and text were displayed. The area where the userwrote the scores was organized into columns where eachcolumn represented an annotation session, with date andtime at the top. A rating scale table was also included as areference.The process consisted in: provide each annotator with afile, based on the annotation template, containing exclu-sively the sentence pairs that have to be evaluated byhim/her; annotators had a fixed period of time of oneweek to rate all pairs; during that period each annota-tor could divide the rating task into as many sessions asTable 3 Refined rating scaleSPSS Description4 Both sentences have in common the same objects and expressthe same meaning.3 Both sentences share the same objects and other elements oftheir meaning. However, one of the sentences lacks relevantelements or refers to the same objects, and it arrives at differentconclusions.2 Both sentences share at least one specific object and someother similarities. In this sense, contrasting conditions are con-sidered related conditions.1 Both sentences have the same object class in common, but thespecific object is different.0 Sentences do not even share objects of the same class.desired as long as he added the sessions date and time; itwas indicated that sessions should be exclusive and con-tinuous, i.e., the task should not be interrupted by morethan 5min and annotators should not be performing othertasks in parallel.The process consisted of providing each annotator witha file, based on the annotation template, containing exclu-sively the sentence pairs that had to be evaluated byhim/her. Annotators had a fixed period of time of 1 weekto rate all pairs; during that period, each annotator coulddivide the rating task into as many sessions as desired, aslong as he or she added the sessions date and time. It wasindicated that sessions should be exclusive and continu-ous, i.e., the task should not be interrupted by more than 5min and annotators should not be performing other tasksin parallel.It is worth noting that the pairs of sentences assignedto each annotator were randomly selected from the set ofpairs.Corpus evaluationThe recommended way to evaluate the quality of theresulting corpus is through the Inter-Rater Agreement,also known as Inter-Rater Reliability (IRR) [19, 2125].IRR is a measure of the agreement between two or moreannotators who have rated an item using a nominal, ordi-nal, interval, or ratio scale. It is based on the idea thatobserved scores (O) are the result of the scores that wouldbe obtained if there were no measurement errortruescores (T)plus themeasurement error (E), i.e.,O = T+E[21]. One possible source of measurement errors is themeasure-instruments instability when multiple annota-tors are involved. IRR focuses on analyzing how muchof the observed scores variance corresponds to variancein the true scores by removing the measurement errorbetween annotators. Thus, the reliability coefficient repre-sents how close the given scores (by multiple annotators)are to what would be expected if all annotators had usedthe same instrument: the higher the coefficient, the betterthe reliability of the scores.There are multiple IRR statistics, and which one to usedepends on the study design. To select the IRR statistic,some factors should be considered, such as the type ofmeasured variable (nominal, ordinal, etc.), if it is a fullycrossed study design or not, and if what it is desired is tomeasure the annotators or the ratings reliability.Our design (see Annotation design section) corre-sponds to a non-fully crossed study design, where anordinal variable is measured and we are interested in mea-suring the ratings reliability. Having that in mind, thestatistics that better accommodated our study were FleissKappa (Fleiss) [26], Krippendorff s Alpha (Kripp), IntraClass Correlation (ICC) [27], Kendall (Kendall) [28], andGwets AC1 (Gwet) [22].Lithgow-Serrano et al. Journal of Biomedical Semantics            (2019) 10:8 Page 8 of 14Fig. 2 Annotation template. The image shows the spreadsheet template that was used by the annotators. Sentence pairs to be rated are shown inthe rows, one sentence pair per row. The cells to the right of each sentence pair were reserved for the annotators evaluation, with one annotationsession per column. At the top is a rating scale table which was included as a referenceOne of the most-used IRR statistics is Cohens Kappaanalysis (k) (5) [29]. It is a relation between the proportionof units in which the annotators agreed (po) and the pro-portion of units for which agreement is expected by chance(pc); thus k = (po ? pc)/(1 ? pc). Originally, this mea-sure was intended for just two annotators who rated allitems, so variants were developed in order to fit non-fully crossed study designs with more than two raters peritem. The Fleiss Kappa (1) is a nonweighting measurethat considers unordered categories; it was designed forcases when m evaluators are randomly sampled from alarger population of evaluators and each item is rated bya different sample of m evaluators. In Eq. (1), pa repre-sents the averaged extent to which raters agree for theitems rate and p is the proportion of assignments to thecategories.k = pa ? p1 ? p (1)Krippendorff s Alpha (2) is an IRR measure that is basedon computing the disagreement. It provides advantageslike being able to handle missing data and handling var-ious sample sizes, and it supports categorical, ordinal,interval, or ratio measured variable metrics. In (2), Do isthe observed disagreement and D is the disagreementone would get if rates were by chance. Thus, it is the ratiobetween the observed disagreement and the expecteddisagreement.? = 1 ? DoD (2)Intra-class correlation (3) is a consistency measure thatcan be used to evaluate the ratings reliability by com-paring the items rating variability to the variability of allitems and all ratings. It is appropriate for fully crossed aswell as for non-fully crossed study designs and when thereare two or more evaluators. Another feature is that thedisagreements magnitude is considered in the computa-tion, as in a weighted Kappa. In (3), var(?) accounts forvariability due to differences in the items, var(?) is fromthe variability due to differences in the items reevalua-tions, and var() is for the variability due to differencesin the rating scale used by annotators. Consistent withour study design, we selected the ICC variant as: a one-way model, to avoid accounting for systematic deviationsamong evaluators, because annotators for each item wereselected at random. We used the average as the unit ofanalysis, because all items were rated by an equal numberof annotators (i.e., 3).ICC = var(?)var(?) + var(?) + var() (3)Kendalls coefficient is an associationmeasure that quan-tifies the degree of agreement among annotators based onLithgow-Serrano et al. Journal of Biomedical Semantics            (2019) 10:8 Page 9 of 14the ranking of the items. As a special case of the correla-tion coefficient, this coefficient will be high when itemsorders (ranked by the given rate) would be similar acrossannotators. It is based on the computation of the normal-ized symmetric distances between the ranks. Because itrelies on the distances instead of the absolute values, itbetter handles consistent rater biases, i.e., the bias effect.In (4), nc refers to the number of concordant and nd to thenumber of discordant ranks within a sample of n items.W = nc ? nd12n(n ? 1)(4)[30] demonstrated that the Kappa coefficient is influ-enced by trait prevalence (distribution) and base rates,thus limiting comparisons across studies. For that rea-son, [22] proposed an IRR coefficient (6) that, as CohensKappa statistic, adjusts the chance agreementratersagree based on a random ratingto avoid inflating theagreement probability with not true intentional ratersagreement. However, Gwets coefficient has the propertyof not relying on independence between observations;weights are based on weighted dissimilarities. This coef-ficient presents several advantages: it is less sensitiveto marginal homogeneity and positively biases for traitprevalence (more stable); it can be extended to multipleraters; as Krippendorff s coefficient it can deal with cat-egorical, ordinal, interval, or ratio measures and it canhandle missing data; contrary to weighted Kappa, it is notnecessary to provide arbitrary weights when applied toordinal data.Kappa = p ? e(?)1 ? e(?) (5)AC = p ? e(? )1 ? e(? ) (6)The difference between Gwet and Kappa is in the waythat the probability of chance agreement is estimated. InKappa, e(?) is based on combining the estimates of thechance that both raters independently classify a subjectinto category 1 and estimates the probability of indepen-dent classification of a subject into category 2 (7), whereaswith Gwet this is based on the chance that any rater (A orB) classifies an item into a category (8).e(?) =(A1N) (B1N)+(A2N) (B2N)(7)e(? ) = 2P1(1 ? P1)= 2((A1 + B1)/2N) (1 ?((A1 + B1)/2N)) (8)It is important to note that Gwet proposes 2 variants ofits statistic, AC1 and AC2. AC2 is a weighted versionsome disagreements between raters are considered moreserious than othersof AC1 and thus a better alterna-tive for ordinal data. AC2 is intended to be used with anynumber of raters and an ordered categorical rating sys-tem to rate objects, as is our case. In AC2, both chanceFig. 3 The progress of IRR through the consensus sessions. The chart shows the IRR measured using five different metrics. The IRR score isrepresented on the y-axis, and the results for the four sessions are chronologically displayed on the x-axis. IRR scores, in all metrics, improved in eachsubsequent consensus session. For example, the IRR measured using Gwets AC2 coefficients improved from 0.545 in the first session to 0.910 in thelast one, that is, the annotators evaluations were much more homogeneous at the end of the consensus sessionsLithgow-Serrano et al. Journal of Biomedical Semantics            (2019) 10:8 Page 10 of 14Table 4 IRR through agreement sessionsSession Kendall Fleiss ICC Kripp Gwet1 0.216 0.024 0.454 0.116 0.5452 0.208 0.267 0.728 0.268 0.5653 0.430 0.390 0.813 0.439 0.8264 0.727 0.546 0.964 0.766 0.910agreement as well as misclassification errors are adjusted;thus, it is defined as a bias-adjusted conditional probabil-ity that two randomly chosen raters agree given that thereis no agreement by chance [22].ResultsTraining periodThe training period consisted of 4 iterations in each ofwhich a set of sentence pairs was rated by all annotators.Afterwards, we had a consensus session where conflictswere resolved and questions about the guidelines wereanswered, resulting in updating the guidelines.We performed the IRR analysis of each iteration in orderto review the effect of consensus sessions in homogeniz-ing the annotation process. As can be seen in Fig. 3 andTable 4, the grade of interagreement increased in eachiteration irrespective of the statistic. In the fourth session,we reached a Fleiss Kappa of 0.546 as the lowest met-ric, which is considered amoderate strength of agreement[31]. However, we have to remember that this metric is anonweighting coefficient, for example, when 2 annotatorsdo not agree on the evaluation of a pair of sentences, forthis metric is equally wrong when one annotator gradesthemwith 4 and the other with 0 (i.e., evaluations differ by4 points) as when one grades them with 2 and the otherwith 3 (i.e., evaluations differ by only 1 point). That is whywe reached an almost-perfect IRR in statistics that bet-ter deals with ordinal scales: ICC (0.964) and Gwets AC2(0.910). It is noteworthy that Gwets coefficients are muchmore highly recommended methods to compute IRR thanthose of the Kappa coefficients family.We also compared the IRR between all combinations ofannotators pairs as a way of detecting consistent bias ofone annotator versus the others (see Fig. 4). We deter-mined that more guideline clarifications were needed forannotator 4, who consistently had lower IRR values thanthe other raters.CorpusAfter the training period, we built the corpus based onthe proposed design (see Annotation design section). Itresulted in 171 pairs of sentences, each rated by 3 anno-tators selected by chance from the group of 7 experts.It is noteworthy that the sentences evaluated during thetraining period were not included in these 171 pairs.Several IRR analyses were performed to assess thedegree that annotators consistently assigned similarityFig. 4 IRR between pairs of annotators at the end of the training sessions. This chart shows the IRR (ICC) of each annotator compared with each ofthe other annotators. Both x- and y-axes represent annotators; for example, the intersection of the y-value 4 and x-value 5 represents the IRRbetween annotator-4 and annotator-5. As shown on the IRR scale to the right, the higher the IRR, the more intense the red color, and so in this case,there is a moderate IRR between annotator-4 and annotator-5 and higher agreement between annotators 2 and 3. We noted that annotator-4 had alower agreement with all others and thus he needed more guideline clarificationsLithgow-Serrano et al. Journal of Biomedical Semantics            (2019) 10:8 Page 11 of 14Table 5 Corpus inter-rate agreement for various statisticsStatistic Variable Value p-valueFleiss Kappa Kappa 0.443 0Krippendorffs Alpha Alpha 0.745Kendalls coefficient W 0.741 7.86e-18Intraclass Correlation ICC 0.919 6.7e-83Gwets coefficient AC2 0.870 0ratings to sentence pairs (see Table 5). The marginal dis-tributions of similarity ratings did not indicate a consid-erable bias among annotators (Fig. 5), but they did showa prevalence effect towards lower similarity rates (Fig. 6).A statistic less sensitive to this effect was Gwets AC,whichmakes an appropriate index of IRR, in particular theAC2 variant, due to the ordinal nature of our data. Theresulting coefficient indicated very good agreement [32] ofAC2 = 0.8696 with a 95% confidence interval [0.8399,0.8993].For the sake of clarity, we investigated if the non-fullycrossed design caused too-inflated coefficients. To do this,we first grouped the sentence pairs by the annotators whorated them (now each of these groups could be considereda fully crossed study design); next, we computed the IRRfor each group; finally, we computed the arithmetic meanof all groups. The resulting averages (Table 6) were quitesimilar to coefficients computed for the whole corpus,reconfirming the corpus reliability.From the individual rating distribution (Fig. 6), we cansee that although the distribution is biased towards nosimilarity, we achieved a good amount (> 50%) of sentencepairs rated within the 1-3 score range.DiscussionWe observed that the IRR increased more significantlyafter the third training session. We think that this increasecan be explained mainly by two factors. First, annota-tors familiarized themselves with the guidelines and theyhad a better understanding of what was expected for thetask. Despite task explanations and annotation guidelines,in the first sessions there was a tendency to grade thesimilarity of the biological objects mentioned in the com-pared texts and to overlook the full semantics conveyedby those texts. Second, after the first two sessions, anno-tators had collected a good set of examples along withthe respective explanatory notes from the previous con-sensus sessions. These examples served as disambiguationsources when needed. It is interesting that both factorsare related to the hypothesis that although similarity is anFig. 5 Ratings distribution per annotator. In this chart, the seven annotators are represented on the y-axis, and on the x-axis the evaluationproportions for each similarity grade are represented. Similarity grades are ordered from lowest similarity (0) at the left to highest (4) at the right. Forexample, it can be seen that both annotator-4 and annotator-5 had the highest proportions of 0-similarity evaluations, but annotator-5 tended togive higher grades in the rest of the casesLithgow-Serrano et al. Journal of Biomedical Semantics            (2019) 10:8 Page 12 of 14Fig. 6 Individual ratings distribution. This chart shows the distribution of annotators ratings per similarity grade during the evaluation of the corpus(not the training period). The x-axis shows the five similarity scale values, and the percentage of evaluations within each grade are represented onthe y-axis. More than 40% of the evaluations were rated as no similarities (score of 0); nevertheless, 50% of evaluations were in the similarity valuerange between 1 and 3intuitive process, there is not a perfect consensus, espe-cially about the grades of similarity [3336]. It dependson the personal context, and we could confirm the impor-tance of guidelines and consensus sessions to homogenize,at a certain grade, the annotators performance.Another practice that we found helpful during the con-sensus sessions was the participation of a mediator whowas familiarized with the guidelines and with the tasksgoal but was not part of the annotators group, i.e., a thirdparty. When needed, the mediators role was limited toexhort annotators to explain their posture and, if pertinentand possible, to put the discussion in equivalent termsthrough a general context analogy. This helped to avoidunjustified influence of those annotators who were moreexperienced or who upheld more strongly their opinions.In general, annotators agreed that the sentences with-out biological objects mentions were more difficult toassess and that in the candidate sentences there was a clearbias toward low similarity scores. This similarity datasetis just the first iteration of an ongoing process. We planto repeat this strategy to extend the dataset; instead ofusing the basic STS process, now we could use a similaritymodel trained with the current corpus [18], and thereforeit is reasonable to expect an improvement in the preselec-tion step, more likely resulting in a more balanced ratingdistribution, i.e., more grades of 3 and 4.In the spirit of weighing the size and distributionof our corpus against previous work, we compared itwith BIOSSES. We selected this corpus because, to thebest of our knowledge, it is the only similarity corpusspecialized for the biomedical domain, and setting ourcorpus side by side with the general-domain ones (e.g.,MSRP, SEMEVAL, ULPC) would be unfair. Regarding bal-ance for these two corpora with respect to the numberof sentence pairs per grade, BIOSSES is better balanced,with 15% of sentences graded with a value of 0, 12% with1, 27% with 2, 35% with 3, and 11% graded with 4. Ourcorpus has a distribution of 48%, 22%, 15%, 14%, and 1%corresponding to the 0, 1, 2, 3, and 4 similarity grades.However, concerning corpora size, although it is still smallour corpus, with 171 sentence pairs, is 70% larger thanthe BIOSSES corpus, which consists of only 100 pairs ofsentences. Moreover, even though BIOSSES is special-ized for the biomedical domain, its coverage is still toobroad for our purpose. This is evidenced by the fact that,when analyzing terms frequencies in BIOSSES, withinTable 6 IRR by annotators groupAnnotators Kendall Fleiss ICC Kripp Gwet1, 2, 3 0.782 0.597 0.941 0.814 0.8641, 2, 7 0.641 0.512 0.926 0.705 0.8941, 6, 7 0.788 0.358 0.912 0.756 0.6862, 3, 4 0.669 0.442 0.916 0.691 0.9073, 4, 5 0.712 0.310 0.894 0.708 0.8024, 5, 6 0.593 0.268 0.753 0.602 0.8185, 6, 7 0.833 0.409 0.913 0.772 0.784Mean 0.717 0.414 0.894 0.721 0.822Lithgow-Serrano et al. Journal of Biomedical Semantics            (2019) 10:8 Page 13 of 14the top 50 terms we found terms like cell, tumor, cancer,study, report, human, gene, lung, leukemia, etc., whereasin our corpus the prevailing terms are site, expression,activation, gene, protein, strain, regulation, DNA, region,downstream, upstream, etc.We believe that our publicly available dataset (seeAvailability of data and materials section) can be ofgreat benefit in several NLP applications. For example, weare already successfully using it to fine-tune and test asemantic similarity engine as part of an assisted curationpipeline. Within these experiments, we used an ensembleof similarity metrics that were string, distributional, andontology based. The individual measures were combinedthrough different regression models which were trainedusing the corpus presented in this publication. Our mod-els obtained strong correlations (? = 0.700) with humanevaluations, which are far from state-of-the-art in generaldomains but are quite good considering our highly spe-cialized domainMicrobial Transcriptional Regulation.In the absence of this corpus, the only alternative wouldhave been to equally weight the different metrics, whichin our experiments results in a Pearsons correlation (?) of0.342, at best. With these experiments, it was shown thatthis corpus is not only relevant but also useful for appliedtasks [18].ConclusionsWe did not obtain a corpus with ratings as balanced asdesired; however, we now have a good representation of4 of the 5 rates and a corpus with very good IRR. There-fore, it is going to serve well our purposes, and we thinkit can be quite a valuable starting point, with respect todata and processes to continue building a standard sim-ilarity corpus in the transcriptional regulation literature.To the best of our understanding, this is the first similar-ity corpus in this field, and thus it represents a steppingstone towards the evaluation and training of NLP-basedhigh-throughput curation of literature on microbial tran-scriptional regulation.Endnotes1 http://regulondb.ccg.unam.mx/2 http://regulondb.ccg.unam.mx/menu/tools/nlp/index.jsp3Declarative, interrogative, exclamatory, etc.4 Based on the stylographic tag assigned by our home-made PDF processing tool.5Applying a baseline metric.6 In fully crossed design studies all evaluated items (pairsof sentences) are rated by the same set of annotators,whereas in non-fully crossed design studies, different itemsare rated by different subsets of annotators.AbbreviationsDNA: Deoxyribonucleic acid; FNR: Fumarate and nitrate reductase regulatoryprotein; Fleiss: Fleiss Kappa coefficient; GC: Growth conditions; Gwet: GwetsAC1 statistic; ICC: Intraclass correlation; IRR: Interrater reliability; Kendall:Kendall coefficient; Kripp: Krippendorffs Alpha coefficient; MSRP: MicrosoftResearch Paraphrase; NLP: Natural Language Processing; RI: Regulatoryinteraction; RNA: Ribonucleic acid; SEMEVAL: Semantic Evaluation workshop;SPSS: Sentence Pair Similarity Score; STS: Semantic Textual Similarity; TF:Transcription Factor(s); TFBS: TF binding site; TU: Transcription Unit; ULPC: UserLanguage Paraphrase CorpusAcknowledgementsNot applicable.FundingWe acknowledge funding from UNAM, from FOINS CONACyT Fronteras de laCiencia [project 15], and from the National Institutes of Health (grant number5R01GM110597). CMA is a doctoral student from Programa de Doctorado enCiencias Biomédicas, Universidad Nacional Autónoma de México (UNAM), andis the recipient of Ph.D. fellowship 576333 from CONACYT.Availability of data andmaterialsThe corpus is available at https://github.com/JCollado-NLP/Corpus-Transcriptional-Regulation.Authors contributionsOWLS carried out the experiments design, the data analysis, and wrote thepaper. JCV participated in the project design, annotation guidelines, writingand correction of the paper. All other authors refined the experiment designand annotation guidelines, participated in the consensus sessions, andperformed the corpus annotation. All authors read and approved the finalmanuscript.Authors informationNot applicable.Ethics approval and consent to participateNot applicable.Consent for publicationNot applicable.Competing interestsThe authors declare that they have no competing interests.Publishers NoteSpringer Nature remains neutral with regard to jurisdictional claims inpublished maps and institutional affiliations.Author details1Computational Genomics, Centro de Ciencias Genómicas, UniversidadNacional Autónoma de México (UNAM). A.P., 565-A Cuernavaca, 62100Morelos, México. 2Instituto de Investigaciones en Matemáticas Aplicadas y enSistemas (IIMAS), Universidad Nacional Autónoma de México (UNAM), MexicoCity, México. 3Department of Biomedical Engineering, Boston University,Boston, Massachusetts, USA.Received: 9 February 2018 Accepted: 16 April 2019Wang et al. Journal of Biomedical Semantics           (2019) 10:11 https://doi.org/10.1186/s13326-019-0202-8RESEARCH Open AccessPredicting instances of pathwayontology classes for pathway integrationLucy Lu Wang1* , G. Thomas Hayman2, Jennifer R. Smith2, Monika Tutaj2, Mary E. Shimoyama2 and JohnH. Gennari1AbstractBackground: To improve the outcomes of biological pathway analysis, a better way of integrating pathway data isneeded. Ontologies can be used to organize data from disparate sources, and we leverage the Pathway Ontology as aunifying ontology for organizing pathway data. We aim to associate pathway instances from different databases tothe appropriate class in the Pathway Ontology.Results: Using a supervised machine learning approach, we trained neural networks to predict mappings betweenReactome pathways and Pathway Ontology (PW) classes. For 2222 Reactome classes, the neural network (NN) modelgenerated 10,952 class recommendations. We compared against a baseline bag-of-words (BOW) model for predictingcorrect PW classes. A 5% subset of Reactome pathways (111 pathways) was randomly selected, and thecorresponding class recommendations from both models were evaluated by two curators. The precision of the BOWmodel was higher (0.49 for BOW and 0.39 for NN), but the recall was lower (0.42 for BOW and 0.78 for NN). Around 78%of Reactome pathways received pertinent recommendations from the NN model.Conclusions: The neural predictive model produced meaningful class recommendations that assisted PW curators inselecting appropriate class mappings for Reactome pathways. Our methods can be used to reduce the manual effortassociated with ontology curation, and more broadly, for augmenting the curators ability to organize and integratedata from pathway databases using the Pathway Ontology.Keywords: Pathway ontology, Ontology-based data integration, Semi-automated ontology curation, Ontologymapping, Pathway data interoperabilityBackgroundOntologies can be used to align and integrate data frommultiple sources. In the case of biological pathways,there are numerous databases collecting and describinginformation about pathway networks, but no centralizedschema to organize these various pathways. A sharedorganizational scheme would allow researchers to identifysemantically similar pathways, providing a framework forpathway data integration.Pathways are a form of graph data describing bio-logical function. Individual pathway modules describethe interactions between dozens or hundreds of genes,*Correspondence: lucylw@uw.edu1Department of Biomedical Informatics and Medical Education, University ofWashington, 850 Republican St, 98109 Seattle, WA, USAFull list of author information is available at the end of the articleproteins, and molecules, and how these interactions con-tribute to events of biological consequence. The com-plexities of analyzing genomic data have led to a rise inthe use of pathways for pathway analysis, a class of sta-tistical methods that aggregate single gene effects overthe genes described in pathway modules. These pathwayanalysis techniques (such as gene set enrichment analysis(GSEA) [1] or network-based pathway analysis methods[2]) allow variations in gene expression to be interpretedat a functional level. Due to the large variety of pathwaysavailable from different databases, pathway analysis oftenleverages pathways from multiple databases. For exam-ple, MSigDB, which is often used as a source of gene setsfor GSEA, combines pathways from the Kyoto Encyclope-dia of Genes and Genomes (KEGG), the National CancerInstitutes Pathway Interactions Database (NCI-PID), andReactome [3].© The Author(s). 2019 Open Access This article is distributed under the terms of the Creative Commons Attribution 4.0International License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, andreproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to theCreative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver(http://creativecommons.org/publicdomain/zero/1.0/) applies to the data made available in this article, unless otherwise stated.Wang et al. Journal of Biomedical Semantics           (2019) 10:11 Page 2 of 11Combining pathways from different databases results inredundancy in the pathway data set. The same or a similarpathway may be represented in multiple databases. Meta-resources such as Pathway Commons [4] and Consen-susPathDB [5] allow for querying and access to pathwaysfrom different databases, but lack the ability to collapseredundant pathways between databases. Other resourcessuch as PathCards [6] or ReCiPa [7] use statistical meth-ods to detect gene overlap between two pathways, merg-ing pathways with significant overlapping entities intosuperpathways to reduce membership redundancy. How-ever, these methods fail to retain the functional bound-aries of pathways, which are crucial for pathway analysisresult interpretation, i.e., allowing gene expression differ-ences to be aggregated and interpreted at a functionallevel.Pathways from different databases are challenging tointegrate due to content and representational differencesbetween various pathway databases. Previous studieshave described the differences that exist between pairsof pathway databases [811], and in our prior work,we have categorically summarized ways in which path-way representations have been found to differ betweenmany common pathway databases [12]. Although mostdatabases provide data in pathway file sharing stan-dards such as BioPAX [13], SBML [14], or GPML [15],these standards are insufficient for ensuring interop-erability. Even when two databases present data usingthe same standard language, the different decisions ofpathway editors at both individual and database levels canresult in variable pathway representation [12].Ontologies have been used successfully to combinedisparate datasets in the biomedical domain [1618].We hypothesize that an ontology of pathway classescan be used to organize data from different pathwaydatabases, allowing us to merge data while maintainingan understanding of the semantic relationships betweenvarious pathways. The Pathway Ontology (PW), anontology of pathway terms, can be used as an anchoringontology to identify similar pathways [19]. The PW wasdeveloped as part of the Rat Genome Database (RGD)as a means to catalog and describe the relationshipsamong various biological pathways. The ontology coversbroad pathway categories such as metabolic, regulatory,signaling, disease, and drug pathways, and allows forthe representation of both subclass and mereologicalhierarchies via the subclass and part-of relationshipsrespectively. The PW is a suitable ontology for integratingpathway data because it provides: a hierarchy of pathway classes and their relations toone another, classes describing altered and disease pathways, and existing mappings to pathways from KEGG, NCI-PID,and the Small Molecule Pathway Database (SMPDB).The Gene Ontology (GO) describes biological pro-cesses, and could be a suitable ontology for pathway dataintegration based on its more developed classes and richerannotations [20]. However, the GO lacks classes describ-ing altered or disease pathways, which are essential fordownstream applications of pathway resources. The PWdescribes both altered and disease pathways in its classhierarchy and is therefore suitable for integrating pathwaydata.Using the PW, we can group together semantically andfunctionally similar pathways by mapping them to theappropriate PW class. All pathways mapped to a partic-ular PW class can then be merged together to form anormalized pathway representation of that class. This setof normalized pathways can be used in pathway analysisapplications, and will have less redundancy compared tonaively combined pathway datasets, as well as increasedfunctional interpretability due to the preserved PW classhierarchy.To better enable pathway data integration, we mustmap the content of other pathway databases to thePW. However, manual mappings are both laboriousand time-consuming to produce. In light of limitedcuratorial resources, we propose a method to inte-grate computational prediction into the curation pipeline,allowing a predictive model to reduce the number of man-ual comparisons that need to be made by PW curators.Machine learning methods have been used with suc-cess for ontology-related tasks such as ontology learning,ontology completion, and ontology alignment [21, 22].Rule-based techniques have been very successful, butsupervised or semi-supervised approaches can also beused when training data are available. We propose andimplement a supervised learning framework for inferringmappings between pathways from pathway databases andthe PW, with a goal of reducing the hours associated withmanual curation.In this article, we describe efforts to generate PW classmappings for pathways from Reactome, one of the largestand most comprehensive pathway databases [23]. Ourmethods are generalizable to other pathway databases,such as BioCyc [24] and WikiPathways [25], that are notcurrently represented in the PW. We have applied ourtrained model to BioCyc and WikiPathways to generatemappings. Our contributions are two-fold; we introduce: A curation pipeline that integrates a predictive modelwith manual curation, and an evaluation of ourprediction results, and Newly predicted and curated mappings between thePW and ReactomeWang et al. Journal of Biomedical Semantics           (2019) 10:11 Page 3 of 11In this work, we describe the design and implemen-tation of this curation pipeline, with emphasis on oursupervised mapping prediction model. We describe howmappings are generated and provide an evaluation ofthe results compared to a baseline bag-of-words (BOW)model. PW curators manually review a randomly selectedsubset of mapping outputs to determine the precision andrecall of each model. We also discuss new mappings andrelationships that we plan to add to the PW in futureversions, with particular emphasis on expanding the part-of hierarchy and the inclusion of regulatory relationshipsthrough the usage of terms from the Relation Ontology.By integrating a machine learning predictive model intothe PW curation pipeline, we hope to reduce the burden ofmanual curation on our efforts to integrate pathway data.It is our hope that other researchers can incorporate sim-ilar methodology into their ontology curation pipelines,thereby reducing curatorial labor while increasing highquality mappings between datasets and ontologies.MethodsOur goal is to associate pathway instances from variousdatabases to the correct class in the Pathway Ontology.The following describes our methods as applied to theReactome database. Specifically, we map each Reactomepathway to a matching class in the PW if a matching classexists. In cases where no matching class exists, a newPW class is introduced to account for the pathway; thenew class is inserted where appropriate into the PW classhierarchy.Each class in the PW consists of its unique identi-fier and its descriptive information: a canonical name,aliases (synonyms), definition, and its location in the PWsubclass and part-of hierarchies. Each Reactome path-way has similar descriptive information, along with thepathway content itself: the entities and relationships thatdescribe the biochemical functions of the pathway. Thesepieces of descriptive information can be used to asso-ciate pathways with PW classes. Our goal is to build apredictive model leveraging this information along withtraining data to generate high-quality mapping recom-mendations between Reactome and the PW. This predic-tive model can then be inserted into the PW curationpipeline to improve the speed and quality of curated map-pings. For this task, we propose a supervised machinelearning algorithm that learns features and weights fromthe information provided for each PW class or Reactomepathway.The pipeline (Fig. 1) we propose and test consists of thefollowing steps: Extract training data from the PW and the UnifiedMedical Language System (UMLS)Metathesaurus [26] Bootstrap additional training data by predicting highlikelihood mappings between Reactome pathwaysand PW classes Train a neural network model using all training data Predict Reactome mappings to the PW using trainedmodel Review predicted mappings manually for correctnessand inclusion into the PWWe treat the predictive task as a binary classificationproblem, where given a pathway and a PW class, we pre-dict whether the two have a high likelihood of matching.We construct two models, one which predicts matchesover the names and aliases of pathways and PW classes,and one which predicts matches over the natural languagedefinitions of pathways and PW classes. The distinction isintroduced because not all pathways or PW classes havenatural language definitions, and neural network modelscan be challenged by the presence of null fields in caseswhere training datasets are small. A subsequent decisionmodule then collects the predictive model outputs for theseparate name and definition models and combines theseto form a final predicted similarity score.Details for each step in the curation pipeline are pro-vided in the following sections. We also provide a descrip-tion of the candidate selector module we used for bothnegative data sampling and candidate selection when run-ning the predictive model. All results presented discusspathways from Reactome v65, released 2018, June 12.Baseline bag-of-words modelA bag-of-words (BOW) model is provided as a baselinemodel for comparison. This baseline is based on stringsimilarity, and is similar to the way curators previouslyretrieved potential class matches for pathway instanceannotation. For the BOW model, each pathway and PWclass is represented as a set of word and n-gram tokens,generated from its names, definition, and the names of itsparent and children classes. A idf -weighted Jaccard indexis computed between the token set of a Reactome pathway(A) and the token set of a PW class (B) as:Jweighted =?tA?B idf (t)?tA?B idf (t)(1)For each Reactome pathway, PW classes with weightedJaccard indices above a threshold similarity score areselected as output. The optimal threshold was determinedusing a grid search over the training data. All resultsprovide comparisons between our neural network-basedpredictive model against this baseline model.Candidate selectionThe candidate selector module takes in a pathway andoutputs a ranked list of PW classes that are potentialWang et al. Journal of Biomedical Semantics           (2019) 10:11 Page 4 of 11Fig. 1 Semi-automated curation pipelinematches. Good matches are determined by large lexi-cal overlap in descriptive information. We first generatea string representation of each pathway or PW class byappending together its names, definitions, and the namesof all its parents and children. Each pathway string or PWclass string from this corpus is then parsed to a set ofword tokens and character n-gram tokens. Each token isweighted by its inverse document frequency (idf ) in theentire corpus. Tokens with higher idf occur less frequentlyand may be more relevant for determining matches. Theoverall lexical overlap score between a pathway and a PWclass is determined by summing the idf of all overlappingtokens between the two.The candidate selector is used to reduce the number ofnecessary comparisons when predicting PW class map-pings. When the candidate selector is given a pathway asinput, it first selects all PW classes with any token over-lap with the input pathway. The selector then sorts theoverall lexical overlap scores for these PW classes andreturns the top 20 as candidates. Instead of performingmcomparisons for each pathway (where m is the number ofPW classes), the candidate selector reduces the number ofcomparisons to 20.The candidate selector is also used to generate hardnegatives (see Training data section), which are nega-tive training data where there is substantial lexical overlapbetween the pathway string and PW class string. Hardnegatives are selected from the candidate list while ensur-ing no overlap with positive training data. Hard negativesare introduced into the training data to force greaterpredictive precision.Training dataTo train a binary classifier, we require both positive andnegative training data. Priormappings of KEGG,NCI PID,and the SMPDB to the PW can be used as positive labeledtraining data. Together, 860 mappings are provided in thePW. These mappings exist over 732 unique PW classes,out of a total of 2627 classes; in other words, around 28%of PW classes have existing mappings to pathways. Thesemappings reference 206 unique pathways from KEGG, 76from NCI-PID, and 557 from SMPDB.For each PW class, negative mappings are also sam-pled from these three pathway databases for training.Approximately two easy and two hard negatives aresampled for each PW class, where easy negatives arerandomly selected from the pathway database, and hardnegatives are selected using the candidate selector mod-ule. Care was taken to ensure that no extracted negativesoverlap with any positive training examples.To augment these existing mappings, we also extractmappings from the UMLS Metathesaurus between GeneOntology (GO) biological process terms and the Medi-cal Subject Headings (MeSH) [26]. GO biological processclasses overlap with concepts in the pathway space, andwe believe these mappings can provide reasonable distantsupervision for our classifier. From UMLS, we extract 732mappings between MeSH and GO.The breakdown of all extracted training data is given inTable 1. Of these, 860 positive and 7116 negative map-pings are extracted from the PW and 732 positive and 325negative mappings from the UMLS Metathesaurus.BootstrappingTo further boost training data, we extract high proba-bility positive matches between the PW and pathwaysfrom Reactome. Including training examples from Reac-tome adapts the predictive model to the specifics of theReactome database and we can expect an improvement inprediction quality. A bootstrapping procedure (Fig. 2) isused to iteratively train a predictive model and append itshighest likelihood predictions to the training data [27].Weemploy a simple logistic regression model using manuallyengineered lexical similarity features. The features we useare: Normalized absolute value percent word tokennumber differenceTable 1 Training data by sourceSource No. positive No. negativePWmappings to KEGG, NCI-PID, and SMPDB 860 7116GO/MeSH mappings 732 325Bootstrapped PW/Reactome mappings 730 720Total 2322 8161Wang et al. Journal of Biomedical Semantics           (2019) 10:11 Page 5 of 11Fig. 2 Bootstrapping procedure. The initial training data is derived from existing PWmappings and UMLS mappings between MeSH and GO. Asimple logistic regression model is trained on this data and used to bootstrap training samples from Reactome. The best matches betweenReactome pathways and PW classes are added to the training data set over 10 iterations to generate a final training data set Word token Jaccard index Character n-gram Jaccard index for n=3, 4, 5For each bootstrapping iteration, we train a logisticregression model over the training data. We run thistrained model over the PW and Reactome, generating aset of predicted PW classes for each pathway in Reac-tome. The top and bottom 0.25% of predictions are addedto the training data as respective positive and negativetraining examples for the following iteration. We itera-tively train the bootstrappingmodule 10 times, generating730 positive and 720 negative training samples from Reac-tome. A cursory review of the added training samplesrevealed good quality matches (88% correct at iteration10), where most of the matches could be considered low-hanging fruit, with pathway and PW class names thatmatch well based on string similarity alone. Incorrectmatches have very close semantic relationships, such asthe Reactome pathway for RNA polymerase II transcrip-tion matching to the PW class for RNA polymerase Itranscription.Neural networkWe constructed two neural network models for process-ing pathway names and pathway definitions. We begin bydescribing the pathway name model.Each pathway name is represented using pre-trainedword embeddings. For each word token, we concate-nate a 100-dimensional word2vec [28] vector and a100-dimensional fasttext [29] vector, generating a 200-dimensional word vector. Both word2vec and fasttextembeddings are trained on Pubmed Central full-lengthjournal articles. Word2vec tends to capture the semanticcontext of a word and fasttext its internal structure (pre-fixes, suffixes etc), so combining the two allows us to cap-ture information about both the meaning and appearanceof a word.The pathway name is treated as a bag of word embed-dings; the word-level embeddings of each word tokenin the name are summed, generating a pathway nameembedding: a 200-dimensional vector. A PW class nameembedding is generated from the PW class name in a sim-ilar fashion. These two embeddings are concatenated andWang et al. Journal of Biomedical Semantics           (2019) 10:11 Page 6 of 11input into a decision network consisting of two fully con-nected neuron layers. A sigmoid function processes theoutput of this network, producing a final similarity scorebetween 0 and 1, which is thresholded to determine thebinary class output.Pathway definitions consist of longer pieces of textwith many internal relationships (see Fig. 3 for exam-ples). Instead of bag-of-embeddings, a bidirectional long-short term memory (LSTM) network is used to capturemore semantic information [30]. The hidden layers atboth ends of the LSTM are concatenated to produce apathway definition embedding vector. The pathway def-inition embedding and PW class definition embeddingvectors are then concatenated and input into a deci-sion network of fully connected neuron layers. Simi-larly, an output score between 0 and 1 is generated asoutput using a sigmoid function. Figure 3 shows thenetwork architecture of the definition model; the namemodel uses bag-of-embeddings networks in lieu of theLSTMs.The final training data are split into a training (90%) anddevelopment (10%) set. The models are trained to min-imize the binary cross-entropy loss with respect to thetraining labels. We use the development set to optimizemodel training for recall, because we are more concernedabout deriving all possible matches rather than all certainmatches.Combining predictionsThe trained neural networks are used to predict mappingsbetween Reactome and the PW. For each pathway in Reac-tome, the candidate selector selects the top 20 PW classes,generating up to 20 candidate pairs. For each candidatepair (N ,M), where N is a pathway from Reactome and Ma class from PW,N has namesNname = {n1, n2, ..., np} andM has names Mname = {m1,m2, ...,mq}. These names areformed into unique name pairs by taking the Cartesianproduct of Nname and Mname. Each pair of names (i, j) isfed into the name neural network model, producing a setof name similarity scores:Sname = {sij | (i, j)  Nname × Mname} (2)Each score sij is the similarity between the pathwayname i and PW class name j.If the Reactome pathway has a definition, then the def-inition texts of the pathway and PW class are fed into thedefinition neural network model, yielding a single similar-ity score Sdef . A final similarity score is produced by com-bining and weighting the name and definition similarities:Stotal = 0.75max (Sname) + 0.25Sdef (3)The weights of max (Sname) and Sdef are selected tofavor name similarity because in many cases, there is alack thereof or non-specific definition in Reactome. Moreoptimal weights are likely to exist, but we do not exploreFig. 3 Architecture of neural network model. The neural network computes similarity between a pathway definition and a PW class definition. Abidirectional LSTM is used to encode the definition texts. This example shows the definition for Reactome pathway R-HSA-109606 and PW classPW:0000104 being encoded and compared in the neural networkWang et al. Journal of Biomedical Semantics           (2019) 10:11 Page 7 of 11them in this work due to limited resources for evaluation.Matching PW classes with Stotal above a threshold of 0.25are output by the predictive model.Evaluation of model resultsFor evaluation, a 5% subset of pathways from Reactomewere randomly selected, a total of 111 pathways out of2222. For this subset, all output predictions from boththe BOW and NN model were extracted and presentedto two curators for manual review. Output predictionswere presented to curators after first grouping by Reac-tome pathway and then sorting the PW classes withineach group by similarity score. A separate subset of 211class recommendations produced by the NN model wasalso evaluated by both curators, allowing us to determineinter-rater agreement.Curators were asked to perform the following task oneach selected subset: for each Reactome pathway-PWclass pair, grade the pair as y(es)/n(o)/r(elated), wherey(es) indicates an exact match, n(o) indicates an incorrectmatch, and r(elated) indicates that although the pair is notan exact match, the pathway is related to the PW class(maps to parent, child, or sibling classes). Two metrics arecomputed over the labeled results, precision per mapping(ppm) and recall per pathway (rpp). The ppm is defined asthe ratio of pathway-PW class pairs rated y(es) or r(elated)over all pairs rated. It is a measure of how correct themodels are for each recommendation produced. The rppis defined as the number of pathways for which at least oney(es) or r(elated) PW class is recommended over the totalnumber of pathways. It is a measure of how successful thealgorithm is at making at least one successful recommen-dation for each pathway. We also report the yield of bothmodels over all Reactome pathways. The yield indicatesthe percentage of pathways receiving any recommendedPWmappings.For each Reactome pathway, curators also selected thecorrect mapping, either from among the predicted PWclass matches, or from elsewhere in the PW. These map-pings are added to the PW for future release. In caseswhere a correct mapping is not predicted by our model,curators must determine whether a new class or relationneeds to be added to accommodate the Reactome pathwayin question.ResultsThe model was used to generate PW mapping recom-mendations for Reactome human pathways. The BOWmodel yielded 4122 mapping suggestions for 2222 Reac-tome pathways. The NN model produced 10,952 sugges-tions for the same pathways. Table 2 shows example NNpredictions generated for the Reactome human apopto-sis pathway, R-HSA-109581, of which there is no directname-matched class in the PW. The predictions show thatthe predictive model is able to retrieve PW classes thatare similar to the Reactome pathway in both name andcontent. The top predicted matches are those describ-ing the apoptotic process, followed by those describingrelated processes in immune response and cell death. Ofthese recommended PW classes, the correct match is toPW:0000009, the apoptotic cell death pathway, the secondranked PW class recommended by the predictive model.This PW class was selected by curators as the correct PWmapping for R-HSA-109581.Two RGD curators (GTH and MT) conducted a repro-ducibility review of the predictions. Table 3 shows theresults of the reproducibility analysis. Review of 211 classrecommendations showed a 0.73 agreement between tworeviewers for each mapping (Cohens kappa for threeclasses (y/n/r) = 0.56).A comparison of BOW and NN models is providedin Table 4. Curators reviewed 243 mapping recommen-dations produced by the BOW model for 111 randomlysampled pathways, and 660 recommendations producedby the NN model for the same 111 pathways. TheBOW model had significantly lower yield compared tothe NN model (BOW: yield = 0.50; NN: yield = 0.80).Although the BOW model had higher precision thanthe NN model (BOW: ppm = 0.49; NN: ppm = 0.39), italso had correspondingly lower recall (BOW: rpp = 0.42;NN: rpp = 0.78). Overall, the NN model provided moreopportunities for selecting an appropriate mapping. Per-haps combining the outputs of bothmodels could producebetter coverage with higher precision.A number of pathways did not receive relevant sug-gestions via either model. Reactome, in particular, con-tains very specialized regulatory pathway representationsthat do not currently have corresponding classes in thePW. Some portions of the PW class hierarchy, such asthose describing the immune system and cellular signal-ing, may require further development. For example, sev-eral Reactome pathways dealing with interferon-mediatedimmunity, such as R-HSA-1834941 (STING mediatedinduction of host immune responses) or R-HSA-918233(TRAF3-dependent IRF activation pathway) do nothave corresponding pathway classes in the PW. The PWcontains classes for type I (PW:0000895) and type II(PW:0000896) interferon signaling pathways, and has sev-eral subclasses describing signaling pathways related toinnate immune response (PW:0000819), but none of theseexisting classes are suitable for describing the functionsrepresented by the example Reactome pathways. The PWmay need to add either more granular pathway classes,or introduce properties such as regulates or related_toto annotate the relationships described above and foundthroughout pathways from Reactome.The above methods can also be applied to other path-way databases. As a test of generalizability, we ran theWang et al. Journal of Biomedical Semantics           (2019) 10:11 Page 8 of 11Table 2 Top ranked predicted mappings for Reactome pathway R-HSA-109581, ApoptosisPW ID PW class name Beginning of definition text1 PW_0000104 intrinsic apoptotic pathway The apoptotic pathway involving organelles,primarily the mitochon...2 PW_0000009 apoptotic cell death pathway Apoptosis is a programmed cell death path-way that is characterized by...3 PW_0000106 extrinsic apoptotic pathway The apoptotic pathway involving the deathreceptors mediated route of...4 PW_0000718 p53 signaling pathway p53 transcription factor is a tumor suppres-sor frequently mutated in...5 PW_0000124 cellular detoxification pathway A pathway triggered by exogenous orendogenous elements, compounds...6 PW_0000823 humoral immunity pathway Humoral immunity is mediated by antibod-ies secreted by the B cell...7 PW_0000824 cell-mediated immunity pathway Cell-mediated immune response pathwaysare carried out by T cell...8 PW_0000499 nuclear factor kappa B signalingpathwayNF-kB signaling plays an essential role in themammalian immune...9 PW_0000680 altered extrinsic apoptotic pathway <no definition>10 PW_0000233 tumor necrosis factor mediated sig-naling pathwayTumor necrosis factor (Tnf) signaling playspivotal roles in immunity...trained predictive model over pathways from Human-Cyc and WikiPathways, generating predicted mappingsto the PW. The NN model produced 1199 recommendations for 217 HumanCyc pathways and 1652 recommen-dations for 351 WikiPathways pathways. These recom-mendations have yet to be reviewed by curators, but canprovide a helpful starting point when mapping pathwaysfrom these other databases to the PW. Early inspectionof the results suggest that similar pathways between thesedatabases receive mappings to similar or the same PWclasses. For example, Table 5 shows the top pathwaysfrom Reactome, HumanCyc, and WikiPathways that theNN model associated with PW:0000029, the fatty acidbiosynthetic pathway. Although imperfect, the recom-mendations are largely relevant. Note that fewer pathwaysfrom HumanCyc and WikiPathways are associated withthis PW class; this is due to both the smaller size ofthe HumanCyc and WikiPathways databases, but also thegranularity of represented pathways.Curator-selected mappings between Reactome and PWclasses can be used as an additional source of training dataTable 3 Inter-rater agreement for mapping labeling taskRater #1Rater #2 y(es) r(elated) n(o) Totalsy(es) 24 8 0 32r(elated) 0 69 4 73n(o) 0 46 60 106Totals 24 123 64 211for improving the predictive model. As the quantity ofhigh-quality training data increases, our predictive modelshould improve, helping to further reduce the curatorialburden of mapping other pathway databases to the PW.DiscussionWe have described our efforts to incorporate a predic-tive classifier into the PW curation pipeline for generatingmappings between pathway databases and the PW. Resultsdemonstrate that our model is able to recommend rele-vant PW class mappings for pathways. By automaticallyinferring high-likelihoodmappings between pathways andPW classes, we hope to reduce the burden on curators.Our decisions maximalize annotation success based onthe curation pipeline described in Figure 1. For example,we bias the NN model during training to maximize recall.This is desirable because we have the luxury of manualcuratorial review as a gatekeeper to annotation. Whenoperating in situations without manual review, it may bemore desireable to bias the model towards maximizingmetrics such as precision or accuracy.The mappings we generated between Reactome path-ways and PW classes contribute to our overall goal ofTable 4 Comparison of BOW and NN model predictionsModel Precision (ppm) Recall (rpp) YieldBOW 0.49 0.42 0.50NN 0.39 0.78 0.80Precision and recall are calculated from a 5% sample of Reactome pathways; yield iscalculated over all Reactome pathwaysWang et al. Journal of Biomedical Semantics           (2019) 10:11 Page 9 of 11Table 5 Top pathways predicted to map to PW:0000029 ("fatty acid biosynthetic pathway")HumanCyc Reactome WikiPathwaysPWY-5966: fatty acid biosynthesis initiation II R-HSA-77288: mitochondrial fatty acid beta-oxidation of unsaturated fatty acidsWP357: Fatty Acid BiosynthesisPWY-5143: fatty acid activation R-HSA-77289: Mitochondrial Fatty Acid Beta-OxidationR-HSA-390247: Beta-oxidation of very longchain fatty acidsR-HSA-75105: Fatty acyl-CoA biosynthesisR-HSA-500753: Pyrimidine biosynthesisR-HSA-8978868: Fatty acid metabolismpathway data organization and integration. By organizingpathways from different databases under a single unify-ing ontology, we can understand how pathway data fromdifferent databases relate to one another. We can use thePW class hierarchy to reduce redundancy among pathwaydatasets by merging pathways under each PW class intonormalized pathways. Normalized pathways may havebetter interpretability due to the class boundaries andrelationships provided by the ontology.As described in previous publications, we face manychallenges to pathway data integration, such as 1) theusage of different pathway organizational schemes by dif-ferent databases, 2) incomplete or inconsistent descrip-tion of pathway-subpathway relationships, as well as 3)differences in identifier and semantic choices in repre-senting pathway data among the various source databases[6, 7, 12, 31]. Using a unifying ontology for organizationat the pathway level will ameliorate the first two of thesechallenges. To address the third, we have demonstratedmethods of entity disambiguation and graph alignmentcapable of aligning pathways even in the presence of iden-tifier or semantic differences [32]. In this prior work, weexplored lexical and topological techniques for pathwayalignment. These pathway alignment techniques shouldbe able to handle many of the described representationaldifferences when merging pathways.LimitationsThe current mapping prediction algorithm uses pathwayname and definition information (and to some extent,the names of parent and child pathways and PW classes,through the candidate selector) to match pathways withPW classes. The algorithm does not incorporate the path-way content itself: the graph of entities and relationshipsthat describe biological function. By incorporating tex-tual descriptions of pathways, we believe we capture mostof the important entities and relationships in a pathway.Explicit information on pathway member entities wereleft out of the current mapping algorithm due to con-cern about increasing the size of the predictive model,and challenges in representing this information as modelinput. How to include this additional information in pre-diction is an open research question.Pathway databases are all different, each with its ownstrengths and limitations. What works for Reactomemay not apply directly to all other pathway databases.Although we have demonstrated the ability to applythe predictive algorithm to HumanCyc and WikiPath-ways, we have not yet evaluated the resulting predic-tions. We have also not evaluated how newly gener-ated Reactome mappings may benefit the detection ofmappings between other pathway databases and thePW. Because these other databases emphasize differentaspects of pathway data (e.g., the BioCyc databases con-tain more information on conserved metabolic pathwaysbetween species), they may require alternate curatorialchoices for selecting appropriate mappings and for han-dling pathways without matching PW classes. These deci-sions will need to be explored in a further study ofgeneralizability.We would also like to explore how our predictive algo-rithm may apply to other ontologies and datasets. Theauthors believe that the design of the bootstrapping algo-rithm and the neural network may need significant adap-tation to work in other biomedical domains. The currentpredictive algorithm depends on the presence of existingmappings that can be extracted and used as training data.In cases where there is no access to pre-existing mappingsbetween data and ontology, a simple machine learningmodel similar to that used in the bootstrapping proceduremay be more fitting.Future workRGD annotators are reviewing the remaining mappingrecommendations for Reactome pathways and addingnew mappings into the PW. Reviewers are also annotatingpathways based on predictions for BioCyc and WikiPath-ways pathways. The predictive model will be retrainedincorporating the additional mappings generated by thisproject. Upon completion of the overall mapping project,Wang et al. Journal of Biomedical Semantics           (2019) 10:11 Page 10 of 11the PW will contain mappings to six pathway databases:the three that precede the developments described in thispaper (KEGG, NCI-PID, and SMPDB), and three newpathway databases (BioCyc, Reactome, and WikiPath-ways).As alluded to earlier, some pathways from thesedatabases do not have direct correspondences in the Path-way Ontology. In some cases, pathways representing pro-cesses at fine granularity can only be mapped to moregeneral PW classes. These observations suggest that semi-automated ontology annotation prediction could play ahelpful role in ontology completion or ontology develop-ment. We are investigating the differences between poorrecommendation quality (failure of the model) and thelack of appropriate recommendations (insufficient repre-sentation in the ontology). In future work, we would liketo produce a model that distinguishes between these twosituations.ConclusionPathway representations are critical for modeling andunderstanding the physiological processes underlyingboth normal and disease health states, but a lack ofunderstanding of the relationships between pathways ofdifferent provenance undermine their collective usabil-ity. Combining the data from different pathway databasesusing a unifying ontology could address many of theseissues. We demonstrate in this article the design, imple-mentation and evaluation of a computationally-assistedpipeline for mapping Reactome pathways to classes inthe Pathway Ontology. Initial results of the classifica-tion model show promise, highlighting a number ofpathway instance to PW class mappings that should beassessed by curators. We are working towards improv-ing the quality and quantity of these mapping rec-ommendations, as manual curation continues over theresults for Reactome and other pathway databases. Fol-lowing the completion of pathway mapping, we willproceed by aligning pathways grouped together undereach PW class, generating normalized pathway rep-resentations. Merging pathway instances along onto-logical class lines will produce non-redundant yetinterpretable pathways for use in secondary statisticalanalysis.AbbreviationsBOW: Bag-of-words; GO: Gene ontology; GSEA: Gene set enrichment analysis;idf : Inverse document frequency; KEGG: Kyoto encyclopedia of genes andgenomes; LSTM: Long-short term memory; MeSH: Medical subject headings;NCI: National cancer institute; NN: Neural network; PID: Pathway interactionsdatabase; PW: Pathway ontology; RGD: Rat genome database; SMPDB: Smallmolecule pathway database; UMLS: Unified medical language systemAcknowledgementsThe authors thank the reviewers and attendees of Bio-Ontologies 2018 fortheir helpful comments and suggestions. The authors also thank the late Dr.Victoria Petri, who conceived of and first created the Pathway Ontology,without which this work could not occur.FundingThis work was supported in part by the National Institutes of Health, NationalLibrary of Medicine Biomedical and Health Informatics Training Program at theUniversity of Washington (T15LM007442), National Library of Medicine grantR01 LM011969, and National Heart, Lung, and Blood Institute grant R01HL064541. The content is solely the responsibility of the authors and does notnecessarily represent the official views of the National Institutes of Health.Availability of data andmaterialsAn implementation of the model is available at https://www.github.com/lucylw/pathhier/. The Pathway Ontology is available on BioPortal at https://bioportal.bioontology.org/ontologies/PW.Authors contributionsLLW designed and implemented the predictive model. GTH and MT carriedout evaluative experiments. LLW wrote the manuscript with support fromGTH, JRS, MT, MES and JHG. JHG and MES helped supervise the project. LLWand JHG conceived the original idea. All authors read and approved the finalmanuscript.Ethics approval and consent to participateNot applicable.Consent for publicationNot applicable.Competing interestsThe authors declare that they have no competing interests.Author details1Department of Biomedical Informatics and Medical Education, University ofWashington, 850 Republican St, 98109 Seattle, WA, USA. 2Department ofBiomedical Engineering, Medical College of Wisconsin, 8701 WWatertownPlank Rd, 53226 Milwaukee, WI, USA.Received: 2 October 2018 Accepted: 22 May 2019RESEARCH Open AccessAn annotation and modeling schema forprescription regimensJohn Aberdeen, Samuel Bayer, Cheryl Clark, Meredith Keybl and David Tresner-Kirsch*AbstractBackground: We introduce TranScriptML, a semantic representation schema for prescription regimens allowingvarious properties of prescriptions (e.g. dose, frequency, route) to be specified separately and applied (manually orautomatically) as annotations to patient instructions. In this paper, we describe the annotation schema, the curationof a corpus of prescription instructions through a manual annotation effort, and initial experiments in modeling andautomated generation of TranScriptML representations.Results: TranScriptML was developed in the process of curating a corpus of 2914 ambulatory prescriptions writtenwithin the Partners Healthcare network, and its schema is informed by the content of that corpus. We developedthe representation schema as a novel set of semantic tags for prescription concept categories (e.g. frequency); eachtag label is defined with an accompanying attribute framework in which the meaning of tagged concepts can bespecified in a normalized fashion. We annotated a subset (1746) of this dataset using cross-validation andreconciliation between multiple annotators, and used Conditional Random Field machine learning and variousother methods to train automated annotation models based on the manual annotations. The TranScriptML schemaimplementation, manual annotation, and machine learning were all performed using the MITRE Annotation Toolkit(MAT). We report that our annotation schema can be applied with varying levels of pairwise agreement, rangingfrom low agreement levels (0.125 F for the relatively rare REFILL tag) to high agreement levels approaching 0.9 F forsome of the more frequent tags. We report similarly variable scores for modeling tag labels and spans, averaging 0.748 F-measure with balanced precision and recall. The best of our various attribute modeling methods capturedmost attributes with accuracy above 0.9.Conclusions: We have described an annotation schema for prescription regimens, and shown that it is possible toannotate prescription regimens at high accuracy for many tag types. We have further shown that many of thesetags and attributes can be modeled at high accuracy with various techniques. By structuring the textualrepresentation through annotation enriched with normalized values, the text can be compared against thepharmacist-entered structured data, offering an opportunity to detect and correct discrepancies.Keywords: Medication, Annotation, Prescriptions, ModelingBackgroundPatient medication regimens are described in a variety ofgenres of medical documents, including prescription or-ders, intake interview medication lists, discharge sum-maries, prescribing guidelines, and medication orders.Often, at least some aspects of the regimen are describedin free text; in many cases, the entire regimen is speci-fied in free text alone. Regimen information is essentialto patient care, as well as for secondary uses such asretrospective studies and pharmacovigilance, but the freetext representation presents great challenges in accessingthe information computationally. In this introduction wedescribe the availability and current state of the art ofmedication information extraction tools. We then de-scribe community evaluations, open representation sche-mata, and corpus development efforts in the medicationregimen domain.Medication information extraction systemsOver the last two decades, several systems have been de-veloped to identify medication names and associated© The Author(s). 2019 Open Access This article is distributed under the terms of the Creative Commons Attribution 4.0International License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, andreproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link tothe Creative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver(http://creativecommons.org/publicdomain/zero/1.0/) applies to the data made available in this article, unless otherwise stated.* Correspondence: davidtk@mitre.orgThe MITRE Corporation, 202 Burlington Rd, Bedford, MA 01730, USAAberdeen et al. Journal of Biomedical Semantics           (2019) 10:10 https://doi.org/10.1186/s13326-019-0201-9dosage attribute information in the free text of clinicalreports. Early rule-based systems include CLARIT [1],MedLEE [2, 3], and MERKI [4]. MERKI is an opensource system that uses a library of regular expressionsand a lexicon of drug names to identify medicationnames and dosage attributes. Authors of this system re-port accuracies of 83.7% for dose, 88.0% for route of ad-ministration, and 83.2% for frequency. CLARIT, acommercial system, combines basic NLP, general andspecial lexicons, and pattern matching rules to identifymedication names and dosage attributes. MedLEE, acommercial system developed to extract various med-ical concepts, identifies medication names but not dos-age attributes. Additional commercial systems includeLifeCode from A-Life Medical, Inc., Natural LanguagePatient Record from Dictaphone Corporation, andFreePharma from Language and Computing NV. Al-gorithms for these systems are not publicly available.A 2009 assessment of the medication extraction per-formance of commercial systems from four vendors (Lan-guage and Computing, Coderyte, LingoLogics, andArtificial Medical Intelligence) [5] found that they did wellidentifying medication names (F-measure 0.932) but lesswell identifying attributes such as strength (F = 0.853),route (F = 0.803), and frequency (0.483), and concludedthat automated extraction could support but not replace amanual process for clinical applications such as medica-tion list generation.Table 1 A comparison of concept coverage, and the identifiers for those concepts, in various information representations: MedXN/PredMed information extraction output, SHARPn annotation schema, FHIR clinical data structures, and TranScriptMLMedXN / PredMed SHARPn FHIR TranScriptMLDosage: amount of medication to be taken with each administrationDosage Dosage Dose Take, DoseamountDuration: how long patient is expected to be or has been taking the drugDuration Duration DurationForm: Physical form of the drugForm Form FormFrequency: how often the drug should be administeredFrequency Frequency Frequency, frequencyMax, period, periodMax, periodUnits FreqIndication: the reason the drug is being taken by the patientReason IndicationMedication: Name of the drugMedication Medication Medication MedicationMiscellaneous:Modifiers Additional Instructions InstructionPRN: Whether the drug is to be taken as neededasNeeded PRNRoute: how the drug is administeredRoute Route Route RouteStatus: whether the medication is currently being takenStatus ChangeStrength: the amount of active drug per unit (e.g. per tablet or per ml solution)Strength Strength StrengthTiming: additional information relating to life eventsWhen TimingAberdeen et al. Journal of Biomedical Semantics           (2019) 10:10 Page 2 of 11The i2b2 2009 Medication Challenge shared task [6]focused on extraction of medication-related informationfrom clinical text. The information to be extracted in-cluded medication name, dosage amount, route of ad-ministration, frequency, duration, and reason foradministration. Twenty teams participated in this chal-lenge, and while all of the top 10 systems recognizedmedication names well with F-measures above 0.75F-measure, they performed less well on other attributes.The attributes that proved hardest to extract were dura-tions and reasons, for which the highest scores were0.525 and 0.459, respectively.Seven of the top ten performing systems wererule-based systems [713]. Three of the top ten [1416]were hybrid systems that combined machine learningand rules, including the highest ranking system [14],which used machine learning for tagging and rules forintegrating related components.PredMed [17] and MedXN [18] are two more recentsystems which improve on the accuracy demonstratedby the 2009 i2b2 challenge entries. PredMed is not yetpublicly available; MedXN is available as a free andopen-source UIMA-based tool. Both target the same setof seven medication-related concepts, which are listed inTable 1 in comparison to other informationrepresentations.Both PredMed and MedXN find spans referencingthese seven concept types in text. Additionally, MedXNassigns an RxCUI id to normalize the medication name,performs coreference between medication names andregimen concepts, and attempts to assign an RxCUInormalization to the full medication concept. The fullnormalization produces a structured string combiningthe referenced regimen concepts. However, neither sys-tem normalizes the individual concepts (e.g. Frequency);RESEARCH Open AccessLevels and building blockstoward adomain granularity framework for the lifesciencesLars VogtAbstractBackground: With the emergence of high-throughput technologies, Big Data and eScience, the use of online datarepositories and the establishment of new data standards that require data to be computer-parsable becomeincreasingly important. As a consequence, there is an increasing need for an integrated system of hierarchies oflevels of different types of material entities that helps with organizing, structuring and integrating data fromdisparate sources to facilitate data exploration, data comparison and analysis. Theories of granularity provide suchintegrated systems.Results: On the basis of formal approaches to theories of granularity authored by information scientists andontology researchers, I discuss the shortcomings of some applications of the concept of levels and argue that thegeneral theory of granularity proposed by Keet circumvents these problems. I introduce the concept of buildingblocks, which gives rise to a hierarchy of levels that can be formally characterized by Keets theory. This hierarchyfunctions as an organizational backbone for integrating various other hierarchies that I briefly discuss, resulting in adomain granularity framework for the life sciences. I also discuss the consequences of this granularity framework forthe structure of the top-level category of material entity in Basic Formal Ontology.Conclusions: The domain granularity framework suggested here is meant to provide the basis on which a morecomprehensive information framework for the life sciences can be developed, which would provide the muchneeded conceptual framework for representing domains that cover multiple granularity levels. This framework canbe used for intuitively structuring data in the life sciences, facilitating data exploration, and it can be employed forreasoning over different granularity levels across different hierarchies. It would provide a methodological basis forestablishing comparability between data sets and for quantitatively measuring their degree of semantic similarity.Keywords: Building block, Level, Hierarchy, Domain granularity framework, SEMANTICS, Ontology, Granularity,Knowledge managementBackgroundArranging a heterogeneous collection of entities into aset of different levels (layers or strata) that are organizedin a linear hierarchy from a fundamental level at the bot-tom to some higher level at the top is a general orderingscheme that dates back at least as far as to ancient times[1]. In biology, attempts to answer the question of howmolecules make up cells and cells make up organismshave led to various proposals of compositionalhierarchies of different levels of biological organizationof living systems and their component parts [222].The underlying levels idea is simple and elegant. It canbe flexibly used in many different contexts [23], rangingfrom descriptions to explanations and the provision ofontological inventories [24]. It is not only frequentlyused in textbooks [2527], but also provides an import-ant conceptual framework in various scientific andphilosophical debates, including debates on downwardcausation, mechanistic explanation, complexity, reduc-tion, and emergence [2832].Various applications of the levels idea have been pro-posed in science and philosophy [4, 29, 3343].Correspondence: lars.m.vogt@gmail.comRheinische Friedrich-Wilhelms-Universität Bonn, Institut für Evolutionsbiologieund Ökologie, An der Immenburg 1, 53121 Bonn, Germany© The Author(s). 2019 Open Access This article is distributed under the terms of the Creative Commons Attribution 4.0International License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, andreproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link tothe Creative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver(http://creativecommons.org/publicdomain/zero/1.0/) applies to the data made available in this article, unless otherwise stated.Vogt Journal of Biomedical Semantics            (2019) 10:4 https://doi.org/10.1186/s13326-019-0196-2Although distinct from each other, many of them alsorelate to one another and take subtly different formswhen applied in related contexts, which often results inconceptual problems [23]. Oppenheim and Putnams[33] theory of reduction, for instance, attempts to ex-plain phenomena of a higher-level science through the-ories that refer to entities and to theories from the morefundamental science, with the goal of achieving the unityof science. As a consequence, however, levels of materialentities are associated with levels of broad scientific dis-ciplines (e.g., physical, chemical) and of their corre-sponding theories and this is a problem, because itleaves the question unspecified, why objects of, for ex-ample, physics, which range from sub-atomic particlesto entire planets and the universe as a whole, comprise asingle level (Bechtel and Hamilton [44]).Many philosophers have made attempts to establishcriteria for the validity or usefulness of the levels idea,sometimes expressed in form of necessary and sufficientformal criteria, but no commonly accepted consensushas been reached for any particular set of criteria [23,32]. Instead of having to decide and stick with a specificaccount of levels, Craver ([23], p.2) therefore suggestsdescriptive pluralism about levels, claiming that theworld contains many distinct, legitimate applications ofthe levels metaphor that are either unrelated or thathave only indirect relations with one another.Irrespective of the lack of commonly accepted formalcriteria, the different accounts of levels suggested so farusually all have in common that each level must repre-sent an increase in organizational complexity, with eachentity of a higher level being directly composed of en-tities belonging to the next lower level [45], resulting ina linear hierarchy of levels from a bottom level to a toplevel. Moreover, the idea presupposes that entities existfor which it makes sense to understand them as being atthe same level.The idea of levels and of hierarchies based on levelshas also been discussed in information science andontology research. Here, it has become increasingly im-portant due to the continuously growing need of re-searchers to manage large amounts of data (i.e., BigData) with the help of computers and software applica-tions, resulting in a new driving force for scientific ex-ploration, called data exploration or eScience [46]. BigData and eScience bring about the necessity for re-searchers to communicate biological data via the WorldWide Web and to use databases and online repositoriesto store, document, archive, and disseminate their data.They also require data to be standardized accordinglyand to be computer-parsable. All this can be facilitatedby the use of ontologies [4752]. As a consequence,ontology researchers have developed their own ap-proaches to levels, which they call granularity levels, andto different types of hierarchies based on levels, whichthey call granular perspectives. Ontology researchersprovide explicit criteria for identifying and demarcatingdifferent levels and different hierarchies. These criteriaspecify what is called a granularity framework.In the following, I develop a domain granularity frame-work for the life sciences that ranges from the atomiclevel to the level of multi-cellular organisms. The frame-work attempts to reflect the hierarchical anatomicalorganization of organisms, marking an important steptowards developing a general overarching informationframework for the life sciences. Since morphology takesa central role in all attempts of developing a hierarchicalsystem of levels of biological entities, because unambigu-ously modeling the various granularity relations acrossmorphological entities in a consistent way has been chal-lenging, I focus mainly on morphology. Morphology isalso ... one of the covering disciplines that spans [al-most] every single entity in any biological organism([53], p. 65). It provides diagnostic knowledge and datafor many disciplines within the life sciences [54, 55].And morphological terminology provides the basic refer-ence system and descriptive framework for thesupra-molecular domain in the life sciences. It is centralto all efforts of biological inventorying and to biologicalknowledge representation in general; and it provides acommon backbone for the integration of all kinds of dif-ferent biological information [47, 48, 5658].The paper is divided into two sections. In the first sec-tion I briefly discuss a formal approach to levels and hier-archies proposed by ontology researchers, which is basedon granular partitions. I compare the notion of a cumula-tive organization, which most theories of granularity as-sume for the anatomical organization of biologicalentities, with the cumulative-constitutive organization anddiscuss some of the conceptual problems that the latterbrings about. I take a brief look at the granularity schemeimplicit in the Basic Formal Ontology (BFO), before Iintroduce the general theory of granularity proposed byKeet [5961] that allows the integration of various differ-ent granular perspectives (i.e., hierarchies).In the other section I discuss BFOs characterization ofbona fide objects based on the identification of differenttypes of causal unity. I suggest adding two more types ofcausal unity for characterizing functional and historical/evolutionary bona fide entities. I also introduce the con-cept of building blocks, which gives rise to a hierarchy oflevels of building blocks that specifies its own granularperspective. This hierarchy is intended to function as anorganizational backbone for integrating various add-itional granular perspectives that are relevant in the lifesciences, resulting in a domain granularity frameworkfor the life sciences. I briefly discuss the implicit conse-quences of this approach for the structure of theVogt Journal of Biomedical Semantics            (2019) 10:4 Page 2 of 29top-level category of material entity in BFO. I concludeby discussing the suitability of the domain granularityframework here suggested for providing the basis onwhich an overarching information framework for the lifesciences [62] can be developed.MethodsOntologies and granularityInformation scientists and ontology researchers devel-oped an account of levels that follows a formal approachallowing for computer-parsability and automated reason-ing over hierarchies of different levels of granularity,with each hierarchy being understood as a distinctgranular perspective. Ontologies play an essential role inthis approach. Ontologies, together with other SemanticWeb technologies, also play a significant role in reliablycommunicating and managing data within and betweendatabases and online repositories, providing hierarchies apractical field of application with commercial significance.An ontology consists of a set of terms with commonlyaccepted definitions that are formulated in a highly for-malized canonical syntax and standardized format, withthe goal to yield a lexical or taxonomical framework forknowledge representation [63]. The terms are organizedinto a nested hierarchy of classes and subclasses, form-ing a tree of increasingly specialized terms that is calleda taxonomy [64]. However, when ontology researchersneed to refer to hierarchies other than taxonomies, forexample, a partonomy (i.e., a hierarchy based onpart-whole relations), they usually do that in referenceto some (external) granularity framework. Such parto-nomies, however, are usually only expressed indirectlythrough formalized descriptions specifying particular part-hood relations between resources within the taxonomy ofan ontology. This often results in the respective ontologycontaining several disconnected partonomies that provideonly locally applicable parthood-based granularityschemes, as opposed to a single globally and universallyapplicable scheme.Whereas the number of biomedical ontologies is con-tinuously increasing [65], they often differ considerably,and their taxonomies as well as their implicit parto-nomies and even some of their term definitions are ofteninconsistent across each other [6668]. As a conse-quence, if databases and online repositories differ withrespect to the ontologies they use, their contents arelikely to be incomparable, which significantly hampersdata exploration and integration. A solution to thisproblem involves two distinct approaches: using formaltop-level ontologies [66, 69] such as BFO [70, 71] and ap-plying a general formal theory of granularity for develop-ing a domain granularity framework that can be appliedas a meta-layer across various ontologies.Partial order, granular partition, and granularity treeKey to the development of any formal theory of granu-larity is the formal characterization of the relation thatholds between entities belonging to different levels ofgranularity. A first step is to identify partial order rela-tions. In mathematics and logics, a partial order is a bin-ary relation R that is transitive (if b has relation R to cand c has relation R to d, than b has relation R to d:(Rbc) (Rcd)? Rbd), reflexive (b has relation R to itself:Rbb), and antisymmetric (if b has relation R to c and chas relation R to b, than b and c are identical: (Rbc)(Rcb)? b = c) [72]. An example of a partial order rela-tion is the parthood relation.Granular partitions are based on partial order rela-tions [7376]. Granular partitions are involved in allkinds of listing, sorting, cataloging and mapping activ-ities. A granular partition is a hierarchical partition thatconsists of cells (here used in the general non-biologicalmeaning of cell) that contain subcells. It requires a spe-cific theory of the relation between its cells and subcells:(i) the subcell relation is a partial ordering relation; (ii) aunique maximal cell exists that can be called the rootcell; (iii) chains of nested cells have a finite length; and(iv) if two cells overlap, then one is a subcell of theother, therewith excluding partial overlap [7376]. Anempirically meaningful theory of granular partition alsorequires a theory of the relations between cells of thepartition and entities in reality (i.e., projective relation toreality [7375]).Depending on what is partitioned and the ontologicalnature of the parts, one can distinguish a bona fidegranular partition from a fiat granular partition. A bonafide granular partition partitions a bona fide object (i.e.,an entity that is demarcated by a bona fide boundaryand thus exists independent of any human partitioningactivities) into its bona fide object parts. A fiat granularpartition partitions any material entity into its fiat entityparts (i.e., entities that are demarcated by a fiat bound-ary and thus exist as a consequence of human partition-ing activities) (for a distinction of bona fide and fiatentities see discussion below and [70, 71, 77]).A granular partition can be represented as a tree, withthe nodes and leaves of the tree being the granular parts.This tree is called a granularity tree [69, 76, 78]. Every fi-nite granular partition can be represented as a rootedtree of finite length [74, 75, 7981]. In a granularity tree,a granularity level is a cut (sensu [82]; see Fig. 2b) in thetree structure. Within a granularity tree, different levelsof granularity can be distinguished, with the root being alevel itself, and all immediate children of the root an-other level, etc. The elements forming a granularity levelare pairwise disjoint, and each level is exhaustive, be-cause for every entity b of the partition exists someother entity c of the same partition, which belongs toVogt Journal of Biomedical Semantics            (2019) 10:4 Page 3 of 29another level of granularity, and b stands in a partial or-dering relation to c, or vice versa [76]. If the partitioningrelation is a mereological relation such as the part-wholerelation, all entities belonging to one granularity level ina granularity tree exhaustively sum to the whole (i.e., theroot cell) that is partitioned [76].Partitioning relations possess constrains regarding thetype of entities that they partition. The primitivepart-whole relation, for instance, exists only between in-stances (particulars/individuals) [23, 8385] (for a trans-lation to a class expression of parthood see [83, 86]). Asa consequence, parthood-based granular partitions canbe represented as instance granularity trees. Theclass-subclass relation is also a partial ordering relation.However, it exists only between types (classes, univer-sals). Granular partitions based on a class-subclass rela-tion therefore can be represented as type granularitytrees. The taxonomy of terms of an ontology representssuch a type granularity tree. (see also instance and typegranularity tree in [58, 87]).Hierarchies are based on strict partial ordering rela-tions, which represent irreflexive (b cannot stand in rela-tion R to itself: ¬Rbb) partial ordering relations. As aconsequence, hierarchies represent a specific case ofgranular partitions and granularity trees. The directproper parthood relation is a strict partial ordering rela-tion. This complies with any formal system of minimalmereology, including pure spatiotemporal parthood.Biological reality: the problem with the cumulativeconstitutive hierarchyOn the basis of the characterization of hierarchies men-tioned above one can distinguish four basic types ofhierarchical systems [17, 21, 88]: (i) constitutive hier-archies, (ii) cumulative constitutive hierarchies, (iii) ag-gregative hierarchies, and (iv) cumulative aggregativehierarchies (Fig. 1), of which only the former two hier-archies are of interest in the here discussed context.Interestingly, constitutive hierarchies are commonlyused by philosophers and ontology researchers to modelgranularity, whereas biologists use cumulative constitu-tive hierarchies.In a constitutive hierarchy [38], all material entities ofa given level of granularity constitute the entities of thenext coarser level. For instance, aggregates of all atomsthat exist constitute all molecules that exist and aggre-gates of all molecules constitute all cells [17]. In otherwords, coarser level entities consist of physically joinedentities of the next finer level of granularity [88]. A con-stitutive hierarchy is thus based on partonomic inclusionresulting from an irreflexive proper part-whole relation,with bona fide entities of different levels of granularitybeing mereologically nested within one another, thusrepresenting a mereological granularity tree [76].Most granularity schemes suggested in the ontologyliterature so far presuppose a constitutive organizationof material entities [78, 89] (for an exception see [58]),and many bio-ontologies, although often not accompan-ied by an explicit representation of formally definedlevels of granularity, also follow this scheme. This isproblematic given that constitutive hierarchies not onlyassume that coarser level entities always exclusively con-sist of aggregates of entities of the next finer level, butalso that every entity belonging to one level of granular-ity is part of some entity of the next coarser level ofgranularity (Fig. 1a). Unfortunately, this is not the casefor many material entities: ions or chlorine radicals dem-onstrate that not every atom necessarily is part of a mol-ecule; in humans, extracellular matrix (ECM; amacromolecular formation that is not a component ofcells, but a component of tissues and therefore also or-gans and multi-cellular organisms) and blood plasmademonstrate that not every molecule is part of a cell;protozoa, protophyta, erythrocytes, coelomocytes, orleukocytes demonstrate that not every cell necessarily ispart of an organ [87]. Obviously, not all the entities be-longing to one level of granularity necessarily form partsof entities of the next coarser level.Moreover, constitutive hierarchies also assume that allparts of any given level of granularity exhaustively sumto their complex whole (Fig. 1a). Regarding biologicalmaterial entities this implies that the sum of all cells of ahuman individual would have to yield the human indi-vidual as a whole. The totality of cells of any given hu-man being, however, does not sum to the body as awhole, since this mereological sum would not includethe ECM in which the cells are embedded and whichprovides the topological grid that determines the relativeposition of the cells to one another. The aggregation ofcells would disintegrate without the ECM and could notconstitute the body as a bona fide whole. Moreover, sincenot all atoms are part of a molecule and not all subatomicparticles are part of an atom, neither the sum of all mole-cules, nor the sum of all atoms that exist in the universeat a given point in time exhaustively sum to the universeas a whole [87]. As a consequence, not all parts that sharethe same granularity level necessarily exhaustively sum tothe maximal whole (contradicting [76, 78]).Instead of employing a constitutive hierarchy, biologistshave argued that typical biological material entities suchas multi-cellular organisms are organized according to acumulative constitutive hierarchy [17, 21, 88] (Fig. 1b).When comparing the characteristics of constitutive hier-archies with those of cumulative constitutive hierarchiesone can easily see why most approaches to granularitythat are frequently used in ontologies, but also the formaltheory of granularity of Kumar et al. [78], model thebio-medical domain on the basis of a constitutiveVogt Journal of Biomedical Semantics            (2019) 10:4 Page 4 of 29hierarchy. When partitioning a particular multi-cellularorganism (i.e., unpartitioned whole, Fig. 2b) into its directproper bona fide parts according to a constitutive hier-archy, all the parts belonging to a cut, and thus to an in-stance level, instantiate the same basic type of anatomicalentity (Fig. 2b, left). Therefore, each cut in the instancegranularity tree can be associated with a specific basic typeof anatomical entity. As a consequence, instead of talkingabout Cut I, one could just as well talk about the organgranularity level. Translating or mapping the topology ofan instance granularity tree to its corresponding typegranularity tree is thus straight forward and poses no con-ceptual problemsif one applies a constitutive hierarchyfor partitioning the multi-cellular organism that is (Fig. 2c,left). One could even derive a globally applicable, linearcompositional levels hierarchy for the life sciences. Onewould only have to apply the constitutive hierarchy modeland compare the type granularity trees of severalmulti-cellular organisms across various taxa.However, when applying the cumulative constitutivehierarchy model, the entire process becomes more com-plex and conceptually more challenging [58, 87]. Ac-cording to the cumulative constitutive hierarchy, theparts of a multi-cellular organism that belong to a cut ofan instance granularity tree do not all instantiate thesame basic type of anatomical entity (Fig. 2b, right). Forinstance, the parts that belong to the first cut in the ex-ample shown in Fig. 2b instantiate organs, cells, andmolecules. As a consequence, the mereological sum ofall entities belonging to one instance granularity leveldoes not necessarily sum to the unpartitioned whole(see, e.g., Cut III in Fig. 2b, right). Thus, one must con-clude that Kumar et al.s [78] theory of granularity andone of Reitsma and Bittners [76] criteria forA BC DFig. 1 Four different Types of Hierarchies. a A constitutive hierarchy of molecules, organelles, cells, and organs of a multi-cellular organism. It canbe represented as an encaptic hierarchy of types, with every molecule being part of some organelle, every organelle part of some cell and everycell part of some organ. b The same set of entities as in A), organized in a cumulative constitutive hierarchy, which models the organization ofbiological material entities more accurately. Here, not every molecule that is part of an organism is also necessarily part of some organelle andnot every cell necessarily part of some organ. c An aggregative hierarchy is based on mereological/meronymic inclusion that results from apart-whole relation (e.g., ecological hierarchies [15, 17]) or it is based on taxonomic inclusion [138] that results from a subsumption relation (e.g.,Linnean taxonomy). In case of mereological inclusion, this hierarchy represents a mereological granularity tree and higher level entities consist ofparts that are not physically connected, but only associated with each other. d In a cumulative aggregative hierarchy, as it is used in thehierarchical organization of military stuff, individuals with higher ranks, such as sergeants, lieutenants, and captains, appear in aggregates ofhigher order, so that squads consist of privates and sergeants, in the next level platoons of privates, sergeants, and lieutenants, and companies ofprivates, sergeants, lieutenants, and captains. (Figure modified from [58])Vogt Journal of Biomedical Semantics            (2019) 10:4 Page 5 of 29mereological granularity trees are not conformant withanatomical reality [58].Moreover, the topology of the resulting instancegranularity tree cannot be easily translated into itscorresponding type granularity tree, because each in-stance level comprises different types of entities (exceptfor the root and the finest level). A consequence of cu-mulative constitutive hierarchies is that, whenABCFig. 2 Instance Granularity Tree and Type Granularity Tree based on bona fide Granular Partition for Constitutive and Cumulative ConstitutiveHierarchies. a Compositional partitions of a constitutively and a cumulative-constitutively organized idealized multi-cellular organism into theirconstitutive bona fide object parts. Four corresponding partitions are shown. Left: into organs (f); cells (e); organelles (c, d); and molecules (a, b).Right: into organs with cells and extracellular molecules (i, j, g, h); cells with organelles and extracellular and cellular molecules (q, m, n, o, p, k, l);organelles and molecules (v, w, t, u, r, s); and molecules (x, y). b The four compositional partitions from A) represented as a bona fide instancegranularity tree. Each partition constitutes a cut in the instance granularity tree (Cut IIV) and thus an instance granularity level. Left: Instances ofthe same type of material entity do not belong to different cuts and thus are restricted to the same level of instance granularity. Right: Instancesof the same type of material entity, for instance molecule, belong to different cuts and therefore to different levels of the respective instancegranularity tree. The extension of the class molecule thus transcends the boundaries between instance granularity levels. c Left: The bona fideinstance granularity tree can be directly transformed into the corresponding type granularity treeno sortation of any parts across theboundaries of granularity levels required, because the topology of the bona fide instance granularity tree is identical with the bona fide typegranularity tree. Right: The bona fide instance granularity tree cannot be directly transformed into or mapped upon the corresponding typegranularity tree. However, by following the simple and intuitive rule that a type must occupy the same granularity level as its finest grainedinstance (i.e., sortation-by-type [58]) and by applying the concept of granular representation (see further below), one can transfer the instancegranularity tree into a corresponding type granularity tree. (Figure modified from [87])Vogt Journal of Biomedical Semantics            (2019) 10:4 Page 6 of 29partitioning a multi-cellular organism, different instancesof the same basic type of anatomical entity can belongto different instance granularity levels. In other words,when conceiving types of anatomical entities as classes,the extension of a class such as bio-molecule crossesthe boundaries of different levels of instance granularitywhen applying the cumulative constitutive hierarchy.Therefore, mapping types directly to instance levelswould result in some types being associated with morethan one level.This poses a fundamental problem, because ontologiesare dealing with types (i.e., classes) and not with individ-uals (i.e., instances), and thus require a type-basedgranularity framework. I have proposed an intuitive solu-tion, i.e., sortation-by-type, in which a type granularitytree is derived from an instance granularity tree by rank-ing types according to the lowest level of granularity oftheir corresponding instances [58]. Sortation-by-typecan be seen as a sort of granular sedimentation of all in-stances of one type to the lowest level they occupy (seelarge transparent arrows in Fig. 2c, right). Whereas thisapproach seems to be intuitive, the downside is that inthe type granularity tree, the entities belonging to agranularity level neither exhaustively sum to their re-spective whole (except for the lowest level), nor do all ofthem form parts of the entities belonging to the nexthigher granularity level [58].The granularity scheme implicit in the basic formal ontologyFormal top-level ontologies such as BFO [70, 71] play akey role in establishing standards across different ontol-ogies. BFO provides a genuine upper ontology uponwhich all ontologies of the Open Biomedical OntologiesFoundry (OBO Foundry [57, 90]) are built. Togetherwith the OBO Relations Ontology it is one of the guar-antors for the interoperability of the ontologies withinOBO Foundry.Because BFO is an upper ontology, its taxonomy iscomparably flat and does not include any distinction ofdifferent granularity levels of material entities. However,BFOs distinction of object, object aggregate, and fiatobject part as top-level categories of material entity[70, 71] can be interpreted as a basic granularity schemeapplied for modeling the granularity within a given levelof object granularity. The underlying basic idea is that acertain domain first must be partitioned into its top-levelobject categories, resulting in a domain-specific bona fidegranularity tree (i.e., a granularity tree that is based onbona fide granular partitions; see [76]), e.g., bio-macromo-lecule < organelle < cell < organ < organism. Accordingto BFO, in order to comprehensively cover the domain,each level of this bona fide granularity tree must be mod-eled by its own level-specific domain reference ontology,with cross-ontology relations managing the relationshipsbetween entities of different levels. Therefore, in a nextstep, the distinction of object, fiat object part, and objectaggregate indicates within each such ontology a simplifiedmodel for fiat partitions and fiat granularity trees (seeFig. 3). Of course, object aggregates can be parts of largerobject aggregates and fiat object parts can be further parti-tioned to smaller fiat object parts, thereby extending thebasic scheme shown in Fig. 3 with additional levels.This approach to modularizing granularity, however,does not seem to be very practicable, because it impliesthat instead of developing a single anatomy ontology ofa specific taxon of multi-cellular organisms, one wouldFig. 3 BFOs Basic Granularity Framework. A bona fide partition from a multi-cellular organism to a molecule represents the center of BFOsgranularity framework and reflects direct subclasses of BFOs object for the biological domain. According to BFO, each level of the correspondingbona fide granularity tree must be modeled by its own domain reference ontology (i.e., a molecule ontology, a cell ontology, etc.). Within eachsuch level-specific ontology, BFOs top-level distinction of object, fiat object part, and object aggregate indicates a basic fiat partition thatorthogonally crosses the bona fide partition. The bona fide partition can therefore be understood as an integrating cross-granular backbone forthe different ontologies of a given domain together with their implicit fiat partitionsVogt Journal of Biomedical Semantics            (2019) 10:4 Page 7 of 29have to (i) develop several granularity-specific ontol-ogies, ranging from an ontology for molecules, to anontology for organelles, for cells, for tissues, for organsand for body parts for this specific taxon, and (ii) onewould have to develop an additional layer of axioms andrelationships to define the granularity relations betweenentities across these different ontologies.Because BFO does not provide a formal granularityframework, applying the sub-categories of material en-tity (i.e., object, fiat object part, and object aggregate)can be ambiguous. As a consequence, many of the cur-rently available biomedical ontologies within OBO Foun-dry significantly vary regarding their underlyinggranularity assumptions and their top-level class-struc-ture for material entity (see subclasses of, e.g., materialanatomical entity of CARO, anatomical structure ofHAO, material entity of OBI, plant structure of PO,anatomical structure of ZFA, independent continuantof CL, cellular component of GO). One could argue thatBFO fails to provide a top-level structure for materialentity that can be applied for modeling the various do-mains covered by OBO Foundry ontologies. This causesproblems with the comparability of biomedical ontol-ogies and substantially limits the comparability of dataacross databases and online repositories that referencethese ontologies. The life sciences in general and com-parative morphology in particular, but also the compos-itional biology style of biological theorizing [91], wouldbenefit from a consistent granularity framework that isgrounded in reality and that accounts for theorganizational complexity of anatomy. In order to allowalgorithm-based reasoning and inferencing, such aframework requires an underlying formal theory ofgranularity that explicitly states formal granularity rela-tions and explicitly ranks levels of granularity. Unfortu-nately, most anatomy ontologies are only based onimplicit assumptions regarding granularity.Keets formal theory of granularityKeet [5961] has developed a formal theory of granular-ity that is agnostic regarding cumulative or cumulativeconstitutive hierarchies and thus circumvents some ofthe problems of theories of granularity that have beenproposed by others (e.g., [78]; problems discussed in[58]). Keet [61] argues that granularity always involvesmodeling something according to certain criteria, witheach model together with its criteria defining a granularperspective. Finer levels within a perspective containknowledge or data that are more detailed than the nextcoarser level, and coarser levels of granularity simplify ormake indistinguishable finer-grained details. A particulargranularity level, however, must be contained in one andonly one granular perspective, whereas a particular en-tity (individual or type) may reside in more than onelevel of granularity, but all levels in which it is containedmust belong to distinct granular perspectives [92].Moreover, a granular perspective has at least two levelsof granularity and there has to be a strict total order be-tween the entities of different levels of a given perspec-tive. And if there is more than one granular perspectivefor a subject domain, then these perspectives must havesome relation between each other. This way, several dif-ferent perspectives of granularity, each with its granular-ity tree and its corresponding set of granularity levels,can coexist within the same granularity framework. Forinstance, a granular perspective of relative location thatis based on fiat granular partitions, alongside with agranular perspective of structural composition that isbased on bona fide partitions, a perspective of biologicalprocesses that is based on temporal parthood relations(i.e., processes partitioned into their sub-processes), aperspective of functional units that is based on func-tional parthood relations (i.e., functional units parti-tioned into their functional sub-units), and a granularperspective based on developmental relations [58].The idea that a domain can be modeled by differentgranular perspectives is not new [69, 88, 91, 93, 94], butKeet [61] provides the first formal theory of granularitythat incorporates different granular perspectives within asingle domain granularity framework. Therefore, Keetstheory can be understood as an attempt to accept de-scriptive pluralism about the idea of levels [23]. How-ever, it also represents an attempt to integrate theresulting set of diverse hierarchies within an integratedand strictly formalized framework, her general formaltheory of granularity.A granular perspective can be specified by the combin-ation of a granulation criterion (what to granulate) and aspecific type of granularity (how to granulate) (for a de-tailed discussion see [61]). When applied to a correspond-ing object, a granular perspective partitions the objectresulting in a specific type of granularity tree. Each per-spective has exactly one granulation criterion and exactlyone type of granulation. This combination determines theuniqueness of each granular perspective. All granular per-spectives contained in a domain are thus disjoint. Keet[61] presumes that a domain of reality can be granulatedaccording to different types of granularity (mechanisms ofgranulation), requiring the existence of a certain type ofgranulation relation that must be specific to each particu-lar granular perspective. The entities (individuals or types)granulated by a type of granularity are disjoint.Various different types of granulation relations can beapplied, which can be classified into (i) scale-dependent(e.g., resolution, size) and (ii) non-scale-dependent typesof granularity (e.g., mereological parthood: structuralparthood, functional parthood, spatial parthood, involve-ment; meronymic parthood: membership, constitution,Vogt Journal of Biomedical Semantics            (2019) 10:4 Page 8 of 29sub-quality relations, participation) [61, 95]. Within agiven perspective, the granulation relation relates entitiesof adjacent granularity levels with one another. If agranular perspective has more than two levels of granu-larity, the granulation relation must be transitive. If agranulation relation is intransitive, then the respectiveperspective has only 2 levels.The granulation criterion delimits the kind or categoryof properties according to which the domain is parti-tioned, the levels identified, and the subject domaingranulated (i.e., data, information, or knowledge). It spe-cifies an aspect that all entities in a granular level musthave in common, whereas the contents of a level can beeither entity individuals (i.e., instances) or types (i.e., uni-versals, classes), but not both. It comprises either (i) atleast two properties, none of which is a quality property(for non-scale-dependent types of granularity) or (ii) atleast one property that is not a quality property togetherwith exactly one quality property that has a measurableregion (for scale-dependent types of granularity) [61].Keets [61] formal theory of granularity thus providesthe respective formal definitions, axioms, and theoremsthat allow the formal representation of granular parti-tions based on parthood relations (i.e., mereology) aswell as on taxonomic inclusion (i.e., class-subsumptionhierarchies based on set theory) and other types ofgranulation relations [60]. It even accommodates bothquantitative (i.e., arbitrary scale) and qualitative (i.e.,non-scale-dependent) aspects of granularity.Keets theory of granularity also provides a well suitedframework for analyzing and identifying some of theproblems of some of the granularity schemes that havebeen proposed earlier, taking Eldredges somatic hier-archy [9] as an examplethis criticism applies to manyof the published levels schemes, even including Kumaret al.s [78] scheme: The somatic hierarchy comprises anatom, molecule, and cell level together with an organ-elle, organ, and individual organism level of granularity.An obvious problem of this hierarchy is that its under-lying granulation criterion has been conflated betweenlevels, because spatio-structural entities have been mixedwith functional entities. As a consequence, the under-lying granulation relation varies depending on the levelbetween spatio-structural parthood and functional part-hood. Moreover, the tissue level seems to involve ascale-dependent granularity type, because it concernsresolutiona tissue is the representation of a cell aggre-gate at a coarser level of resolution, in which thefiner-grained details of the cell aggregate that enable theindividuation of individual cells are simplified or madeindistinguishable. This mixing of criteria and types ofgranularity results in inconsistent granulation: amono-cellular organism is an entity that belongs to boththe cell and the individual organism level of the sameperspective, but according to Keet [61] an entity canonly reside in more than one level if these levels belongsto different granularity perspectives.ResultsDeveloping a domain granularity framework for the lifesciencesThe increase in formalism coupled with the increase ingenerality compared to other theories of granularity re-sults in more flexibility and therefore a broader applic-ability of Keets theory. Her theory allows for detailedand sophisticated modeling of a domain by assigningspecific types or individuals of entities to specific typesof granular perspectives (i.e., hierarchies) that are inter-connected and integrated in a common domain granu-larity framework. This framework can be used (i) astemplate for the organization of top-level categories ofdifferent domain ontologies and (ii) to provide an inde-pendent overarching information framework that func-tions like an additional organizational layer, i.e., ameta-layer, to which terms/resources of different ontol-ogies can be mapped. This meta-layer would provide aconsistent and integrated system of well integratedgranular perspectives that allows for modeling not onlyparthood-based hierarchies, but all kinds of other rele-vant hierarchies, for instance, hierarchies based on de-velopmental or evolutionary relations. It can be formallyadded onto an existent knowledge base to facilitate theconstruction of a realism-based and more detailed modelof the biological domain (see also [58]).In order to be broadly applicable throughout manyexisting bio-medical ontologies, such a domain granularityframework for the life sciences would have to be devel-oped in reference to BFO and its implicit granularityscheme using a compositional bona fide object granularperspective that granulates bona fide object entities ac-cording to a direct proper parthood granulation relation(see Fig. 3). All additional granular perspectives can be dir-ectly or indirectly related to this compositional perspec-tive, which functions as an organizational backbone forthe entire framework, because each additional perspectivepossesses some level that shares entities with some levelof this compositional perspective. The development ofsuch a domain granularity framework, however, may re-sult in new demands that BFO (or some intermediate do-main reference ontology) must meet, which could resultin the necessity to adapt or extend BFO accordingly.Integrating BFO and frames of reference in a domaingranularity frameworkFrames of reference and BFOs object category of materialentitySmith et al. [71] (see also [70]) characterize BFOs bonafide object category and thus natural units that existVogt Journal of Biomedical Semantics            (2019) 10:4 Page 9 of 29independent of human partitioning activities as causallyrelatively isolated [96, 97] entities that are both struc-tured through and maximal relative to a certain type ofcausal unity. They distinguish three types of causal unity:1) Causal unity via internal physical forces, which uni-fies an entity through physical forces (e.g., fundamentalforces of strong and weak interaction, covalent bonds,ionic bonds, metallic bonding) that are strong enough asto maintain the structural integrity of the entity againstthe strength of attractive or destructive forces from itsordinary neighborhood. Whereas Smith et al. [71] men-tion only examples of physical forces that apply to theatomic and molecular scale (atoms, molecules, portionsof solid matter such as grains of sand and lumps ofiron), I would explicitly include all kinds of physical con-nections between material component parts, independ-ent of their scale, including cell-cell connections, butalso screws, glues, and bolts. Ultimately, they all go backto the physical forces discussed in Smith et al. [71].2) Causal unity via physical covering unifies an entitythrough a common physical covering, for instance, amembrane. This covering may have holes, but must becompletely connected (in the sense that a continuous pathcan be traced between any two points on the surface andthat path has no gaps and does not leave the surface) andmust still serve as a barrier for entities from inside and en-tities from outside that are above a certain size threshold.Examples: organelles, cells, tissues, organs.3) Causal unity via engineered assembly of componentsunifies an entity through screws, glues and other fas-teners. Often, the parts are reciprocally engineered to fittogether (e.g., dovetail joints, nuts and bolts). Examples:cars, ballpoint pens, houses, shoes, power grids.These three types of causal unity are ontologically notindependent from one another, because the latter twoexistentially depend and thus supervene on causal unityvia internal physical forces [98]. Moreover, they do notcover all cases of causal unity relevant in the life sciences(BFO does not claim completeness regarding the list ofcases of causal unity; see [70, 71]), but are confined to asynchronic approach to causal unity that is associatedwith a spatio-structural frame of reference (see below).Functional units and historical/evolutionary units arenot covered, although they are bona fide entities in theirown right that exist independent of any human parti-tioning activities [77]. In this context it is important tonote that functional and historical/evolutionary units arenot associated with a spatio-structural frame of referenceand are thus not necessarily also spatio-structural units.Moreover historical/evolutionary units are not confinedto a diachronic instead of a synchronic causal unity. Dia-chronic causal unity identifies natural units based onshared historical/evolutionary origin (for a detailed dis-cussion see [77]). Therefore, I suggest two additionaltypes of causal unity that are suited to cover the missingcases:Causal unity via bearing a specific function unifies anentity through the function that the entity bears, with itsfunctional component parts bearing sub-functions [98].This type of causal unity is more general than causalunity via engineered assembly of components and thusincludes it.Causal unity via common historical/evolutionary originunifies an entity through the common historical/evolu-tionary origin of the entitys component parts. A histor-ical/evolutionary unit is demarcated so that all of itscomponent parts share the same historical/evolutionaryorigin, with no material entity not belonging to it shar-ing the same origin [98]. As a consequence, historical/evolutionary units can be spatio-structurally scatteredentities such as twins living in different cities or applesfrom the same tree sold in different supermarkets.Moreover, because a given material entity can dependon several different types of causal unity at the sametime, of which not all are relevant in every context, eachtype of causal unity is connected to a specific basicframe of reference [98]. Both causal unity via internalphysical forces and causal unity via physical covering, atleast as conceived by Smith et al. [71] (see also [70]), areassociated with a spatio-structural frame of reference. Amotivation for applying a spatio-structural frame of ref-erence lies in inventorying what is given in a particularpoint in time by focusing on the spatio-structural prop-erties of a given entity (spatio-structural perspective[77]). Causal unity via bearing a specific function, on theother hand, is associated with a functional frame of refer-ence, which may be applied for making reliable predic-tions of what can happen in the future by focusing ondispositional/functional aspects of reality (predictive per-spective [77]). And causal unity via common historical/evolutionary origin is associated with a historical/evolu-tionary frame of reference, which may be applied formaking reliable retrodictions of what has happened inthe past by focusing on using a set of known types of re-peatable processes to reconstruct the sequence of eventsthat may have lead to the currently observable situation(retrodictive (diachronic) perspective [77]).Because BFOs general granularity scheme associatesto each top-level category of object a correspondingfiat object part and object aggregate category (e.g.,molecule with fiat molecule part and molecule aggre-gate) and because we can distinguish differentspatio-structural categories of object (e.g., atom, mol-ecule, organelle), we can differentiate additionalspatio-structural sub-frames of reference, one for eachspatio-structural top-level category of object that wecan distinguish (e.g., atomic frame, molecular frame, or-ganelle frame). Each such frame of reference includesVogt Journal of Biomedical Semantics            (2019) 10:4 Page 10 of 29not only the entities of the respective object category,but all entities of corresponding fiat object part and ob-ject aggregate categories. One of the reasons for distin-guishing different spatio-structural frames of reference liesin enabling the identification of what is comparable in aparticular point in time by focusing on entities belongingto a particular top-level object category and its corre-sponding fiat object part and object aggregates entities. Asa consequence, the number of spatio-structural frames ofreference directly depends on the number of top-levelspatio-structural object categories we can distinguish.The basic Organization of a Domain GranularityFramework for the life sciencesAs a consequence of the relevance of the different casesof causal unity for the life sciences, a domain granularityframework for the life sciences would have to coverthree basic categories of granular perspectives: granularperspectives relating to (i) spatio-structural, (ii) to func-tional, and (iii) to historical/evolutionary material en-tities. In analogy to BFOs general granularity schemediscussed above, each such basic category will includeone or more corresponding bona fide granular perspec-tives, with each granularity level of a bona fide perspec-tive having associated fiat object part and objectaggregate fiat perspectives. As a consequence, the num-ber of granular perspectives for each such category de-pends on the number of granularity levels of itscorresponding bona fide perspectives, with each bona fidelevel requiring some additional associated fiat perspectives.However, since each of the three basic categories ofperspectives corresponds with one of the three basicframes of reference relevant to the life sciences, anygiven material entity always belongs to at least three dif-ferent granular perspectivesone for each basic frameof reference (i.e., spatio-structural, functional, historical/evolutionary). Moreover, when considering that at leastthe basic spatio-structural frame of reference actuallyconsists of a set of several distinct spatio-structuralframes of reference, one for each identified spatio-struc-tural top-level object category, any given material entityactually belongs to more than three granular perspec-tives. In other words, an entity belonging to some levelof functional granular perspective will always also belongto some level of historical/evolutionary granular per-spective and some level of each of the differentspatio-structural granular perspectives, and vice versa.And because all the different granular perspectives ofone category overlap in the sense that no granular per-spective exists that does not overlap directly or indirectlywith the bona fide perspective of this category, the per-spectives of the three categories overlap each other aswell, thus integrating all the different perspectives of thedomain granularity framework. As a consequence,assuming that only one bona fide perspective exists foreach basic frame of reference, the bona fide perspectivesfunction as the organizational backbone of the entireframework. Ideally, these bona fide perspectives woulddirectly overlap with each other, which would substan-tially increase the overall integration of the framework.1st step: Identifying the organizational backbone granularperspective for the life sciences based on building blocksBuilding block systems: An evolutionary systems-theoreticalperspectiveAre hierarchies artifactual and thus mind-dependentconstructs? If we use the levels idea merely because ittakes a central role in our representations of reality, whyshould we bother to ask nature which hierarchy is mostrealistic? Whereas these questions are legitimate, evi-dence exists that suggests that evolution (including cos-mic evolution [99]) leads to modularization. If evolutionhas the tendency to aggregate material entities to largercompositions with a significant increase in complexity,robustness, and stability, resulting in a modularization ofmatter, then hierarchy is a necessary consequence ofevolution. If building block systems evolve, which becomeparts of larger building block systems, then a hierarchicalcomposition of building block systems must result thathas lower-level building block systems as its parts. Theresulting compositional hierarchy of building block sys-tems is the product of natural processes and thus existsindependent of any human partitioning activities.The idea that evolution has the tendency to evolvesuch building block systems is not new. Simon [29] ar-gued for the evolution of complex forms from simpleones through purely random processes, with the direc-tion towards complex forms being provided by their sta-bility (survival of the fittesti.e., of the stable, [29], p.471). Simon argued that [t]he time required for the evo-lution of a complex form from simple elements dependscritically on the numbers and distribution of potentialintermediate stable forms ([29], p. 471). Hierarchywould thus emerge almost inevitably through evolution-ary processes for the simple reason that hierarchicalstructures are stable [29].Our understanding of how morphological structuresevolve and how they develop during morphogenesis hassubstantially improved since Simon proposed the idea ofbuilding block systems and it seems to support his idea.Especially with the newly emerged field of evo-devo andthe discovery of hox genes, we start to understand howregulatory gene networks function like modular struc-tures [100102] that can recombine with other modulesin the course of evolution to form new networks [103],and how they strongly affect development of morpho-logical structures, their evolutionary stability, and theirevolvability [104107]. Some gene regulatory networksVogt Journal of Biomedical Semantics            (2019) 10:4 Page 11 of 29have been identified that have the role of individualizingparts of the body during development, and it seems tobe the case that these Character Identity Networks(ChINs, [105]) are more conserved than are other as-pects of character development and thus representprime candidates for building block systems.Building blocks as Spatio-structural bona fide objectsTaking the idea of building block systems as a startingpoint, I provide a specific characterization of buildingblock as a Lego-brick-like entity that evolves, diversifies,and provides realitys inventory of basic categories ofmaterial entities. The concept of building blocks thenprovides the basis for a specific account of levels.According to this account, various types of buildingblocks emerged during evolution, starting when therewere only elementary particles present, to a universe thathas gradually evolved with the emergence of more andmore new types of building blocks [18, 29, 108112].This evolutionary systems-theoretical account of levelsbased on building blocks seems to provide a promisingframework for developing a globally and universally ap-plicable hierarchy of levels of material composition. Theconcept of building blocks is insofar relevant to the de-velopment of a domain granularity framework for thelife sciences, as I argue that it gives rise to a compos-itional granular perspective of building blocks thatrepresents the abovementioned ideal bona fide spatio-structural granular perspective that functions asorganizational backbone for the granularity framework.I characterize a building block as follows: A building block possesses a physical covering that iscomparable to what Jagers op Akkerhuis and VanStraalen [18] have referred to as an interface. Thephysical covering not only demarcates the buildingblock from its environment, making it a spatio-structurally bona fide entity, but also functions as aphysical barrier that protects a specific inside milieufrom the outside milieu that surrounds the buildingblock, establishing a micro-ecosystem within thebuilding block that follows different functional vec-tors than the outside macro-ecosystem. The physicalcovering relates also to Smith et al.s [71] account ofcausal unity via physical covering (see above). It is,however, on the one hand more general, because ittreats also electron shells as a physical covering (seebelow), and on the other hand more specific, be-cause it includes also functional aspects of the phys-ical covering. Moreover, contrary to themathematical account of boundary followed bySmith et al. [71, 113116], the physical covering of abuilding block is itself a three-dimensional materialentity and is therefore rather a boundary region [98].This is an important aspect, as it provides buildingblocks with what Wimsatt called robustness (Thingsare robust if they are accessible (detectable, measur-able, derivable, definable, producible, or the like) in avariety of independent ways, [117], p. 210f; see also[118]). The physical covering not only determines theboundary region of a building block, but is itself abona fide functional unit that not only provides thesurface of the boundary of the building block, but alsobears the dispositions with which the building blockinteracts and communicates with its environment. A building block is not only a spatio-structurallybona fide entity, but also a bona fide functional unitthat possesses its own regulatory machinery withfeedback mechanisms, so that to a certain degree itis self-organized and self-maintained. Building blocksrepresent localized islands of order that have a stableinternal organization and maintain their integrityduring typical interactions. A building block usuallylives/exists longer than its constituent parts and itsbehavior is predictable for the situations typicallyfound in its environment. New types of building blocks come into being as aresult of (cosmic) evolution. A building block is able to interact with otherbuilding blocks to form aggregates and morecomplex building blocks (Simons assemblies [29]).Building blocks of a coarser level are composed ofbuilding blocks of finer level(s). As a consequence, abuilding block of a coarser level is necessarilyexistentially dependent on a building block of somefiner level, resulting in a hierarchy of irreduciblelevels. Building blocks of coarser levels can onlyevolve after finer level building blocks have evolved.Building blocks thus provide nature with its universalinventory of matter, just like lego-bricks with which in-creasingly complex structures can be built. The evolutionof a new type of building block that constitutes a new andcoarser level always corresponds with a substantial in-crease in material diversity and adds a new dimension tothe spatio-structural space for evolution to explore. Build-ing blocks are spatio-structurally, functionally, develop-mentally and evolutionarily both integrated and stable,but at the same time increase natures overall evolvability.Non-biological building blocksAccording to the characterization above, the electronshell is a unit of physical covering of a building block (cf.[18]). There are two types of material entities that arecovered by electron shells: atoms and molecules. In anatom, a cloud of electron waves surrounds the nucleus.It physically covers the atom and also determines theinteraction of the atom with the entities of itsVogt Journal of Biomedical Semantics            (2019) 10:4 Page 12 of 29environment. Electromagnetically, one can clearly iden-tify a stable inside milieu that is protected from an out-side milieu via the electron shell.Electron shells from several atoms can bind to form amolecule. In a molecule, several atoms share a commonelectron shell, forming the building blocks of the nextcoarser level of granularity. This also applies to lumps ofmetal, in which several atomic nuclei share a commonelectron shell. In metals, however, the sharing of elec-trons is not localized between two atoms (i.e., covalentbond), but instead free electrons are shared among a lat-tice of positively charged ions (i.e., metallic bonding).Therefore, causal unity via physical covering in the hereproposed concept of building blocks would includeatoms, lumps of metal and molecules as bona fide ob-jects in the sense of Smith et al. [71] (for the sake of sim-plicity, from here on I include metals in molecules andalso treat ionic compounds as molecules; in other words,I include all compositions of atoms in molecules that arebased on intramolecular forces).Molecules can further combine to form bona fide ob-jects based on intermolecular forces such as a portion ofwater that consists of several water molecules that be-come aggregated due to hydrogen bonds. These objects,however, do not constitute building blocks themselves,because they lack a common physical covering. Instead,they are bona fide aggregates of molecule building blocks.Biological building blocks delimited by a plasma membraneBiological building blocks are building blocks that arebiological material entities that can be found universallyacross a wide range of taxonomic groups. Their proto-typical forms have evolved during biological evolutionand have been very successful in combining and recom-bining finer level building blocks to built building blocksof the next coarser level. Because biological buildingblocks continue to evolve, a variety of different formsexist, all of which, however, share some common charac-teristics so that they can be referred to as instances ofthe same set of prototypical building block categories.As a consequence, biological building blocks can consid-erably vary in size, in particular across different taxa.Correlating biological building block levels with scalelevels across different taxa is therefore often impossible.In order to identify a biological building block, wemust identify, which types of biological physicalcoverings meet the criteria discussed above for physicalcovering of a building block. The biological plasmamembrane qualifies as such a physical covering. Variousbiological material entities are surrounded and naturallydemarcated by a biological plasma membrane, with itsmost important component being amphipathic mole-cules. Amphipathic molecules such as phospholipidspossess both a hydrophobic and a hydrophilic region.According to the fluid mosaic model, the membrane is afluid structure that is arranged in a mosaic-like fashionwith different kinds of proteins embedded in or attachedto a phospholipid bilayer [27]. This supramolecularstructure is thus an aggregate of molecules that is pri-marily held together by hydrophobic interactions, whichare significantly weaker than covalent bonds, but never-theless strong enough to maintain its structural integrity.Therefore, following Smith et al.s [71] definition of bonafide objects, each bio-membrane is a bona fide objectthat is a molecule aggregate that is causally unified viainternal physical forces, i.e., hydrophobic interactions.A specific degree of fluidity is essential for the properfunctioning of the membrane as a semi-permeable barrierand for its embedded enzymatic proteins, many of whichrequire being able to move within the membrane for theiractivity [27]. Whereas the phospholipids provide thespatio-structural skeleton of the membrane, its varioustypes of proteins determine most of its functions, rangingfrom selective transport across the membrane, to variousenzymatic activities, signal transduction, cell-cell recogni-tion, intercellular joining such as gap junctions or tightjunctions, and attachment to the cytoskeleton and theECM. Each type of plasma membrane can be character-ized by its set of membrane proteins.There are two types of biological material entities thatare covered by plasma membranes: cells (prokaryotic aswell as eukaryotic cells) and organelles, the latter of whichare membrane-enclosed structures within eukaryotic cells,including nucleus, endoplasmatic reticulum, lysosome,mitochondrion, peroxisome, cisternae of the Golgi appar-atus, central vacuole, chloroplast, and all vesicles and vac-uoles. In the here suggested strict sense of organelle as amembrane-enclosed material entity within eukaryoticcells, the Golgi apparatus itself is not an organelle, but anaggregate of organelles, because its cisternae are physicallydisconnected organelles themselves.Cells and organelles are thus biological building blocksand therefore spatio-structural as well as functional bonafide entities. When only considering the topology of themembranes, one must, however, distinguish a buildingblock single-membrane-enclosed entity that comprises allorganelles and prokaryotic cells, from a building blockmembrane-within-membrane entity that compriseseukaryotic cells, which are membrane-enclosed entitiesthat have membrane-enclosed entities as their parts.Several eukaryotic cells can fuse to form a syncytium,which is a multinucleated cell (e.g., skeletal muscles andcardiac muscle in humans and the syncytiotrophoblast invertebrates, which is the epithelial covering of a placenta),or they can conduct multiple nuclear divisions without ac-companying cytokinesis to form coenocytes. In both casesseveral nuclei share the same cell membrane, thus, form-ing mutliplets of eukaryotic cells. However, althoughVogt Journal of Biomedical Semantics            (2019) 10:4 Page 13 of 29topologically substantially different to eukaryotic cells witha single nucleus, syncytia and coenocytes are neverthelessmembrane-within-membrane entities.Prokaryotic cells as well as eukaryotic cells can be-come aggregated such as can be seen in bacterial col-onies or in epithelia of multi-cellular animals, formingbona fide objects in the sense of Smith et al. [71] basedon causal unity via internal physical forces. These ob-jects, however, do not constitute building blocks them-selves, because they lack a common physical covering.Instead, they are bona fide aggregates of molecule andcell building blocks.Biological building blocks delimited by an epitheliumAn epithelium is another type of biological physical cov-ering that qualifies as a covering of a building block. Anepithelium is composed of polarized cells that form atightly packed continuous single-layered sheet of cells.Every epithelium has an apical surface and a lower basalsurface, the latter of which is attached to a basal laminathat is a layer of ECM secreted by the epithelial cells.The basal lamina acts as a filter for any moleculesattempting to pass into the space covered by the epithe-lium. Many epithelial cells possess microvilli at their ap-ical side, increasing the surface area of this side of theepithelium, which is important for functions of secre-tion, absorption, and sensory functions. The apical sidecan also possess a motile cilium for pushing substancesalong the apical surface of the epithelium. Tight junc-tions in case of vertebrates and septate junctions in caseof invertebrates connect the plasma membranes of adja-cent epithelial cells through specific proteins in themembranes, forming a continuous semi-permeable sealaround the epithelial cells that prevents fluids frommoving through the intercellular spaces of the epithelialcells and thus across the epithelium. According to Smithet al.s [71] definition of bona fide objects, each epithe-lium as such is thus a cell aggregate that forms a bonafide object that is causally unified via internal physicalforces, i.e., tight junctions or septate junctions respect-ively. The epithelium functions as a diffusion barrier.The epithelium lining the blood vessels of Tetrapoda,for example, functions as a hemato-encephalic barrierthat prevents some substances in the blood (e.g., sometoxins and pathogens) to come in contact with brain tis-sue. This protects a specific inside milieu within thebrain from its outside milieu. Epithelia can have variousadditional functions, ranging from selective absorptionof water and nutrients, protection, elimination of wasteproducts, secretion of enzymes and hormones, transcel-lular transport, to sensory functions. All animal glands,for instance, are made of epithelial cells.There are two types of anatomical entities that arecovered by epithelia: organisms with an epidermis, andepithelially-delimited compartments, the latter of whichare epithelium-enclosed structures within multi-cellularanimals, including, for instance, the circulatory systemin humans, lungs in vertebrates, and the intestine in ani-mals. Therefore, epithelially-delimited compartment andepithelially-delimited multi-cellular organism are bothbiological building blocks, the latter of which areepithelium-within-epithelium entities.Epithelially-delimited compartments can aggregatesuch as the digestive system in humans, which consistsof the gastrointestinal tract together with all accessoryorgans of digestion (tongue, salivary glands, pancreas,liver, and gallbladder). Although one can argue that suchan aggregate forms a functional bona fide unit, it doesnot constitute a building block, because it lacks a com-mon physical covering. Instead, it is an aggregate of mol-ecules, cells and epithelially-delimited compartmentbuilding blocks (see discussion below).Results I: Spatio-structural granular perspectivesCompositional building block (CBB) granular perspectiveOn the basis of the abovementioned characterization ofbuilding blocks one can identify the following prototyp-ical building blocks: atom < molecule (including metalsand ionic compounds) < single-membrane-enclosed en-tity (i.e., most organelles and all prokaryotic cells)< membrane-within-membrane entity (i.e., eukaryoticcell) < epithelially-delimited compartment (i.e., some,but not all of the entities that are commonly referred toas organs) < epithelially-delimited multi-cellular organ-ism (i.e., organisms with an epidermis).Comparable to the hierarchy proposed by Jagers opAkkerhuis and Van Straalen [18], the resulting hierarchyof levels of building blocks ranks complexity solely in astrict layer-by-layer fashionit is a robust hierarchy thatdoes not allow for bypasses, such as the sequence sand< stone < planet allows bypassing the stone level byconstructing a planet from sand alone [18]. Levels in anaggregate hierarchy on the other hand allow suchbypassing (see also distinction of aggregates and levels oforganization in [35]). The hierarchy of levels of buildingblocks provides what Craver [23] would call monolithiclevels that reach across all material domains of realityand that are globally and universally applicable. Becausethe concept of a building block is based on an evolution-ary interpretation, it explicitly predicts the diversificationof newly evolved building blocks of a given level, witheach higher level exhibiting the possibility of an expo-nentially larger number of different types of entities as-sociated with a building block to be evolvedthenumber of possible types of molecules is exponentiallylarger than the number of possible types of atoms. Whenconsidering that actual material entities can be com-posed of a multiplicity of different possible combinationsVogt Journal of Biomedical Semantics            (2019) 10:4 Page 14 of 29(i.e., aggregates) of those building blocks, comparable toconstructions made from lego-bricks, the diversity ofpossible types of material entities increases even morewith each newly evolved building block.On the basis of this concept of building blocks and theimplicit hierarchy of building blocks, a granular perspec-tive of levels of building blocks can be characterized usingKeets general formal theory of granularity [61]. The sub-ject domain in all granularity perspectives discussed in thefollowing is restricted to cumulative-constitutively orga-nized material entities. The bona fide partition of a givenbuilding block entity into its building block componentsrepresents a qualitative compositional partition (as op-posed to a qualitative regional partition or a quantitativeresolution-based partition). This compositional buildingblock (CBB) granular perspective is based on a directproper parthood relation between instances of differenttop-level categories of building blocks (see discussionbelow), and thus has the granulation criterion (Fig. 4):According to Keets formal theory of granularity, thisperspective has a granulation of the non-scale dependentsingle-relation-type granularity type (nrG [61]; alsocalled non-scale dependent primitive granularity type,npG [60]). It is based on the direct proper parthood rela-tion as its granulation relation. Entities residing in adja-cent CBB granularity levels are thus related through thedirect proper parthood relation. In order to constitute aCBB granular perspective, instances of at least two dif-ferent categories of building block must exist, of whichinstances of one category are direct proper parts of in-stances of the other. In other words, the levels of theCBB granular perspective are demarcated from one an-other according to the properties of the top-level cat-egories of building block and they are ordered fromfinest to coarsest granularity level according to the directproper parthood relation. The number of levels withinthe CBB granular perspective directly depends on thenumber of top level categories of building blocks identi-fied (Fig. 4).According to the underlying cumulative constitutiveorganization, for all instances of building block holds(compositional object granularity perspective [58]):1. An instance of a building block is not necessarily aproper part of an instance of some building block ofthe adjacent coarser CBB granularity level.2. Every instance of a building block, except for thosebelonging to the finest CBB granularity level, has atleast two instances of building blocks of finer levelsas its proper parts.3. The instance of the building block that is granulatedis the maximum entity that belongs to the coarsestCBB granularity level, and every other instance of abuilding block belonging to this granulation is aproper part of this maximum entity. However,because this maximum entity is cumulative-constitutively organized, its direct proper parts notnecessarily all belong to the second coarsest CBBgranularity level.Because each entity belonging to a specific CBB granu-larity level represents a BFO object, we can distinguishsix different spatio-structural frames of reference, whichcan be ordered according to the associate CBB granu-larity levels from finer to coarser spatio-structuralframes of reference: an atom, a molecule, an organelle/prokaryotic cell, a eukaryotic cell, an epithelially-delim-ited compartment and an epithelially-delimitedmulti-cellular organism frame of reference. Each suchspatio-structural frame of reference has its own set ofgranular perspectives. As a consequence, whereas anygiven material entity can belong to six differentspatio-structural granular perspectives, it can belong tomaximally one CBB granularity level.Fig. 4 Compositional Building Block (CBB) Granular Perspective. The different building blocks are granulated according to the direct properparthood granulation relation (the large dark arrows). The granulation is of the non-scale dependent single-relation-type granularity type (nrG[61]), and uses the combination of the granulation relation together with the common properties of all categories of the building block type asits granulation criterion. Due to the cumulative constitutive organization, finer-level building block entities can be considered to be partsassociated with coarser-level building block entities, for instance, ECM being an associated part of a eukaryotic cellbuilding block directProperPartOf building block;building block hasDirectProperPart building block.Vogt Journal of Biomedical Semantics            (2019) 10:4 Page 15 of 29Moreover, because a building block is defined as abona fide spatio-structural entity as well as a bona fidefunctional unit, the CBB granular perspective comesclose to the ideal organizational backbone for the devel-opment of a domain granularity framework for the lifesciences. Conceptually, it therefore takes in a centralposition within this framework.Compositional building block cluster (CBB-C) granularperspectivesAs already mentioned above, building blocks can aggre-gate to form bona fide entities that are not buildingblocks themselves. Each spatio-structural frame of refer-ence (i.e., atomic, molecular, single-membrane-enclosed,membrane-within-membrane, etc.) accommodates twodistinct categories of bona fide entities. The eukaryoticframe of reference, for instance, includes eukaryotic cellas well as bona fide cluster of eukaryotic cells. Whereasthe former is a building block and thus belongs to therespective granularity level of the CBB granular perspec-tive, the latter is not, because only the former is basedon the more restrictive causal unity via physical coveringas criterion for their bona fideness. The bona fideness ofbona fide cluster of eukaryotic cells, in contrast, is onlybased on the more general causal unity via internalphysical forces. However, because they represent aggre-gates of building blocks that can be partitioned into theircomponent object parts that belong to the samespatio-structural frame of reference, one cancharacterize the corresponding qualitative compositionalpartitions as compositional building block cluster(CBB-C) granular perspectives (see Fig. 5). Each CBBgranularity level has its own corresponding CBB-Cgranular perspective. This CBB-C granular perspective isbased on a direct proper parthood relation between in-stances of building blocks of a given spatio-structuralframe of reference and their corresponding bona fideclusters, and thus has the building-block-level-specificgranulation criterion (Fig. 5):X = a specific spatio-structural frame of reference.Like the CBB granular perspective, the CBB-C per-spective has a granulation of the non-scale dependentsingle-relation-type granularity type (nrG [61]) and isbased on the direct proper parthood relation as itsFig. 5 Set of Granular Perspectives within a given spatio-structural Frame of Reference. The figure shows all qualitative granular perspectives that thedomain granularity framework for the life sciences distinguishes for any given spatio-structural frame of reference and thus any corresponding CBBgranularity level (here, the set of perspectives for the eukaryotic cell level as an example). The large dark arrows indicate the granulation relation andthe white boxes contain the granulated entity types. a = Region-Based Fiat Building Block Part Granularity Perspective; b = Region-Based Fiat BuildingBlock Cluster Granularity Perspective; c = Region-Based Group of Building Block Level Objects Granularity Perspective; d = Region-Based Group of FiatBuilding Block Level Entities Granularity Perspective (see also Table 1)building block X directProperPartOf bona fide cluster of[building block]s X;bona fide clusterof [building block]s XhasDirectProperPart building block X;Vogt Journal of Biomedical Semantics            (2019) 10:4 Page 16 of 29granulation relation. Because the domain and range ofthe granulation relation differ according to the granula-tion criterion, the granulation relation is not transitiveand thus each of the CBB-C perspectives includes onlytwo distinct granularity levels.Region-based granular perspectivesBesides the two types of compositional granular perspec-tives, each spatio-structural frame of reference has itsown set of seven different associated region-basedgranular perspectives (for an overview, see Fig. 5). Thedifferent perspectives, together with their specific granu-lation criterion, granulation type, and granulation rela-tion are listed in Table 1. They differ only with respectto their granulation type, but they all share the samenon-scale dependent single-relation-type granularitytype (nrG [61]) and are all based on the proper parthoodrelation as their granulation relation.These seven general types of region-based granularperspectives result in a set of 49 different specificregion-based granular perspectives within the domaingranularity framework for the life sciences. This set issufficient to model all possible region-based partition re-lations between any given pair of spatio-structural en-tities for a given spatio-structural frame of reference.Function-based and history/evolution-based granularperspectivesIn analogy to the distinction between the CBB and theregion-based granular perspectives for spatio-structuralentities, one can also distinguish between a compos-itional functional unit (CFU) granular perspective (whichcorresponds with the mechanism-based approach toTable 1 List of Region-Based Granularity Perspectives for each given spatio-structural frame of reference (compare with Fig. 5); nrG= non-scale dependent single-relation granularity type, sgrG = scale-dependent grain size with respect to resolution [61]Level-Specific GranularityPerspectiveGranulation Criterion Granularity Type Granulation Relation # LevelsRegion-Based Building BlockCluster Granularity Perspectivefiat [building block] partfiat [building block] partgroup of fiat [buildingblock] level entitiesfiat [building block]clusterproperPartOfproperPartOfhasProperParthasProperPartgroup of fiat[building block]level entities ORfiat [building block]cluster;fiat [building block]part ORfiat [building block]partnrG proper parthood 2Region-Based Building BlockPart Granularity Perspectivefiat [building block] part[building block]properPartOfhasProperPart[building block];fiat [building block]partnrG proper parthood 2Region-Based Fiat BuildingBlock Aggregate GranularityPerspective[building block][building block]fiat [building block]clusterscattered fiat[building block] entityproperPartOfproperPartOfhasProperParthasProperPartfiat [building block]cluster ORscattered fiat[building block] entity;[building block] OR[building block]nrG proper parthood 2Region-Based Fiat BuildingBlock Part GranularityPerspectivefiat [building block] partfiat [building block] partproperPartOfhasProperPartfiat [building block]part;fiat [building block]partnrG proper parthood ?Region-Based Fiat BuildingBlock Cluster GranularityPerspectivefiat [building block]clusterfiat [building block]clusterproperPartOfhasProperPartfiat [building block]cluster;fiat [building block]clusternrG proper parthood ?Region-Based Group ofBuilding Block Level ObjectsGranularity Perspectivegroup of [building block]level objectsgroup of [building block]level objectsproperPartOfhasProperPartgroup of[building block]level objects;group of[building block]level objectsnrG proper parthood manyRegion-Based Group of FiatBuilding Block Level EntitiesGranularity Perspectivegroup of fiat [building block]level entitiesgroup of fiat [building block]level entitiesproperPartOfhasProperPartgroup of fiat[building block]level entities;group of fiat[building block]level entitiesnrG proper parthood ?Vogt Journal of Biomedical Semantics            (2019) 10:4 Page 17 of 29levels [119123]) and various region-based functional en-tity granular perspectives, as well as between a compos-itional historical/evolutionary unit (CH/EU) granularperspective and various region-based historical/evolution-ary entity granular perspectives respectively.The partition of a given functional unit or historical/evolutionary unit into components that themselves arefunctional units or historical/evolutionary units representsa qualitative compositional partition. The functional com-positional partition is based on a direct proper functionalparthood relation (which can be derived from the directproper parthood relation by restricting its domain andrange to instances of functional unit) between instancesof different sub-categories of functional unit (see nextchapter), which thus represents the granulation relation ofthe CFU granular perspective. Its granulation criterion is:The historical/evolutionary compositional partition, onthe other hand, is based on a direct proper historical/evolu-tionary (DirPropHistEvol) parthood relation (which can bederived from the direct proper parthood relation by restrict-ing its domain and range to instances of historical/evolu-tionary unit) between instances of different sub-categoriesof historical/evolutionary unit (see next chapter), whichthus represents the granulation relation of the CH/EUgranular perspective. Its granulation criterion is:According to Keets formal theory of granularity, bothperspectives have a granulation of the non-scale dependentsingle-relation-type granularity type (nrG [61]). Contraryto the CBB granular perspective, however, an underlyinghierarchy of levels of functional or historical/evolutionarybuilding blocks that defines the number of possible levelsof a CFU or CH/EU granular perspective, like the CBBgranular perspective does for spatio-structural entities, ismissing. Neither the CFU nor the CH/EU granular per-spective can be based on a hierarchy of monolithic levelsof functional or historical/evolutionary units that are glo-bally and universally applicable and reach across all do-mains of the life sciencesto stay within the metaphor: wedo not know realitys inventory of functional and histor-ical/evolutionary lego-bricks. Instead, representatives ofdifferent species, even different particular biological mater-ial entities, can substantially differ in the number andstructure of their CFU and CH/EU granular perspectives.Because we do not distinguish between differentsub-types of functional and historical/evolutionary causalunity, like we do with causal unity via internal physicalforces and via physical covering for spatio-structural en-tities, there is no analog for the CBB-C granular perspec-tive for functional and historical/evolutionary entities.However, one can differentiate various region-based func-tional and region-based historical/evolutionary granularperspectives in analogy to the various region-based granu-lar perspectives for spatio-structural entities, which I donot discuss here for lack of space.2nd step: Dealing with specific problems resulting fromthe cumulative constitutive Organization of RealityExtending and rearranging BFOs top-level category ofmaterial entity to accommodate different frames of referenceThe frame-dependence of the relevance of differenttypes of causal unity and the resulting differentiation ofthree basic categories of granular perspectives and theircorresponding basic frames of reference (i.e., spatio-structural, functional, historical/evolutionary), togetherwith the differentiation of spatio-structural frames of ref-erence in dependence on the number of granularitylevels identified for the CBB granular perspective (i.e.,atomic, molecular, etc.), reflect a basic distinction ofsub-categories of material entity. I therefore suggest thefollowing top-level classes for BFOs material entity (seeFig. 6). The classes functional entity, historical/evolu-tionary entity, and spatio-structural entity distinguishfoundational types of material entity based on theirunderlying type of causal unity, which is causal unity viabearing a specific function, causal unity via common his-torical/evolutionary origin, and causal unity via internalphysical forces, respectively. And because causal unity viaphysical covering supervenes on causal unity via internalphysical forces, the latter covers the former [98]. Becauseof the frame-dependence of the relevance of these differ-ent types of causal unity, these three classes are not dis-joint. As a consequence, some given material entity mayinstantiate functional entity, historical/evolutionary entity,and spatio-structural entity at the same time.On the basis of the identification of differentspatio-structural frames of reference, I can now suggest thefollowing top-level classes for spatio-structural entity:atom level entity, molecule level entity, organelle/prokary-otic cell level entity, eukaryotic cell level entity, epithelial-ly-delimited compartment level entity, epithelially-delimited multi-cellular organism level entity (see Fig. 6).Each of these categories corresponds with one of thespatio-structural frames of reference. Due to theframe-dependence, these six classes of spatio-structuralentity are also not disjoint, because some givenspatio-structural entity may be a molecule, but at the sametime also a fiat organelle part and a fiat eukaryotic cell part.functional unit directProperFunctionalPartOf functional unit;functional unit hasDirectProperFunctionalPart functional unit.hist/evol unit DirPropHistEvolPartOf hist/evol unit;hist/evol unit hasDirPropHistEvolPart hist/evol unit.Vogt Journal of Biomedical Semantics            (2019) 10:4 Page 18 of 29On the basis of (i) the identification of differentspatio-structural frames of reference, (ii) the implicationsof a cumulative constitutive organization of biologicalmaterial entities, and (iii) because bona fideness isgranularity- and thus frame-dependent [77, 98], I treatall bona fide and fiat entities from a given spatio-struc-tural frame of reference in coarser frames of reference asfiat entities. As a consequence, portion of matter entityis introduced as another top level class ofspatio-structural entity in addition to the set ofbuilding-block-level-specific classes. It refers to the rep-resentation of entities from a finer spatio-structuralframe of reference level at coarser frame-levels (see nextchapter and Figs. 6 and 8).Regarding the functional and historical/evolutionaryentities, one can only distinguish bona fide and fiat en-tities with respect to their corresponding frames of refer-ence. Therefore, functional entity has the top-levelclasses functional unit, which comprises all bona fidefunctional entities, and fiat functional unit part, whichcomprises all fiat functional entities respectively.Accordingly, one can distinguish historical/evolutionaryunit from fiat historical/evolutionary unit part. Becausefor functional and historical/evolutionary entities nobackbone granularity scheme exists that is comparableto the building block levels hierarchy and the associatedCBB granular perspective discussed above, no additionaldifferentiation into further subclasses is suggested. Onecould, of course, differentiate functional entities basedon the type of functions they bear and thus the type ofcorresponding processes (i.e., functionings), into func-tional units of locomotion, physiology, ecology, develop-ment, and of reproduction and propagation, andhistorical/evolutionary entities into historical units of de-velopment, heredity, and of evolution and developmen-tal, genealogical and evolutionary lineages [77].Because each spatio-structural frame of reference in-cludes not only the corresponding building block and itsbona fide aggregates, but also their corresponding fiatbuilding block parts and fiat building block aggregates,each direct subclass of spatio-structural entity includesall corresponding fiat and bona fide entities. In otherwords, I interpret BFOs categories object, object aggre-gate, fiat object part as being applicable to eachspatio-structural frame of reference. Therefore, I con-sider the distinction between fiat and bona fide materialentities to be foundational for each spatio-structuralframe of reference. Taking the eukaryotic cell level en-tity (i.e., membrane-within-membrane frame of refer-ence) as an example, this approach results in the basicdistinction of eukaryotic cell level object and fiateukaryotic cell level entity (see Fig. 7).The eukaryotic cell level object corresponds withBFOs object category. Depending on which type ofFig. 6 Top-Level Subclasses of material entity and spatio-structural entity. The labeled grey boxes represent classes. The class spatio-structuralentity is characterized in reference to causal unity via internal physical forces, functional entity in reference to causal unity via bearing a specificfunction, and historical/evolutionary entity in reference to causal unity via common historical/evolutionary origin. As a consequence of theperspective-dependence of bona fideness, these three classes are not disjoint. The functional and historical/evolutionary entities are furtherdifferentiated according to disjoint categories of bona fide units and fiat unit parts. Spatio-structural entities are further differentiated incorrespondence with the granularity levels of the compositional building block granular perspective (see discussion in text), ranging from atom levelentity to epithelially-delimited multi-cellular organism level entity, but include not only the respective bona fide entities of that level, but also theircorresponding object aggregate and fiat object part entities. Because bona fideness is not only perspective-dependent, but also granularity-dependent, each building block level has its own spatio-structural frame of reference and thus its own perspective. Due to the cumulative-constitutiveorganization of biological entities, entities from finer spatio-structural frames of reference (e.g., molecules) must be represented in coarser frames ofreference (e.g., eukaryotic cell) as fiat portions of matter. These representations are covered through the portion of matter entity class (see also Fig. 8)Vogt Journal of Biomedical Semantics            (2019) 10:4 Page 19 of 29causal unity is relevant for the given object entity, I dis-tinguish two types of objects for each spatio-structuralframe of reference and thus two subclasses for each dir-ect subclass of spatio-structural entity. On the onehand the entities that belong to the corresponding CBBgranularity level, which are objects that are based on themore specific causal unity via physical covering. In thecase of eukaryotic cell level object this would beeukaryotic cell (see Fig. 7), or molecule in the case ofmolecule level object. On the other hand, because build-ing blocks can aggregate to form bona fide clusters basedon the more general causal unity via internal physicalforces, another object category is required to deal withthese types of objects. Thus, eukaryotic cell level objectwould not only have eukaryotic cell as its direct subclass,but also bona fide cluster of eukaryotic cells, for example,those cells that together build an epithelium (which pro-vides the physical covering of the building block entities ofthe next coarser spatio-structural frame of reference). Or,in case of molecule level object, bona fide cluster of mol-ecules can form a bio-membrane or a chitin cuticula, bothof which are bona fide objects that are based on causalunity via internal physical forces (as opposed to the build-ing block itself, which is additionally based on causal unityvia physical covering).These building block level objects are contrasted withfiat building block level entities, which cover BFOs fiatobject part and object aggregate and comprise all mater-ial entities that possess spatio-structurally no causal unity(neither via internal physical forces nor via physical cover-ingnote that this fiatness depends on the granularitylevel of the building block entity, which provides the rele-vant spatio-structural frame of reference in this context).Fiat building block entities can be further differenti-ated based on whether they are spatio-structurallyself-connected, giving rise to two distinct subclasses. Incase of fiat eukaryotic cell level entity this results in thedistinction of self-connected fiat eukaryotic cell entityand scattered fiat eukaryotic cell entity (Fig. 7).Self-connected fiat entities can be further differentiatedinto fiat building block parts and thus the building blocklevel specific correlate to BFOs fiat object part, and fiatbuilding block clusters. For the eukaryotic cell level, theformer would translate into fiat eukaryotic cell part andthe latter into fiat eukaryotic cell cluster, respectively. Ascattered fiat entity, on the other hand, can be furtherdifferentiated based on the type of its scattered compo-nent parts. If all scattered component parts are buildingblock level objects that correspond to the relevantspatio-structural frame of reference, the scattered entityis a group of building block level objects (e.g., group ofeukaryotic cell level objects). However, if at least one ofits component parts is a fiat building block level entity,the scattered entity is a group of building block levelFig. 7 Top-Level Subclasses of eukaryotic cell level entity. Eukaryotic cell level entities are differentiated into a bona fide eukaryotic cell levelobject and a fiat eukaryotic cell level entity class, which are disjoint. The former is differentiated based on its underlying type of causal unity intoeukaryotic cell, which is based on physical covering, and bona fide cluster of eukaryotic cells, which is based only on internal physical forcesand not on physical covering. The fiat eukaryotic cell level entities are differentiated based on their self-connectedness into the disjoint subclassesself-connected fiat eukaryotic cell entity and scattered fiat eukaryotic cell entity. See text for more detailsVogt Journal of Biomedical Semantics            (2019) 10:4 Page 20 of 29entities (e.g., group of fiat eukaryotic cell level entities)(see Fig. 7). For a distinction of (i) groups based onmetric proximity as the relation between its parts versus(ii) clusters based on topological adherence as the rela-tion between its parts see Vogt et al. [87, 124].Consequence from the cumulative constitutive organizationof biological material entities and the frame-dependence oftheir representationThe abovementioned direct subclasses of spatio-struc-tural entity must accommodate all types of material en-tities found in cumulative-constitutively organizedbiological material entities. Therefore, its sub-classes al-ways refer to the building block entity of the correspond-ing spatio-structural frame of reference, independent ofwhether finer-level entities are also involved. In otherwords, eukaryotic cell or fiat eukaryotic cell part com-prise all types of eukaryotic cell or eukaryotic cell part en-tities, with and without associated portions of connectedECM, and epithelially-delimited compartment comprisesall types of epithelially-delimited compartments, with andwithout associated portions of connected molecular mat-ter and portions of connected tissue (see also Figs. 4 and5). Therefore, when we talk about a eukaryotic cell cluster,this can refer to a cluster of cells with surrounding ECM,but it could also refer to a cluster of cells without sur-rounding ECM. This is a rather pragmatic choice, asthe alternative would require distinguishing variouscategories to cover each possible combination of dif-ferent levels of building block entities that can befound in a cumulative constitutive organization, whichwould result in a tremendous increase in top-levelclasses [87, 124]. This would neither be convenientand intuitive to use, nor really necessary.Because biological material entities are usuallycumulative-constitutively organized (see discussionabove), entities of finer building block levels can existoutside of building blocks of coarser levels, for instance,molecules outside of eukaryotic cells. Unfortunately,these finer level entities cannot be covered with the cat-egories of the coarser levels, since they are neither bonafide objects nor fiat object parts entities of this objectlevela molecule that exists outside of eukaryotic cellsdoes neither represent a eukaryotic cell level object nora fiat eukaryotic cell level entity. In other words, the ad-equate classes for referring to these entities belong to adifferent and finer spatio-structural frame of reference.However, respective entities still must be represented inthe frame of reference of the coarser level (see sorta-tion-by-type and type granularity trees problematic dis-cussed in chapter Biological Reality: The Problem withthe Cumulative Constitutive Hierarchy, see Fig. 2). Asalready mentioned above, I therefore introduce the classportion of matter entity. For instance, eukaryotic cellclusters and single eukaryotic cells, as well as moleculeclusters and single molecules, can exist outside ofepithelially-delimited compartments (see also Fig. 2).However, none of the subclasses of epithelially-delimitedcompartment level entity can accommodate these mater-ial entities. They therefore must be covered by the classesportion of molecule entity and portion of eukaryotic cellentity respectively, which are frame-of-reference-specificsubclasses of portion of matter entity (see Figs. 6 and 8).A portion of matter is a non-countable entity (c.f.masses [125]; amount of matter [126]; portion of un-structured stuff [127]; see also body substance [64]; andportion of body substance [56]). In order to count thenumber of component parts of a portion of matter, onewould have to change the spatio-structural frame of ref-erence from the current frame to a frame of a finer levelthat corresponds with the component parts of that por-tion. Thus, a cluster of molecules, for instance, the chitincuticula that forms the exoskeleton in insects, which is abona fide cluster of chitin molecules and thus instanti-ates molecule level object at the molecular frame of ref-erence, is represented as a self-connected (fiat) portionof molecular matter at all coarser spatio-structuralframes of reference. The individual molecules that buildthe cluster cannot be individually differentiated anymoreat reference levels coarser than the molecular level, be-cause their bona fideness disintegrates at these coarserlevels [87], which is why all portions of matter aretreated as fiat entities. If a portion of matter consists ofa mixture of building block entities of differentspatio-structural frames of reference such as a portion ofconnective tissue that is a group of cells embedded in acluster of collagen molecules, the coarsest building blockentity is used for classifying it, which in this case wouldbe a portion of connective tissue. Portions of tissue al-ways refer to cell aggregates. Most cells in multi-cellularorganisms are surrounded by a complex cluster of mole-cules, i.e., the ECM.Because entities belonging to a finer spatio-structuralframe of reference are always represented as non-count-able fiat portions of matter in coarser spatio-structuralframes of reference, one can only distinguish betweenself-connected and scattered portions. In case of portionof eukaryotic cell entity, one can thus distinguish self--connected portion of eukaryotic cell tissue from scat-tered portions of eukaryotic cell tissue respectively (seeFig. 8).Cross-granular multiple instantiationDue to its granular nature, any given biological materialentity always instantiates several different material entitycategories at the same time, one for each spatio-struc-tural frame of reference [87]. For example, every in-stance of eukaryotic cell instantiates at finer frames ofVogt Journal of Biomedical Semantics            (2019) 10:4 Page 21 of 29reference also bona fide cluster of molecules and bonafide cluster of atoms, because a eukaryotic cell is a bonafide composition of clustered molecules and at the sametime also a bona fide composition of clustered atoms. Atcoarser frames of reference it also instantiatesframe-specific classes. Which class is instantiated atthose coarser frames, however, depends on the particulareukaryotic cell. If it exists outside of any epithelially-delimited compartment, it is not covered by anylevel-specific subcategory of epithelially-delimited com-partment entity and therefore instantiates some categoryof portion of eukaryotic cell entity (see discussion inprevious chapter). If it is part of an epithelially-delimitedcompartment it instantiates fiat epithelially-delimitedcompartment part.One could, of course, define a class eukaryotic cell, aclass maximal cellular molecule cluster, and a classmaximal cellular atom cluster and all these three classeswould have the same extension, although they belong todifferent frames of reference; and according to theprinciple of extensionality of class logic, these classeswould be identical from a logics point of view. However,from an epistemic point of view, due to the frame- andgranularity-dependence of bona fideness, these classescannot be strictly synonymized [87]. Therefore, whendealing with biological material entities we necessarilyhave to deal with multiple cross-granular instantiations[87] of subcategories of material entity, all of which donot stand in a subsumption relation to one another.Their requirement is a necessary consequence of the factthat every building block level has its own associatedspatio-structural frame of reference.Results II: Additional granular perspectivesGranular representation and resolution-basedrepresentation (RBR) granular perspectivesA consequence of the abovementioned situation of mul-tiple cross-granular instantiation is that each particularbiological material entity necessarily instantiates multiplesubclasses of material entity. This can be modeledthrough providing a URI for each representation. Inorder to indicate that these URIs refer to the same con-crete thing in reality, the resources must be adequatelyrelated to one another. Therefore, a specific strict partialordering relation, i.e., granular representation relation, isintroduced, which can be differentiated into has coarsergranular representation and its inverse relation, has finergranular representation. It has spatio-structural entityas its range and its domain. This relation gives rise to agranular partition, a scale-based resolution granular par-tition. Scale-based, because the CBB granularity perspec-tive can be interpreted to provide a scale that is basedon the ordering of CBB granularity levels from the finestto the coarsest level. Resolution, because each individualresource refers to the same concrete material entity, butrepresents it in its level-specific resolution. Thisscale-based resolution granular partition also covers thenon-countable portion of matter entity granular repre-sentations of a given particular material entity that caninstantiate identical subclasses of portion of matterFig. 8 Top-Level Subclasses of portion of matter entity. The entities of each building block level, except for the coarsest level of epithelially-delimitedmulti-cellular organisms, can be represented as a respective portion of matter entity in coarser spatio-structural frames of reference. Therefore, portionof matter entity is differentiated into building block level specific subclasses. Further differentiations are shown for the classes portion of moleculeentity and portion of eukaryotic cell entity, which are based on whether the entity is a self-connected portion of matter, for instance, a portion ofECM or a portion of connective tissue, or a group of scattered portions, for instance, the group of portions of muscle tissues in a human beingVogt Journal of Biomedical Semantics            (2019) 10:4 Page 22 of 29entity across several spatio-structural frames of refer-ence (see Fig. 2c).As a consequence, the entities that belong to the samescale-based resolution granular partition are only differentgranular representations of the same particular materialentity, with each granular representation directly linked toa specific spatio-structural frame of reference [87].On the basis of this granular representation relation,and in addition to the various qualitative granular per-spectives discussed so far, one can differentiate severalquantitative scale-based granular perspectives (cf. [58]).This is required to formally model the specific relation be-tween resources that refer to different granular represen-tations of the same particular material entity in variousfiner and coarser spatio-structural frames of reference.All resolution-based representation (RBR) granularperspectives are based on the combination of the CBBgranular perspective and a strict partial ordering granu-lar representation relation between instances of differentsubclasses of spatio-structural entity that belong to dif-ferent spatio-structural frames of reference. The possibil-ities for distinguishing different types of RBR granularperspectives is extensive and results from the differentrange and domain combinations for the granulation rela-tion, with each unique combination resulting in a uniquegranulation criterion. Here, however, I will only discussthe most general and inclusive type of RBR granular per-spective that has the granulation criterion (Fig. 9):X = a specific spatio-structural frame of reference; X +1 = the next coarser spatio-structural frame of referenceadjacent to X.This perspective has a granulation of the scaledependent grain-size-according-to-resolution granularitytype (sgrG [61]). It is based on the granular representa-tion relation as its granulation relation. Because thisRBR granular perspective directly depends on the CBBgranular perspective, the number of its granularity levelscorresponds with the number of CBB granularity levels.Resolution-based Countability representation (RBCR)granular perspectivesThe RBR granular perspective does not differentiatewhether a representation is of the countable buildingblock level entity kind (e.g., atom level entity, moleculelevel entity) or the non-countable portion of matter en-tity kind, as it allows all kinds of spatio-structural en-tities to be granulated. In order to identify changes fromcountable to non-countable representations of a givenreal entity across different spatio-structural frames ofreference, two complementary resolution-based count-ability representation (RBCR) granular perspectives aresuggested. For this reason the following two granularcountability representation relations are introduced: (i)has coarser non-countable granular representation(co_n-c_GranRep), with some building block level entity(e.g., eukaryotic cell level entity) as its domain and por-tion of matter entity as its range, together with its in-verse relation has finer countable granularrepresentation (fi_c_GranRep), and (ii) has coarsercountable granular representation (co_c_GranRep), withportion of matter entity as its domain and some build-ing block level entity as its range, together with its in-verse relation has finer non-countable granularrepresentation (fi_n-c_GranRep). On the basis of thesetwo relations two complementary RBCR granular per-spectives can be distinguished: (i) countable tonon-countable RBCR granular perspective, and (ii) non--countable to countable RBCR granular perspective. Thecountable to non-countable perspective has the granula-tion criterion (Fig. 9):The non-countable to countable perspective has thegranulation criterion:X = a specific spatio-structural frame of reference; X +1 = the next coarser spatio-structural frame of referenceadjacent to X.These two complementary perspectives have both agranulation of the scale dependent grain-size-according-to-resolution granularity type (sgrG [61]). Each is basedon its respective granular countability representation re-lation as its granulation relation. Because the domainand range of their respective granulation relation differ,the granulation relation is not transitive and thus bothRBCR granular perspectives comprise only two distinctgranularity levels.Function-based representation (F-BR) and historical/evolution-based representation (H/E-BR) granular perspectivesThe functional frame of reference requires its owngranular representation due to cross-granular multipleinstantiation (analogue to cross-granular multiplespatio-structuralentity XhasCoarserGranRep spatio-structural entity X + 1;spatio-structuralentity X + 1hasFinerGranRep spatio-structural entity X;spatio-structural entity X co_n-c_GranRep portion of matter entity X + 1;portion ofmatter entity X + 1fi_c_GranRep spatio-structural entity X;portion of matter entity X co_c_GranRep spatio-structural entity X + 1;spatio-structural entity X + 1 fi_n-c_GranRep portion of matter entity X.Vogt Journal of Biomedical Semantics            (2019) 10:4 Page 23 of 29instantiation as a consequence of multiple spatio-struc-tural frames of reference). This function-related granularrepresentation is required because some instances ofspatio-structural entity are at the same time also in-stances of functional unit. The filter apparatus of a ter-minal cell of a protonephridium, for instance, instantiatesfiat eukaryotic cell part, because the filter apparatus con-sists of the cells cilium, a filter and a set of microvilli, butnot the other parts of the terminal cell. The filter appar-atus, however, also instantiates functional unit, because itfunctions as a filter during excretion.The historical/evolutionary frame of reference also re-quires its own granular representation due to cross-granularmultiple instantiation. Every anatomical entity that is ahomologue and that thus instantiates historical/evolution-ary unit also instantiates spatio-structural entity.Fig. 9 Resolution-Based Representation (RBR) and Resolution-Based Countability Representation (RBCR) Granularity Perspective. The different levelsof the RBR granular perspective are granulated according to the has coarser granular representation relation (the white broad arrows). Thegranulation is of the scale dependent grain-size-according-to-resolution granularity type (sgrG [61]). The two levels of each of the two RBCRgranular perspectives, on the other hand, are granulated according to the has coarser non-countable granular representation relation and the hasfiner countable granular representation relation, respectively (dotted gray arrows). Their granulation is of the scale dependent grain-size-according-to-resolution granularity type (sgrG [61]). All three perspectives use the combination of the granulation relation together with the scale providedthrough the set of different spatio-structural frames of reference that are sequentially ordered through the associated CBB granular perspective(i.e., the building block levels hierarchy). As a consequence, the RBR granular perspective comprises six granularity levels, whereas the two RBCRgranular perspectives each comprise only two granularity levels, because their granulation relation is not transitive (its domain and range differ)Vogt Journal of Biomedical Semantics            (2019) 10:4 Page 24 of 29For this reason the following two granular representa-tion relations are introduced: (i) has functional granularrepresentation (FuncGranRep), with spatio-structuralentity as its domain and functional entity as its rangeand its inverse relation functional has spatio-structuralgranular representation (FuncSp-StrGranRep), and (ii)has historical/evolutionary granular representation(Hist/EvGranRep), with spatio-structural entity as itsdomain and historical/evolutionary entity as its rangeand its inverse relation historical/evolutionary hasspatio-structural granular representation (Hist/EvSp-Str-GranRep). On the basis of these two relations twogranular perspectives can be distinguished: (i) a func-tion-based representation (F-BR) granular perspectiveand (ii) a historical/evolution-based representation (H/E-BR) granular perspective. The F-BR granular perspec-tive has the granulation criterion:The H/E-BR granular perspective has the granulationcriterion:These two perspectives have both a granulation of thescale-dependent grain-size-according-to-resolution granu-larity type (sgrG [61]). Resolution is here used in the senseof depending on a specific frame of reference that func-tions like a lens for filtering out all aspects irrelevant tothe given frame of reference. Each is based on its respect-ive granular representation relation as its granulation rela-tion. Because in both perspectives the domain andrange of the respective granulation relations differ, thegranulation relations are not transitive. Consequently,both granular perspectives comprise only two distinctgranularity levels.DiscussionThe here proposed approach for the development of adomain granularity framework for the life sciences com-prises a core set of granular perspectives that can be uti-lized for efficiently managing large semantic graphs thatcontain data about material entities that range fromatoms to multi-cellular organisms and beyond. Thegranularity framework provides a meta-layer that (i) de-fines the relations between entities that belong to differ-ent granularity levels of the same granular perspectiveand between entities across different granularperspectives; (ii) integrates various frames of referencewithin a single framework, all of which are essential forthe life sciences, ranging from purely spatio-structuralframes of reference, to functional, developmental, eco-logical, and evolutionary frames of reference; (iii) im-proves searching and navigating through large complexgraphs by using one or a combination of several granularperspectives as filters and for efficiently utilizing thehierarchical structure inherent in the semantic graphs;and (iv) facilitates reasoning and inferencing by provid-ing additional hierarchical structures that can be usedfor measuring semantic similarities between different se-mantic graphs and between resources within a graph.This domain granularity framework complies withCravers [23] claim of descriptive pluralism about thelevels idea. It comprises various hierarchies of differentlevels. The compositional building block (CBB) granularperspective (Fig. 4) takes in a key position in the frame-work, because it provides the backbone hierarchy thatfacilitates the integration of all the other granular per-spectives. The CBB granular perspective resembles apurely compositional account of the levels idea, withoutmaking the mistake to mix entities relevant in differentframes of reference (see problems discussed further aboveregarding Eldredges somatic hierarchy [9]). Furthermore,with its focus on physical covering and evolving buildingblocks, the CBB granular perspective is also influenced bythe evolutionary systems-theoretical accounts of the levelsidea, thereby integrating purely spatio-structural consider-ations with functional and evolutionary aspects. The set ofregion-based granular perspectives, on the other hand, donot have a pre-defined structure in terms of a fix numberof granularity levels, but must be determined on a localcase-by-case approach, thereby reflecting one of the criti-cism regarding the single compositional hierarchy of thecompositional account of the levels idea (for the compos-itional account of levels see [4, 29, 33, 117, 128, 129]; forcritique of this approach see [44, 130133]).The set of functional parthood-based granular per-spectives resemble the mechanism-based account of thelevels idea [119123]. The lack of a globally applicablegeneral granular perspective comparable to the CBBgranular perspective for functional parthood thereby re-flects that functional parthood-based granularity levelsdepend on a given mechanism (i.e., a function, andtherefore also a causal process) and thus are local,case-specific, and cannot result in a universal schemethat is globally applicable [120]. And finally, the differentspatio-structural frames of reference, with their diversesets of parthood-based granular perspectives, togetherwith the granular perspectives mediating between theseand other frames of reference, reflect many aspects thatWimsatt [4, 35, 117, 134] discussed in his prototypicalaccount of levels of organization.spatio-structural entity FuncGranRep functional entity;functional entity FuncSp-StrGranRep spatio-structural entity.spatio-structural entity Hist/EvGranRep historical/evolutionary entity;historical/evolutionaryentityHist/EvSp-StrGranRep spatio-structural entity.Vogt Journal of Biomedical Semantics            (2019) 10:4 Page 25 of 29Although this domain granularity framework for thelife sciences comprises all these different accounts of thelevels idea, it nevertheless is characterized and definedin a formally coherent framework that integrates allthese diverse granular perspectives. There might be con-ceptually and computationally simpler and more elegantsolutions to the theoretical, conceptual, and computa-tional challenge of modeling the granularity ofcumulative-constitutively organized (biological) materialentities, but these solutions model the hierarchies foundin reality incorrectly. It seems that if we want to do just-ice to the complex nature of reality, our models must becomplex as well.ConclusionA domain granularity framework based on Keets theoryof granularity would not only provide a much neededconceptual framework for representing domains thatcover multiple granularity levels such as anatomy/morphology or the life sciences in general, but also astructure that can be utilized for providing users a moreintuitive experience when navigating and exploring datarepresented as semantic graphs in knowledge bases andcontent management systems of the life sciences. Theframework could, for instance, be used for querying agiven semantic graph in order to retrieve any partitionexpressed in the graph that corresponds with the granu-lar perspective that the user is interested in. The frame-work can contain various such perspectives, each ofwhich can be applied on a given semantic graph orknowledge base to the effect of filtering out all informa-tion irrelevant to this particular perspective, thereby sub-stantially facilitating a desperately needed system thatsupports browsing and navigating through increasinglycomplex semantic graphs (i.e., datasets).If the hierarchical order of the various granular per-spectives contained in a domain granularity frameworkreflects reality, the framework would provide a hierarch-ical structure that could be meaningfully employed forreasoning over different granularity levels and even dif-ferent granular perspectives, thereby providing a meth-odological basis for effectively establishing comparabilitybetween different semantic graphs, which can be usedfor automatic assessment and measurement of semanticsimilarity between different semantic graphs. Being ableto quantitatively measure degrees of similarity betweensemantic graphs would provide new means for analyzingall kinds of data from the life sciences (e.g., [135137].AbbreviationsBFO: Basic Formal Ontology; CBB: Compositional Building Block; CBB-C: Compositional Building Block Cluster; CFU: Compositional Functional Unit;CH/EU: Compositional Historical/Evolutionary Unit; ChIN: Character IdentityNetwork; co_c_GranRep: Has-Coarser-Countable-Granular-Representationrelation; co_n-c_GranRep: Has-Coarser-Non-Countable-Granular-Representation relation; DirPropHistEvolPartOf: Direct-Proper-Historical/Evolutionary-Part-Of relation; ECM: Extracellular matrix; evo-devo: Evolutionarydevelopmental biology; F-BR: Function-Based Representation;fi_c_GranRep: Has-Finer-Countable-Granular-Representation relation; fi_n-c_GranRep: Has-Finer-Non-Countable-Granular-Representation relation;FuncGranRep: Has-Functional-Granular-Representation relation; FuncSp-StrGranRep: Functional-Has-Spatio-Structural-Granular-Representation relation;H/E-BR: Historical/Evolution-Based Representation; hasCoarserGranRep: Has-Coarser-Granular-Representation relation; hasDirPropHistEvolPart: Has-Direct-Proper-Historical/Evolutionary-Part relation; hasFinerGranRep: Has-Finer-Granular-Representation relation; Hist/EvGranRep: Has-Historical/Evolutionary-Granular-Representation relation; Hist/EvSP-StrGranRep: Historical/Evolutionary-Has-Spatio-Structural-Granular-Representation relation;npG: Non-scale dependent primitive granularity type; nrG: Non-scaledependent single-relation-type granularity type; OBO Foundry: OpenBiomedical Ontologies Foundry; RBCR: Resolution-Based CountabilityRepresentation; RBR: Resolution-Based Representation; sgrG: Scale dependentgrain-size-according-to-resolution granularity type; URI: Uniform ResourceIdentifierAcknowledgementsI thank Thomas Bartolomaeus, Peter Grobe, Björn Quast, Ludger Jansen, andBarry Smith for commenting on an earlier draft of this MS. It goes withoutsaying, however, that I am solely responsible for all the arguments andstatements in this paper. I am also grateful to the taxpayers of Germany.This work was supported by grant VO 1244/8-1 from the German ResearchFoundation DFG. I am also grateful to the taxpayers of Germany.FundingThis work was supported by grant VO 1244/81 from the German ResearchFoundation DFG. I am also grateful to the taxpayers of Germany.Availability of data and materialsNot applicable.Authors contributionsLV: developed the particular building blocks approach, the differentgranularity perspectives and their relations with one another, and drafted themanuscript. The author read and approved the final manuscript.Ethics approval and consent to participateNot applicable.Consent for publicationNot applicable.Competing interestsThe author declares that he has no competing interests.Publishers NoteSpringer Nature remains neutral with regard to jurisdictional claims inpublished maps and institutional affiliations.Received: 24 September 2018 Accepted: 14 January 2019Chiu et al. Journal of Biomedical Semantics            (2019) 10:2 https://doi.org/10.1186/s13326-018-0193-xDATABASE Open AccessA neural classification method forsupporting the creation of BioVerbNetBilly Chiu1* , Olga Majewska1, Sampo Pyysalo1, Laura Wey2, Ulla Stenius3, Anna Korhonen1and Martha Palmer4AbstractBackground: VerbNet, an extensive computational verb lexicon for English, has proved useful for supporting awide range of Natural Language Processing tasks requiring information about the behaviour and meaning of verbs.Biomedical text processing and mining could benefit from a similar resource. We take the first step towards thedevelopment of BioVerbNet: A VerbNet specifically aimed at describing verbs in the area of biomedicine. BecauseVerbNet-style classification is extremely time consuming, we start from a small manual classification of biomedicalverbs and apply a state-of-the-art neural representation model, specifically developed for class-based optimization, toexpand the classification with new verbs, using all the PubMed abstracts and the full articles in the PubMed CentralOpen Access subset as data.Results: Direct evaluation of the resulting classification against BioSimVerb (verb similarity judgement data inbiomedicine) shows promising results when representation learning is performed using verb class-based contexts.Human validation by linguists and biologists reveals that the automatically expanded classification is highly accurate.Including novel, valid member verbs and classes, our method can be used to facilitate cost-effective development ofBioVerbNet.Conclusion: This work constitutes the first effort on applying a state-of-the-art architecture for neural representationlearning to biomedical verb classification. While we discuss future optimization of the method, our promising resultssuggest that the automatic classification released with this article can be used to readily support application tasks inbiomedicine.Keywords: Verb lexicon, Representation learningBackgroundNatural Language Processing (NLP) and text mining ofbiomedical literature are critically important for the man-agement of rapidly growing literature in biomedical sci-ences. Core bio-NLP technologies such as syntactic andsemantic parsing, event identification, relation extrac-tion, and entailment detection can all benefit from richcomputational lexicons containing information about thebehaviour and meaning of words in biomedical texts.While relatively well-developed resources are available fornouns in biomedicine (e.g. UMLS Metathesaurus, [1]),*Correspondence: hwc25@cam.ac.ukBilly Chiu and Olga Majewska contributed equally to this work.1Language Technology Laboratory, MML, University of Cambridge, 9 WestRoad, CB39DB Cambridge, UKFull list of author information is available at the end of the articleverb-related resources are still lacking in both depth andcoverage [26].One particularly useful verb resource for generaldomain NLP is VerbNet [7]. Providing detailed syn-tactic and semantic information for English verbs, thisbroad-coverage resource has proved useful in supportinga wide variety of NLP tasks and applications, includingword sense disambiguation [8], semantic role labelling [9],semantic parsing [10], information extraction [11] andtext mining applications [12, 13], among others.Our ultimate aim is to create BioVerbNet  thefirst VerbNet for supporting NLP and text mining inbiomedicine. However, because manual VerbNet-styleclassification is a highly expensive and time-consumingtask, we first investigate a data-driven approach to the cre-ation of this resource. Previous works have shown thatwhile an unsupervised verb clustering approach based© The Author(s). 2019 Open Access This article is distributed under the terms of the Creative Commons Attribution 4.0International License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, andreproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to theCreative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver(http://creativecommons.org/publicdomain/zero/1.0/) applies to the data made available in this article, unless otherwise stated.Chiu et al. Journal of Biomedical Semantics            (2019) 10:2 Page 2 of 12on conventional NLP has the advantage of discover-ing novel verb classes from corpus data with minimalprior knowledge, such automatically acquired classes nec-essarily contain quite a lot of noise [14]. Conversely,when training data is available, supervised verb clas-sification can yield higher precision. Korhonen et al.(2006) manually developed a VerbNet-style gold stan-dard for evaluation of automatic verb classification inbiomedicine [15] (detailed in Automatic verb classifica-tion section). We take this resource as a starting pointin supervised classification aimed at finding novel mem-ber verbs and classes in data, with the idea that humanevaluators can validate the output and use the correctclassifications as a starting point for the development ofBioVerbNet.Most existing methods for automatic verb classifica-tion rely heavily on feature engineering, which is time-consuming and requires expert knowledge [16]. Hence, weautomate the process of feature learning by using a neu-ral learning approach, followed by the application of theNearest Centroid Classifier to assign verbs into classes.We encode word features into a low-dimensional spaceusing neural networks [1719]. Neural word represen-tations (embeddings) serve now as invaluable featuresin a broad range of NLP tasks, including named entityrecognition [2022] and text classification [23, 24]. Neuralrepresentation models such as the skip-gram model withnegative sampling (SGNS) are highly efficient in captur-ing syntactic and semantic properties of words in corporaand are therefore intuitively useful also for VerbNet-styleclassification [25].Our methodology consists of two steps: First, we applythe recent method by Vulic´ et al. [26] to identify best con-texts for learning biomedical verb representations. Themethod, based on the skip-gram model with negativesampling (SGNS), has produced successful results in thegeneral domain but has not previously been applied tospecialised domains such as biomedicine. It involves firstcreating a context configuration space based on depen-dency relations between words, followed by applying anadapted beam search algorithm to search this space for theclass-specific contexts, and finally using these contexts tocreate class-specific representations.In this work, we apply the method to a large biomedicalcorpus: the PubMed Central Open Access subset [27] andall the PubMed abstracts, consisting of about 10 billionstokens and 27 million word types in total. We evaluatethe trained representations against a gold standard aimedat capturing verb similarity in biomedicine (BioSimVerb,[6]). Our results show that when the model is optimizedwith context configuration for verbs, it outperforms thebaseline model (a standard SGNS without verb-specificcontexts) significantly, yielding a 5 point improvement inSpearmans rank correlation (referred to as ? henceforth).In the second step, the optimized representation is usedto provide word features for building a verb classifica-tion. This is obtained by expanding the small manuallydeveloped VerbNet-style classification of 192 biomedi-cal verbs by Korhonen et al. [15] (details in Automaticverb classification section) with 957 new candidate verbs.The candidate verbs are chosen from BioSimVerb (detailsin Verb classification section), based on their frequentoccurrence in biomedical journals across 120 subdomainsof biomedicine (as categorized by Broad Subject Terms[28]). This ensures the wide coverage of verb classifica-tion ideal for the development of BioVerbNet. We use theNearest Centroid Classifier to connect the new candidatesto an appropriate class in the resource of Korhonen et al.[15]. The resulting classification provides 1149 verbsassigned to the 50 classes in the original resource. It lists,for each verb, the most frequent dependency contextsthat reflect their syntactic behaviour along with examplesentences.Qualitative evaluation of the automatically expandedclasses by linguists and biologists reveals that the methodis highly accurate: the vast majority of the novel mem-bers verbs and classes are legitimate. The method cantherefore be used to greatly facilitate the developmentof BioVerbNet by hypothesizing novel classifications forexpert validation. We discuss further optimization of themethod for real-life computational lexicography, but ourpromising results suggest that the automatic classificationreleased with this article can be used to readily supportNLP application tasks in biomedicine.Apart from proposing an automatic approach to thecreation of BioVerbNet, our study provides an investi-gation of how different types of dependency-based con-texts influence the learning of verb representations inbiomedicine. The optimal context configuration proved tobe highly domain-specific. Our results and insights canfacilitate researchers to develop useful methods for train-ing class-specific representations for biomedical NLP. Theresources are publicly available to the research commu-nity under an Open Data license at: https://github.com/cambridgeltl/bio-verbnet.Related workComputational verb lexiconsVerbNet [7] is the most extensive verb lexicon currentlyavailable in the general domain. It consists of verbsgrouped into classes based on their shared syntactic andsemantic properties, such as syntactic frames, semanticroles of arguments, etc. For example, the members (e.g.delete and discharge) in the verb class Remove have similarframes and meaning, and can be used to describe sim-ilar events. VerbNet classes have supported many NLPtasks, such as word sense disambiguation [8], informationextraction [11] and text mining applications [12, 13]. TheChiu et al. Journal of Biomedical Semantics            (2019) 10:2 Page 3 of 12current version of VerbNet (v3.3) consists of 9344 verbsorganised in 329 main classes [29]. Although it has a widecoverage for general domain NLP applications, it is notdesigned for specialized domains, such as biomedicine,where verbs tend to have a very different meaning andbehaviour than in general English [2, 3]. Hence, there isa need to develop domain-specific resources to supportbiomedical NLP.Some large lexical resources, such as UMLS Metathe-saurus [1], can be found in the biomedical domain. How-ever, most of them focus on nouns and do not provide agood coverage of other important word classes like verbs.The lexicons which cover biomedical verbs are usuallysmaller in scale and limited to certain sub-domains inbiomedicine. For example, the UMLS SPECIALIST lex-icon [30], which is created manually by lexicographers,mainly contains medical and health-related vocabularies.On the other hand, the BioLexicon [31]  a corpus-drivenlexicon which contains syntactic and semantic frameinformation for verbs  is extracted from the EscherichiaColi (E.Coli) domain, which limits its usefulness to appli-cations that deal with other sub-domains of biomedicine.Automatic verb classificationVerb classification links together syntactic and semanticproperties of groups of verbs by means of lexical classes.Such grouping can reduce the parameters used for repre-senting verbs individually. While it is time-consuming tomanually classify a large number of verbs, previous stud-ies have shown that it is possible to automatically acquireverb classes from both general [3235] and biomedicaltexts [15, 36, 37]. For example, Li and Brew (2008) classify1,300 verbs into 48 Levin classes using Bayesian Multi-nomial Regression for classification [38]. A range of verbfeatures have been explored in their works, includingthe dependency relations between the arguments and theprepositions. On the other hand, Sun (2013) uses rich fea-tures based on the predicate-argument structure (e.g. verbRESEARCH Open AccessDevelopment of a cardiac-centered frailtyontologyKristina Doing-Harris1* , Bruce E. Bray2,3, Anne Thackeray4, Rashmee U. Shah2, Yijun Shao5, Yan Cheng5,Qing Zeng-Treitler5, Jennifer H. Garvin3,6 and Charlene Weir3,6AbstractBackground: A Cardiac-centered Frailty Ontology can be an important foundation for using NLP to assess patientfrailty. Frailty is an important consideration when making patient treatment decisions, particularly in older adults,those with a cardiac diagnosis, or when major surgery is a consideration. Clinicians often report patients frailty inprogress notes and other documentation. Frailty is recorded in many different ways in patient records and manydifferent validated frailty-measuring instruments are available, with little consistency across instruments. Wespecifically explored concepts relevant to decisions regarding cardiac interventions. We based our work on textfound in a large corpus of clinical notes from the Department of Veterans Affairs (VA) national Electronic HealthRecord (EHR) database.Results: The full ontology has 156 concepts, with 246 terms. It includes 86 concepts we expect to find in clinicaldocuments, with 12 qualifier values. The remaining 58 concepts represent hierarchical groups (e.g., physical functionfindings). Our top-level class is clinical finding, which has children clinical history finding, instrument finding, andphysical examination finding, reflecting the OGMS definition of clinical finding. Instrument finding is any score foundfor the existing frailty instruments. Within our ontology, we used SNOMED-CT concepts where possible. Some ofthe 86 concepts we expect to find in clinical documents are associated with the properties like ability interpretation.The concept ability to walk can either be able, assisted or unable. Each concept-property level pairing gets adifferent frailty score. Each scored concept received three scores: a frailty score, a relevance to cardiac decisionsscore, and a likelihood of resolving after the recommended intervention score. The ontology includes therelationship between scores from ten frailty instruments and frailty as assessed using ontology concepts. It alsoincluded rules for mapping ontology elements to instrument items for three common frailty assessmentinstruments. Ontology elements are used in two clinical NLP systems.Conclusions: We developed and validated a Cardiac-centered Frailty Ontology, which is a machine-interoperabledescription of frailty that reflects all the areas that clinicians consider when deciding which cardiac intervention willbest serve the patient as well as frailty indications generally relevant to medical decisions. The ontology owl file isavailable on Bioportal at http://bioportal.bioontology.org/ontologies/CCFO.Keywords: Ontology, Frailty, Surgery, Cardiology, SNOMED-CT* Correspondence: kdoingharris@gmail.com1Nuance Communications, Burlington, MA, USAFull list of author information is available at the end of the article© The Author(s). 2019 Open Access This article is distributed under the terms of the Creative Commons Attribution 4.0International License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, andreproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link tothe Creative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver(http://creativecommons.org/publicdomain/zero/1.0/) applies to the data made available in this article, unless otherwise stated.Doing-Harris et al. Journal of Biomedical Semantics            (2019) 10:3 https://doi.org/10.1186/s13326-019-0195-3BackgroundFrailty and cardiac decision makingFrailty is an important patient attribute for treatment de-cisions in general [14] because assessing frailty severitypredicts response to treatment and patient outcomesacross many conditions [2, 510]. In the modern era ofinterventional cardiac care, patient frailty is increasinglyimportant to decisions regarding major cardiac surgeryand interventional procedures [1, 9, 11]. With the grow-ing numbers of elderly and diabetic patients [6, 12],these decisions are common [13]. Older, frail patientswith aortic valve stenosis can now be referred forcoronary artery bypass graft surgery (CABG), a trans-catheter valve replacement (TAVR), or medical manage-ment [1416]. While TAVR is minimally invasive withshorter length of stay, frail patients may not necessarilybenefit due to non-cardiac illnesses that limit quality oflife or increase risk of procedural complications [11, 17],including increased length of stay, infection rates, andre-hospitalization. In 2015, the National Institute onAging cited frailty assessment as a key priority in theperioperative approach to cardiac surgery [13].Assessing frailty is done by intuitive estimates or ap-praisals, counting comorbid conditions, and the use offormal assessment instruments [2, 18, 19]. Frailty can in-clude physical disability, deficits in mood, sensorium,and cognition, along with patient experience of pain orincontinence [3, 6].The purpose of this paper is to describe the devel-opment of an ontology of frailty, paying special atten-tion to how it relates to cardiac care decisions. Ourontology is designed to access the aspects of frailtythat distinguish it from a simple count of comorbidconditions. We describe a necessary and sufficientview of patient frailty indicators apart from comorbidconditions. This ontology has been designed to allowcomputerized extraction of frailty information fromthe narrative documents patient records. Becausefrailty is a topic that is interpreted in many ways andmeasured with several instruments [5, 1820], webuilt our ontology using as many term identificationtechniques as possible, gathering terms using existentinstruments, physician interviews, and automatedchart reviews. We aimed to allow cross walking be-tween the measurement instruments. The hierarchicalstructure was adapted from SNOMED-CT [21] butexpanded and informed by the nuances in clinicaldecision-making. We tested a draft version of ourontology by creating instrument-scoring rules, byusing it to improve automated detection of frailty in-dicators in a Natural Language Processing (NLP) sys-tem, and by using it as an input feature to a systemtrained to predict patient mortality after a major car-diovascular procedure (MCVP) [22].Frailty and NLPGiven that frailty information is so important, extract-ing it from clinical records is vital for patient careand research. The three methods of extracting infor-mation from clinical records are structured data, hu-man chart review, or automated NLP systems. Thereare 3 reasons why an NLP approach is likely to bethe most successful: 1) physicians do not consistentlyuse frailty instruments, 2) there is no key, which rec-onciles scores across instruments, 3) they do not alluse the same definition of frailty.Clinicians collect frailty information, but not in asystematic fashion nor by consistently using frailty in-struments [20]. They document narrative descriptionsof frailty information that they find relevant to thespecific clinical situation. It is possible that since cli-nicians believe they can rapidly use their clinical judg-ment to assess a patients frailty when they see them[18], they do not feel the need to systematically usespecific frailty instruments. Their narrative notationsare considered sufficient. However, large-scale retro-spective studies of patient outcomes require chart re-view, and if frailty is largely documented in narrative,then structured text cannot be used and the effort ofwading through text in a chart causes a time bottle-neck for human reviewers.The inconsistent use of frailty instruments would notmatter for chart review based on structured informationif there were a method for reconciling scores from dif-ferent instruments. The method would create equiva-lences between the instruments. These equivalenceswould take as many factors into account as possible.Creating score equivalence metrics would be a task thathumans would find challenging.If clinicians all used a similar definition of frailty,humans chart review or NLP systems without ontologycomponents would be able to locate their descriptionseasily, but they do not. Clinicians ideas about whichpatients are frail are influenced by both the culturewithin their organizational department, the decision athand, and the wider society. For example, departmentalculture may involve specific frailty tests (e.g., 6-minwalk distance) and social culture may mean that frailtyindicators have different thresholds (e.g., low body massindex (BMI) in Japan vs. the US [23].) Frailty indicatorsare also specific to each patient. A patients level of mo-bility is highly dependent on prior exercise activities,desire for exercise, and the patients personal prefer-ences. The number of frailty instruments that havebeen developed evidences the variability in the concep-tion of frailty, and therefore the complexity of the rela-tionship between frailty and decision-making. Buta, etal. [20] identified 67 frailty instruments of which ninewere cited more than 200 times.Doing-Harris et al. Journal of Biomedical Semantics            (2019) 10:3 Page 2 of 16Since current charting practices make human chartreview or using structured data untenable, one couldforce a structured data solution by picking a single in-strument and screen all patients. Picking a single in-strument and screening everyone is hampered by thelow specificity of current instruments [4, 20] and bylack of instrument adoption. In addition, frailty assess-ment varies substantially over time. Assessing all indi-viduals over time would be necessary to understand thetrajectory and implications of frailty [4], which wouldmean that the structured data solution would only be-come helpful after a significant time-interval. Systemat-ically conducting frailty assessments at all encounterswould fail to highlight decision-specific frailty issues, itwould add a substantial burden to the clinician, andcost to the healthcare system.Ontology buildingOntologies may be used in NLP projects to bridge struc-tured data fields. Some structured data fields from clin-ical records across institutions or even within the sameinstitution use different words to denote the same infor-mation (e.g., patient name vs. lastname, firstname)[2426]. Ontologies are also used for named entity rec-ognition and decision modeling [2729]. For example,named entity recognition can locate all mentions of dis-orders that patients may have as well as relevant patientdemographics. Decision modeling uses either the namedentities found or other inputs to access ontological ele-ments, which contribute to creating rules or othermodels of decisions. Our ontology of patient frailty isdesigned to fulfill both purposes.We employed the standard methodology for buildingontologies including reconciling clinical text, medical lit-erature, and existing ontologies [26, 3032]. We choseto develop our ontology by adhering as closely as pos-sible to realist principles. Realist principles lead to stableontologies [33], which can be reasoned with while avoid-ing illogical inferences [34].We conceptualized clinical records as textual record-ings of the authors ideas about the patient. An existingontological concept that corresponds to the authorsideas about the patient is clinical finding from theOntology of General Medical Science (OGMS), which isdefined as A representation that is either the output ofa clinical history taking or a physical examination or animage finding, or some combination thereof. [35] Incontrast, the definition of a clinical finding used inSNOMED-CT is observations, judgments or assess-ments about patients. The definition specifies that it isdesigned to convey the actual state of the body andis inclusive of concepts with a semantic tag disorder(http://browser.ihtsdotools.org/). By referring directly tothe patients body and not the clinicians findings, one isignoring consideration of human error, cognitive biases,and other aspects that may influence patient-clinicianand clinician-EHR interactions [36, 37]. However,SNOMED-CTs definition of clinical finding also in-cludes concepts with the semantic tag finding, which are not separate from the observing of them, whichbrings them closer to the OGMS definition. We re-stricted ourselves to findings.Integration with prior workTwo prior studies have successfully mined frailty infor-mation from rehabilitation and nursing home notes.One generated International Classification of Function-ing, Disability and Health (ICF) codes and the otherextracted Barthel index scores [38, 39]. Their workindicates that it is possible to locate and extractfrailty-relevant terms. We expanded their work by in-creasing the number of frailty-related terms identified.The UMLS Metathesaurus [40] contains a complexstructure of frailty-related concepts. It is evident thatSNOMED CT contributes concepts from many, if not all,of the available frailty instruments. However, the UMLSMetathesaurus is not realist due to long-standing require-ments of backward compatibility [33, 41, 42]. We wantedour ontology to be interoperable with as many otherontologies as possible. We did not want to create some-thing that entirely ignored the UMLS Metathesaurus.Recent papers have discussed realist approaches, specific-ally with respect to SNOMED-CT [33, 41, 43, 44]. Com-patibility with SNOMED-CT can be used as a bridge tothe UMLS Metathesaurus. Therefore, we incorporatedSNOMED-CT concepts into the Cardiac-centered FrailtyOntology as often as possible, but did not limit ourselvesto SNOMED-CT.ObjectiveIn this study we created a machine-interoperable de-scription of frailty that reflects all the areas that clini-cians consider when deciding which cardiac interventionwill best serve the patient as well as general indicationsof frailty found in patient records.ResultsIn this section we describe each of the four phases ofontology development (Identify other ontologies and of-ficial clinical tools, group terms into high-level classes,define attributes of classes, analyze and validate), whichled to the final ontological structure.Phase 1  Collect terms by identifying other ontologiesand official clinical toolsThe research team met regularly to iteratively identifyterms from a variety of sources. We reviewed 14 frailtyinstruments described in the methods section (below).Doing-Harris et al. Journal of Biomedical Semantics            (2019) 10:3 Page 3 of 16The terms from these instruments were mapped ontothe UMLS meta-thesaurus. If there was a SNOMED-CTterm we used it.In addition, we interviewed 12 clinicians (cardiologists,geriatricians, and cardiac surgeons) where we provided 7hypothetical patient vignettes. Clinicians were asked todiscuss patient frailty in relation to a decision betweenCABG, TAVR, and medical management. Each hypothet-ical patient had a different mix of frailty indicators. Thefull study will be described in a separate paper. Theterms found in the interviews included muscle weakness,oxygen need, gait velocity, 6-min walk distance, volun-teers, lower extremity strength, robust, functional status,functionality, deconditioned, acute vs. chronic findingsand BMI. We identified terms at the level of conceptgranularity relevant to cardiac decision-making. For ex-ample, terms relating to housework (e.g., dusting,washing dishes, and vacuuming) were grouped into asingle concept ability to perform domestic activities be-cause whether a patient is dusting or vacuuming is notrelevant to their cardiac health.In order to filter the terms into unique groups to aidthe next step of creating hierarchies, the total set ofterms underwent an initial sorting by the research teamto identify explicit synonyms and concepts. The termswere found to correspond to the general categories oftoileting, mental health, social functioning, working, ex-ercise, walking, eating, general health, bathing, dressing& grooming, transfers, and modifiers (i.e., body locationsand qualifiers). Using these groupings, we had an initialset of 108 unique concepts.For those 108 concepts, we identified 198 uniqueconcept-related terms. Terms within concepts were fur-ther expanded by SNOMED-CT synonyms and aug-mented by the teams previous experience with clinicaldocuments. After the term expansion, nearly all of theconcepts had either 1 or 2 terms, while one concept had12 terms. The concept with the most terms was Lack ofenergy finding, with lack of energy, tired, fatigue,lack energy, tiredness, sleepiness, drowsiness, ex-haustion, exhaust, wear out, drain, and weary.Our clinician interviews made it clear that cliniciansrely heavily on the Society of Thoracic Surgeons (STS)score in assessing patients likelihood of surviving sur-gery. We examined the STS calculation and found it wasmore sensitive to comorbid conditions than indicationsof frailty. The clinicians also indicated that comorbidconditions are often included in assessments of patientfrailty. Since we were interested in creating an ontologyof frailty apart from comorbid conditions, we only in-cluded the concept comorbid conditions count, not spe-cific conditions the patient might have.A second term expansion was done using automatedchart review. Terms found included stagger as indicativeof the concept impairment of balance finding, prosthet-ics, shoes, gripping strength, fatigue, weakness,SOB, short of breath, dyspnea, muscle strength,motor strength, decreased strength, assist, para-lyzed, handicap, unassisted, dresses, bathes, andstand. Some terms were removed because they com-monly occurred with a meaning alternate to the one wewere after. These terms included dressing, supine,working, eating, strength, incontinence.After all terms had been gathered we had 246 termsassociated with the 108 concepts.Phase 2  Group terms into high-level conceptsThe identified frailty concepts were arranged in hier-archical relationship by mapping them to SNOMED-CTequivalents using SNOMED-CT concepts within the cat-egory clinical finding, with semantic type finding. Thegoal for this process was to restrict the SNOMED-CTmappings to as small a selection as possible, while main-taining correspondence, which means our ontology issomewhat compatible with SNOMED-CT.Figure 1 shows the top concepts in our Cardiac-centeredFrailty Ontology. In order to create an ontology that isinteroperable with SNOMED-CT, it is important thatwhere concepts in the two ontologies share a name and anid number they are used to represent precisely the sameportion of reality. Therefore, if we did not match the exactuse described by SNOMED-CT, we explain why and donot use the SCTID.As discussed in the introduction, we did not use clin-ical finding in the same way as SNOMED-CT, we re-stricted ourselves to the subset with semantic tagfinding. Therefore, we did not use the SNOMED-CT IDnumber for the concept clinical finding. Our conceptClinical finding (CCFOID:1) has children clinical historyfinding (CCFOID:11), instrument finding (CCFOID:12),and physical examination finding (CCFOID:13), reflectingthe OGMS definition of clinical finding. Instrument find-ing is any score found for the existing frailty instrumentsalready mentioned. We included classes not mapped toSNOMED-CT for demographics (CCFOID:14) and quali-fier values for the properties of our concepts in our toplevel.In the Cardiac-centered Frailty Ontology we includeddemographics in clinical findings because we are refer-ring to demographic information collected by theclinician at a clinical visit, not to the demographic infor-mation that inheres in the patient and may change be-tween visits.Clinical history findingThe obvious choice for findings arising from the pa-tients clinical history taking is clinical history and obser-vation finding (finding) (SCTID: 250171008). It turnsDoing-Harris et al. Journal of Biomedical Semantics            (2019) 10:3 Page 4 of 16out that all of the children listed in the SNOMED-CTbrowser (http://browser.ihtsdotools.org) have semantictype finding, which is what we were after. Like clinicalfinding, we do not want to include all the children ofclinical history and observation finding, which means weare not referring to the same portion of reality. Syn-onymous terms and the SNOMED-CT term identifica-tion number (SCTID) are not necessary because we arenot looking for the concept to be represented in clinicaldocuments. For these reasons, we shorten the name toclinical history finding and exclude the SCTID.The same problem arises when we try to find aSNOMED-CT equivalent of physical function finding(CCFOID:112). The topic modeling, our interviewswith clinicians, and existing instruments all indicatethat the patients physical abilities are a necessarycategory. The closest SNOMED-CT equivalent isfunctional finding (finding) (SCTID: 118228005),which has among its children concepts we need, forexample finding of activity of daily living (finding)(SCTID: 118233009, CCFOID:1124). However, it in-cludes findings unrelated to physical abilities like doescomply with treatment (SCTID: 386673006). There-fore, we do not use functional finding and leave phys-ical function finding, with no SCTID.SNOMED-CT is so exhaustive that there can behierarchical structure that is beyond our needs. Socialand personal history finding (SCTID: 365448001,CCFOID:115) has two intervening problem parentsfinding by method and history finding, which lead toclinical finding and not clinical history and observationfinding. There is no indication in the documentationFig. 1 Top three layers of concepts in the Cardiac-centered Frailty OntologyDoing-Harris et al. Journal of Biomedical Semantics            (2019) 10:3 Page 5 of 16about how history finding differs from clinical historyand observation finding. The children of Social andpersonal history finding and psychological finding(SCTID: 116367006, CCFOID:113) that we are inter-ested in also have intervening concepts. It may be bet-ter practice to just use the SCTIDs for the lowestlevels. Those will be the only ones used in the NLP.Alteration in comfort finding (SCTID: 130979001,CCFOID:111) has the intervening parent problemsensory nervous system finding (finding) (SCTID:106147001) and neurological finding (finding) (SCTID:102957003), which go to clinical finding (finding). Thecourses qualifier value (CCFOID:43) concept we includecorresponds to the SNOMED clinical finding attributeclinical course. We also include a concept for seen by aprofessional allied to medicine finding because the snip-pet annotations indicated that being seen by physicaltherapy, occupational therapy or other allied professionsindicated patient frailty.Physical examination findingWe included in Physical Examination Finding(CCFOID:13) concepts that fall in the SNOMED-CThierarchy under general findings of observation of patient(finding) (SCTID: 118222006). In SNOMED-CT generalfinding of observation of the patient is a child of clinicalhistory and observation finding. Since we did not includeobservation in our concepts, we included this separateconcept for physically observing the patient. We took avery restricted subset of the children of general findings ofobservation of patient (finding), hence the name changeand absence of SCTID. The children we included arephysical deconditioning finding (SCTID: 31031000119102,CCFOID:134), dyspnea on exertion finding (SCTID:60845006, CCFOID:131), muscle weakness of limb finding(SCTID: 713514005, CCFOID:133), weight finding(SCTID: 107647005, CCFOID:135), and general well-beingfinding (SCTID: 365275006, CCFOID:132).Physical deconditioning has no children. We includedall of the children of muscle weakness of limb becausethey separate upper and lower limbs, which our inter-views indicated is an important distinction. Weight find-ing has many irrelevant children including finding ofcolor zone for Broselow Luten pediatric weight estimation(finding). We did not include these children.For dyspnea on exertion finding, and Generalwell-being finding, we kept the SCTID because we couldmap all of the children, although this is not currentlypart of the ontology. For the children not currently ex-plicitly listed, we would need to determine whether theywere indicative of high or low frailty. We added the con-cept comorbid condition count finding (CCFOID:131),which we discussed earlier, as a child of generalwell-being finding.The full ontology has 156 concepts, with 246 terms.The ontology owl file is available on Bioportal at http://bioportal.bioontology.org/ontologies/CCFO. We con-sider CCFO a view into SNOMED-CT. We defineview in accordance with the Ontology Views Project be-ing done by the Structural Informatics Group at Washing-ton University (http://sig.biostr.washington.edu/projects/ontviews/). In this definition a view is a new ontology thatincludes some portion of the viewed ontology. CCFO con-tains portions of SNOMED-CT. It is therefore a view ofSNOMED-CT. As a view, it falls under SNOMED-CTsexisting licensure (https://www.snomed.org/snomed-ct/get-snomed).Table 1 shows the number of concepts by their num-ber of terms. The table lists the number of terms associ-ated with each of the 86 concepts we expect to find inclinical documents. The remaining 58 concepts, not inthe table, represent hierarchical groups (e.g., physicalfunction findings) and 12 qualifier values. Two conceptsfrom demographics (CCFOID:14) have no terms (patientage finding, CCFOID:141 and indeterminate sex finding,CCFOID:1422). Lack of energy finding (CCFOID:132222)still has the highest number of terms.Table 2 lists some important concepts and their asso-ciated terms. The term list is included as Additional file1. Since terms are not synonyms for the concepts in theontology, they are not included in the ontology itself.Terms are text that we consider indicative of the au-thors thoughts about the concept. Concepts themselvesare portions of reality, not pieces of text.Phase 3  Define object properties for conceptsConcept properties were determined by rating scalesused in the instruments. Activities have a frequencyproperty that is found in the SNOMED-CT frequencyqualifier value (SCTID: 272123002, CCFOID:44) re-stricted to high frequency qualifier value (SCTID:27732004, CCFOID:441) and mid-frequency (SCTID:255218000, CCFOID:442). Frequency values contrastwith a value of absent finding qualifier value (SCTID:272519000, CCFOID:42). Possible values are restrictedbased on the likelihood of finding specific text qualifiers.Abilities have an ability interpretation property that isfound in ability interpretation qualifier value (SCTID:371148001, CCFOID:41). These values are also restrictedto able qualifier value (SCTID: 371150009, CCFOID:412),able with difficulty qualifier value (SCTID: 371157007,Table 1 Breakdown of the number of terms per concept in theCardiac-centered Frailty Ontology. These counts are for the 86concepts that we expect to find in clinical documents# terms 1 2 3 4 5 6 7 8 > 8# concepts 24 29 7 8 6 5 0 3 4Doing-Harris et al. Journal of Biomedical Semantics            (2019) 10:3 Page 6 of 16CCFOID:411) and unable qualifier value (SCTID:371151008, CCFOID:413). Finally, all clinical findingshave a course property from courses qualifier value(SCTID: 288524001, CCFOID:43), including chronicqualifier value (SCTID: 90734009, CCFOID:431), clinicalcourse with short duration qualifier value (SCTID:424572001, CCFOID:432), and sudden onset qualifiervalue (SCTID: 385315009, CCFOID:433).More properties of the concepts were determinedby scores of relevance to cardiac decisions and theirlikelihood of resolving after the recommended inter-vention. Three investigators and three interview par-ticipants scored 81 of the 84 concepts that weexpected to find in clinical documents. Three con-cepts were added after scoring was complete (abilityto drive a car finding CCFOID:11241, quadricepsweakness finding CCFOID:1334, and calf weaknessfinding CCFOID:1331).For the 81 concepts that were scored, ability conceptswere qualified with the able qualifier values (able/inde-pendent, with difficulty/assisted, and unable/dependent)each concept-value pair was given a separate score. Ac-tivity and mental state concepts were qualified with fre-quency qualifier values (high frequency, mid-frequency,absent) and scored seperately. Rockwood categories asdescribed in the Dalhousie University Clinical FrailtyScore [45] were averaged across the eight raters. Ratingsof low, medium, or high for relevance to frailty andfix-ability where set to the majority rating for the sixraters, who had clinical experience.Only three concepts were given low relevance to frailtyratings by all six raters calm finding (CCFOID:113331),happy finding (CCFOID:113332), and nervous finding(CCFOID:113333) concepts from the mental state find-ing (CCFOID:11333) concept. Fifty-two concepts wererated as highly relevant by all six raters, nine by at leastthree raters. Thirteen concepts had relevancy ratings ofmedium by all six raters, four by at least three raters.Table 3 shows the findings for nine concepts central tothe assessment of frailty. Ability to participate in leisureactivities finding (CCFOID:112412) is included in Table 3to demonstrate a cardiac intervention-specific concept.Table 2 List of concepts central to assessing frailty and theirassociated terms. Terms are not synonymous with the conceptor the concept name. They indicate author may have beenthinking about the concept. Bolded terms were not found inthe topic modeling paper. Underlined terms were added by theannotation taskConcept Terms (not synonyms)ability to run finding Difficulty running; able to run; unableto run; runability to stand finding Difficulty standing up; unable to stand up;able to stand up; stand upable to mobilize finding ambulate independently; steady gait;unsteady gaitbed-ridden finding bed-ridden; supine; stretcherParalysis finding paralysis; paralyzedwheelchair bound finding wheelchair; scooter; w/c; wheel chairable to perform dressingactivity findingdresses; Able to dress; independent withdressing; Needs help with dressing;Dependent for dressing; unable to dress;Difficulty dressing; shoes; ties shoes;able to perform personalgrooming activity findingAble to wash own hair; Unable to washown hair; Difficulty washing own hair;clean appearance; personal grooming;neatly dressed; well-groomed;well-groomed without assistance;good personal hygieneTable 3 Scores for nine concepts central to the assessment of frailty. Rockwood scores are on a scale of 1 - very fit to 9  terminallyill. They are averaged across raters. Will fix refers to clinical findings that the cardiac intervention will alleviate. Relevance is howimportant the concept is to decisions about cardiac interventions. L  low, m  medium, h  highConcept Rockwood Will Fix RelevanceAble With Difficulty Unableability to run finding 1 3.33 4 M Hability to stand finding 2.67 5.11 7.44 TIED L+ Hable to mobilize finding steady gait3unsteady gait 6 M Hbed-ridden finding Only level8L HParalysis finding Paraplegic6Quadriplegic8L TIED M+wheelchair bound finding Only level6M Hable to perform dressing activity finding 3 4 7 L Hable to perform personal grooming activity finding 1 4 7 L Hability to participate in leisure activities finding 2 3 5.5 H HDoing-Harris et al. Journal of Biomedical Semantics            (2019) 10:3 Page 7 of 16We determined which concepts are specific to cardiacintervention decisions by using the difference between rat-ings for will fix and relevance (in Table 3). Will fix refersto findings the cardiac intervention will alleviate; whilerelevance refers to findings that our reviewers indicatedwere relevant to frailty. We considered concepts that arehighly relevant to frailty and are either highly likely to bealleviated by cardiac intervention or are associated witheventual recovery, to be especially important. For instance,bed-ridden is seen as generally relevant and not specific-ally relevant to cardiology. Enjoys light exercise finding(CCFOID:11231), ability to participate in leisure activitiesfinding (CCFOID:112412), dyspnea on exertion finding(CCFOID:131), and fit and well finding (CCFOID:1323)are all rated as specifically relevant to cardiology as well asbeing generally relevant. Thirty-two concepts are rated asmoderately specific to cardiology and 45 were given lowcardiology-specific ratings.In this section, we also looked at the mapping instru-ment scores found in the clinical document set to frailtyscores from Rockwood categories as described in theDalhousie University Clinical Frailty Score [45]. Table 4lists the instruments and their scoring criteria.Phase 4 - analyze and validateWe created implementation rules to map ontology ele-ments to instrument questions for three common instru-ments. The rules for these three instruments (Barthelindex, Katz ADLs, and SF-36) are listed in Table 5. Notethat the mappings are not one-to-one. Some of the in-strument questions were mapped to equivalent concepts.For example, both Barthel index and Katz ADLs usesthe parent concepts ability to perform personal care ac-tivities (SCTID: 284774007) to include feeding self,dressing, grooming, toileting, and washing oneself, andability to transfer location (SCTID: 714882001). By cre-ating implementation rules, we were able to demonstratethat the Cardiac-centered Frailty Ontology covered thetopics used in the instruments.In addition, we conducted preliminary NLP analysisusing the ontology. We wanted to determine if narrativetext that included frailty terms also included enough in-formation to determine whether the patient hadfrailty-related functional deficits. Frailty terms from theCardiac-centered Frailty Ontology and from a priorstudy [46] were used. We extracted 2460 clinical recordsnippets centered at the frailty keyword terms. ThreeTable 4 Instrument scores found in clinical document set and the scoring criteria, which allow the NLP system to use the scores todetermine indication of frailtyInstrument Name Scoring CriteriaActivities of Daily Living (ADL) Screen 18 patient independent6 patient very independentFunctional Independence Measure (FIM) 7-complete independence;6-modified independence;5-Supervision or step-up;4-Minimal Contact Assistance;3-Moderate Assistance;2-Maximal Assistance;1-Total AssistanceKatz index ADL Score of 6 = High, Patient is independent.Score of 0 = Low, patient is very dependent.Barthel index ADL: 70100 = Independent;Less than 70 = Needs significantphysical/supervisory assistance.Instrumental activities of daily living (IADL) 2 = without assistance,1 = with assistance,0 = unableInstrumental activities of daily living (IADL)scale (Lawton) / IADL ScreenThe total score may range from 0 to 8.A lower score indicates a higher level of dependence.Functional Activity Questionnaire (FAQ) Score of 5 or more indicates significant impairmentin instrumental activities of daily living.Morse fall scale / Annual Fall Scale / MRT > = 45: high fall risk2544: moderate risk024: low riskTinetti assessment measures Maximum possible balance score: 16 points.Maximum possible gait score: 12 points.Maximum total score: 28 points. -Scores below19 indicate high risk for falls.Scores in the 1924 range indicatesome risk for falls.Braden scale Pressure Ulcer Risk:total score < =9 very high risktotal score 1012 high risktotal score 1314 moderate risktotal score 1518 mild risktotal score 1923 no riskDoing-Harris et al. Journal of Biomedical Semantics            (2019) 10:3 Page 8 of 16Table 5 Examples of Frailty Instruments implemented with the Cardiac-centered Frailty OntologyFrailty Insrument: Barthell IndexIncontinence finding (CCFOID:11271) of either kind = 0Continence finding (CCFOID:11271) or absent qualified incontinence finding of both kinds = 2Able to perform personal care activities finding (CCFOID:11244) for each of its children:unqualified or able = 2with difficulty = 1unable = 0Ability to transfer location finding (CCFOID:1122)(any one) = 2Absent (CCFOID:42) qualified = 0Able (CCFOID:412) qualified able to mobilize finding (CCFOID:112121) or no aid for walking finding (CCFOID:112472) = 3Able with difficulty (CCFOID:411) qualified able to mobilize finding or walking aid use finding (any kind) = 2wheelchair bound finding (CCFOID: 1121223) = 1unable (CCFOID:413) qualified able to mobilize finding or bed-ridden finding (CCFOID:1121221) = 0Able qualified able to walk upstairs finding (CCFOID:1124713) or able to walk downstairs finding (CCFOID:1124711) = 2Unable qualified able to walk upstairs finding = 0Barthell Index ScoringAdd up the score: 20 = no disability 0 = complete disabilityFrailty Instrument: Katz  ADLsCount the number of:Each of the able qualified ability to perform personal care activities finding (bathing, dressing, toileting, feeding)(CCFOID:11244) = 1Unable qualified = 0Any able qualified ability to transfer location finding (CCFOID:1122) = 1Unable qualified = 0Both unqualified continence finding or absent qualified incontinence finding of either kind = 1Unqualified Incontinence finding of either kind = 0Katz - ADLs ScoringAdd up the score: 6 = high functioning 0 = low functioningFrailty Instrument: SF-36Average the following for General Health score:Questions 1, 33, 34, 35, 36First assessment covers 5 questions, 1 score.unqualified or high frequency (CCFOID:441) qualified fit and well finding = 100mid-frequency (CCFOID:442) qualified fit and well finding = 75absent qualified generally unwell finding (CCFOID:1324) = 50mid-frequency qualified generally unwell finding = 25unqualified or high frequency qualified generally unwell finding = 0Question 2unqualified or high frequency qualified fit and well finding with sudden onset (CCFOID:433) qualification = 100mid-frequency qualified fit and well finding with sudden onset qualification = 75absent qualified generally unwell finding = 50generally unwell finding:mid-frequency qualified = 25unqualified or high frequency = 0Average the following for Pain scoreQuestion 21absent qualified alteration in comfort: pain finding (CCFOID:1111) = 100mid-frequency qualified alteration in comfort: pain finding = 50high frequency qualified alteration in comfort: pain finding = 0Question 22absent qualified alteration in comfort: pain finding, with able qualified able to carry out daily routine finding (CCFOID:11245) = 100mid-frequency qualified alteration in comfort: pain finding, with able qualified able to carry out daily routine finding = 75high-frequency qualified alteration in comfort: pain finding, with able qualified able to carry out daily routine finding = 50mid-frequency qualified alteration in comfort: pain finding, with difficulty qualified able to carry out daily routine finding = 25high-frequency qualified alteration in comfort: pain finding, with unable or with difficulty qualified able to carry out daily routine finding = 0Average the following for Physical Functioning score:Question 3high frequency qualified enjoys vigorous exercise finding (CCFOID:11233) or able qualified ability to run finding (CCFOID:11213) = 100mid-frequency qualified enjoys vigorous exercise finding = 50gets no exercise finding or unable qualified ability to run finding or absent qualified enjoys vigorous exercise finding = 0Question 4high frequency qualified enjoys moderate exercise finding (CCFOID:11232) = 100mid-frequency qualified enjoys moderate exercise finding = 50gets no exercise finding or unable qualified ability to run finding or absent qualified enjoys moderate exercise finding = 0Question 5able qualified ability to perform general purpose physical activity finding (CCFOID:11243) or able qualified ability to perform shopping activities finding(CCFOID:112413) = 100Doing-Harris et al. Journal of Biomedical Semantics            (2019) 10:3 Page 9 of 16clinicians and two informatics researchers reviewed thesnippets. They categorized them as: a) Yes Deficit, or b)other. We trained a classifier on the snippets using asupport vector machine (SVM). The average SVM per-formance, using 10-fold cross validation, achieved an ac-curacy score of 80.5%. Since frail patients typically haveTable 5 Examples of Frailty Instruments implemented with the Cardiac-centered Frailty Ontology (Continued)with difficulty qualified ability to perform general purpose physical activity finding or with difficulty qualified ability to perform shopping activities finding =50unable qualified ability to perform general purpose physical activity finding or unable qualified ability to perform shopping activities finding = 0Question 6 & 7This covers 2 question (scores twice) able qualified able to walk upstairs finding = 200with difficulty qualified able to walk upstairs finding = 100unable qualified able to walk upstairs finding = 0Question 8able qualified able to kneel finding (CCFOID:11211) = 100with difficulty qualified able to kneel finding = 50unable qualified able to kneel finding = 0Questions 911This covers 3 question (scores three times) able qualified able to walk finding (CCFOID:112471) = 300with difficulty qualified able to walk finding = 200unable qualified able to walk finding = 0Question 12able qualified ability to perform personal care activities finding = 100with difficulty qualified ability to perform personal care activities finding = 50unable qualified ability to perform personal care activities finding = 0Average the following for Role Limitations due to Physical Health score:Question 1315This covers 3 question (scores three times) absent qualified occupational maladjustment finding (CCFOID:1154) = 300mid-frequency qualified occupational maladjustment finding = 150high-frequency qualified occupational maladjustment finding = 0Question 16able qualified able to carry out daily routine finding = 100with difficulty qualified able to carry out daily routine finding = 50unable qualified able to carry out daily routine finding = 0Average the following for Role Limitations due to Emotional Problems scoreQuestion 1719This covers 3 question (scores three times) absent qualified occupational maladjustment finding and any psychological finding (CCFOID:113) = 300mid-frequency qualified occupational maladjustment finding and any psychological finding = 150high-frequency qualified occupational maladjustment finding and any psychological finding = 0Average the following for Energy/Fatigue scoreQuestions 23, 27, 29, 31 (1 score)able qualified able to sustain energy level finding (CCFOID:132221) or absent qualified lack of energy finding or absent qualified fatigue = 100with difficulty qualified able to sustain energy level finding or mid-frequency qualified lack of energy finding or mid-frequency qualified fatigue = 50unable qualified able to sustain energy level finding or high frequency qualified lack of energy finding or high frequency qualified fatigue = 0Average the following for Emotional Well-Being scoreQuestions 24, 26This covers 2 question (scores twice) high frequency qualified calm finding or absent qualified nervous finding or absent qualified anxiety diagnosis(CCFOID:21) = 200mid-frequency qualified calm finding = 150mid-frequency qualified nervous finding = 100absent qualified calm finding = 50high frequency qualified nervous finding or anxiety diagnosis = 0Questions 25, 28, 30This covers 3 question (scores three times) high frequency qualified happy finding or absent qualified sad finding (CCFOID:113334) or absent qualifieddepression diagnosis (CCFOID:22) = 300mid-frequency qualified happy finding = 225mid-frequency qualified sad finding = 150absent qualified happy finding = 75high frequency qualified sad finding or depression diagnosis = 0Average the following for Social Functioning scoreQuestion 32able qualified ability to perform community living activities finding (CCFOID:11241) = 100with difficulty qualified ability to perform community living activities finding = 50unable qualified ability to perform community living activities finding = 0Question 20absent qualified impaired social interaction finding (CCFOID:11531) = 100mid-frequency qualified impaired social interaction finding = 50high frequency qualified impaired social interaction finding = 0SF-36 ScoringScores are from 0 to 100 for each section, higher score = less frail/better healthDoing-Harris et al. Journal of Biomedical Semantics            (2019) 10:3 Page 10 of 16multiple frailty descriptions, the accuracy was deemed toadequately indicate that the terms in our ontology couldbe used to focus a learning system on frailty-relevantclinical text.Finally, in [22] we tested whether the ontology couldbe used to help train a system to predict mortality forheart failure patients who underwent a major cardiovas-cular procedure (MCVP). We collected 2-years of clin-ical history data for a cohort of 20,000 heart failurepatients leading to the MCVP. Frailty terms were identi-fied in the text and classified as asserted or negated (i.e.,yes deficit or other) using NLP. The ontology wasused to map identified terms to their concepts. Thisstudy used an early draft of the ontology that had only 7higher-level concepts: therapy, medical findings, exercise,mobility, living activity, self-care and social function.These concepts became clinical findings; seen by profes-sional allied to medicine, physical examination finding,activity exercise pattern, ability to move, activity of dailyliving, eating, feeding drinking ability, and social andpersonal history finding, respectively. We aggregated thefrailty concepts by group and selected maximum frailtyscore from among the concepts in each group.A deep neural network (DNN), pictured in Fig. 2, wastrained on a visual representation of the data features,which were hospitalizations, ICD9 codes for diagnoses,medications, and the frailty score. In ten-fold cross val-idation, the area under the curve (AUC) for mortalityprediction was 78.3% (95% CI 77.1 to 79.5%) on the testdata for the DNN model. We view this as additional val-idation for the ontology.DiscussionWe developed and validated the Cardiac-centered FrailtyOntology. We created our own hierarchy to allow re-moval of unnecessary layers, unnecessary concepts, andmaintain realist design principles as much as possible.We used SNOMED-CT concepts for all of the lowestlevel concepts. We incorporated 14 existing instrumentsin our initial development. We added five more for scor-ing and rule sets, when analysis of a 400-document clin-ical document set showed these instruments were incommon use [20]. We adapted the standard ontologydevelopment model [32] by using clinician interviews toidentify important concepts, without the necessity of for-cing clinician agreement.Our ontology development techniques differed fromthe standard techniques in two ways. We usedvignette-guided interviews in lieu of a subject matterexpert meeting to gain consensus and used validatedfrailty assessment instruments in lieu of the frailty lit-erature. Interviews allowed us to determine concepts toassess patient frailty based on specific clinical decisions.That our participants came from different institutionshelped minimized institution-related medical-culturalbias in frailty assessment. By including concepts thatany one group might have excluded, we retain thechance that our NLP system will find all relevantFig. 2 Deep neural network described in Zeng-Treitler, et al., 2018 [22]Doing-Harris et al. Journal of Biomedical Semantics            (2019) 10:3 Page 11 of 16concepts. Since the research group determined the con-cepts to include, we needed to be sure that we were notinjecting our own opinions. Based on the amount ofprevious work in the area and existing SNOMED-CTconcepts we included, we felt that our choices were notinfluenced by our opinions. We had our participantsseparately rate concepts for frailty severity, chance ofcardiac intervention alleviating the problem, and rele-vance to frailty. By returning to the participants, wemade explicit the extent and nature of their disagree-ments. We can then use this information goingforward.To address the concepts of frailty related cardiac inter-ventions specifically; we included the concepts found inour interviews that we had not found from othersources. Quadriceps weakness finding is particularlyrelevant to cardiac intervention decisions becausepost-surgical patients cannot use their arms to helpthemselves stand. Surgical incisions require the upperbody not be used. Therefore, if the patient cannot standusing their quadriceps alone, their post-surgical mobilityis impaired, which impedes healing. Our participant rat-ings show that only a few concepts are specifically rele-vant to cardiac decisions, while around half are generallyrelevant, but not specifically relevant to cardiology. Allfour of the cardiac-specific concepts were also consid-ered highly relevant to general assessments of frailty. As-sessment of the utility of these cardiac-specific conceptsin predicting patient outcomes was piloted as part oftwo studies to predict patient mortality [22, 47].The Cardiac-centered Frailty Ontology reflects generalfrailty assessment as implemented in the frailty instrumentsused in its development [2, 4858]. It includes participantratings and our separate analysis of the interview data tocreate a picture of clinical decision-making with respect tocardiac interventions. Based on our orientation towardsurgery-related decision-making [811, 1317], we haveexcluded some of the specificity required to makenon-surgery-related frailty decisions. We grouped all typesof lack of energy findings together even though differencebetween tiredness and weariness may be important inother contexts. Once we have the NLP system functioning,it will be important to assess differences in outcome predic-tion using STS scores, with and without Cardiac-centeredFrailty Ontology concepts.We used a realist ontology development process [59] be-cause it appeals to our understanding of the world, it helpsensure that the ontology is stable, and it avoids illogicalinferences. By separating concept name and term list, weallow for language evolution, because the way terms areused changes over time. However, the portions of reality de-noted by the concept and the concept name do not change.Concepts refer to Representations in the minds of cli-nicians. These representations are far richer than theterms used to indicate their presence in the mind of anauthor. Representations are multi-modal. They includememories and imaginings, relevance to goals, and otherinformation value attributes.We are looking for clinical findings, which are conclu-sions drawn by clinicians and recorded in narrative form[60]. Restricting ourselves to findings also minimizesproblems with illogical inferences. Take for example theconcept enjoys light exercise finding, the truth of this asa conclusion drawn by a clinician is unchanged bywhether or not the patient enjoys the process of exer-cising or whether or not the patient actually exercises.That it is an activity exercise pattern finding also re-mains a valid inference.Our main focus was the findings noted in narrativetext documented during clinical care, i.e., clinical his-tory findings. We recognize that comorbid conditionsare relevant to frailty assessment, but there are exist-ent tools for identifying comorbid conditions. Clinicalhistory findings represent the frailty-specific informa-tion we are interested in automatically extractingfrom clinical documents. We included a very re-stricted subset of findings from physical examination.We tested the comprehensiveness of our coverage bycreating scoring rules for the frailty assessment in-struments. If concepts were missing, we would not beable to create appropriate rules. We assessed the rele-vance of each concept by asking participants to ratethem as high, medium, or low in relevance to asses-sing frailty with respect to cardiac intervention deci-sions. A preponderance of low relevance ratingswould indicate a problem. We found only three.Three quarters of the concepts were rated as highlyrelevant. Taken together these results indicate that wehave covered the necessary and sufficient concepts re-lated to frailty assessment.One of the best qualities of both SNOMED-CT [21]and the UMLS Metathesaurus [40] is their exhaustivecoverage of the medical domain. One would be hardpressed to find a medical concept that was not containedwithin them. This exhaustiveness creates problems whenwe try to use them in NLP applications. Simple matchingto either vocabulary results in too many false positives.The Cardiac-centered Frailty Ontology creates a compre-hensive picture of frailty, while limiting the concepts fromSNOMED-CT to only those directly relevant. We usedconcepts, with semantic type finding, found by human re-view of frailty assessment instruments, physician inter-views, and chart review.LimitationsThe main limitation of this work is the influenceimparted on the ontology by our own ideas and biases.This limitation is shared by all ontologies. Our personalDoing-Harris et al. Journal of Biomedical Semantics            (2019) 10:3 Page 12 of 16bias was minimized by the inclusion of the current ac-cepted validated instruments on frailty. Each instrumentreflects both expert consensus on the relevant conceptsand empirical evidence of validity.As is the case with all ontology development for NLP,ontologies precede NLP systems. The clinical outcomeprediction NLP system used in our validation was notdesigned to model clinician decision-making. Withouthaving a decision-making NLP system, it is difficult toassess whether the Cardiac-centered Frailty Ontologywill facilitate all of the outcome predictions that weenvision.ConclusionsWe developed and validated a Cardiac-centered FrailtyOntology. The ontology is a machine-interoperable de-scription of frailty that reflects all the areas that clini-cians consider when deciding which cardiac interventionwill best serve the patient. It was designed to share asmany elements as possible with SNOMED-CT to allowinteroperability. It could not be simply a subset ofSNOMED-CT because there was no appropriate subsetfor us to choose.MethodsWe used the ontology development process describedin Noy, et al. [32]. This process consisted of fourphases. Phase 1 used existing ontologies and officialclinical tools to identify individual terms. The clinicaltools we used were validated frailty instruments andautomated chart review. We expanded this to termbased on physician interviews. In Phase 2 we groupedterms into high-level concepts. We did this by exam-ining concepts and hierarchies found in the existingSNOMED-CT ontology, while keeping the structurecompact and realist. In Phase 3 we defined objectproperties for concepts. Our methodology includedmapping concept attributes from scoring collected forthe identified concepts and properties indicated by in-strument questions. Instruments have an associatedproperty, which indicates a mapping between instru-ment scores and our ontologys concept frailty scores.For Phase 4, analysis and validation, we created im-plementation rules for using the Cardiac-centeredFrailty Ontology to reconcile scores on three commonfrailty instruments. Ontology structure was developedin Protégé [61], while term mappings were kept andshared in a Google sheet.Phase 1  Aggregate terms form other ontologies andvalidated clinical toolsTo extract frailty concepts from existing instruments,five members of the research team reviewed the specificitems from 14 instruments chosen by the number oftimes they were cited and expert recommendation [20]:(1) Physical Frailty Phenotype (PFP, also called CHSfrailty phenotype) [2]; (2) SF-36 [48]; (3) FIM [49]; (5)Clinical Frailty Scale [50]; (6) Brief Frailty Instrument[62]; (6) the Barthell Index [51]; (7) Health AssessmentQuestionnaire (HAQ) [52]; (8) PSMS [53]; (9) Katz ADL[54]; (10) Duke Activity Index [55]; (11) RDRS [56]; (12)FACIT [57]; (13) NYHA [58]; (14) Deficit AccumulationIndex (DAI, also called Frailty Index) [63]. Each personreviewed each individual item from each instrument.Terms from the World Health Organizations Inter-national Classification of Functioning, Disability andHealth (ICF) were also included in the analysis becausethe instruments varied in their levels of abstraction, theirscopes, and uniqueness.At this step we added an ontology entry for comorbidcondition count. Comorbid conditions are an importantindicator of frailty. However, they are not the focus ofour investigations. We focused on frailty-specific indica-tors in order to identify core frailty concepts in clinicaldocuments.The concept list was expanded by the findings of theinterviews of cardiologist and cardiac surgeons describedabove.Finally, we included terms extracted from manual notereview by members of the research team with clinicalexperience. These reviews were in preparation for NLPtopic modeling by Shao, et al., (2016). They reviewedclinical notes and social media posts [64].Phase 2 - group terms into high-level conceptsWe organized constructs in hierarchical relationshipbased on: 1) the results of topic modeling, 2) thebasic organization of the frailty instruments, and 3)by mapping them to SNOMED-CT equivalents. Weused SNOMED-CT concepts within the category clin-ical finding, with semantic type finding. The goal forthis process was to restrict the SNOMED-CT map-pings to as small a selection as possible, while main-taining correspondence with groupings from topicmodeling and instruments, which means our ontologyis somewhat compatible with SNOMED-CT.Phase 3  Define object properties for conceptsObject properties were determined in two ways,through the scales used to answer instrument ques-tions and by scoring terms and concepts based onkey decisions when making cardiac surgery decisions.For instrument findings, we defined properties, whichrelated instrument scores to the Rockwood global as-sessment of frailty (described below) [45].Rockwood categories are described in the DalhousieUniversity Clinical Frailty score, which has 9 categoriesDoing-Harris et al. Journal of Biomedical Semantics            (2019) 10:3 Page 13 of 16[45]. The categories are (1) very fit, (2) well, (3) man-aging well, (4) vulnerable, (5) mildly frail, (6) moderatelyfrail, (7) severely frail, (8) very severely frail, and (9) ter-minally ill [50]. Concepts in the ontology vary in howthey map onto these severity categories. Some conceptshave three levels of severity of impairment (able,assisted, and unable). The concept ability to walk, forexample, has these three levels, where each level indi-cates a different Rockwood category. The scales providedfor question answering in the frailty instruments indi-cated concept severity levels. These scales took the formof able to unable and all the time to never.To establish the relationship of the concepts tothese aspects of frailty three members of the team(BB, CW, KDH) and 3 participant cardiologists scoredthe concepts on three key decisions identified in theinterviews: 1) Rockwood category (described below)as an indicator of ability to survive surgery, 2) rele-vance to cardiac decision-making as a reflection ofthe patients ability to recover from surgery, and 3)the likelihood that the cardiac intervention will fixthe problem.Another outcome of our physician interviews wasthat clinicians consider indications of frailty withinthe context of cardiac decisions by assessing whetherthey are likely to be a result of the patients cardiaccondition and whether they are specifically relevant tocardiac decisions. The medically trained members ofthis group also characterized the constructs as low,medium, high for both their likelihood to be fixed bycardiac intervention and their relationship to cardiacdecision-making.For instrument scores, we created score rating for 10commonly cited instruments that were not included inthe initial concept-finding step. The initial mapping wascreated by author YC and verified by the remainingauthors.Phase 4  Analyze and validateFor this phase, we created rules to implement three frailtyassessment instruments using the Cardiac-centered FrailtyOntology. We mapped instrument questions and re-sponses to Cardiac-centered Frailty Ontology conceptsand properties.We also tested the utility of the ontology in two differ-ent automated NLP systems. One system was designedto classify clinical note snippets as indicative or frailty ornot. The other was designed to predict patient mortalityafter MCVP.Additional fileAdditional file 1: Frailty ontology concept list. (XLSX 37 kb)AbbreviationsADLs: Activities of daily living; BMI: Body mass index; CABG: Coronary arterybypass graft; CCFOID: Cardiac-centered frailty ontology identificationnumber; DNN: Deep neural network; EHR: Electronic Health Record;FAQ: Functional activity questionnaire; FIM: Functional independencemeasure; IADL: Instrumental activities of daily living; MCVP: Majorcardiovascular procedure; MRT: Morse fall scale; NLP: Natural LanguageProcessing; OGMS: Ontology of General Medical Science; SCTID: SNOMED-CTidentification number; SF-36: MOS 36-item short form health survey;STS: Society of Thoracic Surgeons; SVM: Support vector machine;TAVR: Transcatheter valve replacement; UMLS: Unified Medical LanguageSystem; VA: Veterans affairsFundingThis work is funded by the NIH grant R56 AG052536-01A1 and grants fromthe US Department of Veterans Affairs, Office of Research and Development,Health Services Research and Development including CHIR HIR 08374, HIR08204, CRE 12315 and the CREATE: A VHA NLP Software Ecosystem forCollaborative Development and Integration. Dr. Rashmee Shah, National Insti-tutes of Health (K08 HL136850).Availability of data and materialsThe datasets used and/or analyzed during the current study are availablefrom the corresponding author on reasonable request. The ontology owl fileis available on Bioportal at http://bioportal.bioontology.org/ontologies/CCFO.Authors contributionsKDH oversaw the group generating terms from assessment instruments andconstructed the final ontology; CW and BEB provided oversight and ideas onall aspects of the project, and edits to the manuscript; BEB and RUS providedcardiology expertise, ideas, and edits. AT and JHG provided ideas and edits;YS, YC, and QZT provided terms gathered from two previous studies, ideasand integration with NLP. YC provided initial instrument score to frailty scoremappings. All authors read and approved the final manuscript.Ethics approval and consent to participateThis work is approved under University of Utah IRB_00096877 (Use FrailtyStatus to Predict Postoperative Outcomes in Elderly Patient) consent toparticipate was verbal (use of forms was waived).Consent for publicationNot applicableCompeting interestsThe authors declare that they have no competing interests.Publishers NoteSpringer Nature remains neutral with regard to jurisdictional claims inpublished maps and institutional affiliations.Author details1Nuance Communications, Burlington, MA, USA. 2Division of CardiovascularMedicine, University of Utah, Salt Lake City, UT, USA. 3Department ofBiomedical Informatics, University of Utah, Salt Lake City, UT, USA. 4PhysicalTherapy and Athletic Training Department, University of Utah, Salt Lake City,UT, USA. 5Medical Informatics Center, George Washington University,Washington DC, USA. 6VA Healthcare System, Salt Lake City, UT, USA.Received: 2 July 2018 Accepted: 1 January 2019RESEARCH Open AccessKLOSURE: Closing in on openendedpatient questionnaires with text miningIrena Spasi?1*, David Owen1, Andrew Smith2 and Kate Button3From UK Healthcare Text Analysis Conference (HealTAC 2018)Manchester, UK. 18-19 April 2018AbstractBackground: Knee injury and Osteoarthritis Outcome Score (KOOS) is an instrument used to quantify patientsperceptions about their knee condition and associated problems. It is administered as a 42-item closed-endedquestionnaire in which patients are asked to self-assess five outcomes: pain, other symptoms, activities of dailyliving, sport and recreation activities, and quality of life. We developed KLOG as a 10-item open-ended version ofthe KOOS questionnaire in an attempt to obtain deeper insight into patients opinions including their unmet needs.However, the openended nature of the questionnaire incurs analytical overhead associated with the interpretationof responses. The goal of this study was to automate such analysis. We implemented KLOSURE as a system formining freetext responses to the KLOG questionnaire. It consists of two subsystems, one concerned with featureextraction and the other one concerned with classification of feature vectors. Feature extraction is performed by aset of four modules whose main functionalities are linguistic pre-processing, sentiment analysis, named entityrecognition and lexicon lookup respectively. Outputs produced by each module are combined into feature vectors.The structure of feature vectors will vary across the KLOG questions. Finally, Weka, a machine learning workbench,was used for classification of feature vectors.Results: The precision of the system varied between 62.8 and 95.3%, whereas the recall varied from 58.3 to 87.6%across the 10 questions. The overall performance in terms of Fmeasure varied between 59.0 and 91.3% with anaverage of 74.4% and a standard deviation of 8.8.Conclusions: We demonstrated the feasibility of mining open-ended patient questionnaires. By automatically mappingfree text answers onto a Likert scale, we can effectively measure the progress of rehabilitation over time. In comparison totraditional closed-ended questionnaires, our approach offers much richer information that can be utilised to supportclinical decision making. In conclusion, we demonstrated how text mining can be used to combine the benefits ofqualitative and quantitative analysis of patient experiences.Keywords: Text mining, Natural language processing, Text classification, Named entity recognition, Sentiment analysis,Patient reported outcome measure, Open-ended questionnaire© The Author(s). 2019 Open Access This article is distributed under the terms of the Creative Commons Attribution 4.0International License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, andreproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link tothe Creative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver(http://creativecommons.org/publicdomain/zero/1.0/) applies to the data made available in this article, unless otherwise stated.* Correspondence: SpasicI@cardiff.ac.uk1School of Computer Science & Informatics, Cardiff University, Cardiff, UKFull list of author information is available at the end of the articleSpasi? et al. Journal of Biomedical Semantics 2019, 10(Suppl 1):24https://doi.org/10.1186/s13326-019-0215-3BackgroundMusculoskeletal pain is recognised globally as negativelyimpacting healthy aging and accounts for 21.3% of totalyears lived with disability [1]. It is associated with frailty,loss of function and independence during everyday activ-ities and reduced overall physical and mental wellbeing[2]. The knee is one of the most commonly affected jointsreportedly affecting 30% of people with joint pain [3].Knee osteoarthritis is one of the most common conditionsand affects 18% of people over the age of 45 in England[4]. With an aging population, this number is set to in-crease, placing greater burden on health resources [4],adding to waiting lists and causing delays in receiving ap-propriate care [5]. Therefore, self-management treatmentapproaches, which equip patients with the skills to man-age their health condition, are essential. When away fromthe secondary care setting, patient reported outcome mea-sures (PROMs) can be used to monitor their health statusremotely.PROMs are standardised, validated questionnairescompleted by patients in an attempt to measure theirown perceptions of their health conditions. Patient re-sponses are converted into a numerical score, which canbe used to monitor patient progress over time and plantreatment accordingly. The Knee injuries and Osteoarth-ritis Outcome Score (KOOS) [6] is one of the mostwidely used PROMs for assessing patients opinionsabout their knee condition. It is administered as a 42-item closed-ended questionnaire in which patients areasked to assess five outcomes: pain, other symptoms, ac-tivities of daily living, sport and recreation activities, andquality of life. The resulting scores on a scale of 0100can help both patients and clinicians to monitor the pro-gress of knee rehabilitation. However, KOOS does notcapture details surrounding particular patient circum-stances [7]. By forcing the respondents to choose fromready-made options, closed-ended questions restrictfreedom and spontaneity of responses and as such theyare unlikely to tap into the full range of positive andnegative expressions of patients [8]. Alternatively, modi-fying KOOS into an open-ended questionnaire has got agreat potential to inform clinicians about patients opin-ions including their unmet needs, but this incurs analyt-ical overhead associated with the interpretation ofresponses.Unfortunately, patient experience questionnaires re-main largely quantitative in nature [9] despite the find-ings that they tend to overestimate patient satisfaction[10] and that qualitative analysis tends to uncover moreactionable information [11]. This can be explained partlyby the lack of knowledge on how best to collect andpresent patients responses to the stakeholders [10].From a practical point of view, the cost of qualitativeanalysis in terms of time and labour play a major factorin its prevalence or the scale of such studies. Poorer stat-istical significance has often been used as an excuse todismiss valuable information that can be provided byqualitative research [12]. In light of these issues, textmining (TM), which aims to discover patterns, relation-ships and trends within text documents, has found agreat many biomedical applications [13]. In particular, itis increasingly used to analyse patient experiences, i.e.their thoughts, feelings and behaviours, expressed intheir own words [14]. Therefore, TM may supportscalability of qualitative analyses of open-endedquestionnaires.To date, most TM approaches used to support theanalyses of open-ended questionnaires focused on aggre-gating all responses across a surveyed population, e.g.consumers [15], students [16, 17], patients [18], etc.Early techniques used to process open-ended question-naires included rule-based text classification approaches[15]. The proliferation of user-generated data on theWeb encouraged the use of data mining, e.g. clustering[16] and association rule mining [19]. The rising popu-larity of supervised machine learning approaches pavedthe way to classifying individual responses. In terms ofthe overall aim and techniques applied, the work onscreening patients for posttraumatic stress disorder isthe closest to our own [20]. They used an open-endedquestionnaire to elicit self-narratives from participantswho experienced a traumatic event. They used super-vised machine learning to implement a binary classifierwith an aim to automatically diagnose a participant,based on their overall response, as having or not havingposttraumatic stress disorder. Our approach goes a stepfurther by classifying a response to each open-endedquestion separately against multiple classes.MethodsThe aim of this study was to automate measurement ofhealth outcomes from patients freetext responses toopenended questions. Addressing this aim required usto: (1) develop an openended questionnaire, (2) collectresponses to the questionnaire, (3) analyse the responsesmanually to establish the ground truth, (4) develop textmining methods to analyse the responses automatically,and (5) evaluate the performance of the text miningmethods. The following sections describe these steps inmore detail.Open-ended questionnaireQuestionnaire developmentWe developed an openended questionnaire to capturepatients opinions about all aspects relevant to assessingthe management of their knee condition while minimisingthe number and complexity of questions. We designedKLOG (contracted from knee log) as an openendedSpasi? et al. Journal of Biomedical Semantics 2019, 10(Suppl 1):24 Page 2 of 11version of the KOOS questionnaire [6]. Like KOOS,KLOG was designed to elicit responses that can be usedto assess five outcomes: pain, other symptoms, activities ofdaily living, sport and recreation, and quality of life. Theopenended nature of the questionnaire enabled us to re-duce the number of questions from 42 in KOOS to only10 in KLOG. For example, KOOS contains 9 closedended questions related to pain: (P1) How often do youexperience knee pain? What amount of knee pain haveyou experienced the last week during the following activ-ities? (P2) twisting/pivoting on your knee, (P3) straighten-ing knee fully, (P4) bending knee fully, (P5) walking on flatsurface, (P6) going up or down stairs, (P7) at night whilein bed, (P8) sitting or lying, (P9) standing upright. KLOGcompresses them into a single openended question:Can you describe any knee pain you have experiencedover the past week? To illustrate a greater coverage of theopen-ended question, we provide a sample of answers:1. <P1>Constant</P1> pain whether in < P8>sitting</P8> or < P9>standing</P9>.2. <P1>Occasional</P1> sharp pain as well as ache,especially < NA>walking downhill</NA> or on <NA>uneven ground</NA>.3. No pain when < P8>sitting</P8>, some pain when <P6>walking upstairs</P6> and < NA>walking longdistances</NA>.4. <P1>Occasional</P1> sharp pain especially when <P6>going up steps</P6>.5. Some general pain when < NA>exercising</NA> andquite painful in the joint for < P1>the last 2 days</P1>.6. I have severe aching and bad pain when I < NA>getup from sitting</NA> and < P5>general walking</P5>.7. <P1>Occasionally</P1> the knee joint aches togetherwith momentary sudden stabbing pain in variousparts of the knee. Also, pain if I am < P8>sat</P8>with the knee < P4>bent</P4> such as < P8>sat</P8>in an office chair.8. <NA>Exercise</NA> induced occasional medialand lateral knee joint discomfort knee. Plus some <P7>nocturnal</P7> discomfort.We used XML tags to relate freetext answers to thecorresponding questions in KOOS as shown in theabove answers. We can see that when answering a moregeneric openended KLOG question, patients do pro-vide information related to the corresponding closedended questions in KOOS, but they also provide a muchricher account of circumstances surrounding their ex-RESEARCH Open AccessIdentification of conclusive associationentities in biomedical articlesRey-Long LiuAbstractBackground: Conclusive association entities (CAEs) in a biomedical article a are those biomedical entities (e.g.,genes, diseases, and chemicals) that are specifically involved in the associations concluded in a. Identification ofCAEs among candidate entities in the title and the abstract of an article is essential for curation and exploration ofconclusive findings in biomedical literature. However, the identification is challenging, as it is difficult to conductsemantic analysis to determine whether an entity is a specific target on which the reported findings are conclusiveenough.Results: We investigate how five types of statistical indicators can contribute to prioritizing the candidate entitiesso that CAEs can be ranked on the top for exploratory analysis. The indicators work on titles and abstracts ofarticles. They are evaluated by the CAEs designated by biomedical experts to curate entity associations concludedin articles. The indicators have significantly different performance in ranking the CAEs identified by the biomedicalexperts. Some indicators do not perform well in CAE identification, even though they were used in many techniques forarticle retrieval and keyword extraction. Learning-based fusion of certain indicators can further improve performance.Most of the articles have at least one of their CAEs successfully ranked at top-2 positions. The CAEs can be visualized tosupport exploratory analysis of conclusive results on the CAEs.Conclusion: With proper fusion of the statistical indicators, CAEs in biomedical articles can be identified for exploratoryanalysis. The results are essential for the indexing of biomedical articles to support validation of highly related conclusivefindings in biomedical literature.Keywords: Conclusive association entity, Statistical indicator, Visualization, Exploratory analysisIntroductionConclusive association entities (CAEs) in a biomedicalarticle a are those biomedical entities (e.g., genes, dis-eases, and chemicals) that are specifically involved in theassociations concluded in a. Consider the article inTable 1 as an example (ID in the search engine PubMedis 6,492,995). The article is curated by CTD (Compara-tive Toxicogenomics Database), which maintains a data-base of associations between chemicals, genes, anddiseases [1]. An association is curated only if CTD scien-tists verify that conclusive evidences are reported to sup-port the association. The article mentions seven entitiesin the set of entities considered by CTD. With this art-icle, several associations are curated: the gene prolactininteracts with two chemicals 2-bromolisuride andlisuride; while the disease hyperprolactinaemia has amarker association with two chemicals 2-bromolisurideand reserpine, as well as a therapeutic association withthe chemical lisuride. These chemicals as well as thegene and the disease can thus be CAEs of the article.Other entities in the article are non-CAEs: Dopamine isnot a specific target on which the conclusions are made,while transdihydrolisuride is an entity on which the re-ported findings may not be conclusive enough (as its ef-fects may change in different conditions).As CAEs are the entities on which conclusions of an art-icle are made, identification of CAEs is essential for theanalysis of highly related conclusive findings in biomedicalliterature. Biomedical scientists are often concerned withconclusive findings on specific entities. For example, CTD,GHR (Genetic Home Reference), and OMIM (OnlineMendelian Inheritance in Human) recruit many experts tofrequently update their entity association databases byCorrespondence: rlliutcu@mail.tcu.edu.twDepartment of Medical Informatics, Tzu Chi University, Hualien, Taiwan,Republic of China© The Author(s). 2019 Open Access This article is distributed under the terms of the Creative Commons Attribution 4.0International License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, andreproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link tothe Creative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver(http://creativecommons.org/publicdomain/zero/1.0/) applies to the data made available in this article, unless otherwise stated.Liu Journal of Biomedical Semantics            (2019) 10:1 https://doi.org/10.1186/s13326-018-0194-9carefully searching for those articles whose main findingssupport the associations [24].However, among the candidate entities in the title andthe abstract of an article, identification of CAEs is chal-lenging. For the article in Table 1, it is difficult to iden-tify the specific targets and then estimate how conclusivethe findings on the targets are (recall that Dopamineand transdihydrolisuride are not specific entities onwhich the reported findings are conclusive enough). Foranother example, consider the article in Table 2. Thisarticle mentions eight entities, and with this article,CTD curates two associations: the disease Parkinsonsdisease has a marker association with two chemicalsMPTP and Trichloroethylene. The disease and the twochemicals are thus CAEs, and the other five entities arenon-CAEs. These CAEs are discussed in different ways,and both CAEs and non-CAEs may appear at any partsof the article, including the title of the article. For ex-ample, Parkinsonism appears at the title of the article,but it is not a CAE (based on the curation done by CTDscientists). Parkinsonism refers to a group of neuro-logical disorders that cause movement problems, butthis article focuses on Parkinsons disease specifically,because it investigates a neurodegeneration issue con-cerning Parkinsons disease, which is a neurodegenera-tive brain disorder that causes the loss of motor control.One possible way to tackle the challenges of identify-ing CAEs is to build complete domain-specific know-ledge, as well as intelligent and scalable discourseunderstanding techniques that can determine whetheran entity is a specific target on which the reported find-ings are conclusive enough. However, it is both difficultand costly to build such domain-specific knowledge andintelligent techniques, and no previous studies builtthem to identify CAEs in biomedical articles.Problem definition and contributionIn this paper, we investigate the development of thosetechniques that, given candidate entities in the titleand the abstract of a biomedical article a, identifyCAEs in a for exploratory analysis. More specifically,we investigate how five types of statistical indicatorscan contribute to prioritizing the candidate entities sothat CAEs can be ranked on the top, without relyingTable 1 An article curated by CTD scientists. Five entities are identified as CAEs (see the boxed entities), which are the ones onwhich conclusive associations in the article are presented. Two entities are non-CAEs (see the shaded entities): Dopamine is not aspecific target in the article, while transdihydrolisuride is an entity on which the findings may not be conclusive enough (see theunderlined part).Liu Journal of Biomedical Semantics            (2019) 10:1 Page 2 of 20on any domain knowledge and discourse analysis.These indicators include:(1) Frequency-based indicator: The indicator isconcerned with the frequencies of candidate entitiesin article a. It is motivated by a hypothesis thatCAEs in an article tend to appear frequently in thearticle. For example, in the examples discussedabove, some CAEs have higher frequencies in thearticles (e.g., 2-bromolisuride in Table 1 andtrichloroethylene in Table 2).(2) Rareness-based indicator: The indicator isconcerned with how rarely the candidate entities (inarticle a) appear in a collection of articles. An entitythat appears in few articles is said to appear rarely.This indicator is motivated by a hypothesis thatspecific (general) entities tend to be rare (frequent)entity in articles. As noted above, specific entities inan article are likely to be CAEs in the article,making this indicator potentially helpful for CAEidentification.(3) Co-occurrence-based indicator: The indicator isconcerned with how often a candidate entityco-occurs with other entities in an article. It ismotivated by a hypothesis that an entity thatco-occurs with many other entities in an articlemay be related to these entities, and hence is likelyto be a CAE in the article.(4) Concentration-based indicator: The indicator isconcerned with how candidate entities (in article a)concentrate in a collection of articles. An entity thatappears frequently in individual articles has a highconcentration in these articles. This indicator ismotivated by a hypothesis that an entity with a highTable 2 Another article curated by CTD. Three entities are identified as CAEs (see the boxed entities). More entities are notidentified as CAEs (see the shaded entities), even though some of them appear at several places in the article, including the title.Liu Journal of Biomedical Semantics            (2019) 10:1 Page 3 of 20concentration in articles may be a target of thesearticles, and hence it is likely to be a CAE ofanother article as well.(5) Locality-based indicator: The indicator is concernedwith the positions of candidate entities in article a.It is motivated by a hypothesis that CAEs of anarticle may tend to be mentioned at certain partsthat may be related to the goals and conclusions ofthe article. Such parts may include the title (e.g.,prolactin in Table 1 and trichloroethylene inTable 2), the beginning part (e.g., 2-Br-LIS inTable 1 and Parkinsons disease in Table 2), and theending part (e.g., 2-Br-LIS in Table 1 and MPTP inTable 2) of the article.Obviously, these indicators cannot always succeed indistinguishing CAEs from non-CAEs, because CAEs inan article may be discussed in different ways in differentparts of the article. We thus have two researchquestions:(Q1) How does each indicator perform in identifyingCAEs?(Q2) Can these indicators be fused to improve CAEidentification?We investigate these questions by those articles thatbiomedical experts believe to be targeted at specific as-sociations among genes, diseases, and chemicals. Investi-gation of these questions can provide fundamentalguidelines for the development of systems to index bio-medical articles to support validation of highly relatedconclusive findings in biomedical literature.Related workOur goal in this paper is to investigate how the five typesof statistical indicators can be used to prioritize entitiesin titles and abstracts of articles so that CAEs, which arespecific entities involved in the entity associations con-cluded in the articles, can be ranked on the top for ex-ploratory analysis. To our knowledge, no previousstudies focused on the same goal, and hence we discussseveral types of related studies to clarify the contribu-tions of the paper.Extraction of biomedical entity associationsCAEs are those entities that are involved in specific as-sociations concluded in an article, and hence CAE iden-tification is related to the task of extracting associationsfrom the article. However, an association that happensto be mentioned in an article is not necessarily the con-clusive finding of the article, due to two reasons: (1) theassociation may have been published, and it is men-tioned in the article simply because it is related to thebackground of the article (rather than the main findingconcluded in the article), and (2) the associated entitiesmay not be the specific targets on which the reportedfindings are conclusive enough (e.g., the non-CAEs in thelast sentence of the article shown in Table 2). Therefore,entities in an association extracted from an article arenot necessarily CAEs of the article. We aim at prioritiz-ing candidate entities so that CAEs in the articles can beranked on the top.Moreover, from a technical viewpoint, the statistical in-dicators investigated in this paper may provide differentkinds of information to improve association extractiontechniques, which often extracted associations by prede-fining a set of rules (e.g., [59]) and lexical-syntactic pat-terns (e.g., [7, 8, 10, 11]). As performance of associationextraction was limited, various approaches were devel-oped, such as integrating the rules and the patterns (e.g.,[79, 12, 13]) and designing domain-specific rules andpatterns (e.g., for protein-protein interaction [14], proteinphosphorylation [15], and drug-drug interactions [16]).These previous techniques strived to design and tune therule/pattern sets to consider the lexical, syntactic, seman-tic, anaphoric, and discourse aspects of understandingthose sentences that might indicate associations. Insteadof striving to understand these sentences, the indicatorsinvestigated in this paper rank CAEs based on statisticalanalysis on how candidate entities individually appear inthe whole set of articles. Those entities that are ranked onthe top in an article are likely to be entities of the associa-tions reported in the article. These indicators may thusprovide different types of information to further improveassociation extraction, without relying on a complete andscalable set of rules and patterns.Indexing of biomedical articlesCAEs are different from those MeSH (Medical SubjectHeading) terms employed by PubMed to index articles.For example, for the article in Table 1, PubMed employsover ten MeSH terms as indexes, however many of themare not in the above set of CAEs (e.g., Animals andErgolines) and some of the above CAEs are notemployed as indexes (e.g., Hyperprolactinaemia and2-bromolisuride). Index terms for an article are not ne-cessarily those CAEs that biomedical experts employ tocurate specific associations concluded in the article.Identification of CAEs in an article is thus different fromindexing (labeling or classification) of the article withMeSH terms, which was a goal of many previous studies(e.g., techniques reported in the BioASQ workshop [17]and the Medical Text Indexer tool [18]).Ranking of entitiesWe model CAE identification as an entity ranking task,which aims at prioritizing candidate entities so thatLiu Journal of Biomedical Semantics            (2019) 10:1 Page 4 of 20CAEs in an article can be ranked on the top. Many pre-vious studies focused on entity ranking as well. Howeverthey have various goals different from ours in the paper.Entity ranking was ever defined as a task to find aranked list of entities that are of a specified type andhave a certain relationship with a given entity [19, 20]. Itwas thus concerned with how a system ranked entitiesin response to a query, which consisted of three ele-ments: an input entity, the type of the target entity, anda description of the relation. For example, to find man-ufacturers of vehicles used by UPS, the input entitymay be UPS, the type of the target entity may bemanufacturer, and the relation description may bemanufacturers of vehicles used by UPS [20]. Manytechniques were developed (e.g., [21]), and several vari-ants of the problem scenarios were investigated, such asconsdiering a chronologically ordered list of relevantdocuments [22] and providing support sentences for theentities retrieved [23]. When compared with these previ-ous studies, we have a different goal: finding CAEs in agiven article (rather than for a query). To identify theCAEs, no query is entered as input.Another scenario of entity ranking was concerned withthe ranking of entities in a given set D of documents,based on several factors such as the probability of thetopics discussed in D as well as the correlation betweenthe topics and the entities [24]. Therefore, its goal wasto identify popular topic entities in D, while we have adifferent goal: finding those entities on which conclusivefindings are reported (rather than popular topic entities)in an article (rather than a document collection).Many previous studies aimed at ranking (extracting)entities (keywords) in an article as well, however theirgoals were different from ours as well. In the biomedicaldomain, the MetaMap indexing tool (MMI) was a com-ponent of Medical Text Indexer to index (label) articleswith MeSH terms [18]. MMI only worked on MeSHterms in an article [25]. It employed the depth of eachterm in the MeSH tree as a critical factor to rank MeSHterms [25]. Therefore, effective techniques need to bedeveloped to deal with those entities not in MeSH but inother ontologies (e.g., OMIM and the Entrez-Gene data-base, which are considered by curators of CTD [26]).We investigate potential contributions of five types ofstatistical indicators to identifying CAEs from variousontologies.Another interesting feature of our goal is to identifyCAEs in titles and abstracts of articles, which are morecommonly available than full texts of the articles. Manyprevious studies worked on full texts of biomedical arti-cles to identify important entities or keywords [27, 28].For example, BioCreative defined entity ranking as a taskof identifying important genes in a full-text article [27].Important genes were those genes whose experimentalsettings contributed to main assertions of the article,and hence were essential for biomedical informationcuration [27]. Participants of BioCreative employed vari-ous strategies to rank genes, however many of the strat-egies cannot work well when only titles and abstracts areavailable (e.g., preferring those genes in the abstract, fig-ure legends, table captions, or certain sections of the art-icle [27]). As titles and abstracts are more commonlyavailable than full texts, the techniques developed in thepaper can be applicable to more articles. In the title andthe abstract of an article, several entities may be relatedto experimental assertions of the article, but they are notnecessarily CAEs, based on the curation done by CTDexperts. Only specific entities on which conclusive find-ings are reported were selected as CAEs (recall thatLisuride was a CAE but Dopamine was not in Table 1;Parkinsons disease was a CAE but Parkinsonism wasnot in Table 2).We are thus concerned with the potential contribu-tions of the five types of statistical indicators to rankingentities in titles and abstracts of articles. Some types ofthe indicators were considered by previous keywordrankers (extractors) as well. For example, a frequency--based indicator was employed to select keywords [25].Integration of frequency-based and rareness-based indi-cators was one of the best techniques to extract key-words in articles [29, 30]. A locality-based indicator wasemployed by preferring those terms appearing in thetitle of a biomedical article [25]. A co-occurrence-basedindicator was employed by keyword extractors in thebiomedical domain [28], as well as other domains suchas news [30, 31], computer science [32], and artificialintelligence [29].When compared with these keyword rankers, we in-vestigate how more types of indicators (and their fusion)perform in identifying those CAEs that are involved inthe entity associations concluded in biomedical articles.Interestingly, we find that the indicators do not neces-sarily perform well in identifying the CAEs, andlearning-based fusion of the indicators can further im-prove performance (ref. Results).Retrieval of articles for specific entitiesRetrieval of relevant articles for a query term (entity) isoften based on the estimation of the relatedness betweenthe term and each article. A CAE identifier requires sucha relatedness estimation component as well. However,when compared with article retrievers, instead of retriev-ing articles for a query entity, a CAE identifier con-versely finds entities that are related to the conclusivefindings of a given article. Therefore, although article re-trievers do not aim at CAE identification, some of theirterm-article relatedness components may have potentialcontributions to CAE identification.Liu Journal of Biomedical Semantics            (2019) 10:1 Page 5 of 20The frequency-based and the rareness-based indicatorswere routinely considered by biomedical article re-trievers. Among the previous article retrievers that con-sidered the two indicators, BM25 [33] was one of thebest techniques in finding biomedical articles [34]. Aconcentration-based indicator was considered by an art-icle retriever ES, which was tested in [35] and found tobe one of the best biomedical articles retrievers [36].Locality-based indicators were employed by many articleretrievers, which preferred those articles in which theentities of interest appeared at certain parts of the arti-cles, including the titles, the first sentences, and the lastsentences of the articles [26, 37, 38]. Similar locality in-formation was employed to retrieve articles about spe-cific gene-disease associations [39] and estimateinter-article similarity [40]. The locality-based informa-tion was also used to extract text passages (e.g., sen-tences) about gene functions [41] and evidence-basedmedicine [42].Note that the previous article retrievers also employedseveral indicators that are helpful for article retrieval butnot CAE identification. We thus do not investigate themin this paper. For example, PubMed considered thequery length as an indicator to improve article retrieval[38]. This indicator is query-specific without providinghelpful information to CAE identification in which noinput query is assumed. Similarly, we do not investi-gate article-specific indicators, such as the articlelength, as well as the field length (e.g., the lengths ofthe title and the abstract), publication type, and publi-cation year, which were considered by PubMed [38].They are not helpful for CAE identification, whichaims at finding CAEs in a given article, rather thanranking multiple articles with different article-specificcharacteristics.It is thus interesting to identify those indicators thathave potential contributions to CAE identification, andinvestigate how they really perform in CAE identifica-tion. We identify the five types of indicators based onthe observation of how CAEs may appear in biomedicalarticles. These indicators are investigated both individu-ally and collectively, and case studies are conducted tofurther investigate their practical contributions to cur-ation of biomedical databases.MethodsThe steps to conduct the research include (1) selectionof the potential indicators for CAE identification, (2) fu-sion of the indicators, and (3) performance evaluation.Potential indicatorsTable 3 defines the five types of indicators investigatedin the paper. The first indicator is TF (term frequency),which is a frequency-based indicator. It counts the num-ber of times an entity appears in an article. As CAEs inan article may appear frequently in the article, one mayexpect that an entity with a high TF is likely to be aCAE of the article. The second indicator is IDF (inversedocument frequency), which is a rareness-based indica-tor. An entity that appears in fewer articles will have alarger IDF, which may also indicate that the entity ismore specific. As CAEs in an article a tend to be specificones, we expect that an entity with a higher IDF is likelyto be a CAE in a.The third indicator is CoOcc, which is aco-occurrence-based indicator. Following [28], it is de-fined in Eq. 1. For an entity e in an article a, CoOcc isthe sum of the probabilities of e co-occurs with otherentities in sentences in a. One may expect that an entityTable 3 Definitions of individual indicatorsType Indicator Definition(1) Frequency-based TF TF(e, a) = Number of times e appears in a(2) Rareness-based IDF IDFðeÞ ¼ Log2 jAjþ1½iDFðeÞþ1½ii(3) Co-occurrence-based CoOccCoOccðe; aÞ ¼Xx?a;x?ejSe?xðaÞj½iiijSeðaÞj½iv(4) Concentration-based AvgTF AvgTFðeÞ ¼ cðe;CÞ½vDFðeÞ(5) Locality-based TITLETITLEðe; aÞ ¼ 1; if e appears in title of a;0; otherwise:AbstractXAbstractXðe; aÞ ¼1; if e appears in the first X or Last Xsentences in abstract of a;0; otherwise:8<:[i] |A| = Number of articles in the collection of articles C;[ii]DF(e) = Number of articles (in C) mentioning e;[iii]Se?x(a) = Set of sentences (in a) that e and x co-occur;[iv]Se(a) = Set of sentences (in a) mentioning e;[v]c(e,C) = Number of times e appears in articles in CLiu Journal of Biomedical Semantics            (2019) 10:1 Page 6 of 20with a larger CoOcc in an article a may be related tomore entities in a, and hence is likely to be a CAE in a.The fourth indicator is AvgTF, which is aconcentration-based indicator. For an entity e, AvgTF isthe micro average frequency of e appearing in a collec-tion of articles. An entity with a larger AvgTF in a collec-tion of articles may be a target of these articles, andhence it is likely to be a CAE of articles as well.The fifth and the sixth indicators are TITLE andAbstractX, which are locality-based indicators. For anentity e in an article a, TITLE is concerned with whethere appears in the title of a, while AbstractX is concernedwith whether e appears in the first X or last X sentencesin the abstract of a. As the title, the first sentences, andthe last sentences of an article are often treated as crit-ical parts for retrieval of biomedical articles [26, 37, 38],one may expect that an entity with larger TITLE andAbstractX is likely to be a CAE of a.Fusion of the indicatorsProper fusion of the above indicators may improve CAEidentification. We thus investigate two kinds of fusionstrategies: learning-based strategies and typical strat-egies. For the learning-based strategies, we employ Ran-kingSVM [43], which is one of the best techniquesroutinely used to integrate multiple indicators by SVM(Support Vector Machine) to achieve better ranking(e.g., [36, 44]). We employ SVMrank [45] to implementRankingSVM. All the indicators are integrated by Ran-kingSVM. Different combinations of the indicators arealso tested to identify the best ways to fuse theindicators.For the typical fusion strategies, Table 4 summarizesseveral indicators that are defined based onstate-of-the-art keyword extractors and article retrievers.The first type of typical strategies fused thefrequency-based (TF) and rareness-based (IDF) indica-tors. TFIDF and BM25e are two indicators of this type.TFIDF is the product of TF and IDF. It was found to beone of the best techniques to extract keywords in articles[29, 30]. BM25e is defined based on BM25, which wasfound to be one of the best techniques to retrievebiomedical articles [34]. It employs Eq. 1 to estimate thesimilarity between and entity e and an article a, where k1and b are two parameters, |a| is the number of terms inarticle a (i.e., length of a), and avgal is the averagelength of a collection of articles.BM25e e; að Þ ¼ TF e; að Þ k1 þ 1ð ÞTF e; að Þ þ k1 1?bþ b aj javgal  IDF eð Þð1ÞThe second type of typical strategies fused frequency-based, rareness-based, and concentration-based indica-tors. ESe is an indicator of this type. It is defined basedon ES, which was one of the best techniques to retrievebiomedical articles as well [36]. ESe employs Eq. 2 to es-timate the similarity between and entity e and an articlea, where, where DF(e) is the number of articles contain-ing e (i.e., document frequency of e); C is a collection ofarticles; N is the total number of articles in C; c(e,C) isthe number of times e appears in C. Therefore, ESe im-plements a concentration-based indicator by the ratio ofc(e,C) to DF(e), which measures how e concentrates inarticles by computing the micro average TF of e in thearticles.ESe e; að Þ ¼ TF e; að ÞTF e; að Þ þ 0:45 ffiffiffiffiffiffiffiffiffiffiffiaj javgdlsffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffic e;Cð ÞDF eð Þ 3 NDF eð Þsð2ÞThe third type of typical strategies fusedfrequency-based and locality-based indicators. CCSEeand eGRABe are two indicators of this type. CCSEe isdefined based on a locality-based biomedical article re-triever CCSE (core content similarity estimation [40]).The CCSEe score of an entity e in an article a is the sumof three factors concerning how e is related to the goal,background, and conclusion of a. The factors are definedTable 4 Typical strategies to fuse the indicatorsLiu Journal of Biomedical Semantics            (2019) 10:1 Page 7 of 20as linear weights that are derived based on the positionsof e in a (for detailed definitions for the linear weights,the reader is referred to [40]). For example, e is relatedto the goal of a if it occurs in the title of a; e is relatedto the background of a if it occurs in the beginning partof the abstract of a; and e is related to the conclusion ofa if it occurs in the ending part of the abstract of a.Similarly, eGRABe considers locality information as well.It is defined based on a gene article retriever eGRAB(extractor of gene-relevant abstracts [37]). The eGRABescore of an entity e in an article a is increased by 1 if (1)e appears in a at least three times; (2) e appears in thetitle of a; or (3) e appears in first X or last X sentencesin the abstract of a. We set X to 1 ~ 3, and hence havethree respective versions: eGRABe-1, eGRABe-2,eGRABe-3. Note that, in addition to the locality-basedinformation of an entity, both CCSEe and eGRABe haveincorporated frequency-based information as well, be-cause an entity with multiple occurrences in differentparts of an article will get amplified scores.Performance evaluationThe dataExperimental data is collected from CTD (available athttp://ctdbase.org/), which recruits biomedical expertsto maintain a database of biomedical articles with mainresearch focuses on associations between chemicals,genes, and diseases [1, 26]. CTD recruited and trained anumber of biomedical experts to curate the associationswith a controlled vocabulary. An experiment showedthat the experts achieved a high degree of agreement inselecting articles to curate (77% agreement among allcurators, and 85% average agreement between every twocurators), with good accuracy in curating associations inthe articles (average precision and recall were 0.91 and0.71 respectively) [26]. Associations curated by CTD ex-perts are also reviewed for quality control before theyare released [26].We thus evaluate how CAEs curated by the expertsare identified by systems. We randomly sample 300 en-tities from three kinds of association files in CTD:<chemical, gene>, <chemical disease>, and < gene, dis-ease>. For each entity e all associations involving e arecollected. These associations can serve as the basis tocomprehensively collect test articles. For each of the as-sociations, we collect all articles that CTD experts se-lected to curate the association. For each article a, wecollect all associations that CTD experts curated with a.Entities involved in these associations can thus be theCAEs in a (i.e., the gold standard for a). We totally have60,507 articles with their CAEs appearing in their titlesor abstracts (see Additional file 1). These articlesamount to about 50% of all articles in CTD.As we are evaluating how systems perform in identify-ing CAEs among a given set of candidate entities in anarticle, candidate entities in each article should be iden-tified. For our evaluation purpose, the candidate entitiesneed to be identified based on the vocabulary of CTD,because CTD experts have employed this vocabulary tocurate CAEs in the articles. Other potential entities notin the vocabulary are beyond the scope of consideration,because whether they are CAEs in the articles is notverified by domain experts.More specifically, this vocabulary comprehensively in-cludes about 2.5 million (2,535,754) terms for the names,symbols, and synonyms of entities of three types: genes,diseases, and chemicals. They are selected and modifiedfrom multiple sources, such as MeSH (for chemicals anddiseases), the Entrez-Gene database (for genes, devel-oped by National Center for Biotechnology Information),and OMIM (for diseases) [26]. The vocabulary is thuscustomized for the curation purpose of CTD (e.g., en-tities for species-specific entities are added, while someentities not considered by CTD are removed [4648]).Candidate entities in each article are mapped to theirIDs by a dictionary-based normalization approach,which was employed by many previous studies as well(e.g., [6, 49, 50]). To further fit the approach to ourevaluation purpose, given an article a, all terms that areCAEs of a are first mapped to their corresponding entityIDs, as the existence of the entities in a has been con-firmed by CTD experts. Other terms are then identifiedby checking whether official symbols or names of en-tities in the vocabulary appear in a; and if no, synonymsof entities are checked. Moreover, authors of articlesoften employ their own abbreviations (or symbols) torepresent an entity. For example, the article in Table 1contains several author-defined abbreviationsexpressed in parentheses, such as DA (for dopamine),LIS (for lisuride), and TDHL (for transdihydrolisuride).We thus map these abbreviations to their correspondingentity IDs as well.As noted above (ref. Fusion of the indicators), we alsoinvestigate several learning-based strategies to fuse indi-vidual indicators, and hence we require training data totrain the fusion systems. We thus evenly split the 60,507articles into five parts on which 5-fold cross validation isconducted. In each experiment fold, a part of the data isused for testing while the other four parts are used fortraining, and the cross-validation process is repeated fivetimes, with each of the five parts being used exactly onceas testing data.Evaluation criteriaAs the systems aim at prioritizing candidate entities inan article so that CAEs of the article can be ranked onthe top, we employ three evaluation criteria to measureLiu Journal of Biomedical Semantics            (2019) 10:1 Page 8 of 20how CAEs are ranked high. The first criterion is meanaverage precision (MAP), which is defined in Eq. 3,where |A| is the number of test articles in the experi-ment (i.e., |A| = 60,507), ki is number of entities that arebelieved (by CTD experts) to be CAEs of the ith article,and Seeni(j) is the number of entities whose ranks arehigher than or equal to that of the jth CAE for the ith art-icle. Therefore, AP(i) is actually the average precision(AP) for the ith article. It is the average of the precisionwhen each CAE is seen in the ranked list. Given an art-icle, if a system can rank higher those CAEs in the art-icle, AP for the article will be higher. MAP is simply theaverage of the AP values for all test articles.MAP ¼XjAji¼1AP ið Þj A j ; AP ið Þ ¼Xkij¼1jSeeni jð Þkið3ÞThe second criterion is average precision at top-X(Average P@X, see Eq. 4), which is the average of theP@X values for all test articles. P@X is the precisionwhen top-X entities are shown to the readers (see Eq. 5).Therefore, when X is set to a small value, P@X measureshow a system ranks CAEs very high. In the experiments,we set X to 1, 3, and 5.Average P@X ¼XjAji¼1P@X ið Þj A j ð4ÞP@X ið Þ¼ Number of top?Xentities thatare CAEs in the ith articleXð5ÞThe third evaluation criterion is %P@X > 0, which isthe percentage of the test articles that have at least oneCAE ranked at top-X positions (X = 1, 2 and 3). It canbe a good measure to indicate whether a system can suc-cessfully identify CAEs for a large portion of the test ar-ticles. This measure is of practical significance, becausea CAE identification system can provide practical sup-port to biomedical researchers only if it can successfullyidentify CAEs for most articles.ResultsWe separately present the experimental results, whichaim at answering the two research questions (Q1 andQ2) respectively. Case studies are also conducted toshow how the identified CAEs can be visualized to sup-port exploratory analysis for curating biomedicaldatabases.Q1: How does each indicator perform in identifying CAEs?Figure 1 shows the performance of each individual indi-cator in CAE identification. To verify whether the per-formance differences between two indicators arestatistically significant, we conduct paired t-test with99% as the confidence level. The results show that theconcentration-based indicator (i.e., AvgTF) performs sig-nificantly better than all the other indicators.Fig. 1 Performance of individual indicators: The concentration-based indicator (i.e., AvgTF) performs significantly better than all the otherindicators ( denotes that the indicator performs significantly better than others)Liu Journal of Biomedical Semantics            (2019) 10:1 Page 9 of 20We further analyze each indicator by investigatinghow CAEs and non-CAEs distribute with the informa-tion provided by each indicator. For an indicator c, Eq. 6is used to compute the probability of CAEs whose values(estimated by c) fall in a specific interval. Similarly, Eq. 7is defined for the probability of non-CAEs. Therefore,given an indicator c, these probabilities aim at measuringthe prevalence rate of CAEs and non-CAEs in eachinterval. Moreover, we are also concerned with the prob-ability gain of finding CAEs (ProbGain) in each interval(see Eq. 8). It is the difference between the probability offinding CAEs in an interval and the overall probabilityof finding CAEs. Therefore, a positive (negative) Prob-Gain in an interval indicates that it is generally more(less) likely to find CAEs in the interval.Pi CAEð Þ ¼ Number of CAEs that fall in interval iTotal number of CAEs in all articlesð6ÞPi NonCAEð Þ ¼ Number of non?CAEs that fall in interval iTotal number of non?CAEs in all articlesð7ÞProbGaini ¼ Number of CAEs in interval iNumber of entities in interval i?Number of CAEs in all articlesTotal number of entities in all articlesð8ÞFigure 2 shows how CAEs and non-CAEs distributewith the information provided by CoOcc. The twodashed lines respectively show the prevalence probabil-ities of CAEs and non-CAEs. They indicate that CAEsand non-CAEs mainly fall in the area where 0 <CoOcc ?10. However in this area, ProbGain oscillates aroundzero with small absolute values. Therefore, most CAEsand non-CAEs have similar CoOcc values, makingCoOcc less capable of distinguishing CAEs fromnon-CAEs. Given that co-occurrence-based informationwas found to be one of the best information to extractkeywords [29, 30], the result show that it is not necessar-ily quite helpful for identifying CAEs in biomedicalarticles.Figure 3 shows how CAEs and non-CAEs distributewith the information provided by the locality-based indi-cators (i.e., AbstractX and TITLE). Positions of entitiesFig. 2 Analysis of the co-occurrence-based indicator (CoOcc): Both CAEs and non-CAEs mainly fall in the area where 0 < CoOcc? 10 (see the twodashed lines), however in this area, probability gain of finding CAEs (ProbGain) oscillates around zero with small absolute values (see the solidline), and hence most CAEs and non-CAEs have similar CoOcc values. This is the reason why CoOcc is less capable of distinguishing CAEsfrom non-CAEsLiu Journal of Biomedical Semantics            (2019) 10:1 Page 10 of 20can be measured in terms of words or sentences. An ab-stract is divided into 20 parts, and in each part we com-pute the prevalence probabilities of CAEs andnon-CAEs, as well as ProbGain. The results show that,when considering the abstracts of the articles, bothCAEs and non-CAEs have somewhat uniform distribu-tions at different positions, and they have very similardistributions (and hence ProbGain in the abstract partsoscillates around zero with small absolute values).Therefore, although the first sentences and the last sen-tences of abstracts were used to retrieve biomedical arti-cles [26, 37, 40], they are not necessarily quite helpfulfor CAE identification. On the other hand, TITLE worksbetter, as CAEs are more likely to appear in titles thannon-CAEs. However, TITLE has weaknesses as well, be-cause most CAEs do not appear in titles (as shown inthe leftmost part of Fig. 3, only 11.4% of CAEs appear intitles).Figure 4 shows how CAEs and non-CAEs distributewith the information provided by the rareness-based in-dicators (i.e., IDF). The IDF spectrum is divided into 20parts. IDF values of non-CAEs fall in the wholespectrum, however nearly no CAEs have IDF values fall-ing in the lower 30% part. ProbGain of IDF thusoscillates more dramatically than those of theco-occurrence-based and locality-based indicators notedabove, making IDF more helpful for CAE identification,especially for those entities with lower IDF values.abFig. 3 Analysis of the locality-based indicators (AbstractX and TITLE): Positions of entities can be measured in terms of words or sentences, asshown in (a) and (b) respectively. When compared with non-CAEs, CAEs are more likely to appear in titles of articles, as shown in the left-mostparts of (a) and (b). On the other hand, when considering the abstracts of the articles, both CAEs and non-CAEs have somewhat uniformdistributions at different positions, and moreover they have very similar distributions (see the two overlapping dashed lines). Therefore, TITLEworks better than AbstractX in distinguishing CAEs from non-CAEs (see the solid line). However, TITLE has weaknesses as well, because most CAEsdo not appear in the titles of articles (only 11.4% of CAEs appear in the titles)Liu Journal of Biomedical Semantics            (2019) 10:1 Page 11 of 20However, many entities have IDF values fall in the mid-dle parts of the spectrum (i.e., between 35 and 65%). Forthese entities, IDF may not work well.Figure 5 shows how CAEs and non-CAEs distributewith the information provided by the frequency-basedindicator (TF). Most entities have TF values less than 6.Most non-CAEs have TF = 1, and ProbGain of findingCAEs becomes large when TF ? 4 (see the solid line). TFthus performs well in identifying CAEs whose TF = 1 orTF ? 4. However, many entities have TF values falling be-tween 2 and 3, and for these entities TF has difficulty indistinguishing them (absolute value of ProbGain is smallfor TF = 2 or 3). Therefore, although it is reasonable toretrieve articles for an entity by preferring those articlesin which the entity appears at least three times [37], thisstrategy may not be suitable for identifying CAEs.Figure 6 shows how CAEs and non-CAEs distributewith the information provided by the concentration--based indicator (AvgTF). The AvgTF spectrum is dividedinto 20 parts, and most CAEs have AvgTF values fallingbetween 10 to 40% of the maximum AvgTF, while mostnon-CAEs have AvgTF values falling below 10% of themaximum AvgTF. Therefore, when compared with otherindicators, AvgTF has ProbGain that oscillates more dra-matically, making it more capable of distinguishingCAEs from non-CAEs.Table 5 summarizes the potential and the limitation ofeach indicator in CAE identification. In conclusion,these indicators have significantly different performancein CAE identification. AvgTF has significantly better per-formance than all other indicators. Concentration of anentity in a collection of articles is thus a good way todistinguish CAEs from non-CAEs. CoOcc and AbstractXare less capable of distinguishing CAEs from non-CAEs,although they have been used in many article retrieversand keyword extractors. Other indicators may have theirown weaknesses as well, especially when identifyingCAEs with different statistical characteristics.Q2: Can these indicators be fused to improve CAEidentification?It is thus interesting to fuse the indicators to further im-prove performance. A poorer indicator may still contrib-ute, especially if it can provide helpful information thatis not provided by other indicators. Figure 7 shows theperformance of the typical fusion strategies. As notedabove (ref. Fusion of the indicators), all the fusion strat-egies consider TF, however they have significantly differ-ent performance.CCSEe and eGRABe, which considers both TF andlocality-based information, perform even worse than TF.They have lower MAP than TF (CCSEe: 0.6329;Fig. 4 Analysis of the rareness-based indicator (IDF): IDF values of non-CAEs fall in the whole IDF spectrum, while nearly no CAEs have low IDFvalues (see the two dashed lines). IDF may thus be a useful indicator for CAE identification, especially for those entities with lower IDF values (i.e.,the lower 30% of the IDF spectrum, see the solid line for probability gain of finding CAEs). However, many entities have IDF values fall in themiddle parts of the spectrum (i.e., between 35 and 65%). For these entities, IDF may not work well (see the solid line for ProbGain)Liu Journal of Biomedical Semantics            (2019) 10:1 Page 12 of 20eGRABe-3: 0.6500; but TF: 0.6633, ref. Fig. 1). As notedabove (ref. Fusion of the indicators), CCSEe andeGRABe are respectively based on two article retrieversCCSE [40] and eGRAB [37]. They consider TF andTITLE, which are helpful indicators in certain cases (ref.Fig. 3, and ref. Fig. 5). However, TF has weaknesses aswell because many CAEs and non-CAEs have TF valuesfalling between 2 and 3 (as noted in the discussion forFig. 5). CCSEe and eGRABe cannot properly tackle thisweakness, even though they also consider the positionsof entities in the abstract, which are less helpful for CAEidentification (ref. the poor performance of AbstractX,noted in the discussion for Fig. 3).BM25e and TFIDF, which fuse TF and therareness-based indicator IDF, can successfully improveTF. TFIDF performs better than BM25e, which fuses TFand IDF in a more complicated way (ref. Equation 1).TFIDF performs significantly better than others in Aver-age P@1 and P@2, but not Average P@3 and MAP. Onthe other hand, ESe fuses TF, IDF, and theconcentration-based indicator (AvgTF). It performs sig-nificantly better than others in Average P@3 and MAP.However, it does not further improve Average P@1 ofAvgTF (ESe: 0.6809 vs. AvgTF: 0.6979, ref. Figure 7 andFig. 1). Therefore, both TFIDF and ESe have theirweaknesses in CAE identification as well, although theyare respectively defined based on the best keyword ex-tractors and article retrievers (ref. Fusion of theindicators).It is thus interesting to investigate other ways tofuse the indicators properly. Figure 8 shows the con-tribution of learning-based fusion by SVM. All the sixindicators defined in Table 3 are fused (for theAbstractX indicator, we employ Abstract2, as it is thebest setting for AbstractX, ref. Figure 1). Contributionof an indicator to the fused system can be investi-gated by removing it from the fused system. The re-sults show that removal of a better indicator tends todeteriorate performance more seriously. ALL-Ab-stract2, which fuses all indicators except for Ab-stract2, performs better than all others, includingALL, which fuses all the six indicators. Further Re-moving CoOcc from ALL-Abstract2 gets poorer per-formance. The performance differences betweenALL-Abstract2 and others are statistically significant,except for ALL-CoOcc on Average P@1. Therefore, itmay not be necessary to fuse all the six indicators.Without the locality information provided by Ab-stract2, collaboration of the other five indicators hasbeen good in distinguishing CAEs from non-CAEs.Fig. 5 Analysis of the frequency-based indicator (TF): Most entities have TF less than 6 (see the two dashed lines). Most non-CAEs have a TF valueequal to 1, and probability gain of finding CAEs (ProbGain) becomes large when TF ? 4 (see the solid line). TF thus performs well in identifyingCAEs whose TF= 1 or TF? 4. However, many entities have TF values falling between 2 and 3, and for these entities TF has difficulty in distinguishingCAEs from non-CAEsLiu Journal of Biomedical Semantics            (2019) 10:1 Page 13 of 20Moreover, as noted above, the two best typical fusionstrategies TFIDF and ESe have weaknesses. ALL-Ab-stract2 tackles the weaknesses by learning-based fusionof five indicators. It performs significantly better than allthe typical fusion strategies. There are 9.6% improve-ment in Average P@1 (0.7934 vs. 0.7239 by TFIDF);10.9% improvement in Average P@2 (0.6989 vs. 0.6302by TFIDF); 8.5% improvement in Average P@3 (0.6153vs. 0.5669 by ESe); and 8.3% improvement in MAP(0.7824 vs. 0.7226 by ESe).Figure 9 investigates how CAEs are ranked at top posi-tions for a large percentage of articles (i.e., %P@X > 0,ref. Evaluation criteria). For 92.46% of the articles,ALL-Abstract2 ranks at least one of their CAEs at top-2positions. The percentage achieved by randomly rankingthe entities is only 42.33%. TFIDF and ESe, which havebetter MAP noted above, do not necessarily performbetter than the best individual indicator AvgTF in%P@X > 0, especially when X is 2 and 3. ALL-Abstract2performs better than them as well. The results are ofFig. 6 Analysis of the concentration-based indicator (AvgTF): Most CAEs have AvgTF values falling between 10 to 40% of the maximum, whilemost non-CAEs have AvgTF values falling below 10% of the maximum (see the two dashed lines). Therefore, probability gain of finding CAEs(ProbGain) oscillates more dramatically with larger absolute values (see the solid line), and hence AvgTF performs better than all the otherindicators in CAE identificationTable 5 Summary of the performance of each indicatorIndicator Potential in CAE identification Limitation in CAE identificationTF TF works well for those entities whose TF = 1 or TF? 4, as non-CAEstend to have TF = 1, and few of them have TF ? 4.Many CAEs and non-CAEs have TF values falling between 2 and 3.IDF IDF values of non-CAEs fall in the IDF spectrum, while nearly noCAEs have IDF values falling in the lower 30% part, making IDF help-ful to filter out non-CAEs with lower IDF values.Many CAEs and non-CAEs have IDF values fall in the middle parts ofthe spectrum (i.e., between 35 and 65%).CoOcc None. CAEs and non-CAEs tend to have similar CoOcc values.AvgTF CAEs tend to have AvgTF > 10% of the maximum AvgTF, while non-CAEs tend to have AvgTF? 10% of the maximum.None.TITLE When compared with non-CAEs, CAEs are more likely to appear intitles of articles.Most CAEs do not appear in the titles of articles.AbstractX None. CAEs and non-CAEs have somewhat uniform and similar distribu-tions at different positions in the abstract.Liu Journal of Biomedical Semantics            (2019) 10:1 Page 14 of 20practical significance to stable identification of CAEs formost articles.In conclusion, proper fusion of the indicators is not atrivial task. Typical fusion strategies do not necessarilyhave better CAE identification performance thanindividual indicators, even though these fusion strategieswere employed by state-of-the-art article retrievers andkeyword extractors. Learning-based fusion by SVM is agood way to fuse the indicators. However, it is not ne-cessary to fuse all the indicators. Without the localityFig. 7 Fusion of indicators by typical strategies: All the typical strategies have considered the frequency-based indicator (TF). However, CCSEe andeGRABe, which fuse TF and locality-based indicators, even deteriorates performance (TF has been able to achieve a higher MAP of 0.6633, ref. Fig. 1).BM25e and TFIDF, which fuse TF and the rareness-based indicator IDF, can further improve performance. TFIDF performs significantly better thanothers in Average P@1 and P@2 ( denotes that the indicator performs significantly better than others). ESe fuses TF, IDF, and the concentration-basedindicator (AvgTF). It performs significantly better than others in Average P@3 and MAPFig. 8 Fusion of indicators by SVM: All the six indicators are fused (see ALL), and removal of an indicator X from ALL is denoted as ALL-X. We findthat removal of a better indicator tends to deteriorate performance more seriously. ALL-Abstract2 performs significantly better than ALL ( denotesthat the indicator performs significantly better than others), indicating that it would be good to integrate all indicators except for Abstract2. Itperforms significantly better than others except for ALL-CoOcc on Average P@1 (denoted by ?). It also performs significantly better than typicalfusion strategies (ref. Fig. 7)Liu Journal of Biomedical Semantics            (2019) 10:1 Page 15 of 20information collected from the abstracts of the articles,collaboration of the other indicators has been able toachieve significantly better performance, with most arti-cles (over 92%) having at least one of CAEs successfullyranked at top-2 positions.Case studiesTo further investigate potential contributions of theidentified CAEs, we conduct case studies to show howthe identified CAEs can be visualized to support cur-ation of biomedical databases in practice. Visualizationof the CAEs identified from a collection of articles aimsat supporting the exploratory analysis of the CAEs. Weare motivated by a typical need of biomedical re-searchers: analysis of a specific research finding is oftenbased on validation of the evidence recently published inmultiple articles with focuses on the finding. For ex-ample, to curate a gene-disease association, GHR expertsneed to check multiple articles focusing on the associ-ation so that conflicting or unclarified information canbe excluded [51]. Therefore, the identified CAEs shouldbe visualized to support the exploration of how fre-quently and recently the CAEs are published in articles,as well as how two entities are CAEs in the same arti-cles, which indicates that the two entities may be highlyrelated to each other.More specifically, for each article, top-2 entities identi-fied by ALL-Abstract2 are treated as CAEs of the article.For each entity e, we compute two items: (1) frequency:number of articles having e as a CAE, and (2) recency:average publication year of these articles. A frequency-re-cency map can thus be constructed to visualize the CAEs(see Fig. 10a). With the map, researchers can have a glo-bal view to navigate on the space of how frequently andrecently the CAEs are published in the articles. Considerthree CAEs that are published relatively frequently andrecently: cocaine (ID in CTD: D003042), resveratrol (IDin CTD: C059514), and SIRT1 (sirtuin 1, ID in CTD:23411). They are CAEs of 1838, 772, and 135 articles, re-spectively. To investigate whether the results are helpfulfor biomedical curators, for each CAE, Eq. 9 is used tomeasure Jaccard similarity between the sets of articlesthat are recommended by the system and CTD expertsrespectively.JaccardSimilarity A1;A2ð Þ ¼ j A1?A2 jj A1?A2 j ð9ÞJaccard similarities for cocaine, resveratrol, and SIRT1are 0.8796, 0.875, and 0.8252, respectively. The map canthus serve as a helpful guide to the space of how fre-quently and recently the CAEs are published in thearticles.Moreover, given the map, two kinds of navigation canbe supported: focused view of an entity and zoom-in viewof multiple entities. The focused view is triggered for aspecific entity. As a case study, consider a focused viewof cocaine (ID in CTD: D003042), which is a CAE withthe largest frequency in Fig. 10a. This view focuses onFig. 9 Percentage of articles with CAEs ranked at top positions (i.e., %P@X > 0): For 92.46% of the articles, ALL-Abstract2 ranks at least one of theirCAEs at top-2 positions. The percentage achieved by randomly ranking the entities (i.e., the Random baseline) is only 42.33%. ALL-Abstract2 alsoperforms better than the best indicators noted in Figs. 1 and 7 (i.e., AvgTF, TFIDF, and ESe). It can thus be used to stably identify CAEs for mostarticles in practiceLiu Journal of Biomedical Semantics            (2019) 10:1 Page 16 of 20those articles with cocaine as a CAE (see Fig. 10b). Itprovides a new frequency-recency map to show thoseentities that are CAEs of those articles with cocaine as aCAE. Therefore, with the focused-view map, researcherscan navigate through the information space of how co-caine is related to other entities, as well as those articlesthat report conclusive findings of both cocaine and therelated entities. For example, in Fig. 10b, seizures (ID inCTD: D012640) is an entity with the largest frequency(63 articles), indicating that many articles may have bothcocaine and seizures as CAEs, and hence the associationbetween cocaine and seizures deserves investigation. Ac-tually CTD experts used almost all of these articles (61out of the 63 articles) to curate this association. The fo-cused view can thus support the curation task.The zoom-in view is triggered by selecting a zone inFig. 10a. There are four zones derived by setting thethresholds for the frequency and the recency. In Fig. 10a,the frequency threshold is set to 100 articles, and the re-cency threshold to the year of 2012. The four zones aimat supporting different kinds of exploratory analysis. Fig-ure 10c provides a zoom-in view on zone IV, which sup-ports the navigation of those entities that are beingstudied in fewer articles more recently. Navigation on thiszone can thus facilitate the validation of emergingstudies on these entities. As case studies, consider threeabcZoom-in view of multiple entities Focused view of a specific entityFig. 10 Visualization of the CAEs identified for online exploration: (a) A frequency-recency map for the CAEs identified from a collection of articles;(b) Focused view of a specific entity of interest (e.g., cocaine, which is a CAE of a large number of articles); (c) Zoom-in view of multiple entities(e.g., Zone IV, which contains those entities being studied recently)Liu Journal of Biomedical Semantics            (2019) 10:1 Page 17 of 20CAEs of multiple articles published most recently. Eachof them is CAEs of two articles published in 2015: schi-zandrol B (entity ID: C033585, article IDs: 25319358,25,753,323), ETV6 (ETS variant 6, entity ID: 2120, articleIDs: 25581430, 25,807,284), and polyhexamethylenegua-nidine (entity ID: C060540, article IDs: 25716161,24,769,016). We find that CTD experts have employedall these articles to curate these CAEs. The zoom-in viewcan thus be helpful for the curation task as well.DiscussionApplication and suggestionIdentification of CAEs can be a new service provided bybiomedical search engines (e.g., PubMed), which rou-tinely collect and preprocess articles for subsequent re-trieval. For each collected article, the preprocessingprocess of the search engines can be enhanced by com-puting the individual and fused indicators for CAE iden-tification. With the CAEs identified for each article, thesearch engines can facilitate timely and comprehensivedissemination of conclusive findings in biomedical litera-ture. The new service can also be a good tool for bio-medical researchers, curators (e.g., CTD, OMIM, andGHR), and text mining systems that cross-validate con-clusive findings on certain entities in multiple articles.Visualization of CAEs by a frequency-recency map canbe a new service provided by biomedical search enginesas well. With the new service, researchers can explorethe space of CAEs in a collection of articles retrieved fora specific query. The visualization strategy can also beadopted by biomedical databases curated by experts,such as those entity databases that are being maintainedby CTD and GHR. By setting a certain condition (e.g.,frequency, recency, and entities of interest), researcherscan navigate on the space of highly related entities andarticles for exploratory analysis.Another interesting application is the extraction of keysentences in biomedical articles. Those sentences thatmention CAEs of an article may be the key sentencesthat describe the main findings of the article. Extractionof the key sentences is thus helpful for the identificationand mining of the main findings reported in biomedicalliterature (e.g., mining associations among entities),which are main goals of many biomedical informationextraction and mining systems.Limitation and future researchAs noted above (ref. The data), for our evaluation pur-pose, candidate entities in articles are identified basedon the vocabulary of CTD, which contains millions ofterms for the names, symbols, and synonyms of genes,diseases, and chemicals. The experimental setting pro-vides reliable evidence for performance evaluation, be-cause CTD has employed the vocabulary to curate CAEsin the articles. Other entities not in the vocabulary arenot verified by the domain experts of CTD, and hencetheir effects are not investigated in the paper.As the CAE identification techniques investigated inthis paper work on a given set of candidate entities, theycan collaborate with different techniques that map en-tities in articles to their normalized names or IDs. Previ-ous entity mapping techniques were often developed forspecific applications with different performance in differ-ent cases. For example, entity recognition techniqueswere developed for specific domains or types of entities,such as chemicals [52], genes [53], and diseases [54].Mapping the entities into suitable IDs is an importantresearch topic as well (e.g., mapping of genes [55]) forwhich tools were implemented (e.g., MetaMap, availableat https://metamap.nlm.nih.gov/) and techniques weredeveloped with different performance in different cases[56]. By collaborating with those entity mapping tech-niques that are tuned for specific applications, CAEidentification may be improved for the applications.CAE identification may also be improved by collectingmore information from multiple articles, based on threeobservations: (1) given two entities e1 and e2 that areCAEs in an article, there may be an association <e1, e2 >between them, (2) associations between CAEs may beused to infer possible associations (e.g., given <e1, e2 >and < e2, e3>, an inferred association may be <e1, e3>),and (3) if two candidate entities in an article a are in-volved in an inferred association (e.g., e1 and e3 are can-didate entities in a, and < e1, e3 > is an inferredassociation), they are likely to be CAEs of a. Therefore,CAE identification for an article may be improved byCAE-based association mining on a collection of articles.The CAE identification techniques investigated in thispaper can be used to identify CAE associations (basedon the 1st observation). Novel techniques may be devel-oped to infer possible associations and refine CAE iden-tification for each article (based on the 2nd and 3rdobservations, respectively).The CAE visualization strategy noted above (ref. Casestudies) can be extended as well. An interesting exten-sion is network-based navigation of conclusive findingson a set of entities of interest. Given a set Ei of entitiesof interest, the system identifies a set Eh of entities thatare highly related to the entities in Ei. Two entities arehighly related if they are CAEs of the same article (i.e.,the article reports conclusive findings on them). The sys-tem then visualizes Ei and Eh with an association net-work in which a node is an entity, and an edge betweentwo nodes indicates that they are highly related. Theusers can click on any edge between two entities tocheck the distribution of those articles that have the twoentities as CAEs. With the CAE network, biomedical re-searchers can have global and detailed views on a set ofLiu Journal of Biomedical Semantics            (2019) 10:1 Page 18 of 20entities among which associations are reported as con-clusive findings in literature.ConclusionCAEs in a biomedical article a are specific entities onwhich conclusive associations are reported in a. Theyare different from keywords (e.g., MeSH terms)employed to index (classify or label) a. This paper is thefirst study to investigate how five types of statistical indi-cators can contribute to prioritizing candidate entities inthe title and the abstract of an article so that CAEs canbe ranked on the top for exploratory analysis.The results show that these indicators have signifi-cantly different performance. Some indicators do notperform well in CAE identification, even though theywere used in many article retrievers and keyword extrac-tors. Learning-based fusion of certain indicators can suc-cessfully rank CAEs in most articles at top-2 positions.As it can work on titles and abstracts of articles, whichare more commonly available than full texts of the arti-cles, it can be applicable to much more articles. By visu-alizing the identified CAEs with frequency-recencymaps, biomedical researchers can navigate to check howfrequently and recently the CAEs are published in arti-cles, as well as how two entities are CAEs in the samearticles (i.e., they may be highly related to each other).The results are of both technical and practical signifi-cance to the indexing of biomedical articles to supportvalidation of highly related conclusive findings in bio-medical literature. They can also be used to enhancebiomedical search engines, curated databases, and textmining systems, which often serve as essential compo-nents of many biomedical information processingsystems.Additional fileAdditional file 1: Biomedical articles that are employed as theexperimental data. There are 60,507 articles, which amount to about 50% ofthe articles in CTD. Each article has a PubMed ID, followed by its CAEs(represented by their IDs in CTD and separated by |). CAEs of an article a arethe specific entities involved in the associations that CTD expertscurated based on the conclusive findings of a. (TXT 4849 kb)Abbreviations%P@X > 0: Percentage of articles having at least one CFE ranked at top-X po-sitions; Average P@X: Average precision at top-X; CAE: Conclusive associationentity; IDF: Inverse document frequency; MAP: Mean average precision;ProbGain: Probability gain; SVM: Support vector machine; TF: Term frequencyAcknowledgementsThe author is grateful to Zhe-Ting Guo for collecting and preprocessing theexperimental data.FundingThis research was supported by Ministry of Science and Technology, Taiwan,under the grants MOST 1052221-E-320-004 and MOST 1072221-E-320-004.Availability of data and materialsThe dataset supporting the conclusions of this article is included inAdditional file 1, which contains the list of articles tested in the experiment.Each article has a PubMed ID, followed by a tab character as well as a list ofconclusive association entities in the article recognized by CTD.Authors contributionsRL designs the research, conducts the experiments, analyze the experimentalresults, as well as drafts the manuscript. The author read and approved thefinal manuscript.Ethics approval and consent to participateNot applicable.Consent for publicationNot applicable.Competing interestsThe authors declare that they have no competing interests.Publishers NoteSpringer Nature remains neutral with regard to jurisdictional claims inpublished maps and institutional affiliations.Received: 17 August 2018 Accepted: 20 December 2018Kafkas and Hoehndorf Journal of Biomedical Semantics           (2019) 10:15 https://doi.org/10.1186/s13326-019-0208-2RESEARCH Open AccessOntology based mining ofpathogendisease associations fromliteratureS¸enay Kafkas1,2* and Robert Hoehndorf1,2AbstractBackground: Infectious diseases claim millions of lives especially in the developing countries each year.Identification of causative pathogens accurately and rapidly plays a key role in the success of treatment. To supportinfectious disease research and mechanisms of infection, there is a need for an open resource on pathogendiseaseassociations that can be utilized in computational studies. A large number of pathogendisease associations isavailable from the literature in unstructured form and we need automated methods to extract the data.Results: We developed a text mining system designed for extracting pathogendisease relations from literature. Ourapproach utilizes background knowledge from an ontology and statistical methods for extracting associationsbetween pathogens and diseases. In total, we extracted a total of 3420 pathogendisease associations from literature.We integrated our literature-derived associations into a database which links pathogens to their phenotypes forsupporting infectious disease research.Conclusions: To the best of our knowledge, we present the first study focusing on extracting pathogendiseaseassociations from publications. We believe the text mined data can be utilized as a valuable resource for infectiousdisease research. All the data is publicly available from https://github.com/bio-ontology-research-group/padimi andthrough a public SPARQL endpoint from http://patho.phenomebrowser.net/.Keywords: Text mining, Relationship extraction, Pathogendisease association, Pathogen, Infectious diseaseBackgroundEach year, millions of people die due to infectious diseases.The World Health Organisation (WHO)[1] reported that11? million deaths were due to HIV/AIDS in 2015 alone.Infectious diseases cause devastating results not only onglobal public health but also on the countries economies.Developing countries, especially the ones in Africa, are themost affected by infectious diseases.Several scientific resources have been developed tosupport infectious disease research. A large number ofthese resources focus on hostpathogen interactions [2, 3]as well as particular mechanisms of drug resistance [4].*Correspondence: senay.kafkas@kaust.edu.sa1Computational Bioscience Research Center, King Abdullah University ofScience and Technology, 23955-6900 Thuwal, Saudi Arabia2Computer, Electrical and Mathematical Sciences and Engineering Division,King Abdullah University of Science and Technology, 23955-6900 Thuwal,Saudi ArabiaAdditionally, there are several resources that broadly char-acterize different aspects of diseases [5]. However, rela-tively little structured information is available about therelationships between pathogens and disease, informationthat is also needed to support infectious disease research.For example, pathogendisease relations (and the result-ing relations between pathogens and phenotypes elicitedin their hosts) provide complementary information tomolecular approaches to discover hostpathogen interac-tions [6]. More generally, however, while there is oftena direct correspondence between an infectious diseaseand a type of pathogen, the relation between disease andthe pathogen causing it needs to be available in a struc-tured format to allow automatic processing and linkingof phenotypes (i.e., disease) to the molecular mecha-nisms (i.e., the pathogens and their molecular interac-tions). Such information is further useful as some diseases© The Author(s). 2019 Open Access This article is distributed under the terms of the Creative Commons Attribution 4.0International License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, andreproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to theCreative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver(http://creativecommons.org/publicdomain/zero/1.0/) applies to the data made available in this article, unless otherwise stated.Kafkas and Hoehndorf Journal of Biomedical Semantics           (2019) 10:15 Page 2 of 5can be caused by multiple types of pathogens, and thesame pathogen may cause different types of diseases (e.g.,depending on the anatomical site of infection).Currently, pathogendisease associations are mainlycovered in structured format by proprietary databasessuch as the Kyoto Encyclopedia of Genes and Genomes(KEGG) [7]; KEGGs DISEASE database contains adetailed classification of infectious diseases and linksthem to the taxon or the taxa that are known to causethe disease. For example, KEGG links the disease Tuber-culosis (H00342) to two taxa:Mycobacterium tuberculosisand Mycobacterium canettii. Pathogendisease associa-tions are also described in the biomedical literature andpublic resources such as Wikipedia [8], or in the HumanDisease Ontology [5] in natural language form. Auto-mated methods are needed to extract these associationsfrom natural language.Here, we further developed and evaluated a textmining system for extracting pathogendisease asso-ciations from literature [9]. While most of the exist-ing text mining studies related to infectious diseasefocus on extracting hostpathogen interactions from text[10, 11] and archiving this data [2, 3], to the bestof our knowledge, we present the first text miningsystem which focuses on extracting pathogendiseaseassociations. Our literature-extracted associations areavailable for download from https://github.com/bio-ontology-research-group/padimi and are included inPathoPhenoDB [12] and accessible through a publicSPARQL endpoint at http://patho.phenomebrowser.net/.Materials &methodsOntologies and resources usedWe used the latest archived version of the OpenAccess full text articles subset of PubMed Central(http://europepmc.org/ftp/archive/v.2017.12/, containingapproximately 1.8 million articles) from the Europe PMCdatabase [13]. We used the NCBI Taxonomy [14] (down-loaded on 22-08-2017) and the Human Disease Ontol-ogy (DO) [5] (February 2018 release) to provide thevocabulary to identify pathogen and infectious diseasementions in text. We selected these two comprehen-sive OBO ontologies due to the fact that our methodutilizes ontology structure to propagate information inrelation extraction as well as interoperablity reasons. Fur-thermore, in a relevant study [15], we link pathogensto disease phenotypes in support of infectious diseaseresearch by utilizing the mappings from DO to phe-notpes. We generated two dictionaries from the labelsand synonyms in the two ontologies and refined thembefore applying text mining. In the refinement pro-cess, we filtered out terms which have less than threecharacters and terms that are ambiguous with commonEnglish words (e.g., Arabia as a pathogen name). Weextracted the taxon labels and synonyms belonging toall fungi, viruses, bacteria, worms, insects, and proto-zoa from the NCBI Taxonomy to form our pathogendictionary. The final pathogen and disease dictionar-ies cover a total of 1,519,235 labels and synonymsbelonging to 1,250,373 distinct pathogen taxa and 1380labels and synonyms belonging to 438 distinct infectiousdiseases.Pathogen and disease class recognitionA class is an entity in an ontology that characterizes acategory of things with particular characteristics. Classesusually have a set of terms attached as labels or synonyms[16]. We used the Whatizit text mining workflow [17] toannotate pathogen and disease classes in text with the twodictionaries for diseases and pathogens. Because diseasename abbreviations can be ambiguous with some othernames (e.g., ALS is an abbreviation both for AmyotrophicLateral Sclerosis and Advanced Life Support), we useda disease abbreviation filter for screening out the non-disease abbreviations that could be introduced during theannotation process [18]. Briefly, this filter operates basedon rules utilizing heuristic information. First, it identifiesabbreviations and their long forms in text by using regu-lar expressions. Second, it utilizes several rules to decidewhether to keep the abbreviation annotated as a diseasename or filter out. The rules cover keeping the abbrevia-tion either if any of its long forms from DO exists in thedocument or its long form contains a keyword such asdisease, disorder, syndrome, defect, etct?hat describesa disease name.PathogenDisease association extractionOur association extraction method is based on identifica-tion of pathogendisease co-occurrences at the sentencelevel and applying a filter based on co-occurrence statis-tics (total number of co-occurrences of a given pair is cal-culated by considering the total number of co-occurrencesacross all sentences in all documents) and an extendedversion of Normalized Point-wise Mutual Information(NPMI) [19] association strength measurement to reducenoise possibly introduced by the high recall, low preci-sion co-occurrence method. We selected the associations(between pathogen and disease classes) having an NMPIvalue above 0.2 and co-occurring at least 10 times in theliterature.We extended NPMI, which is a measure of collocationbetween two terms, to a measure of collocation betweentwo classes. Hence, we reformulated the NPMI measurefor our application. First, we identify, for every class,the set of labels and synonyms associated with the class(Labels(C) denotes the set of labels and synonyms of C).We then define Terms(C) as the set of all terms that can beused to refer to C: Terms(C) := {x|x ? Labels(S)?S  C}.Kafkas and Hoehndorf Journal of Biomedical Semantics           (2019) 10:15 Page 3 of 5We calculate the NPMI between classes C and D asnpmi(C,D) = lognC,D·ntotnC ·nD? log nC,Dntot(1)where ntot is the total number of sentences in our cor-pus in which at least one pathogen and one disease nameco-occur (i.e., 4,427,138), nC,D is the number of sentencesin which both a term from Terms(C) and a term fromTerms(D) co-occur, nC is the number of sentences inwhich a term fromTerms(C) occurs, and nD is the numberof sentences in which a term from Terms(D) occurs.ResultsStatistics on extracted pathogenDisease associationsWe extracted a total of 3420 distinct pathogendiseasepairs belonging to 316 1357 distinct diseases andpathogens respectively from over 1.8 million Open Accessfull text articles. To identify the associations, we useda combination of lexical, statistical, and ontology-basedrules. We used lexical matches to identify whether thelabel or synonym of a pathogen or disease is mentionedin a document; we used a statistical measure, the nor-malized point-wise mutual information, to determinewhether pathogen and disease mentions co-occur sig-nificantly often in literature; and we used ontologies asbackground knowledge to expand sets of terms based onontology-base inheritance.Performance evaluationTo evaluate the text mined pathogendisease associa-tions, we used several manually curated resources includ-ing the KEGG [7] database, DO [5], and a list of pathogendisease associations in Wikipedia [8] as reference, andwe compare our results to the information contained inthem. We could identify 744 pathogendisease associa-tions (between 455 distinct pathogens and 331 distinctdiseases) in KEGG, 353 pathogendisease associationsin Wikipedia (between 250 distinct pathogens and 245distinct diseases) and 94 pathogendisease associationsin DO (between 90 distinct pathogens and 41 distinctdiseases) for which we could map the pathogen and dis-ease identifiers from NCBI Taxonomy and DO to theiridentifiers/names in KEGG, DO and Wikipedia. Figure 1shows the overlapping and distinctly identified pathogendisease associations from these resources and literature.The recall of our method is 29.4% (219) for KEGG,50.7% (179) for Wikipedia, 45.7% (43) for DO. There are525 pairs in KEGG, 174 pairs in Wikipedia and 51 pairs inDO which we could not cover by text mining. The mainreason we cannot identify an association is due to limita-tions in our named entity and normalization procedure aswell as its non-existence in the literature.In addition to the information contained in existingdatabases, we extracted many more associations from lit-erature (3121 in total). To determine the accuracy of theseassociations, first we randomly selected 50 pathogendisease pairs and all of the evidence sentences linked tothem. We applied our threshold values based on NPMIFig. 1 Overlapping pathogendisease associations between literature and other resourcesKafkas and Hoehndorf Journal of Biomedical Semantics           (2019) 10:15 Page 4 of 5and number of co-occurrences to distinguish betweenpositive and negative associations; we then manually ana-lyzed the evidence sentences linked to these associations(each association are extracted from one or more sen-tences) to classify each positive association as either FalsePositive or True Positive and each negative associationeither as True Negative or False Negative (manual evalua-tion data is freely available [20]).In our manual evaluation, we achieve a precision of 64%,a recall of 89% and an F-score of 74%. The false pos-itives were mainly due to ambiguous abbreviations andpathogen names. For example, Katanga which is a geo-graphical place name was annotated as a pathogen name(NCBITaxon:966285) by our method.Some false negatives were due to rejections by the sys-tem based on the threshold settings. For example, Bar-tonellosis (DOID:11102) and Bartonella ancashensis(NCBITaxon:1318743) which is also covered by KEGGco-occurred only two times (in two different articles,PMCID:4102455 and PMCID:5382735) in our corpusand therefore the association between them was rejectedas we limited our analysis to pathogendisease pairs thatco-occurred ten or more times. Other false negatives weredue to missing pathogen or disease labels in our dictionar-ies. For example, our system could not identify a KEGGcovered association between necrotizing ulcerative gin-givitis (DOID:13924) and Fusobacterium nucleatum(NCBITaxon:851) since we included only the infectionsdisease branch of DO in our disease dictionary whilenecrotizing ulcerative gingivitis is not a sub-class ofinfectious disease in DO.DiscussionBy using ontologies as background knowledge to expandour sets of terms and labels, it is possible to identifypathogendisease associations even if the labels and syn-onyms directly associated with the pathogen or diseaseare not directly found to co-occur in text. For exam-ple, we extracted a total of 44 distinct pathogendiseaseassociations relevant to dengue disease (DOID:11205).Twelve our of 44 associations are the direct associ-ations of dengue disease (i.e., a label or synonym ofthe disease is explicitly mentioned in text) while theremaining 32 are indirect associations obtained fromassociations with labels and synonyms of the sub-classes asymptomatic dengue (DOID:0050143), denguehemorrhagic fever (DOID:12206), and dengue shocksyndrome (DOID:0050125). In total, we found 812pathogendisease associations which do not directly co-occur in literature but are inferred through the ontology.The performance of our system depends on twoparameters: the NPMI value and the number of co-occurrences used as a threshold. In the future, we mayuse these two values to automatically determine optimalthreshold based on a more comprehensive evaluation setof pathogendisease associations which needs to be cre-ated and could also be useful for developing machinelearning based methods. While our initial text miningapproach performs at a promising level (F-score 74%),there is still some room for improvements. As we foundthe pathogen names to be ambiguous with other domainspecific names, we plan to further improve the abbrevia-tion and name filters we apply. For improving the recallof our system, it may be possible to expand our dictio-naries with other resources covering disease and pathogennames such as the Experimental Factor Ontology (EFO)[21] and the Unified Medical Language System (UMLS)[22] for diseases, and the Encyclopedia of Life [23] forpathogens.ConclusionHere, we present a text mining method for extractingpathogendisease associations from the biomedical liter-ature. Our method performed at a promising level withsome room for improvements. In future, we plan toimprove our text mining method by developing and inte-grating a pathogen abbreviation filter and expanding thecoverage of our pathogen and disease dictionaries. In thescope of infectious disease research, we have included ourresults in a database of pathogens and the phenotypes theyelicit in humans. We believe that our results can furthersupport infectious disease research.AcknowledgementAuthors would like to thank Mrs. Marwa Abdellatif for her help to make thedata available from the SPARQL end-point.Consent of publicationNot applicable.AbbreviationsDO: Human disease ontology; EFO: Experimental factor ontology; KEGG: Kyotoencyclopedia of genes and genomes; NPMI: Normalized point-wise mutualinformation; UMLS: Unified medical language system; WHO: World healthorganisationAuthors contributionsRH and S¸K conceived of the study; S¸K performed all experiments. S¸K and RHanalyzed the results. S¸K drafted the manuscript, R.H. revised the manuscript. Allauthors have read and approved the final version of the manuscript.FundingThis work has been supported by funding from King Abdullah University ofScience and Technology (KAUST) Office of Sponsored Research (OSR) underAward No. URF/1/3454-01-01 and FCC/1/1976-08-01.Availability of data andmaterialsAll the data is available from https://github.com/bio-ontology-research-group/padimi and (http://patho.phenomebrowser.net/) through a publicSPARQL endpoint.Ethics approval and consent to participateNot applicable.Competing interestsThe authors declare that they have no competing interests.Kafkas and Hoehndorf Journal of Biomedical Semantics           (2019) 10:15 Page 5 of 5Received: 3 October 2018 Accepted: 2 September 2019Tissot and Dobson Journal of Biomedical Semantics 2019, 10(Suppl 1):17https://doi.org/10.1186/s13326-019-0216-2RESEARCH Open AccessCombining string and phoneticsimilarity matching to identify misspeltnames of drugs in medical records written inPortugueseHegler Tissot1* and Richard Dobson1,2,3From UK Healthcare Text Analysis Conference (HealTAC 2018)Manchester, UK. 1819 April 2018AbstractBackground: There is an increasing amount of unstructured medical data that can be analysed for differentpurposes. However, information extraction from free text data may be particularly inefficient in the presence ofspelling errors. Existing approaches use string similarity methods to search for valid words within a text, coupled witha supporting dictionary. However, they are not rich enough to encode both typing and phonetic misspellings.Results: Experimental results showed a joint string and language-dependent phonetic similarity is more accuratethan traditional string distance metrics when identifying misspelt names of drugs in a set of medical records written inPortuguese.Conclusion: We present a hybrid approach to efficiently perform similarity match that overcomes the loss ofinformation inherit from using either exact match search or string based similarity search methods.Keywords: Phonetic similarity, Similarity search, Misspelt names of drugsBackgroundThere is a large amount of unstructured data being pro-duced by different kinds of information systems, in avariety of formats, due to the advancement of commu-nication and information technologies [1, 2]. Within theclinical domain, Electronic Health Record (EHR) sys-tems are becoming widely adopted, from which infor-mation describing the patients health conditions is oftenpresented and stored in the form of free text notes [3].Existing text-mining methods aim to extract detailedstructured information from clinical narratives, such asdrug prescriptions, their variability, and adverse drugreactions [4, 5]. However, free-text is susceptible to typ-ing and phonetic misspellings. Spelling errors of genericdrug names can occur in up to one out of six entries*Correspondence: h.tissot@ucl.ac.uk1Institute of Health Informatics, University College London, London, UKFull list of author information is available at the end of the articlein electronic drug information systems. Such errors arelikely to be responsible for up to 12% of adverse drugevents, mainly caused by errors during transcription ofprescriptions, illegible prescriptions, or drug name confu-sion [6]. Due to such frequency and the relevance of druginformation in clinical tasks, spelling correction becomescrucial to support health care professionals with spellingerror-tolerant engine systems.Similarity comparison algorithms can be used to iden-tify and extract concepts from free text [7] when text isloaded with misspellings. String similarity metrics (e.g.Edit Distance [8] and Jaro-Winkler Distance [9]) can mea-sure similarity between two strings. These functions canbe used to compare the elements from the input datasource against an existing dictionary in order to identifya possible valid word matching a misspelling. However,existing string similarity algorithms may be inefficient toanalyse text loaded with spelling errors because they may© The Author(s). 2019 Open Access This article is distributed under the terms of the Creative Commons Attribution 4.0International License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, andreproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to theCreative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver(http://creativecommons.org/publicdomain/zero/1.0/) applies to the data made available in this article, unless otherwise stated.Tissot and Dobson Journal of Biomedical Semantics 2019, 10(Suppl 1):17 Page 2 of 7not necessarily handle specific aspects, such as phoneticerrors [10]. In these cases, it is necessary to use phoneticsimilarity metrics.In order to overcome the possible loss of informationby using exact match search methods to find mentions ofdrugs within patient records, we propose a hybrid solutioncoupling string and phonetic similarity metrics to identifymisspelt names of drugs. This approach was used to pro-duce a dictionary of misspelt variations. A Trie-basedfast similarity search algorithm was then able to iden-tify a broader range of potential candidates as misspeltvariations for each drug name.Use-caseSince July 2013 the Brazilian government tries to addressthe shortage of doctors, especially in the inner cities andthe outskirts of large cities in Brazil, through the hir-ing of doctors from other countries. With the addition ofdoctors with distinct language background in the publichealth system (especially from South and Central Americawhere people originally speak Spanish), a larger number ofspelling errors have been found in electronic record sys-tems. Such errors occur mainly due to the similarity of thePortuguese language with other Latin languages (such asSpanish and Italian) [11].InfoSaude (InfoHealth) [12] is an information systemcreated to manage and track medical records, such asexams, vaccinations, and drug prescriptions. The systemis used to meet the needs of 75 public health centresin the city of Florianopolis/Brazil. It integrates differentinformation structures used by the Brazilian Ministry ofHealth, such as the Outpatient Information System (CIS)and the International Code of Diseases (ICD). The systemalso generates information for Ambulatory Care Indi-vidual Report (RAAI), summarizing data on the type ofcare, pregnancies, procedures performed on the patient,applied vaccines and drug prescriptions.Whilst maintain-ing a series of structured information, the system also con-tains textual fields that are filled by health professionalsduring patient care.Although InfoSaude has structured information aboutdrug prescriptions, a deeper analysis on drug usage, abuse,or checking whether patients are correctly and effectivelymaking use of the prescribed drugs, relies on the observa-tions registered by the clinicians using free text. However,the textual content of the medical records does not gothrough any kind of review. Thus, it is common to find anumber of spelling and phonetic errors that could harmany further analysis. An information extraction systemis expected to overcome this problem in order to avoidinformation loss.Approximate stringmatchThe existing similarity match methods range from usingbasic string similarity distance metrics, which measureinverse similarity between two text strings by providingan algorithm-specific numerical indication of distance, tothe use of more sophisticated methods coupled with thephonetic representation of words in a given language.Edit Distance (ED) (or Levenshtein Distance) [8] isthe most widely known string metric. ED operatesbetween two input strings  ED(w1,w2)  and returns theminimum number of operations (single-character edits)required to transform string w1 into w2. Other exam-ples and variations of string similarity metrics includeJaro-Winkler Distance [9], Hamming Distance [13], andStringSim [14]. However, string distance measures tend toignore the relative likelihood errors.Phonetic representations encode words based on thesound of each letter to translate a string into a canonicalform. Soundex [15] is an example of a phonetic match-ing scheme initially designed for English that uses codesbased on the sound of each letter to translate a string intoa canonical form of at most four characters, preservingthe first letter. In addition, phonetic similarity metrics areable to assign a high score even though comparing dissim-ilar pairs of strings that produce similar sounds [14, 16].As the result, phonetically similar entries will have thesame (or similar) keys and they can be indexed for efficientsearch using some hashing method. However, phoneticsis language-dependent [17, 18] and solutions for this sortof problems must be specially designed for each specificlanguage.In addition, fast similarity search approaches have beenproposed in order to match free text against large dic-tionaries or databases, being supported by either indexeddatabase structures [14, 19, 20] or Trie-based (prefixindex) approximate matching [2123]. In an initial exper-iment, Fuzzy Keyword Search [22] has proved to beefficient by combining Trie-based search with string sim-ilarity functions. However, processing time grows expo-nentially as long as the Edit Distance threshold increases,becoming inefficient for ED > 2, which we were able toconfirm by comparing the processing time (in millisec-onds) spent to perform 1000 searches over a dictionary of80,000 entries, varying ED amongst 0 (16 ms), 1 (218 ms)and 2 (3267 ms).MethodAs part of a NLP pipeline that aims to identify differentaspects of drug usage by patients, one of the atomic stepswithin this pipeline is the identification of drug namesin free text. In this section we describe how string andphonetic similarity metrics can be combined to improveaccuracy on identifying misspelt names of drugs withina set of records written in Portuguese. Our approach hastwo main steps. First, we combine string (StringSim) andlanguage-dependent phonetic (PhoneticMapSimPT ) sim-ilarity metrics proposed in [18] in a hybrid similarityTissot and Dobson Journal of Biomedical Semantics 2019, 10(Suppl 1):17 Page 3 of 7search solution in order to produce a base dictionaryof misspelt variations. These metrics were originallydesigned for the Brazilian Portuguese language. Finally,this dictionary is used as input for a fast Trie-basedsimilarity search algorithm that finds potential candidatesto be annotated as drug names in text.We started using list of 5535 drug names available inthe InfoSaude system, and searching the most cited drugsin a experimental dataset of clinical notes provided bythe InfoSaude team (de-identified data with no ethicalapproval required) from 4748 distinct patients (multipledocuments per patient). An exact match search produceda list of 516 drug names, from which the 20 most citeddrugs in the text were initially selected (Table 1).In this first step, we aim to produce a base dictionaryof misspelt drug name variations by combining string andphonetic thresholds in order to maximise the accuracy onidentifying true positive misspelt words. Such thresholdsare used to determine whether a candidate misspelt wordcorrespond to a drug name. Inappropriate low thresholdvaluesmay return toomany false candidates favouring lowprecision by including words with low similarity valuesthat do not correspond to a drug name. In contrast, highthreshold values may exclude possible valid misspelt drugnames from the final matching, favouring low recall. TheTable 1 Occurrence (#) of the 20 most cited drug names in a setof 4748 medical records written in PortugueseDrug name Number of occurrencesFluoxetina 18624Paracetamol 8697Diazepam 8474Amitriptilina 8463Omeprazol 7825Dipirona 7320Glicose 5721Captopril 5383Insulina 5290Nimesulida 4228Clorpromazina 4226Enalapril 4144Imipramina 4135Sinvastatina 3862Carbamazepina 3853Amoxicilina 3716Ibuprofeno 3714Metformina 3467Risperidona 3464Atenolol 3224method used to find the most suitable string and phoneticsimilarity thresholds is described below: We selected a list of candidate words (similar words)for each drug, by finding all words that have at least 3matching consonantal phonemes in each pair of truepositive and candidate drug name or the EditDistance metric ? 3. The returned list of similar words corresponding to agiven drug name d was manually analysed. Weapplied a filter in order to consider candidates wordsw where StringSim(d,w) ? 0.6 (this threshold can beconsidered relatively low and resulted approximately50% of false positive candidates). The final result is alist of 1791 distinct candidate words for the set ofdrug names listed in Table 1  an average of 90similar candidate words per drug. The candidate words were manually annotated toidentify whether each word corresponds to a validdrug name, resulting 938 positive matches and 853negative matches. We also automatically annotatedeach positive and negative match with thecorresponding string and phonetic similaritymeasures (StringSim and PhoneticMapSimPT). We used the annotated set of candidates to perform agrid search over the combined string and phoneticsimilarity values in order to find the best similaritythreshold values that favour precision and recall. Thelist of 20 drugs was split into two groups (10 drugseach) used as training and validation sets. The gridsearch algorithm is presented in the form of apseudo-code in Fig. 1.The pseudo-code performs an exhaustive search for thebest pair of phonetic and string similarity thresholds. Theinput comprises two manually annotated lists (trainSetand validSet)  containing names of drugs and candidatesimilar words with the corresponding positive or negativematch flag  and a list with 7730 pairs of possible stringand phonetic threshold values. 660 pairs of similarityvalues contain StringSim = 0, i.e. a possible solution con-sidering only the phonetic similarity metric as a threshold.Finally, for each possible pair of threshold values, the algo-rithm calculates Precision, Recall, and F1 for each set of10 drugs (trainSet  lines 2-7  and validSet  lines 8-13).The final thresholds are updated each time both F1trainand F1valid simultaneously achieve better values  lines14-19. After executing the described pseudo-code on thedata extracted from the medical record set, we observeda hybrid solution considering both phonetic and simi-larity thresholds achieved better accuracy on identifyingmisspelt names of drugs. The hybrid solution combinesa smaller phonetic threshold to perform a fast similar-ity search that result more similar words, coupled with aTissot and Dobson Journal of Biomedical Semantics 2019, 10(Suppl 1):17 Page 4 of 7Fig. 1 A pseudo-code to find similarity thresholdsstring similarity threshold that works as a complementaryfilter. Table 2 depicts the final resulting threshold values.ResultsThe final threshold values were used to find positive mis-spelt names for a broader list of drugs. A total of 1442misspelt words corresponding to 409 different drug nameswere identified. Table 3 shows the drug names (exceptthose occurring in the training and validation sets) inTable 2 Best threshold values found by the grid search methodParameter ValueTraining Set Number of true positives 417Number of false positives 31Number of false negatives 25Precision 0.931Recall 0.943F1-score 0.937Validation Set Number of true positives 477Number of false positives 39Number of false negatives 19Precision 0.924Recall 0.961F1-score 0.942Thresholds Phonetic similarity 0.844String similarity 0.831which the greatest number of misspelt forms were found,as well as the corresponding accuracy (precision, recall,F1) on identifying the misspelt variations for each drug.We also compare the accuracy of our approach against thewidely used Edit Distance metric.Information Extraction and NLP systems are tradition-ally evaluated through precision, recall, and F1-score rel-evance measures. Precision is equivalent to the amountof retrieved instances that are relevant, while recall isequivalent to the amount of relevant instances that areretrieved. The terms true positives (TP) and true negatives(TN) represent the correct result and the correct absenceof results respectively, while the terms false positives (FP)and false negatives (FN) correspond to the unexpectedresult and the missing result respectively. These terms areused to define precision and recall according to Eqs. 1and 2. In other words, the greater is precision the lesser isthe proportion of false positive results, whilst the greateris recall the lesser is the proportion of false negativeresults. Finally, the F1-score result can be interpreted asthe weighted average (or harmonic mean) between preci-sion and recall [24], reaching its best value at 1 and worstscore at 0 (Eq. 3).Precision = TPTP + FP (1)Recall = TPTP + FN (2)Tissot and Dobson Journal of Biomedical Semantics 2019, 10(Suppl 1):17 Page 5 of 7Table 3 Drugs with the highest number of misspelt variationsDrug name Number of similar wordsInexact Phonetic Match F1-Score when using only string matchPrecision Recall F1 ED ? 1 ED ? 2 ED ? 3 ED ? 4Propanolol 52 0.960 0.979 0.967 0.310 0.819 0.945 0.955Glibenclamida 49 1.000 1.000 1.000 0.829 0.956 0.955 0.961Anlodipino 49 0.913 0.976 0.944 0.612 0.938 0.952 0.942Medroxiprogesterona 47 1.000 0.914 0.955 0.763 0.881 0.955 0.927Metoclopramida 46 1.000 0.977 0.989 0.750 0.977 0.965 0.964Loratadina 46 0.837 0.947 0.889 0.774 0.973 0.963 0.955Dexametasona 45 1.000 0.800 0.889 0.615 0.915 0.954 0.952Furosemida 43 0.963 1.000 0.981 0.844 1.000 0.976 0.961Prednisona 42 1.000 0.878 0.935 0.730 0.952 0.976 0.956Hidroclorotiazida 41 1.000 0.975 0.987 0.776 0.962 0.952 0.940Diclofenaco 41 0.923 0.947 0.935 0.812 0.914 0.950 0.912Ciprofloxacino 37 1.000 0.918 0.958 0.520 0.878 0.935 0.922Espironolactona 36 1.000 1.000 1.000 0.714 0.941 0.948 0.962Salbutamol 36 1.000 0.972 0.986 0.819 0.956 0.976 0.943Clonazepam 34 1.000 1.000 1.000 0.692 0.969 0.961 0.939Beclometasona 33 1.000 0.967 0.984 0.777 0.935 0.961 0.921Dexclorfeniramina 31 1.000 0.903 0.949 0.708 0.872 0.960 0.959Metronidazol 30 0.965 0.965 0.965 0.816 0.964 0.942 0.926Prednisolona 30 0.965 0.965 0.965 0.739 0.925 0.976 0.966Isossorbida 29 0.963 1.000 0.981 0.761 0.960 0.957 0.936Average F1-score 0.963 0.718 0.934 0.958 0.945The best F1 score is highlighted for each drugF1 = 2 × Precision × RecallPrecision + Recall (3)Some drugs reach recall lower than 0.9 (e.g. Dexameta-sona and Prednisona) and Loratadina has a precisionaround 0.83, which is lower than most others. Althoughnot being conclusive and still needs further investiga-tion, we found in an initial analysis the observed differ-ences among the scores refer to some prefixes (e.g. cap,clo, para, ox) and suffixes (e.g. mina, lina, pina,tina) that are used to compound names of distinct drugs,increasing the value of the similarity scores for negativematches, thus leading to false positives. Some words inPortuguese can also be compound by the verbal derivativeform of a noun, such as insulinizar as a verb referringto the substance Insulina. All these factors combinedincrease the probability of a drug name being similar to amore diverse set of distinct words or other drugs in thisspecific language.A hybrid solution showed to be efficient on dealingwith both phonetic and spelling errors, and combiningboth string and phonetic similarity thresholds favouredprecision and recall when looking for misspelt drugnames. However, this approach suffers in terms of per-formance in a large corpus. Thus, we used the result-ing dictionary of true positive misspelt names of drugsas input for an adapted version of the Trie-based fastsearch approach algorithm proposed in [22]. This com-bined approach showed to be efficient (in terms of per-formance) on finding dictionary-based variations withmax(ED(word1;word2)) = 1. As a result, hundreds ofpotential misspelt variations for drug names were identi-fied after processing a new set of medical records com-prising approximately 5 million documents. To illustratethe potential use of such combined method, 231 positivemisspelt variations for Fluoxetina (Fluoxetine) and 501positive misspelt variations for Paracetamol have beenalready positively identified. Table 4 shows that some ofthis variations for the drug Fluoxetina can have highvalues for the Edit Distance metric.Conclusions and future workIn this paper, we presented a hybrid similarity approachthat efficiently performs a joint string and language-dependent phonetic similarity search over a set of med-ical records written in Portuguese. Experimental resultsshowed this method is potentially accurate and able toTissot and Dobson Journal of Biomedical Semantics 2019, 10(Suppl 1):17 Page 6 of 7Table 4 Examples of misspelt variations for Fluoxetina(Fluoxetine) and the corresponding Edit Distance (ED) valuesMisspelt variation EDdfluoxetina 1flluoxetina 1floxetina 1fluoexetina 1fluoixetina 1fluopxetina 1fluoxertina 1fluoxetiina 1fluoxetijna 1fluoxetin 1fluoxetinas 1fluoxetna 1fluoxetona 1fluoxettina 1fluoxetuina 1fluoxewtina 1fluoxtina 1fluozxetina 1fluuoxetina 1fluuoxetina 1fluxetina 1fluyoxetina 1flhuoxetin 2flluoxetin 2flouxetina 2fluoxeitna 2fluoxetian 2fluxoetina 2fluxotina 2fluloextina 3fluoxetinaate 3fluoxetinapor 3flxtina 3fluoxetinapara 4infloexetina 4identify misspelt names of drugs, overcoming the loss ofinformation inherit from using either exact match searchmethods or string based similarity search. We coupledthe proposed approach with a Trie-based fast similaritysearch algorithm that is able to use small Edit Distancethreshold (? 1) over the produced dictionary of mis-spelt names in order to find a broader number of misspeltvariations within an affordable processing time in a largecorpus.Some of the directions in which this work can beextended include: a) adapting the phonetic matching pro-cess originally designed to the Portuguese language to beused over large corpora in different languages, such asEnglish; b) integrating our method in a framework forMedical Records Information Extraction applications toaddress the problem of generically dealing with spellingerrors in the information extraction process beyondnames of drugs, including other types of clinical variables,such as symptoms and diagnoses; c) exploring the use ofmachine learning methods to optimally and dynamicallytune the threshold parameters and disambiguating mis-spelt candidates in cases when they are similar to morethan one medication; d) comparing the proposed solutionwith other approximate string match approaches.AbbreviationsCIS: Outpatient Information System; ED: Edit Distance (or LevenshteinDistance); EHR: Electronic Health Record; HealTAC: Healthcare Text AnalyticsConference; ICD: International Code of Diseases; NIHR: National Institute forHealth Research; RAAI: Ambulatory Care Individual ReportAcknowledgmentsWe would like to thank the InfoSaude team for the permission to use thepatient EHR data.An initial version of this paper has been presented at the Healthcare TextAnalytics Conference 2018 (HealTAC), in April 2018 (http://healtex.org/healtac-2018/).About this supplementThis article has been published as part of the Journal of Biomedical SemanticsVolume 10 Supplement 1, 2019: HealTAC-2018: Unlocking Evidence Contained inHealthcare Free-text. The full contents of the supplement are available online athttps://jbiomedsem.biomedcentral.com/articles/supplements/volume-10-supplement-1.Authors contributionsHT designed the joint string and language-dependent phonetic similarityapproach used in the work, performed the experiments and analysd the finalresults. RD reviewed the analysis and final results. All authors have read andapproved the final manuscript.FundingThis study was funded Health Data Research UK (grant No. LOND1), which isfunded by the UK Medical Research Council, Engineering and PhysicalSciences Research Council, Economic and Social Research Council,Department of Health and Social Care (England), Chief Scientist Office of theScottish Government Health and Social Care Directorates, Health and SocialCare Research and Development Division (Welsh Government), Public HealthAgency (Northern Ireland), British Heart Foundation and Wellcome Trust. ADSis supported by a postdoctoral fellowship from THIS Institute. Publication costsare funded by UCL open access block grant.Availability of data andmaterialsThe dataset is available at http://github.com/HeglerTissot/mnd, including thecomplete set of drug names and words used in our model, as well as the precalculated values for the string and phonetic similarity matching metrics foreach pair (drug,word).Ethics approval and consent to participateNot applicable.Consent for publicationNot applicable.Competing interestsThe authors declare that they have no competing interests.Tissot and Dobson Journal of Biomedical Semantics 2019, 10(Suppl 1):17 Page 7 of 7Author details1Institute of Health Informatics, University College London, London, UK.2Health Data Research UK London, University College London, London, UK.3Department of Biostatistics and Health Informatics, Institute of Psychiatry,Psychology and Neuroscience, Kings College London, London, UK.Published: 12 November 2019RESEARCH Open AccessAutomated SNOMED CT concept andattribute relationship detection through aweb-based implementation of cTAKESMartijn G. Kersloot1* , Francis Lau2, Ameen Abu-Hanna1, Derk L. Arts1 and Ronald Cornet1AbstractBackground: Information in Electronic Health Records is largely stored as unstructured free text. Natural languageprocessing (NLP), or Medical Language Processing (MLP) in medicine, aims at extracting structured informationfrom free text, and is less expensive and time-consuming than manual extraction. However, most algorithms in MLPare institution-specific or address only one clinical need, and thus cannot be broadly applied. In addition, most MLPsystems do not detect concepts in misspelled text and cannot detect attribute relationships between concepts. Theobjective of this study was to develop and evaluate an MLP application that includes generic algorithms for thedetection of (misspelled) concepts and of attribute relationships between them.Methods: An implementation of the MLP system cTAKES, called DIRECT, was developed with generic SNOMED CTconcept filter, concept relationship detection, and attribute relationship detection algorithms and a customdictionary. Four implementations of cTAKES were evaluated by comparing 98 manually annotated oncology chartswith the output of DIRECT. The F1-score was determined for named-entity recognition and attribute relationshipdetection for the concepts lung cancer, non-small cell lung cancer, and recurrence. The performance of the fourimplementations was compared with a two-tailed permutation test.Results: DIRECT detected lung cancer and non-small cell lung cancer concepts with F1-scores between 0.828 and0.947 and between 0.862 and 0.933, respectively. The concept recurrence was detected with a significantly higherF1-score of 0.921, compared to the other implementations, and the relationship between recurrence and lungcancer with an F1-score of 0.857. The precision of the detection of lung cancer, non-small cell lung cancer, andrecurrence concepts were 1.000, 0.966, and 0.879, compared to precisions of 0.943, 0.967, and 0.000 in the originalimplementation, respectively.Conclusion: DIRECT can detect oncology concepts and attribute relationships with high precision and can detectrecurrence with significant increase in F1-score, compared to the original implementation of cTAKES, due to theusage of a custom dictionary and a generic concept relationship detection algorithm. These concepts andrelationships can be used to encode clinical narratives, and can thus substantially reduce manual chart abstractionefforts, saving time for clinicians and researchers.Keywords: Chart abstraction, Natural language processing, Electronic health records, Algorithms, SNOMED CT© The Author(s). 2019 Open Access This article is distributed under the terms of the Creative Commons Attribution 4.0International License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, andreproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link tothe Creative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver(http://creativecommons.org/publicdomain/zero/1.0/) applies to the data made available in this article, unless otherwise stated.* Correspondence: m.g.kersloot@amsterdamumc.nl1Department of Medical Informatics, Amsterdam Public Health ResearchInstitute, Amsterdam UMC, University of Amsterdam, Meibergdreef 9, 1105AZAmsterdam, The NetherlandsFull list of author information is available at the end of the articleKersloot et al. Journal of Biomedical Semantics           (2019) 10:14 https://doi.org/10.1186/s13326-019-0207-3BackgroundMuch of the data present in Electronic Health Records(EHRs) are stored as unstructured free text [1] as clini-cians often resort to making free-text notes, despiteavailable coding options [2]. The use of free textshould be taken into account when EHR data arereused for other purposes [3], since data reuse for re-search and development of clinical decision supporttools can improve healthcare [4]. However, using free-text notes for searching, summarizing, statisticalanalysis, and as input for decision support systems ischallenging [5].One of the tasks of natural language processing(NLP) methods, named-entity recognition, aims to ex-tract structured information from free text that is lessexpensive and time-consuming than extracting itmanually [6]. NLP in the medical field, medical lan-guage processing (MLP), is more challenging than NLPin various other fields since clinical texts have differentgrammar, contain ambiguous abbreviations (i.e., thesame set of letters has multiple meanings), and containmore misspellings [1, 7]. Recent studies show thatMLP can successfully be used for several purposes in-cluding deriving comorbidities from the EHR [8], de-tecting adverse events [9], and finding eligible patientsfor clinical trials by attaching clinical concepts to pa-tient charts (encoding) [10]. Furthermore, MLP hasbeen proven successful in extracting diagnoses fromfree-text notes from the EHR, thereby reducing manualchart abstraction efforts. It can, for example, be usedto automatically detect the recurrence of breast cancerin patient charts, reducing the number of manuallyreviewed charts by 90% [11]. Other research showsthat MLP can identify uncodified diabetes cases, lead-ing to a more complete ascertainment of diagnosesand, thus, better information provision and targetedcare for patients [12].MLP systems include multiple algorithms to processfree text and extract information from it. Clinical TextAnalysis and Knowledge Extraction System (cTAKES) isan open-source MLP system from The Apache SoftwareFoundation [13]. It is based on the Unstructured Infor-mation Management Architecture (UIMA) frameworkand the OpenNLP toolkit [13]. cTAKES provides linguis-tic and semantic annotations for unstructured free text[13] using SNOMED CT [14] and RxNorm [15] diction-aries. cTAKES is designed to be modular and extensibleat the information model and method levels, ensuringthat it is suitable for a variety of use cases [16].MLP algorithms have been implemented in varioussystems. A recent systematic review has shown thatmost implementations of MLP algorithms are institu-tion-specific, address only one clinical need, might beoverfitted, and thus not scalable [17]. In addition, mostMLP systems do not detect concepts in misspelled text,e.g. Smll cell lng cancer, only detect unqualified rela-tionships (e.g. Non-small cell lung cancer relates in away to Recurrent, Fig. 1.1) between concepts or theirinstances, and cannot detect attribute relationships, e.g.Non-small cell lung cancer with Recurrent as Clinicalcourse (Fig. 1.2). Attribute relationships make the typeof relationship between concepts or their instances ex-plicit (e.g. Clinical Course in Fig. 1.2).Since most MLP systems do not offer these algo-rithms, this study aimed to develop a cTAKES imple-mentation that includes generic algorithms for thedetection of concepts from properly spelled and mis-spelled descriptions and attribute relationships betweenthese concepts. The implementation is evaluated by en-coding free-text oncology charts to detect charts thatdescribe recurrent non-small cell lung cancer, and usethese outcomes to calculate the F1-score.Material and methodscTAKEScTAKES enables encoding through several algorithms,which are included in several pipelines. We used cTAKESAggregatePlaintextFastUMLSProcessor pipeline (e.g. theFig. 1 A representation of a unqualified relationship between Non-small cell lung cancer and Recurrent (1) and an attribute relationship ofNon-small cell lung cancer with Recurrent as Clinical course (2). The attribute relationship is modelled as a SNOMED CT concept definitiondiagram of recurrent non-small cell lung cancer (a new post-coordinated expression). Purple blocks represent defined concepts, blue blocksrepresent primitive SNOMED CT concepts and yellow blocks represent attributes. Attribute groups are represented using a white circle, andconjunctions are represented using a black dotKersloot et al. Journal of Biomedical Semantics           (2019) 10:14 Page 2 of 13output of one algorithm becomes the input to the next[18]), as shown in Fig. 2, for the pre-processing andprocessing of free-text clinical narratives, since it usesthe Unified Medical Language System (UMLS) [19] asits dictionary. In this project, we focus on theSNOMED CT concepts that are included in the UMLS,as the hierarchical and relational structure of SNOMEDCT allows us to determine and define relationships be-tween medical concepts.Development of an MLP toolOur project involved the development of a cTAKESimplementation named Disease Information and Rela-tionship ExtraCtion Tool (DIRECT). cTAKES providesa generic way of concept matching (through dictionarylook-up), and detection of syntactic relationships andRESEARCH Open AccessNatural language processing for diseasephenotyping in UK primary care recordsfor research: a pilot study in myocardialinfarction and deathAnoop D. Shah1,2,3,4*, Emily Bailey4, Tim Williams5, Spiros Denaxas1,2,3, Richard Dobson1,2,3,6 andHarry Hemingway1,2,3From UK Healthcare Text Analysis Conference (HealTAC 2018)Manchester, UK. 18-19 April 2018AbstractBackground: Free text in electronic health records (EHR) may contain additional phenotypic information beyondstructured (coded) information. For major health events  heart attack and death  there is a lack of studies evaluatingthe extent to which free text in the primary care record might add information. Our objectives were to describe thecontribution of free text in primary care to the recording of information about myocardial infarction (MI), includingsubtype, left ventricular function, laboratory results and symptoms; and recording of cause of death. We used theCALIBER EHR research platform which contains primary care data from the Clinical Practice Research Datalink (CPRD)linked to hospital admission data, the MINAP registry of acute coronary syndromes and the death registry. In CALIBERwe randomly selected 2000 patients with MI and 1800 deaths. We implemented a rule-based natural language engine,the Freetext Matching Algorithm, on site at CPRD to analyse free text in the primary care record without rawdata being released to researchers. We analysed text recorded within 90 days before or 90 days after the MI,and on or after the date of death.Results: We extracted 10,927 diagnoses, 3658 test results, 3313 statements of negation, and 850 suspecteddiagnoses from the myocardial infarction patients. Inclusion of free text increased the recorded proportion ofpatients with chest pain in the week prior to MI from 19 to 27%, and differentiated between MI subtypes ina quarter more patients than structured data alone. Cause of death was incompletely recorded in primary care; in 36%the cause was in coded data and in 21% it was in free text. Only 47% of patients had exactly the same cause of deathin primary care and the death registry, but this did not differ between coded and free text causes of death.Conclusions: Among patients who suffer MI or die, unstructured free text in primary care records contains muchinformation that is potentially useful for research such as symptoms, investigation results and specific diagnoses.Access to large scale unstructured data in electronic health records (millions of patients) might yield importantinsights.Keywords: Free text, Myocardial infarction, Primary care, Chest pain, Natural language processing© The Author(s). 2019 Open Access This article is distributed under the terms of the Creative Commons Attribution 4.0International License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, andreproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link tothe Creative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver(http://creativecommons.org/publicdomain/zero/1.0/) applies to the data made available in this article, unless otherwise stated.* Correspondence: anoop@doctors.org.uk1Health Data Research UK London, University College London, 222 EustonRoad, London NW1 2DA, UK2Institute of Health Informatics, University College London, 222 Euston Road,London NW1 2DA, UKFull list of author information is available at the end of the articleShah et al. Journal of Biomedical Semantics 2019, 10(Suppl 1):20https://doi.org/10.1186/s13326-019-0214-4BackgroundElectronic health records (EHR) are increasingly used forclinical research, but much of the information theycontain is stored in an unstructured way [1, 2]. Researchprojects using EHR databases conventionally use onlythe structured information, but could potentially missimportant information if it is not coded correctly (Fig. 1).There has been increasing interest in using natural lan-guage processing (NLP) to extract additional informationfrom the free text for research, such as in the eMERGEhospital network in the US [3]. However, there have beenfew studies using NLP on primary care data, which iscrucial for understanding early manifestations of disease(before a patient is admitted to hospital or attends asecondary care clinic). This may enable the developmentof early diagnosis and treatment strategies.For example, a previous study using structured infor-mation in primary care data found more than a 5-foldincrease in the frequency of chest pain consultations inthe two months prior to a myocardial infarction (MI)[4]. If some consultations for chest pain are not recordedusing appropriate codes, as suggested in US studies [5],the prevalence of chest pain prior to MI may be under-estimated. Accurate information on such symptoms isessential to inform public health endeavours aimed atpreventing MI, but has not previously been studied on alarge scale in the UK.We used primary care data from the Clinical PracticeResearch Datalink (CPRD), a population-based source oflongitudinal clinical information. Although early studiesusing CPRD manually reviewed small samples of text tovalidate coded diagnoses [6], there has been little re-search on the potential contribution of free text beyondthe coded information in UK primary care, and previousstudies have been limited to a few hundred texts [710].At the time of this study, free text from CPRD primarycare was stored at the Department of Health, and couldbe released to researchers after manual anonymisationFig. 1 Illustration of patients experience, information entered in the structured part of the primary care record (Read codes), and additionalinformation that might be available in free text. In this hypothetical example, the subtype of myocardial infarction and preceding symptoms arepresent only in the free textShah et al. Journal of Biomedical Semantics 2019, 10(Suppl 1):20 Page 2 of 10by CPRD staff. This was time-consuming and costly,feasible for only small samples of text for validationstudies. However, free text is no longer collected or madeavailable by CPRD because of confidentiality concerns, soit is essential to know what is missing from the structureddata.To address these challenges, we developed and vali-dated a natural language processing system, the FreetextMatching Algorithm (FMA) [7]. This is an entity linkingprogram which maps sequences of words to Read codes,using manually defined synonyms and patterns to recog-nise the context of words in the text. As well as diagnoses,it can extract symptoms, dates and laboratory test results.The output of the algorithm is structured, containing onlycodes and numeric values. In this paper we describe apilot project to use FMA to analyse primary care free textat source, without needing manual anonymisation, thusanalysing larger samples of text than has previously beenpossible.Our specific aims were to describe the contribution offree text to the recording of information about MI inCPRD primary care data, including MI subtype, leftventricular function, laboratory results, symptoms, andwhether the MI record related to a new or historicevent. We also used FMA to investigate cause of deathrecording in general practice, comparing the results tothe cause of death recorded in the death registry.MethodsStudy data sourceWe used linked electronic health records from fourdata sources in England (the CALIBER resource [11]),which contains primary care data from CPRD linked toadministrative hospital records (Hospital Episode Sta-tistics, HES) and death registrations from the Office forNational Statistics (ONS). The CALIBER programmeinvolved additional linkage with the Myocardial IschaemiaNational Audit Project (MINAP), facilitated by CPRD, andcontained data from 244 practices in England. We previ-ously carried out a study of the completeness and diagnos-tic validity of MI records in CALIBER [12], which included21,482 patients with a first MI recorded in either MINAP,HES, ONS or CPRD primary care in 20032009. For thispilot project we chose a random subset of 2000 patientsfrom this study. This sample size would yield enough freetext to demonstrate the value of this approach as it wouldbe too large to anonymise manually, but it would befeasible to extract and analyse as a pilot project. We alsostudied 1800 patients who died of any cause between 2001and 2009 and had a death registry record in linked ONSdata (200 patients per year).For the MI population, we analysed free text in theprimary care record associated with clinical, test or re-ferral events up to 90 days before or after the MI, andfor the death population, we analysed free text in pri-mary care associated with clinical or referral events onor after the date of death.Natural language processingThe Freetext Matching Algorithm (FMA) is a naturallanguage processing system designed to extract Readcodes and other structured data from UK general prac-tice records. It was developed using small samples ofpre-anonymised text from CPRD and is available underan open source license (GPL Version 3).FMA has been described previously [7]; briefly it is arule-based annotation and information extraction engine.The text is first cleaned of semi-structured computer-generated phrases (defined in a manual lookup), thenconverted to lower case and split into individual words.The program identifies dates, numbers and words, andmaps individual words to lookup tables of medical words(any word contained within any Read term) and non-medical words (from an English lexicon). If a word doesnot match any entry in the dictionaries, it is assumed tobe misspelt, and the program attempts spelling correctionwith a single letter insertion or substitution algorithm.Attributes such as negation are identified by sequentialapplication of regular expression rules, and the programthen attempts to match sequences of up to five words toRead terms. If the text phrase does not match a Read termexactly, parts of the phrase are substituted by alternativewords and phrases using the synonym table. A customscoring function rates the quality of each potential match,and returns the Read term with the closest match above aminimum threshold. The output of the algorithm is a se-quence of Read terms or quantitative data with attributes.We tested the FMA on pre-anonymised samples offree text from patients with coronary artery disease, andadded terms to the lookup tables to enable it to detectsubtype of myocardial infarction and left ventricularfunction. We collaborated with CPRD to arrange fortheir staff to run the program on free text for the studypopulation. CPRD staff verified that the output con-tained only coded or numeric data before releasing it toresearchers. We used FMA in preference to other opensource NLP tools because it was small (a single 200 KBexecutable and 8.5MB lookup tables) and required noinstallation or special software, so it was easy for CPRDstaff to run. It also had the advantage of being custo-mised for text in primary care records, returning resultsin a similar format to existing structured CPRD data.Information extracted from free textWe summarised the frequencies of Read codes extractedby FMA with different data types within 90 days ofmyocardial infarction. We calculated the frequencies ofrecording in Read codes and free text for symptoms andShah et al. Journal of Biomedical Semantics 2019, 10(Suppl 1):20 Page 3 of 10investigation results of particular interest, such as chestpain, shortness of breath, pulse rate, angiogram resultsand left ventricular function.Classifying the type of myocardial infarctionFor patients who had a MINAP record in CALIBER, i.e.those who arrived at hospital alive and whose data weresubmitted to the national acute coronary syndromeregistry, we investigated the accuracy of structured andunstructured information in the primary care record.We classified the type of myocardial infarction accordingto the closest STEMI or NSTEMI Read code or free textrecord after the date of MI within 30 days. We calculatedthe sensitivity and specificity of Read codes and free textfor identifying the type of MI.Validity of myocardial infarction recordsTwo clinicians manually reviewed the CALIBER record(CPRD structured primary care record, linked data fromHES, and information extracted by FMA), for patientswith MI recorded in primary care but not HES orMINAP. They adjudicated whether or not the MI Readcode in CPRD represented a true current MI, resolvingany disagreements by discussion to reach a consensus.For patients with MI recorded in HES, MINAP or ONSwithin 30 days of the primary care record, we assumedthat the MI was genuine and did not review their recordmanually.We tested a machine learning algorithm (Random For-est [13]) on the task of discriminating between correctand incorrect MI records, using the manual adjudicationor presence of a HES or MINAP record as the goldstandard for a true MI. Predictor variables for this taskincluded the likelihood of the exact Read code to be as-sociated with a HES or MINAP record for MI in otherpatients (Supplementary Table 7 in Herrett et al. [12]),specific details about the MI record (the consultationtype, whether it was entered on the date it occurred,whether there was a coronary register entry on the samedate, whether it was recorded as a new or continuingepisode), whether there was a Read code for hospitaladmission within 7 days, and whether there was a Readcode for chest pain or shortness of breath within 7 days.We also generated binary variables for the presence ofthe most common 100 Read codes entered on the samedate, or dated within 30 days of the MI date, or Readcodes extracted by FMA within 30 days of the MI date.We generated composite variables grouping Read codesby their first 1, 2 or 3 characters, in case groups of Readcodes were better predictors than sparse variables en-coding the presence of individual Read codes.We used Random Forest with 100 trees, trying all vari-ables at every split (to avoid bias due to a large proportionof sparse or non-informative variables). We calculated theaccuracy of models generated from 200 bootstrap samplesof the data, using the patients not selected as the test setfor each model.Cause of deathWe manually reviewed structured death certificate infor-mation, Read codes and diagnoses extracted by FMAfrom CPRD primary care data to assign the most likelyunderlying cause of death for the sample of 1800patients. We converted the causes of death to ICD-10using the Read to ICD-10 mapping table, and allocatedthe underlying cause of death by manual review of theextracted coded diagnoses and application of the ICD-10selection rules [14], blinded to the cause of deathrecorded in the death registry (we did not have access toreview the raw free text diagnoses). We calculated theproportion of deaths with cause recorded in differentways, giving priority to the more specific information(e.g. a free text diagnosis with death certificate categorywas given priority over a Read coded diagnosis withoutcategory). We compared the causes of death thusextracted with the gold standard cause in the deathregistry. We assessed the similarity of the underlyingICD-10 code and concordance for three common diag-nosis groups: coronary heart disease, cerebrovasculardisease and cancers.Statistical analysisAll statistical analysis was carried out using R Version3.4 [15], using the packages CALIBERdatamanage andCALIBERcodelists (published on R-Forge [16]) to assistwith data management.ResultsFMA analysed 31,913 text entries in CPRD containing705,523 words in 40 min on a Windows 2008 Server.Information extracted from free text for myocardialinfarction patientsWe included 2000 MI patients in this study, with me-dian age 75 years (interquartile range 63, 83), of whom781 (39%) were female. FMA extracted 21,369 Readcodes with the attribute medical history or current orprevious condition, of which 10,957 were diagnoses(defined as Read codes in the diagnosis chapter, ratherthan administration, procedures, test results etc.), and1117 suspected conditions, of which 850 were diagnoses.FMA also extracted 3658 test results, 3313 statements ofnegation and 968 entries referring to hospital admission(Fig. 2). The most common negated conditions werechest pain (377 entries), breathlessness or dyspnoea(300), unspecified pain (208) and oedema (121). Themost common Read coded diagnosis in the free text wasacute myocardial infarction (8.1%) (Table 1).Shah et al. Journal of Biomedical Semantics 2019, 10(Suppl 1):20 Page 4 of 10Among patients with MI not recorded in CPRD struc-tured data, 108 (18.9%) had MI recorded in free textwithin 30 days. The proportion of patients with record-ing of symptoms and investigations associated with MIincreased when free text was included. For example, theprevalence of chest pain within 7 days prior to MI wouldbe underestimated by a third if free text were ignored(18.9% instead of 27.2%) (Table 2).Classifying the type of myocardial infarctionAmong the 608 patients with a MINAP record givingdetailed information about the MI, 149 (25%) had a Readcode stating the type of MI and 46 (8%) had this infor-mation available only in the free text. Inclusion of freetext information increased the sensitivity for detection ofMI subtypes, with a slight reduction in sensitivity andpositive predictive value (Table 3). Concordance ofderived MI subtypes with the MINAP gold standard waslower for free text (78.3%; 95% CI 63.6%, 89.1%) thanRead codes (91.9, 95% CI 86.4%, 95.8%).Validity of myocardial infarction recordsOur manual review of coded and free text data con-cluded that the majority of patients with MI recordedonly in CPRD primary care data (210/267) had a genuinerecent MI. In some cases, free text contributed directlyto our decision; for example, one patient had an MI codeon the same date as a mental health diagnosis, but thefree text stated that the MI was one year ago. Weassessed whether information in the free text couldimprove the performance of machine learning modelsfor identifying a true MI. Using the Random Forestmodel on the entire sample of 2000 patients, the per-centage correct (mean and 95% bootstrap confidenceinterval) without using free text was 95.9% (95% CI94.3%, 97.4%) and using free text was 95.6% (95% CI93.9%, 97.3%); i.e. no significant difference.Cause of deathCause of death was incompletely recorded in CPRDprimary care data, with only a slight improvement overtime. Free text contributed 37% of the causes recordedin primary care (381/1022) (Table 4). Only 46.7% of pa-tients (95% CI 43.6%, 49.8%) had the same exact ICD-10code for the underlying cause in primary care and thedeath registry, but in 72.5% (95% CI 69.7%, 75.2%) thecause was from the same ICD-10 chapter. CPRD pri-mary care data had high specificity but moderate sensi-tivity for identifying coronary, cerebrovascular or cancerdeaths, but no difference in accuracy between structuredand free text records (Table 5).DiscussionWe analysed a larger quantity of unstructured free textin a UK primary care database than any previous study.We were able to do so by using natural language proces-sing software to extract information without requiringmanual review or anonymisation of the free text record.Free text notes in primary care records commonly containbrief expressions, non-grammatical phrases, spellingmistakes and irregular punctuation, posing a particularchallenge to NLP tools [17]. There have been attempts tobetter phenotype myocardial infarctions using NLP onhospital discharge summaries [18], but none usingprimary care data. Overall there have been very few NLPstudies on free text in UK primary care [710]; this is thelargest to date. Under CPRD policy at the time of thestudy, free text required manual anonymisation by CPRDstaff before being released to researchers, and anonymis-ing the 705,523 words analysed in this project would havecost over £35,000. We previously carried out a validationstudy of myocardial infarction (MI) in the CALIBERlinked EHR resource. We found that agreement betweenthe data sources in CALIBER was poor [12]. MI records inprimary care data typically did not differentiate betweensubtypes of MI (STEMI, ST segment elevation MI, orNSTEMI, non ST segment elevation MI), despite theclinical importance of this distinction.Summary of main findingsWe found that free text contained a large amount of in-formation on symptoms, test results (e.g. left ventricularFig. 2 Data items extracted from primary care free text for 2000 patients within 90 days before or after myocardial infarctionShah et al. Journal of Biomedical Semantics 2019, 10(Suppl 1):20 Page 5 of 10function), clinical measurements, diagnoses, admissionsand administration (e.g. sickness certificates), much ofwhich was not present in the structured data, and couldpotentially be useful for clinical research studies. Freetext contained a large number of records of suspectedconditions, for which the clinical system does not pro-vide a facility for structured recording. Symptoms relatedto myocardial infarction such as chest pain and shortnessof breath were recorded in the free text rather than as Readcodes in about a third of patients, because the informationwas scanned as an image and not converted to text.We attempted to use free text to help determine if aMI record in CPRD with no linked MI record in anotherdata source was a true current MI, rather than an incor-rectly dated historic event. Based on manual review ofthe FMA-annotated CPRD record, we concluded thatthe vast majority were true current MI, which limitedour ability to quantify the contribution of the free textfor such determination. The small number of incorrectMI records made this a difficult machine learning task,as it is known that imbalance in datasets for machinelearning can lead to a biased classifier. Potential methodsof improving performance on such tasks may be to alterthe training balance [19], or develop bias-aware prob-abilistic classifiers [20].Cause of death was incompletely recorded, even withthe addition of free text, and in a significant proportionof cases the cause of death in the death registry and inprimary care were different. This may be because thegeneral practitioner did not receive definitive cause ofdeath information from post mortems or coroner re-ports; cause of death information was more completeand accurate for cancer deaths, where there is less ambi-guity. Linked registry data seems to be the only completeand accurate source of cause of death data.LimitationsResearch studies incorporating NLP must include valid-ation of variables derived using NLP, which is usuallydone by manual review of a random subset of therecords. The main limitation of our study was that wewere unable to manually validate the extracted dataitems against the original raw text, because CPRD with-drew access to free text for researchers part-way throughthe study (and no longer collects free text). We refer toa previous validation of the Freetext Matching Algo-rithm demonstrating over 90% precision [7], which isadequate for this project demonstrating the broad utilityof free text in primary care, but studies with clinical im-plications would require the NLP error rate for specificvariables to be propagated into the uncertainty of thefinal estimates. For some measures we were able to com-pare information extracted from text with linked registrydatasets (MINAP and the death registry).Table 1 Most common Read codes extracted from free text for2000 patients within 90 days of MI in CALIBER (top five codes ineach category)Number of records(%)ReadcodeRead termCurrent or previous condition (diagnosis Read codes)887 (8.1%) G30z.00 Acute myocardial infarction NOS443 (4.1%) R065.00 [D] Chest pain304 (2.8%) C10..00 Diabetes mellitus272 (2.5%) G307100 Acute non-ST segment elevation myocar-dial infarction256 (2.3%) G33..00 Angina pectorisCurrent or previous condition (non ? diagnosis Read codes)991 (9.5%) 8H3Z.00 Other hospital admission NOS913 (8.8%) 8H00 Referral for further care795 (7.6%) 1M00 Pain469 (4.5%) 173..00 Breathlessness445 (4.3%) 8HA..11 Discharged from follow upQuantitative test result577 (15.8%) 42Z7.00 Red blood cell distribution width142 (3.9%) 42M..00 Lymphocyte count141 (3.9%) 42N..00 Monocyte count139 (3.8%) 42K..00 Eosinophil count138 (3.8%) 42J..00 Neutrophil countAbsence of condition (diagnosis Read codes)121 (7.8%) R023.00 [D] Oedema105 (6.8%) G33..00 Angina pectoris90 (5.8%) R065.00 [D] Chest pain57 (3.7%) A....00 Infectious and parasitic diseases38 (2.5%) R006200 [D] Fever NOSAbsence of condition (non-diagnosis Read codes)281 (15.6%) 182..00 Chest pain274 (15.2%) 173..00 Breathlessness208 (11.5%) 1M00 Pain89 (4.9%) 2I18.12 O/E - tenderness48 (2.7%) 199..00 VomitingSuspected condition (diagnosis Read codes)70 (8.2%) G30z.00 Acute myocardial infarction NOS48 (5.6%) K190.00 Urinary tract infection, site not specified40 (4.7%) A.00 Infectious and parasitic diseases32 (3.8%) G33..00 Angina pectoris23 (2.7%) G581.13 Impaired left ventricular functionSuspected condition (non-diagnosis Read codes)44 (16.5%) 8H00 Referral for further care18 (6.7%) 8H3Z.00 Other hospital admission NOS16 (6.0%) 1M00 Pain9 (3.4%) 173..00 Breathlessness7 (2.6%) 2C2..11 O/E - anaemicShah et al. Journal of Biomedical Semantics 2019, 10(Suppl 1):20 Page 6 of 10Another limitation is that we used only one naturallanguage processing algorithm; other open source anno-tators have been released since the development of theFMA. Examples include cTakes [21] (Mayo Clinic),MetaMap [22] (US National Library of Medicine), Hitex[23] (Harvard Medical School) and Bio-Yodie, developedas part of the KConnect Horizon 2020 project [24]. Forthis project we used our in-house FMA algorithm be-cause of its small size and simplicity. We limited thesample size in order to be able to solve any unexpectedproblems, and to facilitate CPRDs process of assuringthat the output contained only numerical data, with nounintended leak of text.Another limitation was the use of only a single annota-tor for the cause of death classification. The ICD-10rules for selecting the underlying cause of death arecomplex; in this study this task was performed by aclinician with experience in classifying the cause of deathfor over 2000 patients in a previous study [7]. It wouldhave required considerable resource to train another an-notator to the same level. Given that agreement betweenthe primary care record and death registry was pooreven with a well-trained annotator, it was unlikely thatadditional annotation would alter the conclusion thatthe primary care record is an unreliable source of causeof death information.Clinical implicationsAlthough there has been much research activity aroundnatural language processing of clinical text, few advanceshave made it to the clinic [25]. A fundamental problemis that information extracted from text cannot be reliedupon to be completely accurate because of the nuancesof human language; an error rate of 5% may be accom-modated in research but is not an acceptable risk whenplanning treatment for an individual patient. A potentialTable 2 Information available in CPRD primary care data (coded data and free text) for a random sample of 2000 patients withmyocardial infarction in the linked CALIBER datasetData element Structured data only Structured or free text % increase byusing free textWithin 90 days before or after MI:Pulse rate 323 (16.2%) 634 (31.7%) 96%Blood pressure 1557 (77.9%) 1609 (80.5%) 3%Left ventricular function result 115 (5.8%) 309 (15.5%) 169%Coronary angiogram results 26 (1.3%) 198 (9.9%) 662%Irregular pulse 2 (0.1%) 6 (0.3%) 200%Atrial fibrillation or flutter 121 (6.0%) 153 (7.6%) 26%Chest pain ?7 days before MI 378 (18.9%) 543 (27.2%) 44%Chest pain ?90 days before MI 455 (22.8%) 642 (32.1%) 41%Shortness of breath ?7 days before MI 62 (3.1%) 102 (5.1%) 65%Shortness of breath ?90 days before MI 125 (6.3%) 196 (9.8%) 57%Table 3 Type of MI as recorded in CPRD primary care data, for patients with a gold standard MI subtype record in MINAPSubtype of MIPrimary care source of type of MI STEMI (N = 315) NSTEMI (N = 293)Structured (Read codes)(number of patients)STEMI 41 6NSTEMI 6 96Free text(number of patients)STEMI 13 5NSTEMI 5 23Patients with no information on type of MI in primary care 250 163Accuracy of MI classification using structured data Sensitivity, % 13.0 (9.5, 17.2) 32.8 (27.4, 38.5)Specificity, % 98.0 (95.6, 99.2) 98.1 (95.9, 99.3)Positive predictive value, % 87.2 (74.3, 95.2) 94.1 (87.6, 97.8)Accuracy of MI classification using structured and free text data Sensitivity, % 17.1 (13.1, 21.8) 40.6 (34.9, 46.5)Specificity, % 96.2 (93.4, 98.1) 96.5 (93.8, 98.2)Positive predictive value, % 83.1 (71.7, 91.2) 91.5 (85.4, 95.7)Shah et al. Journal of Biomedical Semantics 2019, 10(Suppl 1):20 Page 7 of 10solution is to embed real-time natural language process-ing within clinical systems, to generate structured datawhilst giving clinicians the freedom to express theirthoughts in a natural way. The NHS Common UserInterface guidelines [26] contains recommendations forsuch technology, but current systems have not yetimplemented it in practice.Research implicationsNLP has been applied to primary care records in othercountries for research studies attempting early diagnosisof multiple sclerosis [27], classification of childhoodrespiratory illnesses [28, 29] and identification of heartfailure symptoms [30]. However, NLP of primary carenotes can be challenging  the language is terse, oftenungrammatical and abbreviated [17]. The sublanguage ofprimary care clinical notes has not been studied at scale,nor are we aware of international comparisons in thisarea, which would be helpful for generalising NLPmethodology worldwide.One of the difficulties in healthcare text analytic re-search is the governance and access restrictions on theuse of free text. In the UK, CPRD no longer providesaccess to primary care free text, following the Informa-tion Commissioners Office instructions (https://ico.org.uk/), leaving The Health Improvement Network as theonly UK primary care research database containing freetext. CPRD can facilitate GP questionnaires to validateor enhance a small sample of records (at additionalcost), but large-scale research using CPRD will be basedentirely on the coded data. In the long term, incentivessuch as the Quality and Outcomes Framework [31] mayhelp to improve data completeness for specific dataitems that are clinically important.However, in some secondary care NHS Trusts, clinicaltext is available for research under secure governancearrangements. The South London and Maudsley NHSTrust has been using the Cogstack architecture [32] toanalyse clinical text for mental health research for anumber of years [33]. At Kings College Hospital, a simi-lar system is in use for audit and quality improvement,and is undergoing ethical review for use for research.The value of primary care free text as demonstrated inour study and others [8, 9] makes the case forinvestment in systems to enable natural languageprocessing on primary care free text at source, withappropriate governance to maximise the clinical benefitsTable 4 Proportion of deaths with a cause recorded in CPRD primary care data (N = 600 for each 3-year band)How cause of death is recorded in primary care Years 20012003 Years 20042006 Years 20072009 Accuracy (95% CI)Transcribed death certificate entry (e.g. 1a Heart failure, 1b Acute myocardial infarction)Read codes 46 (7.7%) 103 (17.2%) 112 (18.7%) 59% (52%, 65%)Free text 32 (5.3%) 41 (6.8%) 47 (7.8%) 53% (44%, 63%)Explicit cause of death (e.g. Cause of death: myocardial infarction)Read codes 26 (4.3%) 47 (7.8%) 36 (6.0%) 30% (22%, 40%)Free text 16 (2.7%) 17 (2.8%) 16 (2.7%) 55% (40%, 69%)Cause of death implied by diagnosis dated on or after date of deathRead codes 140 (23.3%) 79 (13.2%) 52 (8.7%) 44% (37%, 51%)Free text 69 (11.5%) 67 (11.2%) 76 (12.7%) 40% (34%, 46%)No cause of death in CPRD 271 (45.2%) 246 (41.0%) 261 (43.5%) Table 5 Accuracy of underlying cause of death in CPRD primarycare data compared to the death registry gold standard, for the1022 individuals with cause of death recorded in both sources.For coronary deaths not recorded as coronary in CPRD, themost common causes in CPRD were I469 Cardiac arrest, I500Congestive heart failure and I501 Left ventricular failure. Forstroke deaths not recorded as stroke in CPRD, the mostcommon causes in CPRD were J180 Bronchopneumonia,unspecified, J189 Pneumonia, unspecified and F03XUnspecified dementiaSource of cause of death record in CPRD Free text CodedNumber of deaths 381 641Same underlying cause 184 (48.3%) 293 (45.7%)Same 2-character ICD-10 code for under-lying cause222 (58.3%) 371 (57.9%)Same ICD-10 chapter for underlying cause 278 (73.0%) 463 (72.2%)Coronary deaths (ICD-10 I20I25, N = 163):Sensitivity, % 65.3 (50.4,78.3)68.4 (59.1,76.8)Specificity, % 97.9 (95.7,99.1)98.3 (96.8,99.2)Cerebrovascular deaths (ICD-10 F01, I60I69, N = 101):Sensitivity, % 66.7 (51.6,79.6)58.5 (44.1,71.9)Specificity, % 98.5 (96.5,99.5)97.8 (96.2,98.8)Cancer deaths (ICD-10 C00C97, N = 268):Sensitivity, % 93.0 (86.1,97.1)80.4 (73.5,86.1)Specificity, % 95.7 (92.7,97.8)98.5 (97.0,99.4)Shah et al. Journal of Biomedical Semantics 2019, 10(Suppl 1):20 Page 8 of 10of such research whilst protecting the confidentiality ofpatient data.ConclusionUnstructured free text in primary care records containsmuch information that is potentially useful for researchand is not recorded in the structured data, such assymptoms, investigation results and specific diagnoses.Natural language processing to convert this informationinto a structured form can enrich primary care data atscale for research, and potentially yield population-basedinsights into early presentations of disease.AbbreviationsCALIBER: Clinical Research using Linked Bespoke datasets and ElectronicRecords; CPRD: Clinical Practice Research Datalink; EHR: electronic healthrecord; FMA: Freetext Matching Algorithm; GP: general practitioner;HES: Hospital Episode Statistics; ICD: International Classification of Diseases;MI: myocardial infarction; MINAP: Myocardial Ischaemia National AuditProject; NHS: National Health Service; NLP: natural language processing;NSTEMI: non ST elevation myocardial infarction; ONS: Office for NationalStatistics; STEMI: ST elevation myocardial infarction; UK: United KingdomAcknowledgementsWe acknowledge the help of Nick Wilson and other CPRD staff in dataextraction and running the FMA software. An initial version of this paper hasbeen presented at the Healthcare Text Analytics Conference 2018 (HealTAC),in Manchester, UK in April 2018.About this supplementThis article has been published as part of the Journal of BiomedicalSemantics Volume 10 Supplement 1, 2019: HealTAC-2018: UnclockingEvidence Contained in Healthcare Free-text. The full contents of thesupplement are available onlline at https://jbiomedsem.biomedcentral.com/articles/supplements/volume-10-supplement-1.Authors contributionADS wrote the Freetext Matching Algorithm software, analysed the data anddrafted the paper. EB and ADS manually adjudicated the myocardialinfarction records. TW arranged for the Freetext Matching Algorithm to runat CPRD. TW and HH supervised the study. All authors contributed to, readand approved the final manuscript.FundingThe CALIBER project was funded by the Wellcome Trust (086091/Z/08/Z) andthe National Institute of Health Research (NIHR) (RP-PG-0407-10314). Thisstudy was supported by the Farr Institute of Health Informatics Research,funded by the Medical Research Council (K006584/1) in partnership withother funders. ADS was supported by a Wellcome Trust Clinical ResearchTraining Fellowship (0938/30/Z/10/Z) and is currently supported by the NIHRUniversity College London Hospitals Biomedical Research Centre and a post-doctoral fellowship from THIS Institute. Publication costs are funded by THISInstitute. HH is a National Institute for Health Research (NIHR) Senior Investi-gator. His work is supported by: 1. Health Data Research UK, which is fundedby the UK Medical Research Council, Engineering and Physical Sciences Re-search Council, Economic and Social Research Council, Department of Healthand Social Care (England), Chief Scientist Office of the Scottish GovernmentHealth and Social Care Directorates, Health and Social Care Research and De-velopment Division (Welsh Government), Public Health Agency (NorthernIreland), British Heart Foundation and Wellcome Trust (grant no. LOND1). 2.The BigData@Heart Consortium, funded by the Innovative MedicinesInitiative-2 Joint Undertaking under grant agreement No. 116074. This JointUndertaking receives support from the European Unions Horizon 2020 re-search and innovation programme and EFPIA; it is chaired by DE Grobbeeand SD Anker, partnering with 20 academic and industry partners and ESC.3. The National Institute for Health Research University College London Hos-pitals Biomedical Research Centre.Availability of data and materialsThe data that support the findings of this study are available from CPRD, butrestrictions apply to the availability of these data, which were used underlicense for the current study, and so are not publicly available. This projectuses the CALIBER dataset, which is de-identified (pseudonymised) but is suffi-ciently detailed to be considered sensitive data with a potential risk of pa-tient re-identification if combined with other data sources, and the terms ofthe data sharing agreement do not permit it to be shared. Access to thedatabase for research can be obtained by submitting an application to theCPRD Independent Scientific Advisory Committee.All the software used in this project is available as open source software. TheFreetext Matching Algorithm is available on Github: https://github.com/anoopshah/freetext-matching-algorithm and the lookups are on https://github.com/anoopshah/freetext-matching-algorithm-lookups. Operatingsystem: Windows, or Linux with wine and Visual Basic 6 runtime.Programming language: Visual Basic 6. License: GNU General Public Licensev3.0.Ethics approval and consent to participateThe CALIBER programme has been approved by a NHS Research EthicsCommittee (09/H0810/16). This study was approved by the CPRDIndependent Scientific Advisory Committee (protocol 12_117). Individualpatient consent is not required for observational CPRD studies, but patientshave the opportunity to opt out of contributing to the database.Consent for publicationNot applicable.Competing interestsThe authors declare that they have no competing interests.Author details1Health Data Research UK London, University College London, 222 EustonRoad, London NW1 2DA, UK. 2Institute of Health Informatics, UniversityCollege London, 222 Euston Road, London NW1 2DA, UK. 3The NationalInstitute for Health Research University College London Hospitals BiomedicalResearch Centre, University College London, 222 Euston Road, London NW12DA, UK. 4University College London Hospitals NHS Foundation Trust, 235Euston Road, London NW1 2BU, UK. 5Clinical Practice Research Datalink,Medicines and Healthcare products Regulatory Agency, 10 South Colonnade,London E14 4PU, UK. 6Department of Biostatistics and Health Informatics,Kings College London, De Crespigny Park, Denmark Hill, London SE5 8AF,UK.Published: 12 November 2019RESEARCH Open AccessOHMI: the ontology of host-microbiomeinteractionsYongqun He1* , Haihe Wang1,2, Jie Zheng3, Daniel P. Beiting4, Anna Maria Masci5, Hong Yu1,6, Kaiyong Liu7,Jianmin Wu8, Jeffrey L. Curtis1,9, Barry Smith10, Alexander V. Alekseyenko11 and Jihad S. Obeid11AbstractBackground: Host-microbiome interactions (HMIs) are critical for the modulation of biological processes and areassociated with several diseases. Extensive HMI studies have generated large amounts of data. We propose that thelogical representation of the knowledge derived from these data and the standardized representation ofexperimental variables and processes can foster integration of data and reproducibility of experiments and therebyfurther HMI knowledge discovery.Methods: Through a multi-institutional collaboration, a community-based Ontology of Host-MicrobiomeInteractions (OHMI) was developed following the Open Biological/Biomedical Ontologies (OBO) Foundry principles.As an OBO library ontology, OHMI leverages established ontologies to create logically structured representations of(1) microbiomes, microbial taxonomy, host species, host anatomical entities, and HMIs under different conditionsand (2) associated study protocols and types of data analysis and experimental results.Results: Aligned with the Basic Formal Ontology, OHMI comprises over 1000 terms, including terms imported frommore than 10 existing ontologies together with some 500 OHMI-specific terms. A specific OHMI design pattern wasgenerated to represent typical host-microbiome interaction studies. As one major OHMI use case, drawing on datafrom over 50 peer-reviewed publications, we identified over 100 bacteria and fungi from the gut, oral cavity, skin,and airway that are associated with six rheumatic diseases including rheumatoid arthritis. Our ontological studyidentified new high-level microbiota taxonomical structures. Two microbiome-related competency questions werealso designed and addressed. We were also able to use OHMI to represent statistically significant results identifiedfrom a large existing microbiome database data analysis.Conclusion: OHMI represents entities and relations in the domain of HMIs. It supports shared knowledgerepresentation, data and metadata standardization and integration, and can be used in formulation of advancedqueries for purposes of data analysis.Keywords: Microbiome, Host-microbiome interaction, Ontology, Ontology of host-microbiome interactions, OHMI,Metadata, OBO Foundry, Rheumatic disease, Rheumatoid arthritisBackgroundA microbiome is defined as a community of microbes(for example, bacteria) found in a particular habitat (forexample, a human host) [13]. Microbiomes exist in andon human and other hosts, where they are crucial for ac-tive immunologic and physiological system development[1, 46]. Research in host-microbiome interaction(HMI) has accelerated significantly in the past decade, asevidenced by the rise in the number of microbiome-related publications indexed in PubMed (from 604 toover 11,500 in the ten years since 2018). This growingbody of HMI studies and associated data pose signifi-cant challenges. For example, it can be difficult for in-vestigators to achieve reproducible results acrosslaboratories, and even more challenging to integrate datasystematically across studies. To facilitate advanced dataintegration and knowledge discovery, several fundingsources now require that data generated from funded re-search be structured to conform to the FAIR (Findable,© The Author(s). 2019 Open Access This article is distributed under the terms of the Creative Commons Attribution 4.0International License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, andreproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link tothe Creative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver(http://creativecommons.org/publicdomain/zero/1.0/) applies to the data made available in this article, unless otherwise stated.* Correspondence: yongqunh@med.umich.edu1University of Michigan Medical School, Ann Arbor, MI 48109, USAFull list of author information is available at the end of the articleHe et al. Journal of Biomedical Semantics           (2019) 10:25 https://doi.org/10.1186/s13326-019-0217-1Accessible, Interoperable, and Reusable) data principles[7]. To support data FAIRness and experimental repro-ducibility in HMI research, a strategy is needed tostandardize the representation of the entities involved inHMI, including host and microbial organisms, microbiallocations, and environments. As in other research areas,so also here: the lack of a comprehensive standardizedrepresentation of these entities prevents integration andsystems-level analysis of the HMI data produced by dif-ferent studies, laboratories and institutions.An ontology is a human- and computer-interpretablerepresentation of the types, properties, and interrelation-ships that exist in a particular domain [8]. Ontologiesallow semantically-based reasoning by computer sys-tems, and enable people and machines to make mutuallysupportive logical inferences. In biomedical research, on-tologies have served for some 20 years as powerful toolsfor data classification, representation of standards, con-struction of knowledge bases, and enhanced search andanalysis. Several microbiology-related ontologies exist,including the NCBI organismal classification (NCBI-Taxon) [9], the Uberon multi-species anatomy ontology(UBERON) [10] and the Environment Ontology (ENVO)[11]. These ontologies permit standardized representa-tion of, respectively, host and microbial organisms, ana-tomic locations of microbes inside hosts, andmicrobiome environments. The Ontology for MicrobialPhenotypes (OMP) standardizes phenotypic informationrelating to microbes [12]. The Ontology of ProkaryoticPhenotypic and Metabolic Characters (MicrO) coversthe attributes of prokaryotes, the processes in which theyparticipate, and the material entities (such as cell com-ponents, microbiological culture media and medium in-gredients) with which they are associated in theseprocesses [13]. Many of the terms in OMP and MicrOwere themselves imported from existing OBO ontol-ogies, including the Phenotypic Quality Ontology(PATO) [14], the Gene Ontology (GO) [15], ChemicalEntities of Biological Interest (ChEBI) [16], the ProteinOntology (PR) [17], and the Ontology for Biomedical In-vestigations (OBI) [18].The above-mentioned ontologies provide componentsfor the systematic representation of certain aspects ofHMIs, but they do not cover, for example, HMIs  theinteractions between hosts and microbiomes  them-selves. They also do not cover the associations betweenHMIs and specific diseases (such as rheumatoid arth-ritis), or HMI investigation metadata. We have createdthe Ontology of Host-Microbiome Interactions(OHMI), therefore, not merely in order to incorporateterms in these specific areas, which are important fociof current microbiome research, but also to provide asingle framework for systematic representation of allentities relevant to HMI.MethodsOHMI ontology developmentOHMI follows the Open Biological/Biomedical Ontologies(OBO) Foundry (http://www.obofoundry.org/) principles.For example, OHMI satisfies the openness and collabor-ation principles [19], in that it is based on an open discus-sion involving representatives from multiple disciplinesengaged in microbiome research in which not only thescope of the ontology was identified but also the develop-ment strategy, design patterns, and initial use cases. TheOHMI GitHub website (https://github.com/OHMI-ontol-ogy/OHMI) documents the successive versions of theontology presented at the 23rd International ScientificSymposium on Biometrics (BioStat 2017), the Sixth An-nual Workshop of the Clinical and Translational ScienceOntology Group, and the Microbe 2018 meeting of theAmerican Society of Microbiology (ASM).OHMI uses the eXtensible Ontology development(XOD) methods [20], meaning that it reuses terms fromexisting ontologies and aligns all terms within a single se-mantic framework as defined by the Basic Formal Ontol-ogy (BFO) [21]. The Ontofox tool was used for extractionand reuse of terms from existing ontologies [22]. TheOntorat tool was used for generating new terms based onconsensus ontology design patterns [23]. OHMI was for-matted in the Web Ontology Language (OWL2), and theProtégé OWL Editor (version 5.0) [24] was used for man-ual editing. The HermiT reasoner (http://hermit-reasoner.com/) tool was employed to detect inconsistencies or con-flicts arising during development.Host-microbiome interaction minimal informationcollection and ontological representationAll HMI-related data elements were first compiled in aspreadsheet from the literature, public resources, anduse cases, then discussed by the community, and trans-formed into terms and relational expressions for inclu-sion in the ontology. Following the OBO Foundryprinciple of reuse, wherever a term was already definedin one or more existing ontologies (identified usingOntobee [25]) we imported the term into OHMI usingwhat we deemed to be the most biologically accuratedefinition. Otherwise, we created a new term, which waseither (1) included in OHMI or (2) suggested for inclu-sion in an appropriate higher-level OBO Foundry ontol-ogy in order to make it available for importing intoOHMI.OHMI use case studies and evaluationOur major use case was the study of the associationbetween microbiome profiles and rheumatic diseases.Rheumatic diseases include conditions causing chronic,often intermittent pain affecting the joints and/or con-nective tissues such as rheumatoid arthritis (RA),He et al. Journal of Biomedical Semantics           (2019) 10:25 Page 2 of 14ankylosing spondylitis (AS), and systemic lupus erythema-tosus (SLE). In this study, we manually curated publishedrheumatic disease-related HMI data from peer-reviewedpublications.We have also defined and used two competency questionsderived from the rheumatic disease use case to evaluate theOHMI ontology. For this purpose, we used the SimpleProtocol And Resource Description Framework (RDF)Query Language (SPARQL) and Description Logic (DL)languages. SPARQL is a query language that retrieves datastored in the RDF format [26]. SPARQL queries were per-formed using the Ontobees SPARQL endpoint (http://www.ontobee.org/sparql) [25]. The SPARQL scripts are providedin the OHMI GitHub (https://raw.githubusercontent.com/OHMI-ontology/OHMI/master/docs/SPARQL%20scripts.txt). DL queries were performed using the Protégé 5.0 (beta15) DL Query plugin as described in the Results section.Ontology access and licenseOHMI is an open source project maintained throughhttps://github.com/ohmi-ontology. The source code, in-cluding development and release versions, is available athttps://github.com/ohmi-ontology/OHMI. OHMI is re-leased under a Creative Commons 4.0 License. It hasbeen accepted as an OBO library ontology (http://obo-foundry.org/ontology/ohmi.html) and deposited in theOntobee ontology server [25] at http://www.ontobee.org/ontology/OHMI, and in BioPortal [27] at https://bioportal.bioontology.org/ontologies/OHMI. Ontobee isthe default server for dereferencing OHMI terms.ResultsOHMI ontology design and upper-level structureFigure 1 shows selected upper-level terms and branchesof the OHMI hierarchy. Instead of coding everythingfrom scratch, we imported and aligned related termsfrom existing reference ontologies in the OBO Library,including BFO, NCBITaxon, ENVO, UBERON, OBI, andthe Information Artifact Ontology (IAO) [10].The class OHMI: microbiome is defined as a subclassof ENVO:biome. The latter is defined as follows:biome = def. an ecosystem to which resident ecologicalcommunities have evolved adaptations.OHMI then defines microbiome as follows:microbiome = def. a biome that consists of a collectionof microorganisms (i.e., microbiota) and the surround-ing environment where the microorganisms reside andhave evolved adaptations.OHMI further defines the term microbiota as a sub-class of the term collection of organisms in the Popu-lation and Community Ontology (PCO):microbiota = def. a collection of microbial organismsthat reside in a particular environment.Fig. 1 Selected upper level terms and hierarchy of OHMI. OHMI terms are marked by red labels. The full names of listed ontologies are providedin the list of abbreviations at the end of this paperHe et al. Journal of Biomedical Semantics           (2019) 10:25 Page 3 of 14To define the host class in OHMI, we first of all de-fine the host role, which is a BFO:role borne by an entitywhen one or more further entities are spatially locatedin its interior. An OHMI:host is then an organism thatbears a host role in relation to some microbiome.The basic design pattern of OHMI is illustrated in Fig. 2.An ontology design pattern is a general pattern to solve arecurrent modeling problem in ontology development byproviding scalable and robust representations of entitiesand entity relations of a certain sort [23]. Terms from theRelation Ontology (RO) [28] have been used to representOHMI assertions and to formulate corresponding defini-tions. Specifically, a host-microbiome interaction (HMI) isdefined as follows:host-microbiome interaction = def. an interaction thatoccurs between a microbiome and its host.with a logically equivalent class definition as follows:host-microbiome interaction: interaction and (has partici-pant some host) and (has participant some microbiome).Each HMI occurs in some specific anatomic entity (forexample the gut) located in the host organism. This hostorganism may in addition have a disease  a phenomenonthat is illustrated by the representation of a general HMIpattern in patients with ankylosing spondylitis (AS) (Fig.2). In this example, AS human-gut microbiota interactionis a HMI in which the host is a human with AS, whilegut is the anatomic entity where the microbiota resides.The expansion of Porphyromonas macacae in AS humangut is an AS human-gut microbiota interaction in whichthe size of the population of Porphyromonas macacae isincreased (Fig. 2).As of September 9, 2019, OHMI contains 1238 terms, in-cluding 1020 classes, and 128 object properties. OHMI in-cludes 481 OHMI-specific classes and properties with theOHMI_ prefix, which are new ontology terms not cov-ered in any other OBO Foundry ontologies. More detailedand updated OHMI statistics can be found at the Ontobeestatistics page at: http://www.ontobee.org/ontostat/OHMI.Systematic collection and representation of rheumaticdisease-related HMI knowledgeAs a major use case, we systematically collected and an-notated the peer-reviewed results of studies of HMI re-lated to rheumatic diseases. Rheumatic diseases arecharacterized by inflammation of connective tissues,most commonly the joints, but also the tendons, liga-ments, bones, muscles, and even solid organs. Our usecase study focused on the most common rheumatic dis-eases, including AS, enthesitis-related arthritis (ERA),gout, psoriatic arthritis (PsA), RA, and systemic lupus er-ythematosus (SLE), which affect approximately 1% of theglobal human population. RA is a common rheumaticFig. 2 Illustration of OHMI ontology design pattern for representing host-microbiome interactions. The red box represents different levels of host-microbiome interactions. A specific example is the OHMI representation of a human-microbiome interaction in which the human host has thedisease ankylosing spondylitis (AS). The human and microbiome classes are duplicated in this figure for clarity. Note that not every organism hasthe host role, and the role is here assigned to a host organism only in the case of host-microbiome interactionsHe et al. Journal of Biomedical Semantics           (2019) 10:25 Page 4 of 14disease characterized by persistent synovitis, systemic in-flammation, and autoantibodies [29]. Many studies havefound close associations between rheumatic diseases andHMI [3033]. Specifically, the gastrointestinal microbiomeand its homeostasis are altered in patients with autoimmuneand inflammatory rheumatic diseases such as RA [33, 34].A significant amount of research on the role of the micro-biome in autoimmunity has focused primarily on RA [35].To better understand the relations among rheumaticdiseases and microbiomes, we performed a meta-analysisof such relations from relevant literature. In total, fromAlex et al. Journal of Biomedical Semantics 2019, 10(Suppl 1):23https://doi.org/10.1186/s13326-019-0211-7RESEARCH Open AccessText mining brain imaging reportsBeatrice Alex1,2,3*, Claire Grover1,3, Richard Tobin1, Cathie Sudlow4, Grant Mair5 andWilliam Whiteley5From UK Healthcare Text Analysis Conference (HealTAC 2018)Manchester, UK. 1819 April 2018AbstractBackground: With the improvements to text mining technology and the availability of large unstructuredElectronic Healthcare Records (EHR) datasets, it is now possible to extract structured information from raw textcontained within EHR at reasonably high accuracy. We describe a text mining system for classifying radiologistsreports of CT and MRI brain scans, assigning labels indicating occurrence and type of stroke, as well as otherobservations. Our system, the Edinburgh Information Extraction for Radiology reports (EdIE-R) system, which wedescribe here, was developed and tested on a collection of radiology reports.The work reported in this paper is based on 1168 radiology reports from the Edinburgh Stroke Study (ESS), ahospital-based register of stroke and transient ischaemic attack patients. We manually created annotations for thisdata in parallel with developing the rule-based EdIE-R system to identify phenotype information related to stroke inradiology reports. This process was iterative and domain expert feedback was considered at each iteration to adaptand tune the EdIE-R text mining system which identifies entities, negation and relations between entities in eachreport and determines report-level labels (phenotypes).Results: The inter-annotator agreement (IAA) for all types of annotations is high at 96.96 for entities, 96.46 fornegation, 95.84 for relations and 94.02 for labels. The equivalent system scores on the blind test set are equally high at95.49 for entities, 94.41 for negation, 98.27 for relations and 96.39 for labels for the first annotator and 96.86, 96.01,96.53 and 92.61, respectively for the second annotator.Conclusion: Automated reading of such EHR data at such high levels of accuracies opens up avenues for populationhealth monitoring and audit, and can provide a resource for epidemiological studies. We are in the process ofvalidating EdIE-R in separate larger cohorts in NHS England and Scotland. The manually annotated ESS corpus will beavailable for research purposes on application.Keywords: Text mining, Electronic healthcare records, Neuroimaging reports, Stroke classificationBackgroundThe goal of the EdIE-R system [1] is to label eachreport with an indication of what the radiologist wasable to observe in the scan image, for example, smallvessel disease, ischaemic stroke etc. Like most other sys-tems for extracting information from electronic health-care records, we use text mining techniques to identify the*Correspondence: balex@ed.ac.uk1School of Informatics, University of Edinburgh, Informatics Forum, 10Crichton Street, Edinburgh, UK2Edinburgh Futures Institute, School of Literatures, Languages and Cultures,University of Edinburgh, 50 George Square, Edinburgh, UKFull list of author information is available at the end of the articlerelevant parts of the report which can then be used as abasis for predicting the document-level labels.Text mining systems typically apply Named EntityRecognition (NER), Relation Extraction (RE) and nega-tion detection. NER is used to identify words or phrasesthat are entities relevant to the text mining task andRE links entities when they are related in some rele-vant way. Negation detection identifies contexts where theauthor is stating that entities or relations do not exist. Forexample, Fig. 1 shows different types of annotations: twoischaemic stroke entities, infarcts and infarction, two tem-poral modifiers, old and acute, and a location modifier,thalamic. The first ischaemic stroke entity enters© The Author(s). 2019 Open Access This article is distributed under the terms of the Creative Commons Attribution 4.0International License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, andreproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to theCreative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver(http://creativecommons.org/publicdomain/zero/1.0/) applies to the data made available in this article, unless otherwise stated.Alex et al. Journal of Biomedical Semantics 2019, 10(Suppl 1):23 Page 2 of 11Fig. 1 Example of entity, relation and negation mark-upinto two relations, one with a temporal modifier and onewith a location modifier, while the second ischaemicstroke entity is in a relation with a temporal modifier.These latter two entities are marked as negative (crossedout) because they are in the scope of the negative wordNo.Annotations such as these are output by the text miningsystem and are then used as the basis for the assignmentof labels to the reports.In order to develop NER and RE components, decisionsneed to be made about which entities and which rela-tions the system should identify. These decisions are bestmade through dialogue between the domain experts, whoknow what information they would ideally like to access,and text mining experts, who can judge which pieces ofinformation can be identified with sufficient accuracy.In addition, manually annotated subsets of the data areneeded to train and develop the components as well as toevaluate their performance.In building EdIE-R, we used the process of annotationas a means to focus the radiologist/text miner dialogueat the same time as developing the prototype system. Weused an agile development methodology where iterationsof system development were interleaved with annotationiterations. After initial scoping, automatic annotationsfrom the system were presented to the domain expertsfor correction using the BRAT annotation tool [2]. Thesystem and manual annotations were compared and dis-agreements were resolved either by adjusting the man-ual annotation or by improving the system. We iteratedover the process a number of times with both systemand manual annotation improving in each cycle. Thismethod has several advantages. First, it allows both teamsto work simultaneously, unlike methods where all theannotation is done in advance of system development.Second, discussion of the system and manual disagree-ments allows the text miners to come to a much clearerunderstanding of the meaning of the domain languageand the domain specialists to understand the limitationsof the technology. Through negotiation, several changesto the annotation scheme were made during the iterativeprocess. Third, doing annotation as correction tends toreduce insignificant differences between manual and sys-tem annotation.Related workNamed entity recognition is a well-established task inNLP. The CoNLL shared-task evaluations [3] establishedbenchmarks for NER evaluation and prompted researchinto supervised machine learning methods for NER, forexample, the Stanford NER tagger [4]. Rule-based tech-niques are also still used for NER: see e.g. the ANNIENER tagger which is part of GATE [5]. Relation extractionis often included as a subtask in text mining applications[6] with approaches to it ranging from rule-based throughsupervised to unsupervised machine learning.Text mining technology for the biomedical domain hasbeen a subject of research for two decades with severalcommunity initiatives to provide data and a forum forshared tasks, such as BioCreative [7] and BioNLP [8].Both of these organised shared tasks in NE and RE: see[9, 10] for our contributions. More recently the sharedtask approach has been used for electronic health records(EHRs) by the LOUHI workshops, e.g. LOUHI17 [11] orLOUHI18 [12]. There are many individual studies apply-ing information extraction to EHRs, see [13] for a reviewof some of these. Negation detection has been recognisedas an important step, particularly in medical text mining,with the NegEx algorithm [14] being frequently used.Several researchers have applied NLP and text miningapproaches to radiology reports. Pons et al. (2016) providea useful systematic review of NLP in radiology [15]. Theyinclude 67 different studies which they group accordingto 5 distinct purposes, namely diagnostic surveillance,cohort building for epidemiological studies, query-basedcase retrieval, quality assessment of radiologic practice,and clinical support services. Conditions targeted by thesystems are various and include appendicitis, pneumonia,renal cysts, pulmonary embolism, liver conditions andFig. 2 EdIE-R processing pipelineAlex et al. Journal of Biomedical Semantics 2019, 10(Suppl 1):23 Page 3 of 11general metastases, to name but a few. Across all theseapplication areas the NLP systems surveyed tend to havethe same broad structure where a flow diagram showingthe individual components looks much like our diagramof the EdIE-R system shown in Fig. 2 below.Two recent studies by Hassanpour and Langlotz (2016)and by Cornegruta et al. (2016) describe machinelearning methods for entity recognition from radiol-ogy reports [16, 17]. Hassanpour and Langlotz [16]tested two existing feature-based machine learning clas-sifiers for this task. Their annotation scheme containsfour broad types of named entities (Anatomy, Anatomymodifier, Observation and Observation modifier) as wellas strings expressing Uncertainty. They used NegExto identify negation in the text as a feature feed-ing into their models. The machine learning classifierboth result in an average F1-score of 85% for 10-foldcross-validation on a data set containing 150 manu-ally annotated radiology reports from three differentinstitutions.Cornegruta et al. [17] describe work on analysing alarge corpus of historical chest X-ray reports. Their sys-tem described is interestingly similar to ours in the waythe report text is annotated with named entity and nega-tion mark-up although the entity list (Body Location,Descriptor, Clinical Finding, Medical Device) is bothsmaller and more complex in that disjoint entities arepermitted. No relation extraction is performed but nega-tion mark-up is included. The NER method uses a bidi-rectional LSTM (BiLSTM) neural network architecture,which is contrasted with a baseline system which usesstring matching look-up against RadLex [18] and MedicalSubject Headings (MeSH) [19] concepts combined withparsing, plus NegEx for negation detection. The BiLSTMNER tagger significantly outperforms the baseline butit is worth noting that, in general, rule-based andmachine learning approaches attain similar levels of per-formance on NER if the rule-based system uses moresophisticated techniques than string matching, as oursdoes.There has also been some work on summarising radi-ology reports. Most recently, Zhang et al. [20] proposeda state-of-the-art neural network-based approach to sum-marisation of radiology impressions. An impression is theConclusion section of a radiology report summarised bythe radiologist after dictating or writing down their find-ings presented in the image. Automating this step is anextremely useful task that can save radiologists a lot ofeffort and time. Two different radiology reports describ-ing similar symptoms and conditions, however, are notguaranteed to result in the same summary text. The out-put of summarisation therefore does not lend itself wellfor large-scale data analysis in the same way as classifica-tion of symptoms and conditions does, for example, foridentifying patients with the same findings for epidemio-logical studies.With a specific focus on stroke, Flynn et al. (2010) [21]developed a system for analysis of brain scan radiologyreports from Tayside, Scotland, i.e. EHR reports whichare very similar to the those in the ESS data set [22].Their aim was to improve on the coding of the reportswhich were frequently given generic stroke codes evenwhen a more precise code could be determined by look-ing at the report. Their method used a keyword matchingstep looking for affirmative or negative uses of key wordsfrom a stroke lexicon. They report results which wereacceptably accurate in identifying ischaemic stroke (94.7%positive predictive value (precision)) on a dataset of 150reports manually classified as ischaemic stroke. Theirmethod performed less reliably in identifying intracere-bral haemorrhage (76.7% positive predictive value) on adataset of 150 reports manually classified as intracere-bral haemorrhage. The paper does not report sensitivity(recall) scores as the data only contains positive examplesof either type.To the best of our knowledge, EdIE-R is the first sys-tem that performs named entity extraction, negated entitydetection, relation extraction and document level labellingwith the goal to classify radiology report with types ofstroke, tumours and other information. The extractedentities (positive or negative) and relations are all used todo the final classification (labelling) step. The informationcaptured in and about the reports include a compre-hensive set of entities and labels. We provide a detailedevaluation of EdIE-R for all the steps it is designed toperform using standard natural language processing eval-uation metrics, including precision, recall and F1-score.Compared to the previous study [21] we therefore teston an unseen test set of random radiology reports whichcontain positive and negative examples of the informationEdIE-R is designed to extract and label.MethodAnnotation schemeThere are four aspects to the annotation of brain scanreports in our data: entities, relations, negation mark-up,and labels. These are all illustrated in Fig. 3, a screen grabof an annotated report loaded into the BRAT tool. Asshown, each report is preceded by a list of all possiblelabels but only those that have beenmarked as selected arelabels for the report. Entities, relations and negation havebeen annotated within the textual body of the report.Entities are of two types, observations or mod-ifiers. The full set of observation entities are:ischaemic stroke, haemorrhagic stroke,stroke (unknown type), tumour:meningioma,tumour:metastasis, tumour:glioma, tumour,subdural haematoma, small vessel disease,Alex et al. Journal of Biomedical Semantics 2019, 10(Suppl 1):23 Page 4 of 11Fig. 3 An annotated reportatrophy, microbleed, subarachnoid haemorrhage and haemorrhagic transformation.The four modifier entities, which are used to identify loca-tion (deep vs. cortical/lobar) and recency (old vs. recent)of an observation, are loc:deep, loc:cortical,time:old, time:recent.Relations link a subset of observation entities, namelystroke and microbleed entities, with modifier entities.Strokes may be associated with both a location and atime, while microbleeds are associated only with loca-tion. Some words or phrases, such as POCI (PosteriorCirculation Infarct) in Fig. 2, carry both observation andmodifier meaning and in these cases nested entities areused. Here there is a mod-loc relation between theloc:cortical entity and the ischaemic stroke entitybut we do not require this to be made explicit in theannotation since the nesting implies it.There is a close relationship between the entityand relation names and the labels. For example,the label Ischaemic stroke, cortical, old hasbeen chosen and this clearly relates to the two occur-rences of an ischaemic stroke entity in a relationwith both a loc:cortical and a time:old modifier.The annotators are instructed not to select labels unlessthere is explicit linguistic evidence to support the choice.Occasionally they will be able to infer labels from implicitinformation but they are asked not to annotate these casesas the aim is to model linguistically explicit informationnot human expertise.Proper identification of negation and its scope isessential to achieving high accuracy. We model negationin the annotation as an attribute on entities, which isvisualized in BRAT as a crossing out. Wherever thetext contains negation scoping over entities, the anno-tators must add the negative attribute. The negativeexample in Fig. 2, No acute haemorrhage, masses orextra-axial collections, is a clear and simple case butsyntactically more complex cases occur, e.g. cases wherethe negation marker is distant from the entities withinits scope. There are cases where the radiologist is unableto positively identify or exclude an observation, as forexample in a small focus of acute infarct cannot be com-pletely excluded. The annotators are asked to mark thesecases as negative, as only clearly positive observationsAlex et al. Journal of Biomedical Semantics 2019, 10(Suppl 1):23 Page 5 of 11should contribute to the labels assigned to thereports.The EdIE-R systemEdIE-R is a rule-based text mining systemwhich we devel-oped in tandem with manual data annotation in the formof correction of the system output. The presentation ofthe data in the BRAT tool, as illustrated in Fig. 2, is theview that the annotators see, but this is a format that hasbeen derived from the data structure which the systemmanipulates and outputs, which is an XML data structure.We have developed the systems text analysis componentsusing the LT-XML2 programs, which are the core of ourXML rule-based text mining software [23]. Our mostrecent software release, the Edinburgh Geoparser [24],contains all of our general-purpose components, such asthe tokeniser, NER tagger and chunker, which we haveadapted to the brain scan report domain in EdIE-R.As shown in Fig. 3, the EdIE-R system has a pipelinearchitecture. Scan reports are converted from their orig-inal format into an initial XML format and subsequentcomponents incrementally add annotations to the XMLstructure, with each stage making computations over theannotations of previous stages. The document zoningstep segments the reports into sections including clinicaldetails, the report itself and the radiologists conclusion.It also adds metadata which includes all of the possi-ble labels that can be assigned; by the final stage of thepipeline an attribute on each label indicates whether thatlabel has been selected. An example of a report in XMLafter document zoning is shown in Fig. 4. We combineNER and label mark-up in this way so that manual anno-tation of all levels of analysis can be done at the sametime.Subsequent steps of the pipeline do linguistic process-ing. The tokeniser splits textual content into paragraphs,sentences and word tokens, with punctuation charactersalso treated as tokens. The C&C POS tagger [25] labelseach word with its syntactic category. The default C&Cmodel has been trained on modern U.S. newspaper textand although it performs well on most text types, it is notwholly suitable for the medical text in our reports. For thisFig. 4 XML format after document zoningAlex et al. Journal of Biomedical Semantics 2019, 10(Suppl 1):23 Page 6 of 11Fig. 5 Example lexical entriesreason, we also use a model trained on the Genia biomed-ical corpus [26]. After running the POS tagger with eachof the models we apply a correction stage to moderate dis-agreements between them. After POS tagging, we applythe morpha lemmatiser [27] to analyse inflected nounsand verbs and compute their lemma (morphologicalstem). The output of POS tagging and lemmatizationis stored in attribute values on word tokenelements.The fifth step in the pipeline is the NER component,which incorporates lexical lookup. From examples in thedevelopment set we manually curated two lexicons, onefor observations (e.g. the atrophy entity inter-cerebralvolume loss and the ischaemic stroke entity lacunarFig. 6 XML representation of entities and relations in Fig. 1Alex et al. Journal of Biomedical Semantics 2019, 10(Suppl 1):23 Page 7 of 11Table 1 The annotated ESS data setsReports Of which CT Of which MRI Sentences WordsDevelopmentdev1 18 18 0 158 1651dev2 25 16 9 231 2671dev3 80 78 2 888 6833dev4 82 74 8 833 6935dev5 82 69 13 965 8,061dev6 77 67 10 762 6078Total 364 322 42 3837 32,229Testtest1 89 74 15 969 7,919test2 92 82 10 996 8,226test3 85 82 3 890 6697Total 266 238 28 2855 22,842event) and one for modifiers (e.g. the time:old enti-ties old, previous and established), e.g. see Fig. 5. Theprocess of lexical lookup results in the addition of fur-ther attributes to the word tokens of matching words andphrases. The lexicons are applied one after the other, firstthe observations lexicon and then the modifiers, so thatsome words or phrases can be marked as both observa-tion and modifier to achieve the nested entity mark-updescribed above.The next stage of processing performs a shallow syntac-tic analysis using our chunker [28] to segment sentencesinto phrases or word groups, i.e. syntactic structuresheaded by nouns (noun groups), verbs (verb groups) etc.The purpose of doing this is to create a useful data struc-ture for dealing with nested entities and coordinations ofentities as well as to define the scope of negation mark-ers in terms of structure rather than just word sequences.At this stage complex negative noun groups such as Noacute haemorrhage, masses or extra-axial collections havean appropriate structure to allow information from thenegative article No to be propagated through the group sothat all three observation entities (haemorrhage, masses,extra-axial collections) are marked as negative.Relation Extraction is the final stage of the text min-ing part of the system. In this component some pairsof entities are linked in relations held as structures instandoff XML mark-up as illustrated in Fig. 6. Thereare two possible relations, location and time, which holdbetween stroke entities (ischaemic, haemorrhagicor unknown type) and modifiers. In addition, amicrobleed entity can be in a relation with a locationmodifier.Negation arising from the verb particle not, for exam-ple in Very acute infarction may not be visible on CT, ishandled as part of the relation extraction module becauseTable 2 Annotations in the data setsAnnotated by PositiveentitiesNegativeentitiesRelations Labelsdev1 Both: reconciled 197 85 68 46dev2 Both: reconciled 242 116 85 62dev3 Both: reconciled 670 324 230 192dev4 Annotator 1 600 284 195 167dev5 Annotator 2 708 302 212 174dev6 Annotator 1 524 280 169 151Total 2941 1391 959 792test1 Annotator 1 605 291 203 159test2 Annotator 1 786 337 278 192test3 Annotator 1 572 333 206 167Total 1963 961 687 518test1 Annotator 2 614 304 220 160test2 Annotator 2 792 361 281 199test3 Annotator 2 574 355 200 176Total 1980 1020 701 535rules linking not with the entities it scopes over are simi-lar to the other relation rules. The result, however, is notan explicit relation but an attribute on the negated entities(acute and infarction, in this case). This is the same formatas for noun group negation detected during chunking.Table 3 Inter-annotator agreement on the test dataPrecision Recall F1Entitiestest1 96.41 98.77 97.57test2 95.84 98.40 97.10test3 94.94 97.46 96.18Total 95.73 98.22 96.96Negationtest1 95.90 98.19 97.03test2 95.07 97.70 96.36test3 94.73 97.29 96.00Total 95.22 97.72 96.46Relationstest1 92.99 98.03 95.44test2 97.47 97.47 97.47test3 96.39 91.67 93.97Total 95.77 95.91 95.84Labelstest1 92.50 93.08 92.79test2 90.95 94.27 92.58test3 94.32 99.40 96.79Total 92.52 95.56 94.02Alex et al. Journal of Biomedical Semantics 2019, 10(Suppl 1):23 Page 8 of 11Table 4 IAA precision, recall and F1 for entities includingnumbers of true positives (TP), false positives (FP) and falsenegatives (FN)Type TP FP FN Precision Recall F1Entitiesischaemic stroke 453 9 2 98.05 99.56 98.80haemorrhagic stroke 264 20 3 92.96 98.88 95.83stroke (unknown type) 25 0 1 100.00 96.15 98.04tumour:meningioma 8 0 0 100.00 100.00 100.00tumour:metastasis 12 0 0 100.00 100.00 100.00tumour 165 2 1 98.80 99.40 99.10subdural haematoma 109 32 0 77.30 100.00 87.20small vessel disease 269 15 7 94.72 97.46 96.07atrophy 147 14 6 91.30 96.08 93.63microhaemorrhage 10 0 0 100.00 100.00 100.00subarachnoid haemorrhage 9 3 1 75.00 90.00 81.82haemorrhagic transformation 2 2 0 50.00 100.00 66.67time:old 314 9 7 97.21 97.82 97.52time:recent 354 0 0 100.00 100.00 100.00loc:cortical 410 5 2 98.80 99.51 99.15loc:deep 321 17 22 94.97 93.59 94.27TOTAL 2872 128 52 95.73 98.22 96.96The final labelling step of the pipeline uses the infor-mation from the previous steps to compute which labelsshould be associated with a record. Because the mark-upcoming from the text mining is very detailed, the label-ing rules can be fairly simple. For example, to choosethe Small vessel disease label the rules need onlyto check that there is a non-negative small vesseldisease entity in either the report or conclusionspart of the report. To choose the label Ischaemicstroke, cortical, recent there needs to be anon-negative ischaemic stroke entity which is ina location relation (mod:loc) with a cortical loca-tion entity (loc:cortical) and in a time relation(mod:time) with a time:recent entity. There area few added complexities to these rules, for exam-ple, a deep ischaemic stroke which is not in anexplicit relationship with a time modifier is assumed tobe old.Table 5 IAA precision, recall and F1 for relations includingnumbers of TPs, FPs and FNsType TP FP FN Precision Recall F1Relationsmod-loc 235 17 25 93.25 90.38 91.80mod-time 421 12 3 97.23 99.29 98.25TOTAL 656 29 28 95.77 95.91 95.84Table 6 IAA precision, recall and F1 for labels including numbersof TPs, FPs and FNsType TP FP FN Precision Recall F1LabelsIschaemic stroke,deep, recent4 0 0 100 100 100Ischaemic stroke,deep, old81 4 4 95.29 95.29 95.29Ischaemic stroke,cortical, recent13 3 1 81.25 92.86 86.67Ischaemic stroke,cortical, old58 6 3 90.62 95.08 92.8Ischaemic stroke,underspecified6 6 6 50 50 50Haemorrhagicstroke, deep, recent2 1 0 66.67 100 80Haemorrhagicstroke, deep, old4 0 0 100 100 100Haemorrhagicstroke, lobar, recent4 0 0 100 100 100Haemorrhagicstroke, lobar, old3 0 0 100 100 100Haemorrhagicstroke, underspecified9 0 1 100 90 94.74Stroke,underspecified14 1 1 93.33 93.33 93.33Tumour,meningioma4 0 0 100 100 100Tumour, metastasis 0 0 0 - - -Tumour, glioma 0 0 0 - - -Tumour, other 2 3 1 40 66.67 50Small vessel disease 158 3 1 98.14 99.37 98.75Atrophy 119 9 3 92.97 97.54 95.2Subduralhaematoma6 0 0 100 100 100Subarachnoidhaemorrhage,aneurysmal0 0 0 - - -Subarachnoidhaemorrhage, other5 2 1 71.43 83.33 76.92Microbleed, deep 1 1 0 50 100 66.67Microbleed, lobar 1 0 0 100 100 100Microbleed,underspecified0 0 1 NaN 0 NaNHaemorrhagictransformation1 1 0 50 100 66.67TOTAL 495 40 23 92.52 95.56 94.02EvaluationIn order to evaluate system performance, we anno-tated development and test data as discussed in theAnnotation section. For this we used 1168 reports fromthe Edinburgh Stroke Study (ESS) [22]. We reserved theAlex et al. Journal of Biomedical Semantics 2019, 10(Suppl 1):23 Page 9 of 11Table 7 Evaluation of the system on the two annotators testsets. We reproduce IAA from Table 3 for comparisonPrecision Recall F1 IAA F1EntitiesAnnotator 1 test set 94.63 96.37 95.49 96.96Annotator 2 test set 97.21 96.50 96.86NegationAnnotator 1 test set 93.54 95.30 94.41 96.46Annotator 2 test set 96.35 95.66 96.01RelationsAnnotator 1 test set 97.32 99.24 98.27 95.84Annotator 2 test set 95.47 97.61 96.53LabelsAnnotator 1 test set 94.94 97.88 96.39 94.02Annotator 2 test set 92.70 92.52 92.61first 500 reports as the development set and the remain-der as the test set. ESS contains MRI, CT and DopplerUltrasound reports but we used only the CT and MRIreports. We also discarded a few reports which containednon-brain results, e.g. combined brain and neck, chest, orabdomen scans. In total the annotated development setcontains 322 CT and 42 MRI reports. We have annotateda random subset of the test set containing 238 CT and 28MRI reports.Manual annotation of the development data was accom-plished in six tranches, where annotation was correc-tion of the system output. The system was modified andimproved between the tranches. Table 1 provides infor-mation on the sizes of the data subsets. The first threetranches were doubly annotated by the radiology expertsso that IAA could be monitored. For these three tranchesonly, disagreements between the annotators were recon-ciled to produce an agreed gold standard. The remainingdevelopment data was singly annotated. The test data wasdoubly annotated in three tranches but not reconciled.Table 2 provides details of the annotators and annotationsin all the data sets.ResultsFollowing standard practice we measure both IAA andsystem performance using precision, recall and F1. Notethat IAA represents an upper bound for system perfor-mance as an automatic method would not be expectedto out-perform human capabilities. The overall resultsfor IAA on the test data are shown in Table 3. Notethat IAA measures for relations are only computed forthose relations where the two annotators agree on bothentities linked by the relation. Overall the IAA resultsare very high which indicates that the annotation task iswell-defined.Table 8 Detailed evaluation of system labelling compared toAnnotator 2 showing numbers of true positives (TP), falsepositives (FP) and false negatives (FP), as well as precision, recalland F1Type TP FP FN Precision Recall F1Ischaemic stroke,deep, recent4 1 0 80.00 100.00 88.89Ischaemic stroke,deep, old81 5 4 94.19 95.29 94.74Ischaemic stroke,cortical, recent14 1 2 93.33 87.50 90.32Ischaemic stroke,cortical, old56 5 8 91.80 87.50 89.60Ischaemic stroke,underspecified6 8 6 42.86 50.00 46.15Haemorrhagicstroke, deep,recent3 0 0 100.00 100.00 100.00Haemorrhagicstroke, deep, old4 1 0 80.00 100.00 88.89Haemorrhagicstroke, lobar,recent4 1 0 80.00 100.00 88.89Haemorrhagicstroke, lobar, old3 1 0 75.00 100.00 85.71Haemorrhagicstroke,underspecified9 3 0 75.00 100.00 85.71Stroke,underspecified13 1 2 92.86 86.67 89.66Tumour,meningioma4 1 0 80.00 100.00 88.89Tumour,metastasis0 3 0 0.00 - -Tumour, glioma 0 0 0 - - -Tumour, other 4 2 1 66.67 80.00 72.73Small vesseldisease158 0 3 100.00 98.14 99.06Atrophy 120 3 8 97.56 93.75 95.62Subduralhaematoma5 0 1 100.00 83.33 90.91Subarachnoidhaemorrhage,aneurysmal0 0 0 - - -Subarachnoidhaemorrhage,other4 1 3 80.00 57.14 66.67Microbleed, deep 1 0 1 100.00 50.00 66.67Microbleed, lobar 1 0 0 100.00 100.00 100.00Microbleed,underspecified0 2 0 0.00 - -Haemorrhagictransformation1 0 1 100.00 50.00 66.67TOTAL 495 39 40 92.70 92.52 92.61Alex et al. Journal of Biomedical Semantics 2019, 10(Suppl 1):23 Page 10 of 11Tables 4, 5 and 6 provide a more detailed breakdownof the IAA results per type on the entities, relations andlabels across the three test sets. The majority of lowerIAA scores for entity types are for low frequency ones,for example subarachnoid haemorrhage. This pat-tern is mirrored in the IAA scores for labels, forexample for Haemorrhagic transformation andMicrobleed. However, since these types are very infre-quent their low IAA scores do not have a serious effect onthe overall figures.Table 7 shows evaluation results for the EdIE-R systemon the two annotators versions of the test set. For labelsand relations, the system agrees more with Annotator 1than with Annotator 2, while the pattern is reversed forentities and negation. We would expect system scores tobe lower than IAA (see final column), which is the casefor entities and negation for Annotator 1, and for all butrelations for Annotator 2. We speculate that these differ-ences indicate that Annotator 1 focused more on entitymark-up and spotted and corrected more system entityerrors while Annotator 2 focused more on the labels andmade more corrections there. To improve the accuracy ofthe evaluation we would ideally arbitrate the annotatorsdisagreements and produce a consensus test set. Nev-ertheless, the overall evaluation results are reassuringlyhigh, indicating that this method of labelling radiologyreports is highly effective.In Table 8 we provide a breakdown of system perfor-mance for the labelling task as compared with Annotator2. This shows the comparative frequency of the dif-ferent labels. Small vessel disease and Atrophyare the most frequent and the system performs wellon both. The presence of these labels boosts thetotal precision, recall and F1 into the low 90s. Withthe exception of Ischaemic stroke, deep, oldand Haemorrhagic stroke, deep, recent, per-formance is generally slightly lower for both IschaemicandHaemorrhagic stroke labels than the total entity score.The comparative frequency of these labels (Ischaemicmore frequent than Haemorrhagic) does not appear tomake a difference in Table 8, but it may be that thenumber of Haemorrhagic stroke instances is too low forthe sample to be representative. Similarly, other labelsare so infrequent that their results may not be inter-pretable and it would be useful to acquire and annotatemore data to improve the robustness of the evaluationresults.ConclusionWe have described the development and evaluation of theEdIE-R system on brain imaging radiology reports fromthe Edinburgh Stroke Study. The evaluation results areencouraging and the system is sufficiently accurate thatwe believe it can be used for its intended purpose of dataprovision for epidemiological studies. To that end, we arecurrently testing and revising the system on a dataset ofover 150,000 routine brain scans from NHS Tayside col-lected between 1994 and 2015. We are also in the processof evaluating whether the system can reliably identifycases of intracerebral haemorrhage in patients in GreaterManchester.The evaluation of EdIE-R against these larger datasetswill show how robust it is against new data. The disad-vantage of a rule-based system such as EdIE-R is that ittakes time to write the rules. However, we found that withthe help of the domain expert input we were able to get afirst prototype running fairly quickly. For a small datasetsuch as ESS, we found this to work very well as we did nothave any training data available at the start to test machinelearning methods. Now that we have the annotated dataready we are evaluating machine learning approaches inparallel to investigate if we can obtain better results usingthem.AcknowledgementsAn initial version of this paper was presented at the Healthcare Text AnalyticsConference 2018 (HealTAC) in Manchester in April 2018 [29].About this supplementThis article has been published as part of the Journal of Biomedical SemanticsVolume 10 Supplement 1, 2019: HealTAC-2018: Unlocking Evidence Containedin Healthcare Free-text. The full contents of the supplement are availableonline at https://jbiomedsem.biomedcentral.com/articles/supplements/volume-10-supplement-1.Authors contributionsAlex and Grover wrote this article. Grover developed the text mining systemand performed the evaluation experiments and Alex assisted in theannotation, evaluation and discussions of this project. Tobin wrote the XMLprocessing tools used in the EdIE-R text mining pipeline. Whiteley and Mairdid the manual data annotation, provided expert domain knowledge duringsystem development and edited the article. Sudlow provided the dataset andoffered domain expertise. All authors edited the paper and approved the finalmanuscript.FundingAlex and Grover are supported by Turing Fellowships from The Alan TuringInstitute (EPSRC grant EP/N510129/1). Sudlow is Chief Scientist of UK Biobankand Director of Health Data Research UK Scotland. Mair is supported by aStroke Association Edith Murphy Foundation Senior Clinical Lectureship (SAL-SMP 18\1000). Whiteley was supported by an MRC Clinician Scientist Award(G0902303) and is supported by a Scottish Senior Clinical Fellowship(CAF/17/01). Publication costs are funded by the RCUK Open Access Fund.Availability of data andmaterialsThe annotated ESS corpus that we have created as part of this project hasmuch potential value as a resource for developing text mining algorithms. Thisdata will be available on application to Prof. Cathie Sudlow (email:Cathie.Sudlow AT ed.ac.uk) to bona fide researchers with a clear analysis plan,in line with the Wellcome Trust policy on data-sharing (https://wellcome.ac.uk/what-we-do/topics/data-sharing). We are in the process of creating a releaseof EdIE-R free for research purposes (https://www.ltg.ed.ac.uk/software/edie-r).For more information contact Dr. Beatrice Alex (email: balex AT ed.ac.uk).Ethics approval and consent to participateThe Edinburgh Stroke Study received ethical approval from the LothianResearch Ethics Committee (LREC/2001/4/46). This is a patient-consentedAlex et al. Journal of Biomedical Semantics 2019, 10(Suppl 1):23 Page 11 of 11dataset. We also received permission from the NHS Tayside Caldicott Guardianto use the anonymised brain imaging reports for this work.Competing interestsThe authors declare that they have no competing interests.Author details1School of Informatics, University of Edinburgh, Informatics Forum, 10 CrichtonStreet, Edinburgh, UK. 2Edinburgh Futures Institute, School of Literatures,Languages and Cultures, University of Edinburgh, 50 George Square,Edinburgh, UK. 3The Alan Turing Institute, The British Library, 96 Euston Road,London, UK. 4Centre for Medical Informatics, University of Edinburgh, 9 LittleFrance Road, Edinburgh, UK. 5Centre for Clinical Brain Sciences, University ofEdinburgh, Chancellors Building, 49 Little France Crescent, Edinburgh, UK.Published: 12 November 2019RESEARCH Open AccessOntology patterns for the representation ofquality changes of cells in timePatryk Burek2, Nico Scherf3,4,5 and Heinrich Herre1*AbstractBackground: Cell tracking experiments, based on time-lapse microscopy, have become an important tool in biomedicalresearch. The goal is the reconstruction of cell migration patterns, shape and state changes, and, comprehensivegenealogical information from these data. This information can be used to develop process models of cellulardynamics. However, so far there has been no structured, standardized way of annotating and storing the trackingresults, which is critical for comparative analysis and data integration. The key requirement to be satisfied by anontology is the representation of a cells change over time. Unfortunately, popular ontology languages, suchas Web Ontology Language (OWL), have limitations for the representation of temporal information. The currentpaper addresses the fundamental problem of modeling changes of qualities over time in biomedical ontologiesspecified in OWL.Results: The presented analysis is a result of the lessons learned during the development of an ontology, intendedfor the annotation of cell tracking experiments. We present, discuss and evaluate various representation patterns forspecifying cell changes in time. In particular, we discuss two patterns of temporally changing information: n-ary relationreification and 4d fluents. These representation schemes are formalized within the ontology language OWL and areaimed at the support for annotation of cell tracking experiments. We analyze the performance of each pattern withrespect to standard criteria used in software engineering and data modeling, i.e. simplicity, scalability, extensibility andadequacy. We further discuss benefits, drawbacks, and the underlying design choices of each approach.Conclusions: We demonstrate that patterns perform differently depending on the temporal distribution of modeledinformation. The optimal model can be constructed by combining two competitive approaches. Thus, we demonstratethat both reification and 4d fluents patterns can work hand in hand in a single ontology. Additionally, we have foundthat 4d fluents can be reconstructed by two patterns well known in the computer science community, i.e. statemodeling and actor-role pattern.Keywords: Ontology, Design patterns, Cell tracking, Web ontology languageBackgroundLife is a complex, hierarchical and dynamic process [1]:it is a hallmark of all living systems that they changeover time. This is obvious during development, regener-ation, or disease; but even under homeostatic conditionsliving matter is in a dynamic equilibrium; an example isthe constant turnover in the hematopoietic system tomaintain a certain number of blood cells. Thus, a deeperunderstanding of basic biological principles requires us toresolve the systems spatial and temporal structures [2].Over the past decades, advances in biomedical imaging,experimental procedures, and computational analysis ledto the establishment of time-lapse microscopy thatallowed us to study the spatio-temporal organizationof tissues, organs, or whole animals at the cellularlevel [3, 4].Time-lapse microscopy has become a fundamental ex-perimental tool in biomedical research. The goal is to re-construct migration patterns, shape changes, changes inprotein expression and, eventually, comprehensive ge-nealogical information [5, 6] from the data. However,the analysis of the resulting videos has become a majorbottleneck: manual analysis can be done on short se-quences with few cells, but it is practically infeasible for© The Author(s). 2019 Open Access This article is distributed under the terms of the Creative Commons Attribution 4.0International License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, andreproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link tothe Creative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver(http://creativecommons.org/publicdomain/zero/1.0/) applies to the data made available in this article, unless otherwise stated.* Correspondence: heinrich.herre@imise.uni-leipzig.de1Institute for Medical Informatics, Statistics and Epidemiology, University ofLeipzig, Haertelstr. 16-18, 04107 Leipzig, GermanyFull list of author information is available at the end of the articleBurek et al. Journal of Biomedical Semantics           (2019) 10:16 https://doi.org/10.1186/s13326-019-0206-4large-scale, systematic experiments. Consequently, thedevelopment of computational tools for cell tracking, ei-ther fully or partly automated, is a vital field of researchin image analysis [79]. However, what is still largelymissing is a structured, standardized way of annotatingand storing the tracking results. But this is exactly whatwe need in the future to build systematic databases ofcell tracking experiments and to mine, infer and com-pare the inherent biological information.A few steps have been taken in this direction: in [1012]we reported on our work in progress on the frameworkfor annotating results of experiments and simulations instem cell biology. The core component of the frameworkis a Cell Tracking Ontology (CTO) formalized in the WebOntology Language (OWL) [13], which enables the anno-tation of time-lapse experiments.Typically, the information about a cells history is or-ganized into pedigree-like data structures called cellulargenealogies [14]. In such a genealogy the root representsthe founder cell and its progeny is arranged in thebranches of the tree, with branching events representingcell division. Here, a cell is perceived as a spatially andtemporally extended object. The existence of a cell istemporally restricted by its birth (the division of themother cell) and either its death (apoptosis) or terminaldivision (mitosis), yielding two daughter cells of the nextgeneration [10]. The observed cells themselves are dy-namic entities, i.e. they can change their shape, theirposition (migration), or their internal state (differenti-ation). Therefore, the key requirement for an ontologyof cellular genealogies is the representation of changesover time in individual cells, such as, for instance, thechange of a cell from a round to an elongated shape.Unfortunately, representing temporal information is aserious problem appearing across numerous areas of in-formation modeling, including data modeling and rela-tional database design [15] as well as the semantic weblanguages typically used for ontology modeling, such asResource Description Framework (RDF) [16], WebOntology Language (OWL), or the Description Logicsunderlying OWL. One problem originates from thelack of direct support for n-ary relationships, whichin turn limits the capabilities for representing tempor-ally indexed information.One possible approach to overcoming this limitation isthe extension of these languages so that they can expresstemporal information. For instance, in the area of de-scription logics numerous approaches have been pro-posed to incorporate time into the logic model [1719].Unfortunately, as discussed in [20], temporal logics stillhave problems with representing temporally changinginformation, as they are geared towards synchronic rela-tionships, not diachronic ones. In the field of RDF theincorporation of temporal information and temporalreasoning has been proposed by [21] using the so-calledtemporal RDF graphs or a query and storage syntax [22].For OWL, [23] proposed an extension for representingdynamic entities using a four-dimensional (4d) model.An alternative to language extensions, and one morerelevant for the development of CTO, is a solution onthe user level without any need to modify the languageitself. Along these lines, numerous patterns have beenproposed [24], and two strategies are of particular inter-est: reification of n-ary relations and 4d fluents.The former strategy is rather straightforward: an n-aryrelationship is represented by introducing an additionalmodel element, the so-called reified entity. This ap-proach is well known in many areas of information mod-eling, e.g. Associative Entities in Entity-Relationship-Diagrams (ERD)[25], Intersection Tables in SQL [26], orAssociation Classes in Unified Modeling Language(UML) [27]. This strategy has also been suggested forOWL [28].The alternative approach originates from the philo-sophical theory of four-dimensionalism [29], where en-tities are considered as the so-called 4d worms, whichcan be sliced into temporal parts. Different variants ofthe 4d fluents pattern have been introduced in literature,among others by [24, 3032], yet all have in commonthe same underlying principle, which, analogously to thereification strategy, introduces to the model an add-itional entity (or entities) representing temporal informa-tion. However, in contrast to reification, the introducedentity does not represent a reified relationship but atemporal part/slice of a modeled entity.In the current paper we take a closer look at both pat-terns and their relevance to modeling the dynamicchange of information in biomedical ontologies such asCTO. We focus primarily on the application of thesepatterns for constructing new ontologies from scratch. Itshould be noted that our goal is neither to address otherrelated issues, such as time representation and temporalreasoning, nor the extension of existent OWL domainontologies, as it has been presented e.g. in [33, 34].Although we focus on the use-case of cell tracking ex-periments, the problem is generic and has to be ad-dressed by ontology engineers in different domains ofthe biomedical field. In contrast to many overviews ofthe discussed problem, which typically conduct theiranalyses on single isolated temporal information, wefocus on a dynamically changing web of information.We demonstrate that the patterns perform differentlydepending on the temporal distribution of the informa-tion. We further demonstrate that a 4d approach can bere-constructed using other well known patterns not re-quiring the introduction of 4-dimensionalism. We con-duct our analysis discussing the benefits and drawbacksof each pattern with respect to common criteria forBurek et al. Journal of Biomedical Semantics           (2019) 10:16 Page 2 of 18software systems and information modeling, i.e. scalabil-ity, extensibility and adequacy.Cell trackingTo get an idea of the Cell Tracking Ontology, it is usefulto sketch some aspects of typical cell tracking experi-ments. Figure 1 demonstrates examples from the varietyof image sequence data acquired via time-lapse micros-copy, which can be either two-dimensional (e.g. in vitroexperiments using traditional wide-field microscopy) orthree-dimensional volumes (e.g. in vivo imaging usingfluorescence microscopy) over time. The data are cor-rected, annotated and analyzed with the help of softwaretools such as [11, 3537]. The tool from [11] is shown asan example in Fig. 2. A single experiment can span from afew hours [38] to several days or even weeks [39, 40], de-pending on the frame rate (i.e. the time between two con-secutive snapshots). This yields a few hundreds up tothousands of images (or image volumes) per experiment.The number of cells observed in each image varies withbiological applications: from tens of cells in in vitro stemcell assays [39] to tens of thousands of cells in develop-mental studies [4, 8, 41]. That is, the total number of indi-vidual observations (snapshots of a cell in time) in adatabase will lie somewhere between 10,000 and 500,000for typical studies but can easily reach a few million.For biological studies, a number of cellular featuresshould be recorded and properly stored in the database.There are various qualities of interest which are associ-ated with a snapshot of a single cell; these can be classi-fied and systematized within a top level ontology of data,being a part of GFO [42]. Examples of such snapshotqualities are: Cell position: typically given as the centroid of thecell in Cartesian coordinates as a vector [x, y] in 2Dor [x, y, z] in 3D, Cell shape: either given as a mask (a set of spatialgrid elements (voxels) occupied by the cell), as apolygonal outline, or in an abstract representation(e.g. as an oriented ellipsoid), Cell dimensions: e.g. the area or volume occupied bythe cell, Cell state: usually measured as the concentration, orthe presence/absence of certain gene products (RNAor protein) found in particular cell types, Depending on the research question additionalfeatures could be of interest, e.g. cell polarity,orientation, or intracellular features.At the level of cell trajectories, the following featureswould be of interest: Migration: the speed and direction of cell movement, Deformation: changes in cell shape, Mitosis: occurrence of cell division, Apoptosis: occurrence of cell death, Differentiation: changes in cell type reflected bychanges of other features, such as genetic markers.Finally, using the information gathered in complete ge-nealogies a number of aspects can be analyzed: Topology: overall structure of the pedigree and itssub-trees, Cell cycle kinetics: distribution of cellular life-times, Fate maps: the identification of sub-populations ofcells that give rise to certain structures of interest(e.g. tracing the origins of specific organs), General structure of sub-populations: the distributionof different features (e.g. cell fate) within thegenealogy, Inter-cellular communication: the influence of cellbehavior by other cells within its spatial andtemporal neighborhood.Preliminaries: terminological clarifications and problemstatementWe do not make many ontological restrictions on thetop level categories used for the development of anontology. The broad spectrum of top level categories,which can be utilized for knowledge representation inFig. 1 Examples of cell tracking data: (a) In vitro tracking of an initially small number of cells. (b) In vitro tracking of a fast expanding culture ofpancreatic cells (200 images, 4600 cells in total). Resulting trajectories and genealogies are shown in a space-time plot. (c) In vivo tracking of earlyzebrafish development over several hours (400 images, 10,000 cells per image)Burek et al. Journal of Biomedical Semantics           (2019) 10:16 Page 3 of 18general and for ontology development in particular, canbe found in literature [43, 44].We do not want to limit the analysis to any of thoseontologies, instead we only make a few common-senseassumptions, keeping in mind that even those presup-pose some ontological commitments, hence ontologycannot be escaped: Entities such as cells endure through time spanscalled their lifetimes. We call these Objects (Obj). Objects such as cells possess certain characteristicsdescribing them. Those characteristics, called in thecurrent paper Qualities (Q), are expressed in naturaland artificial languages by means of syntacticelements such as adjectives/adverbs or attributes/properties, respectively (p. 30, [45]). Typical qualitiesof cells are e.g. round shape or a specific location. A quality such as an oval shape can be predicatedupon an object in a sense that we can say that theobject has that quality as e.g. a cell has an ovalshape. In the current paper we will call suchassignments Quality Assignments (QA). A particular QA can change over time. For instance,the shape of a cell can change, i.e. shape quality attwo different time points may differ. We refer to alltypes of entities as Time Entities (TE). Those are e.g.intervals and time points.1 A complete analysis ofthe current time-ontologies is presented in [46],which also includes a comparison between GFO-Time and Allens theory of temporal intervals[47]. Allens theory can be reconstructed withinGFO-Time, though the converse is not possible.GFO-Time provides a coincidence-relation betweentime-boundaries which allows to model discretechanges, if needed..Putting the above together allows us to interpret thesentence a cell has an oval shape at time t1  as follows:a cell c is an object, a round shape o is a quality and t1 isa time entity indicating the time-extent of quality assign-ment of o to c.Based on the above assumptions and terminologicalclarifications the problem addressed in the current papercan now be formulated as follows: How to model theFig. 2 Screenshot: An example showing a software for manual correction and annotation of cell tracking experiments as described in [11]1For the purpose of the current paper the class Time is considered asan abstraction of the time parameter and no specific time ontology isassumed.Burek et al. Journal of Biomedical Semantics           (2019) 10:16 Page 4 of 18change of an objects quality assignments over time inOWL? E.g. how to represent a change of a cells shapefrom round at time t1 to elongated at time t2 ?We believe that in ontology development, as it is rec-ognized in software engineering [48], there is nouniquely determined approach which is optimal in allcontexts. For this reason, the goal of the current paper isnot to provide some ultimate template for modeling achange of an objects qualities, but instead to review pos-sible patterns and verify them against our specific usecase of developing CTO.Problem statement exemplifiedFigure 3 presents a straightforward approach to model-ing qualities in OWL: objects are modeled as OWLClasses, Qualities as OWL Classes or Datatypes andQuality Ascriptions - as Object Properties or DatatypeProperties, respectively. The upper part of Fig. 3 presentsa UML diagram depicting the pattern itself. The applica-tion of the pattern to our use-case is shown in thebottom part of Fig. 3. For instance, a shape of a cell ismodeled by owl:ObjectProperty named has_shape, link-ing an owl:Class Cell with an owl:Class Shape.2Utilizing this pattern, an individual cell and its shapecan be defined in turtle notation [49] as follows:The major advantage of pattern 1 is its simplicity,the limited number of entities and the ease of exten-sion. Unfortunately, this pattern does not allow forrepresenting the change of qualities over time, e.g.the change of a cells shape from round to elongated.In order to overcome the limitations of pattern 1 andto model the change of an objects qualities over timeone can extend pattern 1 by adding a temporal index tothe Quality Assignment property as presented on Fig. 4.For instance, a class Cell linked with a class Shape bymeans of two distinct OWL properties: has_shape_at_t1and has_shape_at_t2, denotes that a cell has a differentshape at time t1 and t2, respectively.With the help of that pattern one can easily model thechange of cell shape:This approach is simple and works well in situationswhere the number of time indexes is limited or when thereis some idiosyncratic time index, as for instance the G2checkpoint and Meta-phase checkpoint in the cell cycle.Then, the change of shape can be modeled simply by meansof two distinct OWL properties: has_quality_at_G2_check-point and has_quality_at_Metaphase_checkpoint. Unfortu-nately, this pattern is not applicable to our use case, since incell tracking experiments the number of observations canbe very large for a single experiment. Additionally, time in-dices are not known a priori. Therefore, the application ofpattern 2 would require the adjustment of the T-box foreach experiment. Moreover, it would result in hundreds ofquality assignment properties, which is hardly maintainable.MethodsTo find an optimal pattern for representing change inbiomedical ontologies encoded in OWL we base our2For the sake of simplicity in the examples given here we model allqualities as OWL classes and their values as instances. Clearly, in reallife systems different means can be utilized for that purpose, e.g. OWLEnumerated Datatypes or RDF Literals.Fig. 3 Pattern 1: Quality assignment modeled as OWL property. The upper part of the figure presents a semi-UML diagram depicting the categoriesused in the pattern. The bottom part presents the application of the pattern to our domain of interestBurek et al. Journal of Biomedical Semantics           (2019) 10:16 Page 5 of 18analysis on three common criteria for software sys-tems, i.e. scalability, extensibility and adequacy. Thefirst is a common criterion for benchmarking systemperformance with respect to a growing amount ofwork. The question to be posed in the context of anontology is: How does it scale to accommodate an in-creasing amount of data and, in particular, is thenumber of entities kept to the minimum even in situ-ations when the amount of information increases?This corresponds to Ockhams razor [50], a principlebroadly adopted to data modelling according to whichthe number of entities must not be multiplied beyondnecessity. That principle entails two rules of databasedesign, i.e. avoidance of data redundancy and simpli-city [26].Extensibility is the second measurement of soft-ware architecture anticipating the future growth ofthe software. In the context of ontology engineeringit can be judged by analysing if and how new infor-mation can be incorporated into the ontology, with-out or with a minimal need of reorganizing theexisting knowledge base.Adequacy is a well know criterion of data model-ling, also called faithfulness [26], which boils down tothe rule that model elements should reflect reality.The principle can be verified by examining the fol-lowing questions: How far do the constructs of theontology reflect the elements of the domain and isthe ontology comprehensible to domain experts (whoare often non-technicians)? Although the last criterionis subjective in nature, it works well in practice, espe-cially in situations where ontology constructs reflecttangible elements of the domain. It should be notedthat the criterion of adequacy in the current paper isunderstood and applied in purely engineering terms;we do not aim to contribute to the philosophically-oriented discussion on the nature of the elements ofthe modeled domain, i.e. on realism vs. idealism vs.conceptualism [51, 52].ResultsPatterns for modeling qualitiesIn the current section we review two patterns fre-quently proposed for modeling temporal information,i.e. reification of n-ary relations and 4d fluents. First,we present the patterns and then discuss their appli-cation in three scenarios of distinct temporal distribu-tion of qualities.ReificationThe reification of n-ary relations is a popular strat-egy for modeling temporally changing information.It interprets a time-indexed quality as a 3-ary rela-tionship linking an object, its quality and the timeat which the quality is assigned to the object. Next,the relation is reified and introduced to the modelas a class.Pattern 3 depicted in Fig. 5 presents the applicationof this reification strategy to our use case. In contrastto patterns 1 and 2, a Quality Assignment is notmodeled as owl:ObjectProperty but instead as a re-ified owl:Class acting as a proxy between an Objectand its Quality.A reified QA represents a specific assignment of aQuality to a particular Object and as such isdependent on both the Object and the Quality. Thatmeans that each Quality Assignment is inherent inexactly one Object and is the assignment of exactlyFig. 4 Pattern 2: Quality assignment modeled as time-indexed OWL propertyBurek et al. Journal of Biomedical Semantics           (2019) 10:16 Page 6 of 18one Quality. The former constraint is represented bythe cardinality restriction on the carries link betweenObject and Quality Assignment and the latter - bythe cardinality restriction on the of_quality link be-tween Quality Assignment and Quality. Time-index is at-tributed directly to QA by means of the at_time propertylinking QA with the Time class.The bottom part of Fig. 5 illustrates the applica-tion of pattern 3 to the CTO use-case. The objectproperty carries links the Cell class with theShapeAssignment class, which is a subclass of QualityAssignment. ShapeAssignment represents a quality assign-ment at a given time and has two OWL properties: of_quality and at_time. The former specifies the value of aquality, i.e. a specific shape, whereas the latter - the timeindex of the parameter.3This pattern can be applied to annotate a single cellwith two distinct shapes at two different time points:In many situations it is not the time index of qualityassignments that is relevant but only their t8emporalorder. This may also be true for some cell tracking ex-periments. In such cases pattern 3 can be simplified: inthe upper part of Fig. 6 the property at_time and theclass Time can be replaced with the property is_next, es-tablishing the temporal order of quality assignments.Fig. 5 Pattern 3: Quality assignment modeled as time-indexed OWL class3In a slightly different variant of the pattern a genericQualityAssignment class could be used instead of classShapeAssignment. This generalization of handling qualities minimizesthe number of classes required in case of diverse qualities. However, itdoes not influence the discussed patterns as such when it comes torepresenting the change of quality value over time. Thus, it seems thatfor the sake of readability the specific properties are more suitable.Burek et al. Journal of Biomedical Semantics           (2019) 10:16 Page 7 of 18The implementation of this pattern to our case is pre-sented in the bottom part of Fig. 6.Pattern 3 overcomes the limitations of patterns 1 and2 reported above, since time-indexed quality value as-signments are represented as instances only. Thus, evenin situations where many time-indexed value assign-ments occur, the number of classes and properties in theontology remains constant (and is relatively low).On the other hand, as observed in [31], the model in-troduces additional OWL classes and OWL propertiesfor representing time-indexed quality ascriptions, redu-cing its lucidity.4d FluentsAn alternative to the n-ary relation reification is the so-called 4d fluents pattern [30]. It is inspired by four-dimensionalism [29], a philosophical theory explainingthe persistence of objects through time, called perdur-ance, in analogy to their extension in space: similarly toan object occupying some space s having parts occupy-ing parts of s, an object occupying some time t may havetemporal parts occupying parts of t. In that understand-ing, time-extended objects are considered as the so-called 4d worms, which can be sliced into temporalparts, as 3d objects can be sliced into their spatial parts.The top-part of Fig. 7 presents a 4d pattern. In contrastto the reification pattern, the idea behind 4d fluents isnot to reify a temporally indexed relation but instead atemporal part of an object. For instance, in order tomodel the fact that a cell c has a round shape at time t1one can reify a temporal part of c and then assign aquality directly to the reified part:Conceptually, the two patterns seem quite distinct, yetwhen comparing Fig. 5 and Fig. 7 one can observe thatstructurally they are almost the same and both are basedon introducing an association class. The only structural dif-ference is the cardinality constraint determining the num-ber of qualities linked to the reified class. In the reificationpattern it is 1, whereas in the 4d fluents pattern it is 0..n.Therefore, when modeling an objects single quality assign-ment, both patterns are in fact equal.The difference between the patterns can be well illus-trated when applying the patterns to relations ratherFig. 6 Pattern 4: Temporally ordered quality assignmentsBurek et al. Journal of Biomedical Semantics           (2019) 10:16 Page 8 of 18than quality assignments. Let us consider the CTO rela-tion of cell-cell contact, denoting the fact that twocells touch each other. In order to model a tempor-ally indexed cell-cell contact, the reification patternrequires the introduction of a single reified time-indexed relation, whereas the fluent pattern wouldintroduce a reified and time-indexed slice for eachcell participating in the contact.The difference between the patterns can also be ob-served in cases where numerous quality assignments arebeing represented, which is in fact the real challenge ofontology engineering. Therefore, we will analyze the pat-terns using three different cases of temporal distributionof qualities: Temporally non-overlapping quality assignments.For instance, a cell can have an oval shape at onetime and an elongated shape at another, but it cannever have both shapes at the same time. Temporally equal quality assignments. Thit is atypical scenario in time lapse experiments whereat a single time point numerous distinct qualitiesare observed, e.g. shape, location, etc. Temporally overlapping, but not temporally equalquality assignments. This is a common situationwhen qualities change independently from oneanother, as is the case with the location andshape of a cell.Temporally non-overlapping quality assignments of asingle qualityAs a starting point, we consider the simplest case, inwhich no two quality assignments of an object are lo-cated at the same temporal location. Such a situation isnatural for many qualities when considered separately,e.g. typically a cell has a single location or a single shapeat any given time. This scenario is often assumed in theworks devoted to the modeling of temporal information,e.g. in [24, 30, 31]. In such a case it can be easily ob-served that both patterns behave the same, in fact thereis no difference when applying them. Modeling n qualityassignments of a single quality of a single object we needto introduce n instances of a reified class in both cases.Both models are equally extensible, i.e. to introduce anew characteristic a new instance must be added to themodel. Finally, the adequacy of both solutions seems tobe merely a matter of personal taste since the choice be-tween the patterns generates no structural differences inthe models.Temporally equal quality assignmentsThe above discussion is justified when considering a sin-gle quality in isolation. Yet, when considering numerousqualities of an object, it is clear that there can be two ormore quality assignments which overlap temporally, e.g.a cell at a given time point can have some location andsome shape. This is a typical scenario in cell trackingFig. 7 Pattern 5: Reified 4D fluentsBurek et al. Journal of Biomedical Semantics           (2019) 10:16 Page 9 of 18experiments, where at a single time point more than onequality is observed. In such cases the application of thereification pattern results in a model with redundantlytime-indexed Quality Assignments: for each quality ob-served at a given time point a separate Quality Assign-ment instance has to be introduced.It seems that the 4d fluents pattern solves that problem.Time slices in their simplest form are temporal parts ofobjects having an arbitrary temporal extension (usuallyconsidered an interval). An alternative approach, presente.g. in the General Formal Ontology (GFO), introducestemporal particles located at discrete time points (the so-called presentials) which are distinct from time extendedslices [45]. In GFO, a presential is an entity that is whollypresent at a single time point. For instance, a cell observedat a single time point would be considered a presentialcell. A presential may have multiple assigned qualities, allpresent at the same time point as the presential which car-ries them. Thus, a presential is a snapshot of a time ex-tended entity, i.e. a cell observed at a single time point canbe considered a snapshot of a time extended cell.Figure 8 presents the pattern for modeling time slicesand presentials where both are considered temporal par-ticles of objects. Based on that pattern a modeler canutilize both time interval slices and/or presentials, de-pending on the actual needs.The annotation of an individual cell using the presen-tial pattern would look as presented below:In contrast to the reification pattern, the presentialpattern reduces the number of instances introducedto the model. Instead of reifying each quality assign-ment at a given time point, all coinciding quality as-signments are modeled with the help of a singlepresential instance.Fig. 8 Pattern 6: Generalized 4D fluents. Presentials and SlicesBurek et al. Journal of Biomedical Semantics           (2019) 10:16 Page 10 of 184d fluents also scales better: each new quality assign-ment added to the reification-based model requires anew instance, whereas in the case of the 4d-based modelno additional instance is needed when a time slice withthe same time index already exists in the model.The frugality of the 4d pattern seems to make it moreintuitive than the reification pattern, especially in thecase of cell tracking experiments where the presentialcells are the entities physically represented in the ac-quired images. Thus, they can be easily identified and itseems quite natural to reify them.Temporally overlapping characteristicsIn cell tracking experiments the qualities of enduringcells are deduced on the basis of a sequence of observedpresential cells and their qualities. For instance, if a cellis observed to have a round shape over the sequencetaken at time points t1, t2,.., tn, then typically one can de-duce that the cell has a round shape during the wholetime interval (t1, tn). Clearly, in the case of numerousmutually independent quality assignments it may turnout that the temporal extensions of many of them mayoverlap. For instance, during a time interval (t1, t5) a cellmay remain in location l1 but its shape may change fromround in (t1, t3) to elongated in (t3, t5). That results intwo shape quality assignments overlapping with the lo-cation quality assignment. This situation is clearly visiblewhen the reification pattern is used, as for each observedquality assignment a reified instance is introduced.However, when turning to 4d fluents, the first observationwe make is that the adaptation of the pattern to this case isnot as straightforward as in previous cases, when it wasrelatively easy to say what the cells time slice is, namely, apresential cell observable in an image and thus having itsown identity. However, in the current case we want to reifynot the presential (observable) cells but instead the time ex-tended, temporal parts of cells. This raises the followingquestion: What is a temporal part of a cell and what rulesdrive the slicing of an object (a cell) into its temporal parts?It seems that at least two strategies for introducing tem-poral parts could come in handy. The first is based on theprincipal idea of 4-dimensionalism, namely that a time ex-tended entity can be sliced into temporal slices in such away that each slice fully represents the sliced object at agiven time. This means that all qualities assigned to an ob-ject within the time span of a slice are attributed to theslice directly. We call this type of slicing vertical.Unfortunately, modeling temporally overlapping qual-ity assignments with vertical slices easily leads to seriousredundancy and is hardly maintainable. This is due tothe fact that slices are overlapping and each one rep-resents an object in full at a given time and as suchit carries all qualities attributed to the object duringthe slices lifetime.An intuitive solution to fix this problem would be toprohibit the overlapping of slices. This results in a modelin which a time extended entity is sliced into non-overlapping slices so that the sum of all the parts consti-tutes the full lifespan of the object.Let us illustrate this strategy with an example, startingwith the model of a cell remaining in location l1 duringthe interval (t1, t5):Now, let us assume that we add to our model a newobservation (fact) that the cell changes its shape fromround in (t1, t3) to elongated in (t3, t5). If we add thatobservation to our model, we end up with two additionaltime particles depicting the location of the cell: one end-ing at t3 and the other starting at t3, thus both new parti-cles are overlapping with:my_cell_slice. In order to fixthis, one could reorganize the time slices into two non-overlapping slices, the first representing the state of thecell being round and located in l1 and the second - thestate of the cell being elongated and located in l2.Unfortunately, this strategy has its problems. As it canbe seen from the above example, the change of any ofBurek et al. Journal of Biomedical Semantics           (2019) 10:16 Page 11 of 18the qualities may entail the reorganization of the objectsslices. That leads to a proliferation of slices, but moreimportantly, it makes the knowledge base stronglycoupled and thus harder to extend, i.e. the addition ofnew information entails the reorganization of previousknowledge.In addition, despite the fact that the strategy solves theproblem of the models redundancy, it still results inheavily overloaded models. As presented on the listingabove, each slice carries a full specification of the cell ata given time, even for those qualities which remain con-stant across many slices.In order to overcome those limitations an alternativeinterpretation of 4d fluents could be considered: an en-tity could be sliced not only vertically, i.e. along the timedimension, but also horizontally, i.e. along its quality as-signments. That way a slice does not fully represent anobject at a given time but only some of its aspects, e.g.that a cell is located at l1 at t1 - t2. Thus, a slice is a kindof temporally indexed reified attribute of an entity.That interpretation fixes the problem of model redun-dancy, but it also blurs the difference between the 4dfluents and the reification pattern, since a time slice nowrepresents some quality assignment, i.e. some temporallyindexed attribute of an entity. The actual difference be-tween such an interpretation of time slices and reifiedquality assignments is hidden in the cardinalityconstraint on the quality role (presented in Fig. 5 andFig. 7). While the reified quality assignment links an ob-ject with a single quality, a slice can link an object withmultiple qualities when quality assignments overlap tem-porally. Thus, if we add the fact of a cells size, which istemporally equal to that of its shape, we are not forcedto introduce a new temporal particle but it is sufficientto add that fact to: my_cell_slice_2:DiscussionOur analysis shows that there is no single best choicewith respect to simplicity, scalability, extensibility andadequateness for modeling a change of qualities overtime. Table 1 provides a condensed summary of the dis-cussed patterns and their flavours. Additionally, as theontology of cell tracking experiments is still under devel-opment and relevant amounts of annotated data are cur-rently lacking, we provide a synthetic example in Table 2as a benchmark for the performance of discussedpatterns. We simulated data of a single cell undergoinga parallel changes of four qualities K, L, M, N over timet15. Since the size of A-box depends on the distributionof quality changes we have simulated several schemas ofchange as depicted on Fig. 9, i.e. qualities K and Lchanges independently from all others, from values k1to k2 and from l1 throughout l2, l3, l4 to l5, respectively.M and N, in turn, undergo a change simultaneously.Below we elaborate in detail on two of the presentedpatterns, which are our main focus in the current paper,i.e. the reification and the 4d fluents patterns. These pat-terns perform differently depending on the temporal dis-tribution of quality assignments. However, both patternsresult in the same model in the case where quality as-signments are not temporally overlapping. This situationseems, however, merely theoretical and in real life casesit is to be expected that numerous qualities have to bemodeled (as it is also the case in the cell tracking ontol-ogy). In fact, the introduction of numerous qualitieswhich are temporally overlapping or equal is the majorsource of modelling complexity.In cases where quality assignments are temporallyequal, the 4d fluents pattern performs better. Firstly, theexpected size of T-box is smaller in case of the 4d flu-ents pattern as the number of reified classes is equal tothe number of domain classes/types having the qualitiesattributed, whereas, in case of the reification pattern, itis equal to the number of qualities, which, in turn is typ-ically much higher than the number of classes/types.4 Infact, in case of the cell tracking ontology the number ofclasses is reduced to one as we are only interested incells. The size of A-box is also expected smaller for the4d fluents pattern as the number of reified instances isthe product of objects and t-indexes and the number ofqualities has no additional influence in contrast to thereification pattern. The extension and maintainability ofsuch models is also simpler than of models based on thereification pattern, since adding new quality assignmentsrequires no additional (reified) model element. Especiallyin cases where temporal slices are tangible objects (as incell tracking experiments), the number of reified entitiesis lower and the reified presentials are well-groundeddomain concepts, which in turn increases the adequate-ness of the model.In cases of temporally overlapping quality assignmentsthe application of 4d fluents is not straightforward. Itcould come in variants (a) vertical 4d fluents: a fully spe-cified non-overlapping slices, and (b) horizontal 4d flu-ents: a not fully specified overlapping slices. For bothvariants of the pattern the size of T-box is expected to4In case a reification pattern is applied in its generic form with a singlegeneric QualityAssignment the amount of T-Box elements for bothpatterns would be the same.Burek et al. Journal of Biomedical Semantics           (2019) 10:16 Page 12 of 18Table1OverviewofpatternsandtheirperformanceinrepresentationofchangeofqualitiesPatternOverviewT-boxSimplicity(wrtnumberoft-boxelements)A-boxsimplicity(wrtnumberofA-boxelements)Extensibility/maintainabilityAdequatenessOWLpropertyAdefaultOWLhandlingofqualities.VeryHigh-noadditionalclassesorproperties.VeryHigh-noreifiedinstances.HighVerylow-nosupportforrepresentingchangeofqualityassignments.T-indexedOWLpropertyThepatternissimpleandworkswellforlimitednumberoftimeindexesorforidiosyncratictimeindex.Lowforcelltrackingexperiments-thenumberofobjectpropertiesishighandproportionaltothenumberoft-indexesLowforcelltrackingduetohighnumberoft-indexedpropertyaxioms.Lowforcelltracking-requirestheadjustmentoftheT-boxforeachexperiment.ComplexityofT-boximpliespoormaintainability.High-noreifiedmodelingartifactmustbeintroduced..ReificationThepatternovercomesthelimitationsofpatternsabove-time-indexedqualityvalueassignmentsarerepresentedasreifiedinstancesonly.Therefore,eveninsituationswheremanytime-indexedvalueassignmentsoccur,thesizeofT-boxisconstant.Moderate-thenumberofreifiedqualityvalueassignmentclassesequalsthenumberofqualities.Moderate-thenumberofreifiedinstancesequalstheproductofobjects,qualitiesandt-indexes.Fortemporallyequalqualityas-signmentsitcausesredundancy,i.e.foreachqualityobservedatagiventimepointaseparateQualityAssignmentinstancehastobeintroduced.Moderate-anewqualityassignmentrequiresanewinstanceofareifiedclass.Moderate-reifiedqualityassignmentsdonotcorrespondtoanytangibleobjectsinadomainofcelltrackingbutaremeremodelingconstructs.Reificationw/temporallyorderedassignmentsThepatternsimplifiesandrestrictstheexpressivityofthereificationpatternbynoexplicitrepresentationoftimeentitiesbutonlyatemporalorderofqualityvalueassignments.High-sameasabovewrtqualityassignment.Additionally,noclassesfortimeentitiesareintroduced.Sameasabovewrtqualityassignment.Additionally,noinstancesfortimeentitiesareintroduced.Moderate-sameasabove.Moderate-sameasabove.4dfluents(vertical)/statesThepattern,incontrasttothereificationpattern,reifiesnotatemporallyindexedrelationbutinsteadatemporalpartofanobjectwhichcanbeinterpretedasastateofanobject.High-numberofreifiedclassesisreducedtothenumberofobjecttypesVeryHighfortemporallyequalqualities-insteadofreifyingeachqualityassignmentatagiventime,allcoincidingqualityassignmentsarerepresentedasaasingleinstance.Moderatefortemporallyoverlappingqualities-thenumberofreifiedqualityinstancesisafunctionofqualityassignmentchangesanddependsonthedistributionofchanges.VeryHighfortemporallyequalqualities-noadditionalinstanceisneededwhenatimeslicewiththesametimeindexalreadyexistsinthemodel.Lowfortemporallyoverlappingqualities-newqualityassignmentresultsinproliferationandreorganizationofreifiedinstances(slices)andmultiplicationofpropertyaxiomsfornon-changingqualities.Highforcelltrackingexperiments-presentialcellsrepresentthedomainadequately-theyarethecellsrepresentedintheacquiredimagesorthetemporallyindexedstatesofcells.4dfluents(horizontal)Thepattern,overcomesthelimitationsofthevertical4dfluentspatterninrepresentingthetemporallyoverlappingqualitiesbytheintroductionofhorizontalslicingsuchthatareifiedentityrepresentssomequalityassignment.High-sameasabove.VeryHighfortemporallyequalqualities-sameasabove.Highfortemporallyoverlappingqualities-incontrasttothereificationpattern,itenablesthebundlingoftemporallyequalcharacteristicsintoasingleentity,whichlimitsthenumberofreifiedentitiesVeryHighfortemporallyequalqualities-sameasabove.High-forcelloverlappingqualitiessolvestheproblemofthevertical4dpattern.Additionally,incontrasttothereificationpatternanewqualityassignmentrequiresanewinstanceonlyifatimesliceforagiventimedoesnotexistyetinA-box.Low-timeslicesdonotreflectcellsobservedontimepointsbutinsteadcollectionsoftemporallyequalqualityassignments.Anon-obviousinterpretationoftheassociationentitylimitstheintuitivenessofthemodel.Burek et al. Journal of Biomedical Semantics           (2019) 10:16 Page 13 of 18be smaller compared to the reification pattern. The sizeof the A-box varies depending on the distribution of thequality changes over time, yet the total sum of instancesand property axioms is higher for both variants than forthe reification pattern.Here, the first variant does not work well since it ishardly extensible, i.e. adding a quality assignment whichis temporally overlapping with existing ones requires thereorganization of the A-box - it results in proliferationand reorganization of reified instances (slices) and multi-plication of property axioms for non-changing qualities.For instance, the attribution of m2 over t25 must besplit into three axioms, one for each vertical slice.The second variant solves that problem, as there is noneed of redundant quality assignments for non changingqualities. Additionally, in contrast to the reification pat-tern, it enables the bundling of temporally equal charac-teristics into a single entity, which limits the number ofreified entities. New quality assignment only requiresintroduction of a new instance if a time slice for a giventime is not yet present. However, a drawback of such anapproach is the non-obvious interpretation of the associ-ation entity, which limits the intuitiveness and adequacyof the model.From the above considerations, we see that a presen-tial variant of the 4d fluents pattern is naturally applic-able to the case of temporally equal quality assignments,especially in time lapse experiments where the presentialcells are tangible/observable objects. Yet, in cases ofnon-equal but overlapping quality assignments, the ap-plication of 4d fluents is not straightforward, demon-strating the major weakness of a 4d approach: it is notcommon-sense. In [30] the authors observe that it is notvery natural to convert statements such as Joe walkedinto the room into their 4d equivalents such as A tem-poral part of Joe walked into a temporal part of theroom. It seems that four dimensionalism has severalweaknesses, also on the level of philosophical theoryunderlying the 4d fluents pattern, and the discussion isstill not settled [53]. One of the open problems is theidentity of four-dimensional entities. For a four-dimensionalist, the identity of an entity resides in its un-changing temporal parts, but, on the other hand, onecan argue that an entity has different temporal parts atdifferent times. In contrast, three-dimensionalism seemsmore common-sense in that respect. 3d objects are con-sidered to be identical over time, and only their proper-ties change over time with no harm to the criteriaconstituting the identity of 3d objects.Therefore, one may still ask if it is possible to get thebenefits of the 4d-pattern without slipping into the 4-dinterpretation of time extended entities. We believe thatsome well known approaches in the area of software en-gineering permit a modeler to abandon a 4d account ofreality, sticking to the 3d approach and still obtaining asimilar output as the 4d pattern.For instance, the second variant of the 4d pattern canbe successfully represented using state modeling, a tech-nique originating from finite-state machines, which, dueto its intuitiveness, is applied far beyond hardware andsoftware engineering. In state modeling the behaviour ofan object (a system) is modeled with the help of thestates the object can be in. An objects state correspondsto a phase of the execution of the state machine duringwhich some invariable condition holds. A state can bedefined by the attributes of the object and theirTable 2 Amount of elements for a fragment of ontology representing the change of qualities of a single cell illustrated in Fig. 9Classes Object properties Individuals Object Property ExpressionsT-indexed OWL property 5 7 11 7Reification Pattern 10 (7) 3 28 304D Vertical 7 3 21 304D Horizontal 7 3 25 24Fig. 9 A fragment of simulated cell tracking experiment results presenting changes of qualities K, L, M, N over time t15Burek et al. Journal of Biomedical Semantics           (2019) 10:16 Page 14 of 18respective values. For instance, a state of a cell can bedefined by the cells shape and location.The change of an objects state is modeled with thehelp of a transition, which is a directed arc linking thesource state with the target state. An object can changeits state over time but at any given time an object canonly be in a single state. That corresponds to the secondvariant of the 4d pattern, where time slices are non-overlapping.Thus, a change of quality assignments over time canbe interpreted in terms of a change in the objects state.In that sense, a model presenting temporal non-overlapping slices of a cell can be easily reformulatedwith the help of state modeling:In contrast to the previous model, the new model doesnot use the notion of time slices, which requires a 4-dinterpretation of entities. Instead, a collection of qualityassignments constitutes the state of the object.Another alternative approach is the actor-role pat-tern, also known as actor-participant pattern [54].The pattern originates from software engineering, butcan be applied in the context of ontology engineeringas well [55]. In principle, the pattern is used to de-couple the identity (the actor) from the behavior (therole). The pattern consists of two entities, an actorand a role, linked by a one-to-many relationship. Anactor is an entity which has an identity and attributednon-changing characteristics. A role is existentiallydependent on an actor and bundles all characteristicsattributed to the actor in the context in which heplays a role. An actor can have many roles both sim-ultaneously as well as sequentially, whereas a role isalways a role of a single actor. A classical example ofan actor-role pattern are social roles such as e.g. a person(an actor) having different roles such as a student, a driveror an employee. A role pattern has been extended by someauthors to an actor-role-context pattern, introducing anadditional entity representing a context in which an actorplays a given role [55, 56].The modeling of temporally indexed quality assign-ments with the role pattern results in a model analogousto the third variant of the 4d pattern. In that sense, hori-zontal and vertical slices of an object can be interpretedas roles of the object in the context of a bundle of qual-ities. Hence, each bundle of temporally equal quality as-signments is represented as a separate temporallyindexed role. Thus, each role represents some aspect ofan entity at a given time, but, in contrast to the statemodeling pattern, roles can temporally overlap and asingle role does not provide a full specification of the ob-jects characteristics at a given time, but only those rele-vant in its context.Summing up, the 4d pattern can be successfully recon-structed with two intuitive and well known patterns, i.e.state and role modeling. This finding can be helpful tomodelers not familiar with the philosophical account of4-dimensionalism or those for whom considering timeextended objects in terms of 4d entities could becounter-intuitive.Choices adapted to the cell tracking ontologyOur analysis demonstrate that there is no single silverbullet approach to modeling temporally changing infor-mation. The key aspects here are the number of time in-dexes and the actual temporal distribution of theinformation to be modeled. Based on our analysis we de-rive the following guidelines for ontology engineers: The default handling of OWL properties is mostperformant but provides no means for modelingchanges in quality values and therefore cannot beused when those changes need to be represented. The t-indexed property pattern is suited for caseswith a limited number of time indices or in case ofan idiosyncratic time index. The vertical 4d fluents/states pattern is suited forcases with many time indexes and with temporallyequal quality assignments. That is a typical setting indomains and applications where states of objects areobserved and documented at particular time windowsas it is the case of time lapse experiments where cellsare imaged at equal time intervals. The horizontal 4d fluent and the reification patternare best suited for the cases with overlapping butnot equal quality assignments. This is the case forinstance when object qualities change independentlyBurek et al. Journal of Biomedical Semantics           (2019) 10:16 Page 15 of 18one from another, as for instance in situation wherethe shape of a cell changes independently from itslocation.Accordingly, we have developed CTO as a combinedapproach of n-ary relations and presentials. In CTO,there are two possible types of temporal particles in-volved: presentials and interval-based particles. Theformer correspond to tangible objects observable in im-ages and indexed with discrete and, therefore, non-overlapping time points. This is why we have decided toreify them. This reduces the number of entities, since weare not forced to reify each QA on the presential levelbut instead we can use a straightforward OWL approachto model qualities as properties of presentials. On theother hand, in order to model interval-based, overlap-ping and dynamically changing quality assignments wehave decided to use reified quality assignments.The combination of both patterns supports at thesame time the requirements of Ockhams razor (thenumber of entities used for representing presential qual-ity assignments is limited by the usage of presentials)and the extensibility of the ontology (since we use reifiedtime extended quality assignments, there is no need toreorganize the existing ontology after adding new over-lapping quality assignments).In the current paper we focus on a specific use case ofmodeling the change of an objects qualities. Yet, wethink that the patterns and design choices presented arenot restricted to that case: in the development of CTOwe have followed the very same principles for modelingthe change of relations between cells. One example ofsuch a relation is cell_cell_contact representing adhesionof two or more cells. Here, in analogy to the case ofquality assignments (modeling relations indexed withtime points), we have decided to follow the presentialpattern and we have used the reification pattern tomodel time-extended relations.ConclusionsBiomedical systems are dynamic in their nature; the rep-resentation of change is thus one of the fundamentalchallenges for knowledge engineering in the biomedicaldomain. The current paper addresses the problem ofmodeling the change of quality assignments over time inbiomedical ontologies encoded in OWL. The paper dis-cusses two patterns for modeling temporally changinginformation, i.e. n-ry relation reification and 4d fluents.In contrast to the rich literature on the topic, we are notinterested in modeling temporally isolated characteristicsbut an entire web of characteristics in a dynamicallychanging domain. Concerning an ontology of time, wetake a minimal ontological commitment which can beeasily fulfilled by various time ontologies, depending onintended granularity of the model. In many cases, OWL-time is sufficient, though there might be situations inwhich the modeling of a discrete change is needed. In thiscase, OWL-time is not sufficient and we may use GFO-time (and the corresponding OWL-representation).We discuss the application of these patterns to thebiomedical ontology dedicated to the annotation of celltracking experiments (which is currently under develop-ment). We have analyzed the performance of each solu-tion in three different settings with respect to commoncriteria of software engineering and data modelling, i.e.scalability, extensibility and adequacy. We have dis-cussed the benefits and drawbacks of each approach aswell as the underlying design choices. For each designchoice, we have presented possible options and modelingvariants.The lesson learned from this analysis is that there isno single best approach. We demonstrate that the pat-terns behave differently depending on the temporal dis-tribution of the information modeled. Thus, the optimalmodel can be obtained by combining the two competi-tive approaches. The example of CTO demonstrates thatboth reification and 4d fluents patterns can work handin hand in a single ontology.Additionally, we have found that in the (common) caseof temporally overlapping quality assignments the appli-cation of the 4d fluents pattern can be reconstructed bytwo alternative patterns well-known in computer sci-ence, i.e. the state modeling pattern and the actor-rolepattern. This finding can be helpful to those users notfamiliar with the philosophical discussion on four-dimensionalism to whom considering entities in termsof 4d worms may seem awkward.Although the discussed patterns are dedicated forOWL, the underlying conceptual choices are generic innature and we believe that they can be successfully ap-plied to other technologies and formalisms, such as, e.g.,UML or ERD. We also expect that the same patternscould be helpful for modeling other types of temporalinformation, such as temporal relations.The patterns have been investigated in the context ofdeveloping a biomedical ontology dedicated to the anno-tation of cell tracking experiments. The ontology isintended for integration with software used for annota-tion of cell tracking results [11, 3537] (see also Fig. 2).Obviously, there are two main tasks to solve: Firstly,we need a sufficiently expressive annotation ontology(mainly an ontology describing qualities of cellular ge-nealogies), secondly, we need a support for the anno-tation of time lapse experiments (being sequences ofvisual frames) by using the concepts of the CTO. Thesecond step could be supported by machine learningmethods, though the training data must be providedby experts.Burek et al. Journal of Biomedical Semantics           (2019) 10:16 Page 16 of 18The evolution of ontologies is an important researchtopic which must be taken into account as existing an-notations of time lapse experiments would have to bere-annotated for a new version CTO (1) of the ontologyCTO. Here, we would build on the framework for classi-fying and realizing ontology- versions in the context ofontology evolution as presented in [57].Finally, modeling of quality value change is not limitedto cell tracking experiments, but is a common and non-trivial task across many domains of interest. The ana-lysed patterns are domain-independent and, since achange of quality values is common to many biomedicaldomains, we believe that the application of these pat-terns is important in many related problems. In such asetting the patterns discussed can be used for the exten-sion of the existing modeling languages such as e.g.UML and used for the purpose of ontology engineeringand conceptual modeling in various applications includ-ing modeling of new ontologies as well as refactoring ofexisting ones. We already realized this approach andproved its utility for a different modeling task of func-tion representation, firstly by introducing the extensioninto the UML [58] and, secondly, by the application ofextended UML for the task of refactoring of the GeneOntology [59, 60].AbbreviationsCTO: Cell Tracking Ontology; GFO: General Formal Otology; OBJ: Object;OWL: Ontology Web Language; Q: Quality; QA: Quality Assignment;RDF: Resource description framework; TE: Time Entity; UML: Unified ModelingLanguageAcknowledgementsThe paper was presented at the Workshop on Ontologies and Data in LifeSciences (ODLS) 2014 in Freiburg. We acknowledge support from theGerman Research Foundation (DFG) and Universität Leipzig within theprogram of Open Access Publishing.Authors contributionsPB drafted the paper and conceived the initial idea. NS provided theexperimental material and the application to time-lapse experiments. HHcontributed to the ontological foundation of the topic. All the authorsparticipated in the discussion, elaboration and revision of the paper. HHsupervised the project. All authors read and approved the final manuscript.FundingThe publication fee is funded by the DFG and the University of Leipzig withinthe program of Open Access Publishing.Availability of data and materialsNot applicable.Ethics approval and consent to participateNot applicable.Consent for publicationNot applicable.Competing interestsThe authors declare that they have no competing interests.Author details1Institute for Medical Informatics, Statistics and Epidemiology, University ofLeipzig, Haertelstr. 16-18, 04107 Leipzig, Germany. 2Institute of ComputerScience, Faculty of Mathematics, Physics and Computer Science, MariiCurie-Sklodowskiej University, pl. Marii Curie-Sklodowskiej 5, 20-031 Lublin,Poland. 3Max Planck Institute for Human Cognitive and Brain Sciences,Stephanstr. 1a, 04103 Leipzig, Germany. 4Max Planck Institute of MolecularCell Biology and Genetics, Pfotenhauerstr. 108, 01307 Dresden, Germany.5Carl Gustav Carus Faculty of Medicine, Institute for Medical Informatics andBiometry, TU Dresden, Fetscherstr. 74, 01307 Dresden, Germany.Received: 21 July 2018 Accepted: 31 July 2019RESEARCH Open AccessOrganizing phenotypic dataa semanticdata model for anatomyLars VogtAbstractBackground: Currently, almost all morphological data are published as unstructured free text descriptions. This notonly brings about terminological problems regarding semantic transparency, which hampers their re-use by non-experts, but the data cannot be parsed by computers either, which in turn hampers their integration across manyfields in the life sciences, including genomics, systems biology, development, medicine, evolution, ecology, andsystematics. With an ever-increasing amount of available ontologies and the development of adequate semantictechnology, however, a solution to this problem becomes available. Instead of free text descriptions, morphologicaldata can be recorded, stored, and communicated through the Web in the form of highly formalized and structureddirected graphs (semantic graphs) that use ontology terms and URIs as terminology.Results: After introducing an instance-based approach of recording morphological descriptions as semantic graphs(i.e., Semantic Instance Anatomy Knowledge Graphs) and discussing accompanying metadata graphs, I propose ageneral scheme of how to efficiently organize the resulting graphs in a tuple store framework based on instancesof defined named graph ontology classes. The use of such named graph resources allows meaningful fragmentation ofthe data, which in turn enables subsequent specification of all kinds of data views for managing and accessingmorphological data.Conclusions: Morphological data that comply with the here proposed semantic data model will not only becomputer-parsable but also re-usable by non-experts and could be better integrated with other sources of data in thelife sciences. This would allow morphology as a discipline to further participate in eScience and Big Data.Keywords: Phenotypic data, Semantic data model for anatomy, Instance anatomy knowledge graph, Anatomy,ontology, Zoology, Knowledge management, Morphological description, MorphologyBackgroundMorphological data drives much of the research in the lifesciences [1]. Unfortunately, however, the morphologicalrecord consists for the most part of unstructured text.This has far-reaching consequences for research based onmorphological data, since conventional morphological freetext descriptions not only bear problems relating toterminology and lack of semantic transparency, but theyalso cannot be parsed by computers. Someone interestedin using morphological data, for instance, for systematic-ally searching for correlations between phenotypic dataand genotypes over a broad set of non-model organisms,will soon be discouraged after briefly having delved intothe relevant morphological literature, having not only tosearch for relevant data in published morphological de-scriptions, but also having to deal with morphologicalterms, the meaning of which depends on the describedtaxon, the describing author and the time when the de-scription has been conducted. Moreover, while some termsrefer to common spatio-structural properties, others referto a common function or a presumed common evolution-ary origin, or some mixture of those three categories (seeLinguistic Problem of Morphology [2]). As a consequence,interpreting and analyzing morphological data becomesunnecessarily difficult for non-experts and integratingmorphological data with other sources of data in the lifesciences very difficult and time-consuming.This is unfortunate because morphology offers a treas-ure trove of valuable data that only has to be harvested.Morphological data remain the primary data source for© The Author(s). 2019 Open Access This article is distributed under the terms of the Creative Commons Attribution 4.0International License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, andreproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link tothe Creative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver(http://creativecommons.org/publicdomain/zero/1.0/) applies to the data made available in this article, unless otherwise stated.Correspondence: lars.m.vogt@gmail.comInstitut für Evolutionsbiologie und Ökologie, RheinischeFriedrich-Wilhelms-Universität Bonn, An der Immenburg 1, 53121 Bonn,GermanyVogt Journal of Biomedical Semantics           (2019) 10:12 https://doi.org/10.1186/s13326-019-0204-6defining most species and understanding their phylogen-etic history but are also important for recognizing, defin-ing, and diagnosing pathological conditions in plants,animals, and other organisms [1]. Morphological dataalso provide insights to questions of development, func-tion, evolution, and interaction of phenotypes with theirenvironments, yielding in the discovery of new pharma-ceutical agents and the development of new materialsand technical solutions. Therefore, if morphological datawould be easily accessible, re-usable by non-experts, andcomputer-parsable, they could significantly contribute toa better understanding in a diverse field of researchareas within the life sciences, ranging from evolutionand ecology to pharmacy, health, engineering, andmaterial sciences. In an ideal world, this data would beopenly accessible and easily findable through the Web,they would be stored in online databases in a highly for-malized and structured syntax and format, they wouldbe semantically transparent and thus easier to compre-hend and interpret, and data from different authors anddifferent taxa could be easily integrated and algorithmscould read and analyze them.Since we are living in the age of Big Data, Linked-Open-Data, and the Semantic Web, this ideal world should notbe too far-off for morphology. Efficiently managing andorganizing data has become key to data exploration andeScience, and developing adequate data and metadata stan-dards is becoming increasingly important [35]. eScienceis a new driving force for scientific progress in data-richfields of empirical research [6] and requires data and meta-data to be maximally findable, accessible, interoperable,and reusable (FAIR guiding principle [7]). This can beachieved by establishing semantic transparency and makingdata and metadata computer-parsable [810]. Ontologiesand other controlled vocabularies have taken a central rolein this context because they provide the required standard-ized semantic structure for data and metadata to becomecomparable and computer-parsable (e.g., [1113]).Ontologies are vocabularies that are used for describing acertain reality. They consist of terms with commonly ac-cepted definitions that are formulated in a highly formalizedcanonical syntax and standardized format, such as the WebOntology Language (OWL) serialized to the Resource De-scription Framework (RDF), with the goal to yield a lexicalor taxonomic framework for knowledge representation [14].Unfortunately, in morphology, the use of ontologies isstill very limited. Currently, only a small fraction of mor-phological data is eScience-compliant and that fraction isusually restricted to data about model organisms (e.g., [1519]). However, an increasing amount of taxon-specific on-tologies is becoming available (e.g., Hymenoptera AnatomyOntology [20, 21]; Spider Ontology [22]; Plant Ontology[23]; Vertebrate Trait Ontology [24]; Uberon multi-speciesanatomy ontology [25]; Cell Ontology [26]). A first steptowards increasing the amount of eScience-compliant mor-phological data is to semantically enrich free text descrip-tions with ontology terms. This is a step in the rightdirection. However, semantic technology would be used toits full potential only when the entire description is repre-sented using Uniform Resource Identifiers (URIs) with theRDFs syntax of Subject, Predicate, and Object and whenstoring these triples as semantic graphs in a tuple store. Asemantic graph is a network of RDF/OWL-based triplestatements, in which some URIs take the Object positionsin some triples and the Subject position in other triples,connecting several triples to form a semantic graph.Tuple stores are capable of handling large semanticgraphs, and semantic technology facilitates detailed data re-trieval of RDF/OWL-based data through SPARQL end-points [27], as well as inferencing over OWL-based datathrough semantic reasoners [28]. Some tuple stores such asthe Jena tuple store framework [29] allow for organizingthe store into different physically separate RDF stores, witheach RDF store being structured into different namedgraphs. A named graph identifies a set of triple statementsby adding the URI of the named graph to each triple be-longing to this named graph, thus turning these triples intoquads. The Jena tuple store framework can handle suchquads. The use of named graphs thus enables partitioningdata in an RDF store and enables making statements aboutstatements comparable to OWL reification, but outper-forms the latter for more complex queries [30].In the last decade, progress has been made in semantic-ally representing phenotypic data. Two alternative basicapproaches have been suggested for documenting the ana-tomical organization of a given specimen using ontologyterms:Class-based approachA particular morphological phenotype is described bydefining an ontology class according to a set of proper-ties that are characteristic to that phenotype. In otherwords, the definition of the ontology class contains thedescription of the phenotype. The description itself isthus contained in class axioms, which in OWL areexpressed as TBox expressions. The morphologicaldescription of a specimen that bears the phenotype thenmerely expresses that this specimen instantiates the re-spective ontology class. Corresponding descriptions havebeen called Semantic Phenotypes. In this class-basedapproach, Semantic Phenotypes are therefore definedthrough TBox expressions that are formally describedfollowing an Entity-Quality (EQ) scheme [3134].Instance-based approachA particular morphological phenotype is described bygenerating a semantic graph consisting of instances thatinstantiate ontology classes, with each instance referringVogt Journal of Biomedical Semantics           (2019) 10:12 Page 2 of 14to a particular part of the structure to be described. Thecorresponding descriptions are thus contained in ABoxexpressions and are called Semantic Instance AnatomyKnowledge Graphs (or Semantic Instance Anatomies [2,12, 3537]; from here on Anatomy Knowledge Graphs).Contrary to the Semantic Phenotypes approach, theAnatomy Knowledge Graphs approach follows a moremodular framework that makes use of anatomical entityterms from existing ontologies and does not necessarilyrequire the definition of new ontology classes to repre-sent a given phenotype. Besides the smaller demand foradditional ontology classes, Anatomy Knowledge Graphs,when compared to Semantic Phenotypes, have usuallybetter properties regarding retrievability of data, for in-stance, when attempting to retrieve the numbers out ofmeasurement data. The reason for that is that queryingTBox expressions is more difficult than querying ABoxexpressions. When querying TBox expressions, the basicgraph-pattern-matching of SPARQL has to be definedusing entailment regimes [38], which is more complexand computationally difficult under full expressivity ofOWL [39, 40]. Therefore, querying Anatomy KnowledgeGraphs is more straightforward and computationally lessdifficult than querying Semantic Phenotypes. Moreover,the instance-based approach allows for identifying andre-using every individual part and property that thedescription mentions because each of them possesses itsown URI. As a consequence, Anatomy KnowledgeGraphs can be easily fragmented into sub-graphs. This isnot possible when applying the class-based approach,because its TBox expressions treat all described partsand properties as anonymous resources (for a detailedcomparison of the Semantic Phenotypes approach andthe Anatomy Knowledge Graphs approach see [41]).In the following, I give a brief introduction to AnatomyKnowledge Graphs and their accompanying metadata be-fore I will propose a general scheme of how to efficientlyorganize respective morphological data and metadata in atuple store.MethodsOrganizing a document as a semantic graphIn RDF, propositions are structured as triple statementsconsisting of Subject, Predicate, and Object, with Subjectand Predicate being resources in the form of a UniformResource Identifier (URI) and the Object, depending onthe type of Predicate used in the statement, being either aresource or some numerical or literal value. A resource al-ways refers to a real thing or a piece of data (e.g., a Webpage), and the value can be a unique ID, a numerical value,an arbitrary label, a proper name, a kind name, or a stringof free text. An RDF statement can be modeled as a graph,with Subject and Object forming nodes that are connectedthrough a Predicate as a labeled directed arch (edge). Sincea given URI can take the Object position in one statementand the Subject position in another statement, triple state-ments can connect to each other and jointly form asemantic graph. Such semantic graphs can be used forrepresenting specific properties of a particular anatomicalentity or its relation to other anatomical entities of a givenspecimen and thus for describing the anatomicalorganization of that specimen.However, simply storing a large semantic descriptiongraph in a database and making it openly accessible is usu-ally not an efficient way of organizing morphological dataand does not comply with the FAIR guiding principles.Additional information must be provided when being pub-lished in a database. One way would be to treat a semanticmorphological description as a scientific publication, andthus organize it according to the commonly used generalstructure for scientific publications. This would requiremodeling semantic morphological descriptions as docu-ments that consist of several different parts, including ab-stract, author list, introduction, methods, results,Conway et al. Journal of Biomedical Semantics            (2019) 10:6 https://doi.org/10.1186/s13326-019-0198-0SOFTWARE Open AccessMoonstone: a novel natural languageprocessing system for inferring social riskfrom clinical narrativesMike Conway1* , Salomeh Keyhani2,3, Lee Christensen1, Brett R. South1,4, Marzieh Vali2,Louise C. Walter2,3, Danielle L. Mowery1,4, Samir Abdelrahman1 and Wendy W. Chapman1,4AbstractBackground: Social risk factors are important dimensions of health and are linked to access to care, quality of life,health outcomes and life expectancy. However, in the Electronic Health Record, data related to many social risk factorsare primarily recorded in free-text clinical notes, rather than as more readily computable structured data, and hencecannot currently be easily incorporated into automated assessments of health. In this paper, we presentMoonstone, anew, highly configurable rule-based clinical natural language processing system designed to automatically extractinformation that requires inferencing from clinical notes. Our initial use case for the tool is focused on the automaticextraction of social risk factor information in this case, housing situation, living alone, and social support fromclinical notes. Nursing notes, social work notes, emergency room physician notes, primary care notes, hospitaladmission notes, and discharge summaries, all derived from the Veterans Health Administration, were used foralgorithm development and evaluation.Results: An evaluation of Moonstone demonstrated that the system is highly accurate in extracting and classifyingthe three variables of interest (housing situation, living alone, and social support). The system achieved positivepredictive value (i.e. precision) scores ranging from 0.66 (homeless/marginally housed) to 0.98 (lives at home/nothomeless), accuracy scores ranging from 0.63 (lives in facility) to 0.95 (lives alone), and sensitivity (i.e. recall) scoresranging from 0.75 (lives in facility) to 0.97 (lives alone).Conclusions: The Moonstone system is  to the best of our knowledge the first freely available, open sourcenatural language processing system designed to extract social risk factors from clinical text with good (lives in facility)to excellent (lives alone) performance. Although developed with the social risk factor identification task in mind,Moonstone provides a powerful tool to address a range of clinical natural language processing tasks, especially thosetasks that require nuanced linguistic processing in conjunction with inference capabilities.Keywords: Natural language processing, Social determinants of health, SoftwareBackgroundSocial risk factors are important dimensions of health andare linked to access to care, quality of life, health out-comes, life expectancy and health care utilization. Somesocial risk factors such as alcohol and drug abuse canbe captured using administrative and laboratory data.However, data related to measures such as housing, living*Correspondence: mike.conway@utah.edu1Department of Biomedical Informatics, 421 Wakara Way, University of Utah,alt Lake City, UT 84108, USAFull list of author information is available at the end of the articlesituation and social support are primarily recorded infree-text clinical notes, rather than as computable struc-tured data, and hence resists easy incorporation into pre-diction models. In this paper, we present Moonstone, anew, highly configurable rule-based natural language pro-cessing (NLP) system designed to automatically extractinformation that require inferencing from clinical notes.The use case to which we applied Moonstone for thisstudy is extraction of Social Determinants of Health(SDOH) specifically, housing situation, living alone, andsocial support  from clinical notes derived from the© The Author(s). 2019 Open Access This article is distributed under the terms of the Creative Commons Attribution 4.0International License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, andreproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to theCreative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver(http://creativecommons.org/publicdomain/zero/1.0/) applies to the data made available in this article, unless otherwise stated.Conway et al. Journal of Biomedical Semantics            (2019) 10:6 Page 2 of 10Veterans Health Administration (VA). We chose thesethree variables as our focus as this information is notcaptured in structured fields within the VAs administra-tive data, and because these domains of social risk areimportant to health outcomes. Building on previous rule-based clinical NLP systems [1], the Moonstone systemis designed to be extensible to a range of clinical NLPtasks, especially those that involves the need for nuancedlinguistic processing and inference.Use case: social risk factors & healthThe relationship between SDOH and health outcomesis well established [2]. Lack of housing, social isolationand lack of social support are associated with highermortality and poor health outcomes. Despite the clearrelationship between SDOH and health, these metricsare not routinely used in health services and outcomesresearch, mainly because many of these health measuresare not collected as part of routine care. Therefore, mostclinical outcome studies that rely on risk adjustment donot typically utilize social risk data, and models that doincorporate SDOH data are limited to demographic infor-mation derived from structured data (e.g. race, ethnicity,rural location) [3, 4]. The importance of these metricshave been recently reinforced by the institution of Afford-able Care Act penalties on hospitals with higher thanaverage readmission rates, with the result that hospitalsthat care for vulnerable and disadvantaged populations areplaced at financial risk. The models used by the Centersfor Medicare & Medicaid Services to compare hospitalsdid not include measures of social risk as these factorsare not available in administrative data. In recognitionof the important role social factors play in health, theNational Quality Forum, National Academy of Medicine,and the Department of Health and Human Services haverecently emphasized the need for health care systems toidentify and address social risk factors effects on patientcare [5].Natural language processingThere are numerous NLP systems that attempt to extractclinically relevant data from unstructured clinical nar-ratives [6]. For example, MedEx, a rule-based systemdesigned to extract medication information  drug, dose,frequency  achieves F-scores1 of greater than 0.93[7]. Similarly, MedLee (Medical Language Extraction andEncoding System) uses a rule-based approach to extractclinically relevant information from radiology reports anddischarge summaries, and has been used successfully for anumber of different clinical information extraction appli-cations (e.g. [1, 8, 9]). More recently, cTAKES (clinicalText Analysis and Knowledge Extraction System) uti-lizes open source technologies and a highly modularizedsystem architecture in conjunction with both machinelearning and rule-basedmethods to perform clinical infor-mation extraction tasks. The system has been used formultiple clinical NLP application domains (e.g. smokingstatus identification [10] and cohort identification [11]).The NLP systems described above are designed toextract information explicitly stated in clinical text (e.g.explicit documentation of drug and alcohol use); how-ever, a significant proportion of information regardingsocial context is not explicitly stated in the clinical note,but can be inferred. For example, from the statementpatient family by bedside, it can be indirectly inferredthat the patient enjoys a degree of social support (i.e. fam-ily members who visit). This inferencing process requiresa degree of semantic analysis and reasoning that existingclinical NLP systems, optimized as they are for explicitinformation extraction, cannot easily perform. Further-more, existing clinical NLP systems are not necessarilywell suited for tasks that require the processing of highlyambiguous everyday words. For example, to process thesentence patient has to stay at the VA hospital overnightbecause he had no one to take him home after the proce-dure requires identification of everyday words, tasks, androles, in addition to inference capabilities to arrive at the(correct) conclusion that the patient lacks social support.Our goal with this work is to demonstrate the effective-ness of the Moonstone systems semantic processing andinferencing capabilities by extracting and evaluating keymeasures of social risk  housing situation, living alone,and social support  from the clinical notes using NLP.ImplementationMotivationThe current state of the art in automatic social risk fac-tor analysis  as exemplified by Chen et al. [12] andGreenwald et al. [13]  utilizes a dictionary of stringsor regular expressions (e.g. patient lives alone, patientlacks family support). However, there is a substantialamount of information relevant to the three variables ofinterest that is implicit (i.e. not stated directly) and henceis not amenable to pattern matching-based informationextraction approaches. For example social support isoften manifested in narrative notes as the interaction ofpatients with family members. For example, spouse atbedside, accompanied to medical appointment by son,family member visiting regularly to help with the foodand chores, and patient in phone contact with adult chil-dren, are naturally understood as connoting social sup-port. Conversely, sentences that suggest that the patientdoes not experience regular contact and help from familyand friends imply a lack of social support. For exam-ple, if an elderly patient requires public transport to gethome from a medical procedure, this can be taken as evi-dence  but not proof  of lack of social support. Thenumber of possible textual instantiations of social supportConway et al. Journal of Biomedical Semantics            (2019) 10:6 Page 3 of 10interactions is very large, and probably beyond the capa-bilities of a simple string matching approach to adequatelyaddress. Similar examples can be found for both the hous-ing and living alone variables. For example, the statementdischarged: home with wife implies that the patient bothlives in a stable home, and does not live alone. Further-more, the identity of the person with whom the patientlives can be indicative of whether a housing situation isstable ormarginal. For example, lives with wife and livesin ex-wifes basement both indicate that the patient doesnot live alone, but the latter suggests a more precariousliving situation.The effort to identify implicit, indirect meaning is com-plicated by several factors:1. Inference. The target variable is often severalinference steps away from what is stated explicitly inthe text. For instance, family at bedside literallymeans that family members are with the patient inthe clinical care setting, which in turn implies thatthey are involved in the patients care, whichconnotes support.2. Ambiguity. The meaning-bearing words relevant tosocial support are typically everyday high frequencywords which, in contrast to medical terminology,have a high probability of appearing in contextsirrelevant to social support. For example, the wordbedside can be used in many ways unrelated tosocial support (e.g. medical equipment at thebedside). Although potentially relevant words arerelatively common in clinical text, relevant sentencesappear much more sparsely, with very fewdocuments in our corpus containing such sentences.3. Semantic roles. Understanding semantic roles  i.e.who is the actor and who is the recipient of an action is vital to sentence interpretation. For example, inthe sentences the wife helps the patient withmedications and the patient helps the wife withmedications, only the first conveys the fact that thepatient receives social support, as the patient is thedirect object of the verb helps. Similarly, wordplacement can affect interpretation. For example, thesentences he needs no help with ADL (Activities ofDaily Living) and he has no help with ADL needs,differ in only one word (has), and yet have verydifferent meanings. NLP systems that do notconsider word order, and which do not analyze themeaning and placement of modifiers, cannot reliablymake such distinctions.Corpora & annotationThe clinical document corpus used in this study wasselected with the goal of developing information extrac-tion methods capable of automatically extracting SDOHvariables relevant to 30-day readmission predictive mod-els, with a focus on four diseases of interest (congestiveheart failure, acutemyocardial infarction, pneumonia, andstroke). We selected these conditions as, at the time ofstudy initiation, they were the four medical conditions forwhich hospital readmission rates were publicly recorded.To create an initial cohort, we identified all VA patientsaged 65 or older admitted with at least one of the four dis-eases of interest between January 1st 2012 and December31st 2012. More than 21,000 patients were identified2. Wethen randomly sampled 500 patients from this cohort andextracted their associated documents  353,889 notesin total  from the VA Corporate Data Warehouse fora period of one year prior to hospital admission. Twophysicians (SK and LW) then reviewed document titles,selecting only those documents likely to contain evidenceof SDOH variables. Clinical document types selectedincluded nursing assessment, social work notes, emer-gency room physician notes, primary care notes, hospi-tal admission notes, and discharge summaries. In total,52,304 documents were selected.Social risk factors pose a significant challenge to the cre-ation of reliable annotated reference standards given thathuman annotators typically experience extreme difficultyin identifying and reliably annotating rarely documentedvariables. For this reason, using the corpus describedabove, we pre-annotated social support instances usinga prototype version of Moonstone. We trained threeannotators who were familiar with VA documentationpractices to review a randomly selected sample of pre-annotated instances, with all disagreements between theannotators discussed until consensus was achieved. Wethen ran the final, trained version of Moonstone over thedocument set and presented disagreements between thehuman annotators and Moonstone to a fourth annotator(again, a nurse familiar with VA documentation practices)who was blinded as to whether the value was assignedby Moonstone or by the previous consensus of annota-tors. The fourth annotator selected the best variable value,which was then used as the final gold standard value.System descriptionMoonstone is an open-source, Java-based NLP systemdeveloped by the Biomedical Language UnderstandingLaboratory (BLULab) at the University of Utah andderived from a lineage of clinical NLP systems (ONYX[14], TOPAZ [1]) that utilize rule-based semantic analy-sis. The system consists of a Knowledge Base, which inturn is made up of a type hierarchy, a semantic gram-mar, a set of inference rules, and a word dictionary, andprocessing modules including a named entity recognitionmodule, a grammatical analysis module, and an inferencemodule. In addition, we used a tool called the Evalu-ation WorkBench [15] to compare two sets of humanConway et al. Journal of Biomedical Semantics            (2019) 10:6 Page 4 of 10and/or machine-produced annotations over a set of doc-uments, and display match statistics (e.g. precision, recall,accuracy, f-measure). The EvaluationWorkBench allows ahuman reviewer to view the annotation schema, and thenview annotations highlighted within the text of the docu-ments, thus supporting rule development and debugging.We used theWorkBench to compare Moonstones perfor-mance against reference standard annotations producedby human experts using the eHOST annotation tool [16].The architecture of the Moonstone system is shown inFig. 1 , with system features described below.Moonstones activities are user-controlled through itsgraphical control tool. A function in that tool can be usedto apply Moonstone to analyze a corpus of documents.For each document, Moonstone splits that document intotokens representing words, numbers, punctuation andother symbols, attaches a dictionary definition to wordtokens if available, and groups the tokens into namedsections (e.g. "History of Present Illness") and sentenceswithin those sections.For each sentence in a document, the Moonstone gram-matical parser applies the semantic grammar to analyzethe tokens in that sentence, and gathers resulting con-cepts which are relevent to the current NLP task into alist for further processing. The grammatical parser alsoconsults the Moonstone ontology to fire those grammarRESEARCH Open AccessIntegrating terminologies into standardSQL: a new approach for research onroutine dataAndré Sander1* and Roland Wauer2AbstractBackground: Most electronic medical records still contain large amounts of free-text data. Semantic evaluation ofsuch data requires the data to be encoded with sufficient classifications or transformed into a knowledge-baseddatabase.Methods: We present an approach that allows databases accessible via SQL (Structured Query Language) to besearched directly through semantic queries without the need for further transformations. Therefore, we developedI) an extension to SQL named Ontology-SQL (O-SQL) that allows to use semantic expressions, II) a framework thatuses a standard terminology server to annotate free-text containing database tables and III) a parser that rewrites O-SQL to SQL, so that such queries can be passed to the database server.Results: I) We compared several semantic queries published to date and were able to reproduce them in areduced, highly condensed form. II) The quality of the annotation process was measured against manualannotation, and we found a sensitivity of 97.62% and a specificity of 100.00%. III) Different semantic queries wereanalyzed, and measured with F-scores between 0.91 and 0.98.Conclusions: We showed that systematic analysis of free-text-containing medical records is possible with standardtools. The seamless connection of ontologies and standard technologies from the database field represents animportant constituent of unstructured data analysis. The developed technology can be readily applied torelationally organized data and supports the increasingly important field of translational research.Keywords: Ontology-based queries, Terminology server, Translational research, Infant mortality, Data mining(knowledge discovery)BackgroundThe launching of a working group on the use of elec-tronic medical records for clinical research [1] in 2011by the GMDS (Deutsche Gesellschaft für MedizinischeInformatik, Biometrie und Epidemiologie) is evidence ofthe enormous importance of medical records for re-search; however, it also underlines the difficulties thatarise when trying to analyze these data. In the following,we therefore explain an approach that addresses the effi-cient usage of medical records in well-established struc-tures. We introduce an approach that integratesfree-text-based query terms into standard SQL and thusallows such queries to be run on existing databasesystems. The free text is mapped to a terminology andsemantically interpreted using an ontology provided by aterminology server.Related workTwo major problems are addressed with our approach: I)the semantic structuring and evaluation of free text andII) the querying of such information from medicalrecords.Many research papers have presented different ap-proaches to the semantic structuring of free text. Theoutcomes vary in many aspects; however, in general,these approaches provide good to excellent results. Re-cent NLP (natural language processing)-based mapping© The Author(s). 2019 Open Access This article is distributed under the terms of the Creative Commons Attribution 4.0International License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, andreproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link tothe Creative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver(http://creativecommons.org/publicdomain/zero/1.0/) applies to the data made available in this article, unless otherwise stated.* Correspondence: asander@id-berlin.de1ID GmbH & Co. KGaA, Platz vor dem Neuen Tor 2, 10115 Berlin, GermanyFull list of author information is available at the end of the articleSander and Wauer Journal of Biomedical Semantics            (2019) 10:7 https://doi.org/10.1186/s13326-019-0199-zsystems were published by Friedman et al. in 2004 [2]and later by Savova et al. [3], both of which exhibitedhigh accuracy. Elkin et al. analyzed mapping algo-rithms with the SNOMED (systematized nomenclatureof medicine) ontology on chest X-ray reports with ex-cellent results [4]. A similar task for pathology wasrecently presented by Allones et al. but required fur-ther improvement [5]. In the German language, a2015 paper presented by Toepfer et al. showed verygood results [6]. Some well-established mapping toolshave been used by many groups and were evaluatedin [7, 8]. One of the core challenges of these tools isthe disambiguation of mapping alternatives, whichwas currently achieved best by Zwicklbauer et al.,who developed DoSeR [9].Many attempts to enable knowledge-based queryingof information from medical records have been de-scribed; for example, Hogarth et al. suggested theso-called TQL (terminology query language), whichencompassed SQLs idea of universality [10]. SPARQL(SPARQL Protocol and RDF Query Language) in par-ticular has established itself in many areas as the defacto standard [11]. However, for specific problems,such as mapping between ontologies, additional in-ternal query languages have been developed, even inrecent years [12]. There has been an evolution of in-tegrated frameworks for the implementation ofbrowser-based knowledge systems since early on [13,14]. Today, SPARQL- and OWL (Web Ontology Lan-guage)-based systems are successfully implementedfor defined applications, such as the management ofblood pressure or hypertension [15]. In the area ofinfectious diseases, Kama et al. used the concept of asemantic data warehouse that integrates OLAP (on-line analytical processing) techniques [16]. Neverthe-less, in this approach, specific query languages haveremained unaltered in their respective domains. Ep-stein et al. therefore chose to implement and inte-grate needed subsystems (e.g., NLP pipelines) intoSQL [17]. One of the most recent and interesting ap-proaches came from Zheng et al., who have extendedstandard SQL with semantic constructs [18]. Never-theless, for this purpose, numerous algorithms havebeen implemented in the middleware instead of con-sequently outsourcing them to a terminology server.Recently, the field of OBDA (ontology-based dataaccess) has been examined as a profound theoreticalbasis. However, these approaches are currently limitedto specific types of databases and their querying lan-guages [19].Classification-based approaches (e.g., ICD (Inter-national Classification of Diseases)-encoded data) arealso used in current attempts to integrate heteroge-neous data sources for cohort formation [20]. Thisapproach, however, is associated with three majorproblems: I) loss of specificity [21], II) low interoper-ability [22] and III) low stability over time [22].We present an approach that overcomes many of thedescribed technical hurdles and still achieves comparableor even better results.MaterialsIn the work presented here, we use epicrises from1868 patients collected from free-text medical re-cords. These data were captured in the period from1973 to 1989 in former East Berlin/East Germany bythe Commission on the Reduction of the Infant Mor-tality Rate1 [23]. The medical records of all newbornswho died in the first 28 days of life were analyzed,discussed and evaluated by this Commission and clas-sified based on their avoidability. Avoidability was cat-egorized from a medical and social point of view intonon-avoidable, conditionally avoidable and avoid-able. Subsequently, measures were taken in differentareas, ranging from staff training to structuralchanges, such as the centralized treatment of certainrisk groups.At that time, data from the original medical records(pregnancy card, birth history logs, all hospital docu-ments, reports of hospital stay, reports of interventionsand so on) were stored on handwritten index cards inDIN A5 (see Fig. 1). Apart from some structured proper-ties, these data mainly included clinical text  as definedin [24]  addressing anamnesis, course of birth, treat-ment and postmortem classification. In each case, bothperi- and postnatal care were described in detail, and adifferentiated assessment of the cause of death was car-ried out. When creating the index cards, color highlight-ing was used to classify cases into the categoriespremature birth (red highlighting) or lethal malforma-tion (yellow highlighting) (see Fig. 1 which has a redhighlighting).Digitalization of the cards was performed in two steps:first, a professional service provider for archivingpaper-based patient records scanned the index cards andprovided high-resolution images of the front and backsides of the cards. In the second step, the cards weremanually transcribed into an SQL database. Spelling andgrammar, however, were copied exactly. Quality assur-ance was implemented by a three-stage release process(involving three independent transcriptionists). In thefinal step, all values of the structured data items wereanalyzed by A-Z analysis for implausible data.MethodsThe central idea of the approach presented here consistsof integrating a terminology server into an SQL-basedRDBMS (Relational Database Management System) andSander and Wauer Journal of Biomedical Semantics            (2019) 10:7 Page 2 of 11extending the SQL language itself by adding the abilityto formulate semantic criteria within the query with freetext. Hence, the approach comprises two components:I) Semantic structuring and annotation of the RDBMStables, andII) Syntactic extension of standard SQL (Ontology-SQL).Semantic structuring and annotationWe chose to store the semantic annotation by usingadditional tables to extend the database schema insteadof changing existing tables. This approach offers the ad-vantage that the data tables that store the annotationscan be created in their own logical instance of an exist-ing database server.First, we created a single table for each source col-umn that had to be annotated. The results are annota-tion tables that contain semantic representations ofthe content of the source columns. The preconditionis that each table contained a unique primary key,which held true in practice. For each row of the givencolumn, we created n rows in the annotation table thatcontained the semantic interpretations. These annota-tions are the specific concept identifiers in theselected ontology. The records are linked via the pri-mary unique key. In addition to storing direct annota-tions, we also stored the respective super classes(derived from the is a hierarchy from the ontology)to enable a performance analysis. Figure 2 shows thedesigned structure, and Table 1 shows a sample dataset.The approach of using a generic table with metainforma-tion for the description of the source table was discardedin favor of performance or respective costs. The annotationtable schema is fairly simple with four columns (one for thekey, one for the concept identifier, one for the concept labeland one for the semantic distance (level)), and thus, modernRDBMS are expected to handle such tables extremely well.As an additional benefit of this solution, semantic datamodels can be generated from analysis of the annotations,especially if the source column contains keyword data [25].The annotation of free text is accomplished by inte-grating a CTS2 (common terminology services)-compa-tible terminology server [26]. The terminology serverused here includes a complete NLP pipeline based onGate [27] and Jape in addition to numerous supportingalgorithms, such as an extensive, discipline-specific listof abbreviations, collocation-based disambiguation, atyping error corrector, which can break up compoundsand correct them step by step, and a function forFig. 1 Original sample of a handwritten index card (anonymized). In preparation for each commission meeting on reducing infant mortality (IM),the chairman of the commission prepared such an index card (N = 1868). The index cards contain basic demographic data regarding the motherand child and free text regarding anamnesis, birth, postnatal treatment and course of death. The index cards also contain a color-coding systemdenoting a premature birth (a red mark on top of the card) and a (lethal) malformation (a yellow mark). Additionally, the index cards included thefinal judgment made by the commission if the case was avoidable, conditionally avoidable or not avoidable. In many cases, the index cards alsocontained a revision of the initial judgment and an explanatory statementSander and Wauer Journal of Biomedical Semantics            (2019) 10:7 Page 3 of 11German language-optimized word stemming (for furtherinformation, see Additional file 1: Addendum 1).Ontology-SQL syntaxWe developed an extension to standard SQL that enablesthe use of free-text and semantic relations within such aquery. Expressions formulated through this extension canbe transformed into standard SQL syntax using a preproces-sor. The resulting query contains only standard SQL andthus can be directly passed on to the database server engine.A basic O-SQL expression consists of a free-text part thatis surrounded by square brackets and followed by a tableand column name in which the free-text should be searchedfor. The latter is surrounded by round brackets. So thesimpliest expression looks like this:[free-text](tablename.columnname)Furthermore, the table and column name can be acomma separated list. Since the free-text is mapped to theontology, a semantic role (or in short: relation) can be givenFig. 2 For each table (aTableName) and each column (aColumnName_x) enabled for semantic queries, an annotation table is created with thenaming scheme [_][aTableName][_][aColumnName_x]. The annotation table is linked to the source table via the unique primary key. Each rowin the annotation table results in n rows in the annotation table, each holding the concept identifier (ConceptID) and a concept label(ConceptLabel) from the ontology and a level denoting the semantic distance (the super classes of the annotation concepts are also stored)Fig. 3 Inheritance via depth parameter: in this sample, indications of the concept Analgesic subsum indications of Ibuprofen; thus, a query forindications of Analgesic will find Pain and Fever if the depth is set to ?2Sander and Wauer Journal of Biomedical Semantics            (2019) 10:7 Page 4 of 11that will be applied to the expression. That relation is a key-word written before the O-SQL expression:relation[free-text](tablename.columnname)The default value for the relation is isA, which wouldquery all concepts subsumed under the concept de-scribed in the free text.The generic relation context can be further specifiedby a modifier to extent the standard relations like is aand part of to relations like has indication. This con-text modifier is a free-text written in curly braces be-tween the relation and the free-text query:context{modifier}[free-text](tablena-me.columnname)The approach of a context modifier was chosen to allowa generic, ontology independent syntax of O-SQLexpressions.As shown in Fig. 3, the attributes of the semanticroles can be passed on through the isA-hierarchy,which allows inheritance of these attributes up to aspecific depth. The inheritance depth is specified by anumber separated from the context modifier by acolon. Finally, a leading prefix can be added to in-clude the is a relation to the given relation.Consequently, the complete syntax for O-SQL expres-sions is as follows:[prefix][relation][{modifier}][:-depth][[query]](table.column,)Its elements and their values are further illustrated inAdditional file 1: Addendum Table S1.When designing the syntax, we attempted not to focus ona functional characteristics but rather decided to maintain thenarrative character of a query. A free-text formulation ofthe actual query offers enormous advantages as the know-ledge base is seamlessly integrated and implementation detailsof the underlying terminology and ontology are hidden. Lie-bermann et al. demonstrated early on that SQL-based queriesof annotated databases can provide very high recall values,but the respective queries required extensive knowledge ofthe underlying ontology and manual research on the ontologyconcepts [28]. Since the terminology server provides an NLPengine, the query is tolerant to typing errors, and even com-plex medical concepts requiring post-coordination can beused.ConversionAn efficient conversion of O-SQL into standard SQL is cru-cial, as this step mainly affects the runtime of given queries.Fig. 4 Schematic overview of transforming an O-SQL query into a standard SQL query using a standardized terminology serverSander and Wauer Journal of Biomedical Semantics            (2019) 10:7 Page 5 of 11First, O-SQL expressions are extracted via regular expressionsand are then converted into SQL subqueries.We decided to use the IN operator for subqueries becausethe source table holds a primary unique key and the sub-clause can be a simple enumeration of the found annotationrows. Modern RDBMS use a so-called Clustered Index Scanto process such queries efficiently.For each O-SQL statement, we created a subclause by firstmapping the free-text part of the O-SQL expression onto theterminology and then querying the annotation table for thefound concept identifiers. From the results of these queries,the values of the column containing the key were used tobuild the subclause. Then, the O-SQL expression was re-placed by that subclause. All other parts of the SQL queryremained untouched. Therefore, all logical operators and lan-guage components  especially parentheses and the use ofthe logical operator NOT  function as usual so that struc-tured discrete information can be directly linked to semanticinformation.Given an O-SQL query such as the following:SELECT * FROM table_name WHERE <O-SQL ex-pression>We transform the free-text part of the O-SQL expressionwith the help of the terminology server to form conceptidentifiers and look them up in the annotation table (seeTable 1):SELECT ID FROM annotation_table WHEREconceptID = <concept identifier>We then join all the results together and replace theO-SQL expression with an IN subquery:SELECT * FROM table_name WHERE ID in ()If a query contains multiple O-SQL expressions, eachexpression is converted separately. Therefore, one canuse all standard SQL operators to combine O-SQL ex-pressions. For an example, see Additional file 1: Adden-dum 2.Figure 4 illustrates the entire pipeline via which se-mantic queries can directly be integrated into standardSQL. The pipeline also provides feedback on the termin-ology concepts actually used to avoid undetected errors.Such errors can happen if an abbreviation is not knownand is therefore misinterpreted.ResultsFirst, we measured the accuracy of the annotationprocess to evaluate the results gathered from O-SQLqueries. We then analyzed published knowledge-basedTable 1 Sample of the resulting data structure. The upper table represents a diagnosis table that has a primary unique key(DiagnosisId), a patient and case key, an ICD code and a description of the diagnosis. The diagnosis cluster headache for twoweeks is annotated with D0009F4 Bing-Horton syndrome Z000002 two GA000F8 week and subsequently stored in the annotationtable (lower table). The semantic distance is 0 here because the concepts directly represent the narrative description of thediagnosis. Additionally, the parents of all concepts found are stored in the annotation table with the same diagnosis id. Therefore,cephalea is a parent of the 4th degree of cluster headache. The parent concepts are retrieved with a function call from theterminology server that returns the taxonomy of a given concept. The tables are linked with the relation DiagnosisId ? IdSander and Wauer Journal of Biomedical Semantics            (2019) 10:7 Page 6 of 11queries from various publications to show whether andhow our approach was applicable and able to simplifythem. Finally, we examined the data with specific queriesand measured the results with respect to precision andrecall. For all statistical calculations, we used MedCalc®[29].Annotation accuracyThe annotation algorithm of the terminology servercould recognize abbreviations and had a spell checkfunction optimized for the German language and a mod-ule for disambiguation of semantic interpretations. Inparticular, the spell check function was urgently neededsince German allows the construction of so-called com-pound nouns and since many of these compound nounshad been shortened into their subwords and then recon-structed again. A typical example was the German termfor pregnancy advisory, which is Schwangerenbera-tung; this term was often written as Schw.brtg inmany variants.We did not set up a standardized procedure that in-cluded a manual annotation and an inter-annotatoragreement to calculate precision and recall for two rea-sons: I) we were mainly interested in whether the anno-tation was correct and not whether the annotation wasoptimal (focus on precision and not on recall) and II)the architecture is independent of the terminology serverand uses a standard interface for the integration. Thus,any CTS compliant terminology server can be easilyused.We manually analyzed the automated annotationfrom 10% (N = 187) of the cards, namely, the sectionthat contained the postmortem diagnoses. We found423 diagnoses, 304 of which were unique. Each anno-tation was classified as completely correct, partlycorrect or incorrect. The category partly correctcontained items that could not be mapped better dueto missing precoordinated concepts in the ontology,and thus, the expert partly disagreed with the inter-pretation (e.g., aspiration of infected amniotic fluidwas annotated as aspiration of amniotic fluid andinfection). The category incorrect contained allitems that were incorrect. In total, we found that 301of the 304 (99.0%) items were correctly mapped orcould not be mapped better. Twenty-three of theseitems were in the category partly correct and couldbe fixed by adding new (precoordinated) concepts tothe terminology. The remaining three wereincorrect.Furthermore, annotation quality was evaluated using asingle concept from the terminology, namely, the anat-omy concept tentorium. We analyzed all 1868 caseswith a total of 9080 postmortem descriptions and notedwhether the concept tentorium was present. We found50 different spellings in 77 cases. For all of these cases,we verified whether the mapping algorithm used thecorrect concept. From these comparisons, we found asensitivity of 97.62% (CI 95%: 91.6699.71%) and a spe-cificity of 100.00% (CI 95%: 98.87100.00%) for the auto-mated annotation.Published queriesWe analyzed published queries and examined whetherwe were able to express them in O-SQL and whetherthat expression was more compact and easier to createand understand. The following section demonstrates thatthese expectations held true for all examined samples.In Lieberman et al., the request for patients with cor-onary artery disease resulted in the following partial ex-pression [28]:concept_id in (select concept_id from snomed_mapwhere snmd_cncpt = 8957000 orsnmd_cncpt in (select snmd_cncpt1 fromsnmd_relationshipconnect by snmd_cncpt2 = priorsnmd_cncpt1 andrelationship_type = 116680003Table 2 Statistical results of semantic queries of different complexity (complexity is represented by number of query concepts). Allstatistics are calculated with MedCalc® [29]. Raw data can be found in Additional file 1: Table S2 in the addendumQuery Vitium cordis Respiration disorder Lethal malformationNumber of query concepts 1 5 16Sample size (Percentage of all cards) 1868 (100%) 467 (25%) 1868 (100%)Sensitivity 93.22% (CI 95%: 89.2296.08%) 97.76% (CI 95%: 95.7998.97%) 92.13% (CI 95%: 89.4894.29%)Specificity 99.94% (CI 95%: 99.66100.00%) 95.45% (CI 95%: 87.2999.05%) 96.30% (CI 95%: 95.1697.24%)Positive predictive value 99.55% (CI 95%: 96.8799.94%) 99.24% (CI 95%: 97.7599.75%) 90.57% (CI 95%: 87.7592.92%)Disease prevalence 12.57% (CI 95%: 11.1014.15%) 85.90% (CI 95%: 82.4188.92%) 27.80% (CI 95%: 25.7829.89%)F score 0.96 0.98 0.91Sander and Wauer Journal of Biomedical Semantics            (2019) 10:7 Page 7 of 11start with snmd_cncpt2 = 8957000 andrelationship_type = 116680003))Its complexity is basically derived from the need touse nested subqueries to represent relationships withinthe ontology. The IDs are from SNOMED CT:8957000 = Coronary artery disease(disorder)116680003 = Is a (attribute)This query can be represented in O-SQL by the fol-lowing compact expression using a common abbrevi-ation:[chd](diagnosis_column)The next sample shows that the complexity ofSPARQL can also be greatly reduced. In [30], the filtercriterion Find all patients having a side effect of Prandinafter administration is defined. Pathak et al. trans-formed this criterion into the following SPARQL query(abbreviated):SELECT DISTINCT ?MCLSS_KEY {{ SERVICE <http://www4.wiwiss.fu-ber-lin.de/sider/sparql>{ SELECT ?mySideEffect ?mySideEffec-tLabel WHERE {?x rdf:type sider:drugs ;rdfs:label "Prandin" ;sider:sideEffect ?mySideEffect .?mySideEffect rdfs:label ?mySideEffec-tLabel .}}}{ SELECT DISTINCT ?rxnormCode WHERE {SERVICE <http://link.informatics.-stonybrook.edu/sparql/> {?rxAUIUrl rxnorm:hasRXCUI ?rxCUIUrl ;rdfs:label ?rxnormLabel .?rxCUIUrl rxnorm:RXCUI ?rxnormCode .FILTER(regex(str(?rxnormLabel), "Pran-din", "i")) .}}}{ SELECT DISTINCT ?MCLSS_KEY WHERE {SERVICE <http://edison.mayo.edu/lss1p#> {?icd9Url semr:dx_code ?icd9Code ;semr:dx_abbrev_desc ?diagnosis .FILTER(regex(str(?diagnosis),str(?mySideEffectLabel), "i")) .?patientUrl semr:whkey ?MCLSS_KEY ;semr:diagnosis ?diagnosisCode ;semr:concept_id ?rxnormCode .FILTER(regex(str(?icd9Code),str(?diagnosisCode), "i")) .}}}}This query requires a deep understanding ofSPARQL and the structure of external knowledgebases. In addition, this query requires that local diag-noses are encoded in ICD-9, as the medication data-base uses this classification to structure informationon side effects.In contrast, the query can be drastically reduced to thefollowing form using our approach:select * from tableMed, tableDiag wheretableMed.CID = tableDiag.CID and+partOf[Prandin](tableMed.Drug) andhasContext{side effect}[repaglinide](tableDiag.Diag)The first partial expression searches the columnDrug in the table tableMed for all occurrences ofPrandin itself (note the +) and for all concepts con-taining Prandin. In doing so, the agents of Prandin arealso found, and possible generic drugs are included. Thesecond partial expression simply scans the ontology fora side effect of the agent and uses these results tosearch the column Diag in the table tableDiag. Here,it must be ensured that specifications are also found ineach case. Therefore, Prandin has hypoglycemia as aside effect and with the assistance of the ontology, thequery will also identify patients in which hyperinsulin-ism is recorded because hyperinsulinism is a form ofhypoglycemia.The last example was published by Leroux and Lefort,who queried anti-diabetic drugs, such as Metformin,therefore defining the following request (abbreviated) [31]:SELECT count (distinct ?subject) as?count ?mp_med WHERE {SERVICE <http://wifo5-04.informatik.u-ni-mannheim.de/drugbank/sparql>{?s drugbank:genericName "Metformin" .?s drugbank:drugCategory ?category .?drug drugbank:drugCategory ?category .}{ SELECT distinct ?drug ?med ?subject?mp_med WHERE {GRAPH <http://localhost/dataset/aibl/lcdc/clinical> {?obs a lcdcobs:Observation .?obs cm:medicinalProduct ?cm_mp .?cm_mp skos:exactMatch ?drug .Sander and Wauer Journal of Biomedical Semantics            (2019) 10:7 Page 8 of 11?cm_mp amt:synonym ?mp_med .?obs lcdccore:subject ?subject .}}}}Additionally, in this case, the query can be drasticallyreduced when using O-SQL:select * from tableMed wherehasContext{indication}:5[diabetes](Drug)The indications for all children are determined recur-sively from diabetes up to the specified depth of 5(semantic distance).Specific queriesWe used three typical neonatal complications to verifythe querying capabilities: (I) all of the of the index cardswere manually reviewed to see whether the patient had avitium cordis, (II) 25% of the index cards were manu-ally reviewed for the presence of a sign of respiratorydisorder, and (III) we used the yellow highlighting onthe index cards to carry out a full scope examination ofall 1868 index cards for lethal malformation. We thencreated corresponding O-SQL queries to look up thesegroups, compared the results and calculated standardstatistics (see Table 2).DiscussionWe developed an approach that enables free-text queriesstored in standard SQL-based RDBMS. Thus, we ex-tended standard SQL syntax and created an architecturethat allows us to integrate a terminology server intoexisting databases.The usefulness of historical data is becoming clearerdue to the tremendous progress in the development andavailability of medical terminologies and ontologies andin the field of NLP [32]. However, when comparing thespecific findings of queries in this work with the resultsof Epstein [17], it is striking that in certain areas, theontology first had to be extended to enable the use ofhistorical text. This extension was required for the rec-ognition or annotation of drugs, as trade names that areno longer in use had been employed.We overcame the disadvantage of Zhengs approach[18], which needed an already annotated database, by in-tegrating a terminology server into the analysis pipeline.In addition, the user is not required to have any know-ledge about how the terminology works since the dataannotation and free-text annotation of the query expres-sions use the same NLP-based terminology server.The annotation results outperformed the approachespresented by Allones et al. [5] and Shah et al. [7] andcompared very well to the ones presented by Topferet al. [6], who obtained slightly better results, and Elkinet al. [4], whose results were slightly inferior to ours.This comparison of final metrics shows that theemployed NLP pipeline and annotation algorithm deliverstate-of-the-art results and provide an objective evalu-ation of the query results. Since the results come from arelatively small set of data, they can only be generalisedif the terminology is complete and homogeneous, whichneeds to be validated. Maintaining terminology andontology was not a specific topic of our research, as weused a standardized terminology server that can providedifferent terminologies and is easily interchangeable.The slight loss of sensitivity when querying for heartdefects was traced back to 16 cases that were false nega-tives. The reasons for these false negatives wereunrecognized abbreviations, missing precoordinated ter-minology concepts, missing ontology links and in onecase, selection of an incorrect term-to-concept combin-ation by the annotation algorithm. However, the resultscompare very well to those of Pakhomov et al. [33].The imperfect specificity for respiration disorders canbe explained by misinterpreted cases of intrauterinehypoxia and the reduced sensitivity was mainly due tocases with a hyaline membrane that were not correctlyclassified.The decreased sensitivity in the cases of malformationwas mainly caused by the inconsistent gold standard. Theoriginal marking was performed under the assumption thatthe malformation ultimately led to death, since this malfor-mation influenced the original judgment of avoidability. Thissituation becomes particularly clear in the case of congenitaltumors. Systematic yellow marking in the case of teratomasshowed that these tumors had been generally recognized aslethal malformations, whereas some neuroblastomas werenot included in this category. The overall quality was still ex-cellent, as over 90% of the individuals were correctly classi-fied with this rather difficult medical definition.When comparing the complexity of SPARQL queriesto O-SQL queries, it became clear that a considerableadvantage was not only the ability to use free text butalso the commonly available knowledge of the SQL syn-tax. We assume that committed physicians with existingknowledge of SQL can be trained to use O-SQL withoutissue. In particular, clinicians calls for secondary usehave caused big software companies to open up their da-tabases to clients. The use of routine systems, however,bears certain limits, as the data must not be changed,and the stability of the database models is not providedper se. The first limit is completely circumvented by theframework presented here, as all annotations are storedin their own tables and the original tables remain un-touched. Changes in the database schema with respectto the data model can be represented quite easily byre-generating the annotations. Also, when evaluating thedifferences, it is important to note that SPARQL isSander and Wauer Journal of Biomedical Semantics            (2019) 10:7 Page 9 of 11designed to query RDF data and SQL is designed toquery relational data. Thus, the advantages of both lan-guages directly reflect the data models on which theywork [34].Physician training on the use of O-SQL expressionsmust be conducted in two steps: first, learning the ac-tual syntax, which was rather unproblematic, and sec-ond, learning how to use the mechanics of anontology. The latter could be addressed by providinga detailed demonstration with examples, which couldlater be adopted, of what an ontology is and how itcan be used. Without such a demonstration, physi-cians tend to use rather simple queries, which do notexploit the full power of the ontology.Conclusions and future workMany of the difficulties in using ontologies for the se-mantic analysis of free text that were described in theintroduction of this paper were overcome by the ap-proach presented here. The overall concept of integrat-ing an NLP-based terminology server into SQL syntaxhas been proven to be extremely viable.In particular, the high complexity and diversity ofthe German language were processed at a quality thatmeets the requirements of medicine. The terminologyserver used here is multilingual, so the O-SQL syntaxsimply had to be extended to specify the languageused. With this approach, it is now possible to com-pare databases on an international level, andcountry-specific annotations with only one uniformquery language, such as German or English, could beimplemented. A first application, in which neotalogicepicrises were analysed with regard to avoidable in-fant mortality, has already proved successful [35].The ontology-SQL syntax will be extended to allow fornested expressions. For this purpose, the extent to whichthese expressions are relevant and whether they cannotperhaps be represented by concatenated expressions willhave to be evaluated. One example would be a query forpatients showing symptoms of diseases that can betreated with specific agents.From a medical point of view, queries for rare diseasesshould be investigated. Here, selection will have to becarried out via O-SQL and will be followed by concretecase-by-case examinations.In addition, the ontologies themselves (especiallythe standard ontologies) will become increasingly ex-tensive as more and more omics data are repre-sented. Genetic information that was unknown at thetime of data collection can thus be considered inqueries using the approach presented here. Derivingquality factors from historic data is of growing inter-est because it enables a comparison of historicprocedures and treatments to the current medicalstate-of-the-art.The approach presented here is independent of aspecific ontology, on the contrary it allows access toany number of ontologies. However, also controlledvocabularies can be made applicable through this sys-tem. Therefore, physicians can access and exploredata with specially developed ontologies that go be-yond the spectrum of standard ontologies. Thisremoves one of the typical limitations of standard on-tologies, which cover a broad spectrum of knowledgebut usually have a limited depth. This should signifi-cantly increase the acceptance of the system. The factthat routine data from many sources  as long as itis stored in SQL based databases - can be immedi-ately used at an ontology-driven level without furthertransformation or integration demonstrates that thepresented work makes an important contribution totranslational research of routine data.Endnotes1Infant mortality rate (IMR) = the number of deaths ofchildren under 1 year of age per 1000 live birthsAdditional fileAdditional file 1: Addendum 1. Detailed description on the specificused terminology and ontology. Explaines some of the advancedfeatures possible. Addendum 2. Further details on O-SQL expressions,namely on the rewriting process. Also contains a structured documenta-tion of the parts of an O-SQL expression. (DOCX 57 kb)AbbreviationsCI: Confidence interval; CTS: Common terminology services; GMDS: DeutscheGesellschaft für Medizinische Informatik, Biometrie und Epidemiologie;ICD: International classification of diseases; NLP: Natural language processing;OCR: Optical character recognition; OLAP: Online analytical processing;OWL: Web Ontology Language; RDBMS: Relational database managementsystem; RDF: Resource Description Framework; SEP: Structure Entity Part;SPARQL: SPARQL Protocol and RDF Query Language; SQL: Structured QueryLanguageAcknowledgementsThe author thanks the Friedrich Wingert Foundation for its permission toapply the terminology and ontology used in this study. The author thanksthe company ID Information and Dokumentation im GesundheitswesenGmbH & Co KGaA for its permission to work with their product ID LOGIK®.The author is especially thankful to Prof. Rapoport for providing the originalindex cards.FundingNo funding. The author was allowed to use ID LOGIK®.Availability of data and materialsThe dataset analyzed in the current study is not publicly available due toobligations by the Department of Data Protection in Berlin/Germany but isavailable from the corresponding author upon reasonable request.Authors contributionsAS transcribed the index cards (and developed an application to supportthat process), developed the O-SQL syntax and implemented all parts of thesoftware for processing O-SQL queries (including the transformation intoSander and Wauer Journal of Biomedical Semantics            (2019) 10:7 Page 10 of 11standard SQL) and processing to RDBMS to enable O-SQL queries. AS alsoanalyzed the data for the medical examples (including the gold standard)and conducted all statistical measurements. RW reviewed the index cardtranscriptions, advised the medical examples and reviewed the gold stand-ard. Both authors read and approved the final manuscript.Ethics approval and consent to participateEthics approval is not required for historical data over 30 years old.Consent for publicationNot applicable.Competing interestsThe author works for the company ID Information und Dokumentation imGesundheitswesen GmbH & Co KGaA and has contributed to thedevelopment of the product ID LOGIK®.Publishers NoteSpringer Nature remains neutral with regard to jurisdictional claims inpublished maps and institutional affiliations.Author details1ID GmbH & Co. KGaA, Platz vor dem Neuen Tor 2, 10115 Berlin, Germany.2Klinik für Neonatologie, Charité-Universitätsmedizin Berlin, 10098 Berlin,Germany.Received: 23 July 2018 Accepted: 26 March 2019Arguello-Casteleiro et al. Journal of Biomedical Semantics 2019, 10(Suppl 1):22https://doi.org/10.1186/s13326-019-0212-6RESEARCH Open AccessExploring semantic deep learning forbuilding reliable and reusable one healthknowledge from PubMed systematicreviews and veterinary clinical notesMercedes Arguello-Casteleiro1*, Robert Stevens1, Julio Des-Diz2, Chris Wroe3, Maria Jesus Fernandez-Prieto4,Nava Maroto5, Diego Maseda-Fernandez6,7, George Demetriou1, Simon Peters8, Peter-John M. Noble9,Phil H. Jones9, Jo Dukes-McEwan10, Alan D. Radford9, John Keane1,11 and Goran Nenadic1,11,12From UK Healthcare Text Analysis Conference (HealTAC 2018)Manchester, UK. 18-19 April 2018AbstractBackground: Deep Learning opens up opportunities for routinely scanning large bodies of biomedical literatureand clinical narratives to represent the meaning of biomedical and clinical terms. However, the validation andintegration of this knowledge on a scale requires cross checking with ground truths (i.e. evidence-based resources)that are unavailable in an actionable or computable form. In this paper we explore how to turn information aboutdiagnoses, prognoses, therapies and other clinical concepts into computable knowledge using free-text data abouthuman and animal health. We used a Semantic Deep Learning approach that combines the Semantic Webtechnologies and Deep Learning to acquire and validate knowledge about 11 well-known medical conditionsmined from two sets of unstructured free-text data: 300 K PubMed Systematic Review articles (the PMSB dataset)and 2.5 M veterinary clinical notes (the VetCN dataset). For each target condition we obtained 20 related clinicalconcepts using two deep learning methods applied separately on the two datasets, resulting in 880 term pairs(target term, candidate term). Each concept, represented by an n-gram, is mapped to UMLS using MetaMap; wealso developed a bespoke method for mapping short forms (e.g. abbreviations and acronyms). Existing ontologieswere used to formally represent associations. We also create ontological modules and illustrate how the extractedknowledge can be queried. The evaluation was performed using the content within BMJ Best Practice.Results: MetaMap achieves an F measure of 88% (precision 85%, recall 91%) when applied directly to the total of613 unique candidate terms for the 880 term pairs. When the processing of short forms is included, MetaMapachieves an F measure of 94% (precision 92%, recall 96%). Validation of the term pairs with BMJ Best Practice yieldsprecision between 98 and 99%.Conclusions: The Semantic Deep Learning approach can transform neural embeddings built from unstructured free-text data into reliable and reusable One Health knowledge using ontologies and content from BMJ Best Practice.Keywords: Semantic deep learning, Ontology, Deep learning, CBOW, Skip-gram, One health, SNOMED CT, PubMed,Veterinary clinical narratives, Module extraction© The Author(s). 2019 Open Access This article is distributed under the terms of the Creative Commons Attribution 4.0International License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, andreproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link tothe Creative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver(http://creativecommons.org/publicdomain/zero/1.0/) applies to the data made available in this article, unless otherwise stated.* Correspondence: m.arguello@manchester.ac.uk1School of Computer Science, University of Manchester, Manchester, UKFull list of author information is available at the end of the articleArguello-Casteleiro et al. Journal of Biomedical Semantics 2019, 10(Suppl 1):22 Page 2 of 28BackgroundOne Health is an approach to achieve better publichealth outcomes by combining efforts from different dis-ciplines and domains [1]. It entails the recognition thatthe health of animals and the environment are essentialfor human health, and  specifically  that human medi-cine can benefit from veterinary medicine, as animalsdevelop many of the same diseases as humans do [2].Zoonotic infections and anti-microbial resistance are ex-amples that have received much of the attention re-cently. A recent study by Stroud et al. [3] compiledseveral examples of One Health cases where humanmedicine can benefit from veterinary studies. However,while both biomedical and clinical knowledge about hu-man and animal health are growing, they remain isolatedsilos. This paper investigates to what extent it is possibleto acquire One Health knowledge from the evidence-based biomedical literature and veterinary clinicalnarratives.We focus on using Semantic Deep Learning (Sem-Deep) [4, 5]  an emerging area combining the SemanticWeb resources and technologies and Deep Learning forthis task. Deep Learning is an area of machine learningthat applies neural networks to learn representations ofdata with multiple levels of abstraction [6]. The Seman-tic Web embodies standards and tools for publishingand processing meta-data, with ontologies at its core.This paper proposes the use of ontologies as a way ofspecifying the meaning of semantically related terms de-rived from neural language models obtained via DeepLearning. We explore how to turn information aboutdiagnoses, prognoses, therapies, as well as other clinical/healthcare entities into computable knowledge integrat-ing individual clinical expertise and best external evi-dence [7].There are two main challenges to achieving actionableor computable knowledge about human diseases orsyndromes:Multiple evidence-based resources  such as BMJ BestPractice [8], DynaMed Plus [9] or UptoDate [10]  areconsulted by clinicians on a daily basis to assist clinicaldecision making at point-of-care. Healthcare profes-sionals need to provide effective and safe patient care,and this also implies complying with Clinical PracticeGuidelines (CPGs) like those provided by the UK Na-tional Institute for Health and Care Excellence (NICE)[11]. CPGs tend to be evidence-based and have been de-fined as systematically developed statements to assistpractitioners and patient decisions about appropriatehealth care for specific circumstances [12]. Typically,evidence-based resources, such as the NICE CPGs orBMJ Best Practice, consist of human-readable text thatis updated periodically and is intended only for expert-to-expert communication. A fundamental obstacle forachieving interoperability between evidence-based re-sources is lack of grounding or normalisation [13],i.e. the fact that biomedical/clinical terms appearing inthe NICE CPGs or BMJ Best Practice are not mapped tospecific terminological entries like the Unified MedicalLanguage System (UMLS) [14] Metathesaurus. Normal-isation may help with periodic updates of evidence-based resources from the biomedical literature, asPubMed/MEDLINE articles are indexed with MedicalSubject Headings (MeSH) [15], which is included in theUMLS Metathesaurus. Unfortunately, annotating bio-medical articles with MeSH terms is difficult and expen-sive [16] and normalisation of evidence-based resourcesis not being carried out.World-leading terminologies, such as the SystematizedNomenclature of Medicine Clinical Terms (SNOMEDCT) [17], are included within the UMLS Metathesaurusand provide multiple terms for expressing a biomedicalconcept. However, SNOMED CT does not contain for-mal or semi-formal descriptions that help understandhow a disease develops and which treatment approachescan be considered. For example, medication statementsthat state which drugs treat a disease or syndrome arenot included in SNOMED CT. Hence, even automaticacquisition of a partial set of SNOMED CT conceptsrelevant for a disease or syndrome (e.g. medications/drugs and clinical findings) remains an unmet need.This paper investigates whether a SemDeep approachcan help address both challenges. On the one hand, theneural language models can be applied to PubMed Sys-tematic Reviews [17], which is a large collection ofevidence-based articles (e.g. clinical trials, systematic re-views, and CPGs) available in PubMed/MEDLINE. Vec-tor representations of the terms (word embeddings orneural embeddings) can be learnt from this unstruc-tured text corpus, where semantically related terms willend up close in the representational space. On the otherhand, if the terms that participate in the associations de-rived from these distributional similarities are normal-ised (i.e. terms with vector representations are mappedto UMLS Metathesaurus concepts and SNOMED CTconcepts), that would allow: a) the expansion of theknowledge that exists in SNOMED CT; and b) auto-matic derivation of SNOMED CT subsets of semantic-ally related concepts that can be reused and shared.In this paper we focus on 11 well-known medical con-ditions that affect both humans and animals: heart fail-ure, asthma, epilepsy, glaucoma, chronic kidney disease,osteoarthritis, anaemia, arthritis, diabetes mellitus,hypertension, and obesity. We adhere to comparative/translational medicine [18] and investigate the addedvalue of One Health by combining: a) the Systematic Re-views Subset of PubMed, and b) a large set of veterinaryclinical narratives collected by the Small AnimalArguello-Casteleiro et al. Journal of Biomedical Semantics 2019, 10(Suppl 1):22 Page 3 of 28Veterinary Surveillance Network (SAVSNET) [19]. Werely on existing ontologies (lemon (Lexicon Model forOntologies) [20] and OBAN (Open Biomedical Associa-tioNs) [21]) to formally represent associations (semantic-ally related term pairs) derived from neural embeddings.However, as Deep Learning algorithms have a black-box representation [22], their wider acceptance andadoption in the biomedical and clinical domain requiresconfidence and trust. To build such confidence (throughtransparency and interpretability), we use evidence-based resources (namely BMJ Best Practice) to verify ifthe associations (the semantic relatedness) captured byneural embeddings are reliable for human medicine. Wenote that clinicians consult multiple evidence-based re-sources, so BMJ Best Practice cannot be taken as theonly gold standard that provides ground-truth. However,in practical terms, when there is a lack of external evi-dence from systematic research about the meaningful as-sociation of two terms (e.g. a medical condition and atreatment), the term pair should be considered asunrelated.Related workNeural embeddings learnt from the biomedical litera-ture or clinical narrative corpora have been widelyused from many tasks, but they pose a challengewhen measuring their quality. On the one hand, thebiomedical/clinical domain requires backgroundknowledge that makes crowd-worker evaluation (e.g.users of Amazon Mechanical Turk) unsuitable. Onthe other hand, there are no similarity and related-ness benchmarks developed for well-known medicalconditions per se. Currently, there are four mainstandard benchmarks that are specific to the medical/clinical domain and suitable for a semantic similarityand relatedness task: Caviedes and Cimino [23] with10 medical term pairs; Pedersen et al. [24] with 30medical term pairs; Pakhomov et al. [25] with 101clinical term pairs; and Pakhomov et al. [26] with 724medical term pairs (the last two available at [27]). Intotal, these standard benchmarks provide less than 1K term pairs. It should be noted that similarity andrelatedness benchmarks were used to evaluate trad-itional distributional semantic models [28]  e.g. La-tent Semantic Analysis (LSA) [29] or Latent DirichletAllocation (LDA) [30]. Faruqui et al. [31] emphasisethat the lack of standard evaluation methods forneural embeddings was the trigger to create newbenchmark datasets (e.g. Simlex-999 [32] andSimVerb-3500 [33] that are outside of the biomedical/clinical domain) and highlight that the use of wordsimilarity tasks for evaluation of word vectors is notsustainable and calls for further research on evalu-ation methods.A common characteristic of biomedical/clinical docu-ments is that longer words and phrases are frequentlymapped onto a shorter form such as abbreviations or ac-ronyms for efficiency of communication [34]. For ex-ample, heart failure (long form) can appear as HF(short form). Another issue is that the number of abbre-viations and the average number of definitions per abbre-viation is ever growing [34]. For example, HF (shortform) can have multiple meanings, and therefore, referto multiple senses besides heart failure, such as His-panic female or high-fat or Hartree-Fock or hemo-filtration. Although short forms (abbreviations andacronyms) are present in UMLS, several studies [3537]have shown UMLS to have shortcomings when mappingshort forms to long forms. Sense inventories have beencreated such as SaRAD [38], ADAM [39], and more re-cently Allie [40]  in May 2018, Allie contained 840 K ofshort forms. These sense inventories and their algo-rithms assume that the short and long form co-occur inthe biomedical literature, such as MEDLINE/PubMedabstracts; however, they rarely co-occur in clinicalnarratives [41, 42]. Sense inventories from clinicaldocuments are fewer in number than sense inventor-ies from the biomedical literature and contain fewershort forms. Wu et al. [43] highlight that accurateidentification of clinical abbreviations is a challengingtask and advanced abbreviation recognition modulesare needed for existing clinical NLP systems. Dealingwith short forms is therefore a challenge that requiresan approach to deal with terms appearing in bothbiomedical and clinical documents.The paper is organised as follows. In the next section,we present a SemDeep approach that builds on our pre-vious work [4447]. We first introduce the datasets, andthen present the approach that deals with two NLPtasks: a semantic similarity and relatedness task, and anamed-entity recognition (NER) task. As part of theSemDeep pipeline, we show how to reuse existing ontol-ogies to formally represent the associations derived fromneural embeddings in OWL. We also create ontologicalmodules with the SNOMED CT ontology and illustratehow to query the extracted knowledge using theSPARQL query language [48], which exploit the under-lying ontological representations and can be executedusing Jena ARQ [49].Materials and methodsDataThe PubMed Systematic Reviews dataset (the PMSBdataset): we downloaded the MEDLINE/PubMed base-line files for 2015 and up-to-date files through 8th June2016. Applying the PubMed Systematic Reviews filter[17], a subset of 301,201 PubMed publications publishedbetween 2000 and 2016 was obtained. We extractedArguello-Casteleiro et al. Journal of Biomedical Semantics 2019, 10(Suppl 1):22 Page 4 of 28titles and available abstracts. We note that this datasetwas also used in our previous study on sepsis [46].The SAVSNET dataset (the VetCN dataset): a col-lection of 2,465,420 de-identified and non-empty vet-erinary clinical narratives was obtained fromSAVSNET on 20th October 2017. SAVSNET is aninitiative by the British Small Animal Veterinary As-sociation and the University of Liverpool that collectsfree-text consultations notes across around 500 UKveterinary premises in real-time.We used the UMLS Metathesaurus with close to 3.7M biomedical/clinical concepts with 203 sources con-tributing to concept names (as of May 2018), includingSNOMED CT and the Veterinary Extension forSNOMED CT (VetSCT) [50]. We used MetaMap 2016v2(released September 2016) and the SNOMED CT ver-sion released in January 2017 in OWL to maximise com-patibility among versions. When using the UMLSTerminology Services [14] to access the UMLS Metathe-saurus online, we select the UMLS2016AB version. Aswe cannot release a subset of the UMLS Metathesaurusor SNOMED CT, to replicate the results obtained withour method it is necessary to use the UMLS API [51]and the OWL API [52].SemDeep pipelineBelow we describe each step of the pipeline intended toacquire and validate knowledge about medical condi-tions from the unstructured text datasets.Step 1: computing n-grams from unstructured textWe employed word2phrase within the word2vec soft-ware package [53] to compute n-grams from the un-structured text datasets (e.g. PMSB or VetCN). Itshould be noted that text within consultation notes(e.g. today pain++) contains a significant number ofmisspellings, local abbreviations and short forms, andlacks the grammatical correctness found within bio-medical literature. After applying word2phrase, thecharacter _ appears within tokens that co-occur re-peatedly together (e.g. heart_failure is a bigram withtwo tokens). Each n-gram has a frequency count. Wenote that an n-gram captures words or tokens thatappear together in a textual corpus with a certain fre-quency. Therefore, an n-gram can capture words andphrases as well as combinations of tokens that maynot correspond exactly to meaningful unit whenlooked in isolation phrase, e.g. (COPD)_is_a.Step 2: creation of neural embeddingsWe create neural embeddings with CBOW (ContinuousBag-of-Words) and Skip-gram [54] using the word2vecsoftware. The input for CBOW and Skip-gram is the un-structured text with n-grams, where the character _typically denotes the presence of an n-gram of sizegreater than one (e.g. a bigram or a trigram). The outputfor CBOW and Skip-gram is typically: 1) a lexicon (i.e. alist of n-grams) that is present in the unstructured textand for which the vector representations have beenlearnt; and 2) a binary file that contains neural embed-dings, i.e. real-number representations for the terms inthe lexicon. When producing neural embeddings, thereare a small number of hyperparameters that need to betuned  we used the hyperparameters configuration de-scribed in our previous work [55].Step 3: obtaining term pairs for the semantic similarity andrelatedness taskTaking the vector for a specific target term (e.g. a diseaseor syndrome) and applying the cosine similarity, a list oftop ranked terms (highest cosine values) can be obtainedfrom the created neural embeddings. These top rankedterms are candidate terms, i.e. terms that need to bejudged as semantically similar or related to the targetterm. Some authors agree that semantic similarity rep-resents a special case of semantic relatedness [24]; Hillet al. [32] interpret relatedness as association, wherethe strongest similarity relation is synonymy; this inter-pretation is applied in this study.Target terms selection: to choose the target terms, wefirst select the n-grams that pass the threshold of 1 Kfrequency count and MetaMap has assigned themUMLS Metathesaurus concepts with the SemanticType T047|Disease or Syndrome. The final selectionof target terms needs to be done manually as: a)MetaMap may erroneously assign a UMLS Metathe-saurus concept to an n-gram, particularly if the n-gram is a short form such as HF; and b) the well-known medical conditions selected as target termsshould be covered by BMJ Best Practice  the pre-ferred gold standard in this study.Number of top ranked candidate terms per target term:to the best of our knowledge, no published study justifiesthe number of terms selected with the highest cosinevalue. Different studies used different numbers: fromthree [56], ten [57, 58], 40 [59] to a range of numbers(e.g. 5, 10, 20, 40, and 100) [60]. We limit the list of can-didate terms to the 20 n-grams with the highest cosinevalue.Step 4: named entity recognitionNamed Entity Recognition (NER) consists of identifyingspecific words or phrases (entities) and categorizingthem [61]. We use MetaMap to categorise the n-gramsinto one or more of 133 broad categories (SemanticTypes) from the UMLS Metathesaurus. To determine ifMetaMap supplies a correct CUI for an n-gram, detailedguidelines were developed that intend to favourArguello-Casteleiro et al. Journal of Biomedical Semantics 2019, 10(Suppl 1):22 Page 5 of 28compatibility with the SNOMED CT CompositionalGrammar [62]: Single Map (SM)  MetaMap provides a single CUIthat captures the full meaning of the n-gram. Thiscase corresponds to Simple Expression [62], i.e. asingle concept identifier. For example, the n-gramseptic_shock is mapped only to UMLS CUI =C0036983. Multiple Maps (MM)  MetaMap providesmultiple CUIs that capture the meaning of the n-gram, and one or more focus concepts may ap-pear among the CUIs provided. This case mayalso correspond to Simple Expression [62], al-though it more often corresponds to Expressionwith Refinements or Multiple Focus Concepts[62]. Selection of focus concept(s) is guided by sixprinciples described in the Additional file 2. Incorrectly Mapped (IM)  MetaMap provides oneor more CUIs, however, none captures the meaningof the n-gram. For example, the n-gram HF is notmapped to C0018801|Failure, Heart (Heartfailure). Not Mapped (NM)  MetaMap does not provideany CUI. For example, the n-gram HFpEF is notmapped to C3889077|Heart failure with preservedejection fraction.Three domain experts (two biomedical terminologistsand a medical consultant) inspected the results of Meta-Map considering the above-mentioned guidelines andassigned to each candidate term (n-gram) one of theabove values {SM, MM, IM, NM}. Beside the candidateterm (n-gram), we also provide the target terms (n-grams) in lower case to provide local context. When ann-gram is incorrectly mapped or not mapped, a CUI forthe n-gram is manually assigned. On the one hand, theguidelines presented aim to reduce the number of CUIsassigned to each n-gram. On the other hand, the n-grams are the result of statistical NLP and may containshort forms, and therefore, decomposing the n-gramsinto lexico-semantic units of meaning has proved de-manding in our previous work [4547] (even with yearsof experience doing clinical coding). Hence, the threedomain experts worked together to identify the minimalsemantic constituents of the n-grams according to theguidelines, i.e. determining systematically the focusconcept(s).Dealing with short formsWe created a short form detector to identify n-gramswith or without one or more clinically meaningful shortforms. The detector is based on a hybrid approach: itcontains if-then-else heuristic rules and utilises two listsof terms, i.e. a list of measurement units compiled fromthree resources [6365] and the rank frequency list ofthe British National Corpus of written and spoken Eng-lish [66] with 7726 words. The underlying assumption isthat a measurement unit can have one or more shortforms. For example, mmHg is a short form for thelong form millimetre of mercury.Figure 1 depicts a flowchart outlining how the shortform detector that assigns one of the following labels toan n-gram: SF-U when an n-gram contains a unit of measure-ment. The n-gram is mapped to the UMLSMetathesaurus concept C1519795|Unit ofMeasure. SF-NU when an n-gram contains a number with aunit of measurement. The n-gram is mapped to theUMLS Metathesaurus conceptC0242485|Measurement. SF when an n-gram contains a short form tokenthat is not a measurement unit or a measurementunit and a number. No label when an n-gram does not contain a shortform.For those n-grams with a short form that is not ameasurement unit or a measurement unit and a number,the domain experts manually utilised Allie as the pre-ferred sense inventory, for expanding short forms intolong forms. The reasons for using Allie are: a) it containsa much larger number of short forms than the UMLSSPECIALIST Lexicon; b) it has long forms for a shortform ranked based on appearance frequency inPubMed/MEDLINE abstracts; and c) for each long formthe research area and co-occurring abbreviations areprovided, thus aiding disambiguation.The short form detector can make two errors, and thedomain experts will assign the following labels to an n-gram: SF-I denotes that a short form identified in an n-gram was assessed as not clinically meaningful, i.e.incorrect. SF-NF denotes that a clinically meaningful shortform was not identified in an n-gram, i.e. notfound.Experiment set-up and performance measuresWe investigate the impact of the short forms on the per-formance of MetaMap via two experiments: Experiment 1 (EXP1): we expose the candidateterms directly to MetaMap, i.e. the lists with the 20top-ranked n-grams (i.e. the 20 n-grams with theFig. 1 Flowchart of the short form detector introduced  a diagrammatic representation outlining how the short form detector assigns the labels{SF-U, SF-NU, SF}. If no label is assigned, this means that the n-gram has no clinically meaningful short form(s)Arguello-Casteleiro et al. Journal of Biomedical Semantics 2019, 10(Suppl 1):22 Page 6 of 28highest cosine value) are taken as input forMetaMap. Experiment 2 (EXP2): we expose firstly thecandidate terms (n-grams) to the short formdetector described above, and for those n-gramswith one or more short forms, we expand eachshort form into the corresponding long form byutilising Allie. Once the short forms are replacedwith the long forms, we take the modified/ex-panded candidate terms (n-grams) as input forMetaMap.For both experiments, we assume that the candidateterms are biomedical or clinical terms, and thus, thereshould be no True Negatives (TNs). We use the con-ventional evaluation measures of Precision, Recall,and F measure [67] to calculate the MetaMap per-formance. As Pratt and Yetisgen-Yildiz [68], we haveweaker MetaMap precision and recall where exactmatches (typically Single Map) and partial matches(typically Multiple Maps) are equally counted, i.e. SMand MM are considered as True Positives (TPs). AnIncorrectly Mapped (IM) is interpreted as False Posi-tive (FP). A Not Mapped (NM) is interpreted as aFalse Negative (FN). Hence, we calculate precision asTP/(TP + FP) [67] and recall as TP/(TP + FN) [67]. Tocalculate F measure, we use equal weighting ofprecision and recall, calculating F measure as (2 xPrecision x Recall)/(Recall + Precision) [67]. We com-pute precision, recall, and F measure for each well-known medical condition under study (i.e. targetterm), and then, average each evaluation measure overall to obtain an overall measure of performance (a.k.a.macro-averaging) [67]. We also report micro-averaging, i.e. making a single contingency table forall data [67]  all lists of the 20 n-grams with highestcosine value that are the input to MetaMap.Following Smucker et al. [69], we measure statisticalsignificance of the difference in the mean averageprecision, recall, and F measure to judge if there is astatistically significant improvement in performancefor EXP2 (short form detection and expansion intolong form before applying MetaMap to the uniquecandidate terms) when compared with the perform-ance for EXP1 (applying MetaMap to the unique can-didate terms). We use the Students paired t-test [70]as implemented in scikit-learn [71] to compare per-formance of EXP1 and EXP2.All unique candidate terms (n-grams) are exposed to theshort form detector. We also compute precision, recall,and F measure for the short form detector considering allcandidate terms (micro-averaging) and the capability ofthe short form detector to identify n-grams with or with-out one or more clinically meaningful short forms.Arguello-Casteleiro et al. Journal of Biomedical Semantics 2019, 10(Suppl 1):22 Page 7 of 28Step 5: validation of the term pairs mapped to UMLSMetathesaurus concept pairs using BMJ best practiceThis step validates the candidate terms obtained in Step3 for the semantic similarity and relatedness task usingBMJ Best Practice, which covers prevention, diagnosis,treatment and prognosis for well-known medical condi-tions. It contains top down knowledge manually ex-tracted by medical experts and is based both on thelatest clinical practice guidelines and underlying researchevidence. Hence, BMJ Best Practice can be consideredan evidence-based gold standard, supporting frontlineclinicians.The validation involves four domain experts. The threeexperts from the previous step (two terminologists and amedical consultant) together validate the concept pairsconsidering BMJ Best Practice and external resources(whenever necessary). A health informatician  whoworks with the content of BMJ Best Practice  contrib-utes to the final stages of validation of the concept pairsand (additionally) provides feedback to the editors ofBMJ Best Practice. To avoid bias, the domain expertsvalidate the concept pairs without knowing: a) the data-set from which the concept pairs were derived; and b)the neural language models applied to the dataset. Toavoid further hints about the underlying dataset, the tar-get terms (n-grams) are presented in lower case.The outcome of this step is a set of 3-tuples (targetconcept, candidate concept, validation label). The targetand candidate concepts are UMLS Metathesaurus con-cepts representing the focus concept(s) of the n-gramsfor the term pairs (target term, candidate term). The val-idation label indicates how the matching between a can-didate concept and a term from BMJ Best Practice isperformed and reflects the amount of domain knowledgerequired to perform such a match. We distinguish sixcases when matching a candidate concept name fromthe UMLS Metathesaurus to a term appearing in BMJBest Practice:1. Itself  a candidate term may have as its focusconcept(s) the same UMLS Metathesaurus conceptas the target term (i.e. the well-known medical con-dition), and therefore, they will not be matched toterms appearing in BMJ Best Practice. This case de-notes synonymy (i.e. the strongest similarityrelation).2. Relatedness by exact/approximate match candidate concept names as they appear in theUMLS Metathesaurus may match exactly orapproximately terms appearing in BMJ BestPractice, where the biomedical/clinical meaning isthe same. This typically denotes a similarity relationbetween the candidate concept and the BMJ term.This case can be interpreted as normalising BMJBest Practice terms. For example, pyrexic(adjective) when used to refer to patients withpyrexia (noun) can be interpreted as pyrexia.From a linguistic point of view, pyrexic is amorphological variant of pyrexia, and thus, this isan example of an approximate match where thebiomedical/clinical meaning is the same. Someimplicit knowledge may be needed for this case.3. Relatedness by inexact match (hypernym/hyponym)or (hyponym/hypernym)  candidate concept namesas they appear in the UMLS Metathesaurus mayhave is-a relations with the terms appearing in BMJBest Practice or vice versa. An is-a relation is alsosimilar to a hypernym/hyponym relation or general-isation/specialisation relation and it denotes a simi-larity relationship. For example, bacterial sepsis is-a type of sepsis, where bacterial sepsis is thehyponym (specialisation) and sepsis is the hyper-nym (generalisation). Hypernym/hyponym relationscan be used to build semantic taxonomies (a.k.a.hierarchies). Some implicit knowledge may beneeded for this case.4. Relatedness by inexact match (backgroundknowledge)  candidate concept names as theyappear in the UMLS Metathesaurus may havesimilarity (similar meaning or is-a relations) or re-latedness (association) relations with the termsappearing in BMJ Best Practice, although the rela-tions are not obvious for someone lacking biomed-ical/clinical knowledge. To make the implicitknowledge explicit, one or more excerpts of exter-nal evidence from systematic research or termino-logical resources are provided. This case may applytransitivity, i.e. if A is related to B and B is relatedto C, then A is related to C. Therefore, by makingknown one or more terms (call them B) it is feasibleto make transparent how a UMLS Metathesaurusconcept A related to a term C appearing in BMJBest Practice. In other words, by making B known,and how A and C relate to B, implicit knowledgebecomes explicit.5. Unrelated: not clinically meaningful  An n-gramcan capture combinations of words or tokens thatcan be mapped to a focus UMLS Metathesaurusconcept(s), although it may not be interpreted perse as clinically meaningful in connection with agiven medical condition. For example, guided is aunigram for which alternative UMLS Metathe-saurus concepts are available to represent multiplemeanings or senses: C0181090|Guide (Professionalguide); C0302614|Guide (Guide device); andC1706050|Guide (Guide Device Component).However, for sepsis, any sense for the n-gramguided per se is not clinically meaningful.Fig. 2 Overview of the extended version of the lemon core ontology (called here the lemonEXT) used for this studyArguello-Casteleiro et al. Journal of Biomedical Semantics 2019, 10(Suppl 1):22 Page 8 of 286. Unrelated: excluded  candidate concept names asthey appear in the UMLS Metathesaurus may nothave up-to-date clinically meaningful association(relatedness) relations with the terms appearing inBMJ Best Practice, even if there is implicit know-ledge that can justify the association. A typical ex-ample of this case are treatments or therapies thatbecame known as ineffective or have adverse effects.For example: The only novel anti-sepsis agent tosuccessfully complete a phase 3 sepsis trial, humanrecombinant activated protein C, was recently takenoff the market after a follow up placebo-controlledtrial (PROWESS SHOCK) failed to replicate the re-sults of the initial registration trial (PROWESS) per-formed 10 yr earlier. [72]The process of assigning the six validation labels intro-duced above is iterative. A focus concept for a candidateterm and a term from BMJ Best Practice may have beenallocated the Relatedness by Inexact match (backgroundknowledge) label to indicate that one or more excerptsof external evidence from systematic research or ter-minological resources are needed to establish related-ness. However, a closer inspection of the implicitknowledge that has become explicit may change thelabel into: Relatedness by exact/approximate match, orRelatedness by Inexact match (hypernym/hyponym) or(hyponym/hypernym), or Unrelated: Excluded. Thecases under the Relatedness by Inexact match (back-ground knowledge) label may be further refined, for ex-ample, by considering the relationship between causeand effect.The six validation labels introduced can be used forcalculating precision by considering: a) the last two un-related labels representing False Positives (FPs); and b)the itself and the labels starting with Relatedness byrepresenting True Positives (TPs).Step 6: formal representation of the knowledge acquiredand validatedWe use OWL-DL to formally represent concept names,concept expressions, and terminological axioms. Figures2 and 3 overview the two core ontologies that will bepopulated, i.e. the extended lemon core ontology (calledhere the lemonEXT) [73] and the modified OBAN coreontology (called here the OBANmod) [74]. Both coreontologies reused the USTG (UMLS Semantic Typesand Groups) core ontology in OWL-DL that we createdprogrammatically and utilised in [45, 46]. The USTGcore ontology represents in OWL the information publi-cally available at [75].The USTG core ontology represents formally theUMLS Semantic Types and Groups as well as the part-whole relations among them by reusing the OWL objectproperties part_of (obo:BFO_0000050) and has_part(obo:BFO_0000051) from the Basic Formal Ontology(BFO) [76]. The USTG core ontology also contains theUMLS Metathesaurus concept, an OWL class we cre-ated that can have as a subclass any Metathesaurus con-cept from the UMLS. A new addition to the USTG coreontology is the OWL annotation property hasDbXre-fInSCT to create annotation assertion axioms that actas cross-reference between the UMLS Metathesaurusand SNOMED CT. The annotation property hasDbXre-fInSCT is a sub-annotation property of the annotationproperty database_cross_reference (oboInOwl:hasDbX-ref) from the oboInOwl meta-model [77]. The USTGcore ontology has a total of 593 axioms (class count:151; individual count: 0) and its Description Logic (DL)expressivity is ALEI.Table 1 shows the axiom patterns in ManchesterOWL Syntax [78] for populating programmatically themain OWL Classes of lemonEXT and OBANmod coreontologies. In this study, a pattern (a.k.a. axiom pattern)can represent a set of OWL axioms.Fig. 3 Overview of the modified version of the OBAN core ontology (called here the OBANmod) used for this studyArguello-Casteleiro et al. Journal of Biomedical Semantics 2019, 10(Suppl 1):22 Page 9 of 28The extended lemon core ontology (lemonEXT)In Fig. 2, the concept Lexical Topic represents the tar-get term (i.e. an n-gram corresponding to a given med-ical condition); the concept Lexicon represents thelexicon, i.e. a list of the 20 top-ranked terms (n-gramswith the highest cosine value for the target term) ob-tained with CBOW and Skip-gram; and the conceptLexical Entry represents an n-gram in the lexicon. Wereuse two concepts from MeSH: D064886|Data Setand D016571|Neural Networks (Computer). The latteris a MeSH heading that has the entry term Neural Net-work Models, which is the term that appears in Fig. 2.The two MeSH concepts are represented as OWL clas-ses and they are connected with the lemon conceptLexicon by reusing the OWL object property corre-lated with (obo:RO_0002610) from the Relations Ontol-ogy (RO) [79] .As depicted in Fig. 2, the concept Lexical entry fromlemon is connected to the UMLS Metathesaurus con-cept from the USTG core ontology with the OWL objectproperty denotes from the Ontology Lexicon (Ontolex)ontology [80]. We made the OWL Class Lexical sensefrom lemon a superclass of the OWL Class UMLS Se-mantic Type from the USTG core ontology. As one ormore UMLS Metathesaurus concept(s) is the focusconcept(s) for each n-gram, one or more UMLSMetathesaurus concept(s) from the UTSG ontology cap-tures the senses or meanings of a lexical entry. Takinginto account the UMLS Semantic Type(s) assigned toeach UMLS Metathesaurus concept, it is possible tocategorised the n-grams based on the OWL class de-scriptions within the USTG ontology  e.g.C0036983|Septic Shock is a subclass of T046|Patho-logic Function  and therefore, we follow the seman-tics by reference principle from [81] that says: theexpressivity and the granularity at which the meaning ofwords can be expressed depend on the meaning distinc-tions made in the ontology.The lemonEXT core ontology has a total of 643 ax-ioms (class count: 158; individual count: 0) and its DLexpressivity is ALEI. Once the lemonEXT is populated,it is possible to create SPARQL SELECT queries retriev-ing for each target term (i.e. n-gram) the candidate con-cepts, i.e. the UMLS Metathesaurus concepts that arethe focus concepts of candidate terms (n-grams). Webuilt three queries (see the Additional file 4 for details)that retrieve candidate concepts based on few UMLS Se-mantic Types and a UMLS Semantic Group. The UMLSSemantic Types and Group chosen intend to bring for-ward candidate concepts related to the diagnoses andTable1TheaxiompatternsinManchesterOWLSyntaxforpopulatingthemainclassesofthetwocoreontologies:theextendedlemoncoreontology(lemonEXT);andthemodifiedOBANcoreontology(OBAMmod).Eachaxiompatterninthesecondcolumncontainsvariables,whichcanbeeasilyidentifiedastheystartwiththecharacter?.ThethirdcolumnexemplifiesOWLindividualsthataretheresultofpopulatingtheaxiompatternsintroducedinthesecondcolumnBriefdescriptionofaxiompatternAxiompatterninManchesterOWLSyntaxExampleofpopulatingtheAxiompatterninManchesterOWLSyntaxIndividualoftheOWLclasslemon:LexicalTopicIndividual:?xAnnotations:label?lbx@enTypes:LexicaltopicIndividual:heart_failureAnnotations:labelheart_failure@enTypes:LexicaltopicIndividualoftheOWLclasslemon:LexicalEntryIndividual:?yAnnotations:label?lby@enTypes:LexicalentryFacts:denotes?CUIIndividual:beta-blockersAnnotations:labelbeta-blockers@enTypes:LexicalentryFacts:denotesAdrenergicbeta-AntagonistsIndividualoftheOWLclasslemon:LexiconIndividual:?zAnnotations:label?lbz@enTypes:LexiconFacts: correlatedwith?dataset,correlatedwith?model,entry?y1,entry?y20Individual:PMSB_CBOW_heart_failureAnnotations:labelPMSB_CBOW_heart_failure@enTypes:LexiconFacts:'correlatedwithPMSBdataset,'correlatedwithCBOW,entrybeta-blockers,entrycardiac_resynchronization_therapy_(CRT)IndividualoftheOWLclassoban:associationIndividual:?CpairAnnotations:rdfs:label?lbCpair@enTypes:associationFacts:oban:association_has_object?CUI1,oban:association_has_subject?CUI2Individual:(C0017601,C0020581)Annotations:label(C0017601,C0020581)@enTypes:associationFacts:'associationhasobjectHyphema,'associationhassubjectGlaucomaIndividualoftheOWLclassoban:provenanceIndividual:?ECpairAnnotations:rdfs:label?lbECpair@enTypes:provenanceFacts:'hassource?BMJdoc,'hasexcerpt?BMJterm,'hasevidence?lbEvidence,'hasexcerpt?EEexcerpt,'isabout?Cpair,'datecreationassociation?d1^^string,'sourcedateissued?d2^^stringIndividual:(C0017601,C0020581,Relatednessbyinexactmatch(backgroundknowledge))Annotations:label(C0017601,C0020581,Relatednessbyinexactmatch(backgroundknowledge))@enTypes:provenanceFacts:'hassourceBMJBestPractice:Open-angleglaucoma,'hasexcerpttrabeculotomy,'hasevidenceRelatednessbyinexactmatch(backgroundknowledge),'hasexcerptEEexcerpt_70,'isabout(C0017601,C0020581),'datecreationassociationMay-2018?^^string,'sourcedateissued09-Dec-2016?^^stringArguello-Casteleiro et al. Journal of Biomedical Semantics 2019, 10(Suppl 1):22 Page 10 of 28Arguello-Casteleiro et al. Journal of Biomedical Semantics 2019, 10(Suppl 1):22 Page 11 of 28management of a given medical condition (i.e. the targetterm): The UMLS Semantic Types T059|LaboratoryProcedure; T060|Diagnostic Procedure; andT061|Therapeutic or Preventive Procedure. Theseare the three subtypes of the UMLS Semantic TypeT058|Health Care Activity [82]. We call the queryq1 and it utilises these four UMLS Semantic Types. The UMLS Semantic Types T034|Laboratory orTest Result; and T184|Sign or Symptom. Theseare the two subtypes of the UMLS Semantic TypeT033|Finding [82]. We call the query q2 and itutilises these three UMLS Semantic Types. The UMLS Semantic Group Chemicals & Drugs(a.k.a. CHEM) that contains UMLS Semantic Typesthat are chemicals taking into account theirstructural and functional perspective [82]. Some ofthe UMLS Metathesaurus concepts belonging toCHEM are typically drug treatments (medications).We call the query q3 and it utilises the SemanticGroup CHEM.The modified version of the OBAN core ontology(OBANmod)An OBAN association relates biomedical entities (e.g. X,Y) without enforcing directionality on the link [21] (i.e.X is associated with Y or Y is associated with X) andseparating the association between entities from its prov-enance [21]. Although we can safely state that there is aclinically meaningful association for the term pair (heartfailure, pulmonary edema) it does not mean that all pa-tients with heart failure will also have pulmonaryedema. Instead, we should interpret the term pair (heartfailure, pulmonary edema) as a sometimes true associ-ation relationship [21] that can be represented in OWLas an OBAN association.Figure 3 presents a modified version of the OBANcore ontology for this study considering:1. The OBAN association is between two UMLSMetathesaurus concepts represented as OWLClasses as in [21], and we also use punning. Itshould be noted that OWL 2 DL relaxes theseparation between classes and individuals.2. The validations labels introduced in Step 5 arerepresented as OWL Classes that have as super-classes OWL Classes from the Evidence andConclusion Ontology (ECO) [83] (release of 2018-04-06). A total of five OWL Classes from ECO havebeen reused as well as the subclass axioms for themin the ECO.3. The provenance that validates the sometimes trueassociation relationship is BMJ Best Practice. Torepresent a document from BMJ Best Practice, wefirst reuse the OWL Class Document from theBibliographic Ontology Specification ontology(BIBO) [84], and then, create a new subclass withthe name BMJ Best Practice document. Therefore,BMJ Best Practice for chronic congestive heartfailure [85] will be an OWL instance of the OWLClass BMJ Best Practice document.4. Excerpts from biomedical or clinical resources areneeded for this study, such as: 1) the term(s)appearing in BMJ Practice that are key whenvalidating the concept pairs; or 2) additionalinformation that make the implicit knowledgeexplicit, such as excerpts from the scientificliterature (e.g. PubMed articles or MedlinePlus [86]Webpages) or from terminologies like SNOMEDCT [62]. To represent an excerpt, we reuse theOWL Class Excerpt from the BIBO. In the BIBO,an Excerpt is part of a Document. We create theannotation property excerpt_text to store termsfrom BMJ Best Practice or lines of text that areconsidered pertinent when making the implicitknowledge explicit. Therefore, in this study, everyOBAN association will have at least one instance ofthe OWL Class Excerpt, i.e. BMJ term(s) that arekey to validate the focus concept pairs for the termpairs.5. The replacement and modification of OWL dataproperties from OBAN to better fit the currentstudy: a) the OWL data propertydate_creation_association where we store themonth and year when the association was validated;b) the OWL data property source_date_issuedwhere we store the last update of BMJ Best Practicedocument used to validate the association; and c)relax the xsd:dateTime declarations from OBAN assometimes it proves difficult to trace thepublication date for a PubMed paper or the releaseday for a terminological resource.The OBANmod core ontology has a total of 779 axioms(class count: 181; individual count: 6) and its DL expres-sivity is ALEHI (D). Once the OBANmod is populated, itis possible to refine the SPARQL queries q1 to q3 intoq1V to q3V (see the Additional file 4 for details), wherethe candidate concepts (i.e. UMLS Metathesaurus con-cepts that are the focus concepts for the candidate terms)should have an up-to-date clinically meaningful associ-ation to the target concepts (the selected diseases or syn-dromes) according to BMJ Best Practice (i.e. humanmedicine), and thus, the UMLS Metathesaurus conceptpairs should have the validation labels introduced in Step5 starting with Relatedness by or the validation labelItself.Arguello-Casteleiro et al. Journal of Biomedical Semantics 2019, 10(Suppl 1):22 Page 12 of 28Extracting locality-based modulesOur aim is the extraction of locality-based modules fromthe SNOMED CT ontology that are: 1) much smaller insize (i.e. number of axioms) than the SNOMED CTontology; 2) as specific as possible for a given medicalcondition while being logically sound according toOWL-DL; and 3) can be reused and shared amongorganisations.We extract a locality-based module (a.k.a. upper mod-ule) [87] per target term using as signature all theSNOMED CT concept identifiers mapped to UMLS CUIpairs validated with BMJ Best Practice content. We usethe reasoner FaCT++ [88] for the method ModuleTypeBOT in the OWL API [52] as we did in [47]. A DL rea-soner, like FaCT++, can calculate inferred information(e.g. inferred subsumption hierarchy) from the assertedinformation, i.e. the axioms within an ontology. Alocality-based module contains at least all the (entailed)super-classes of an OWL class included in the signature[87] as well as all axioms relevant to the meaning of theOWL Classes in the signature. A SNOMED CT conceptmay have one or more attribute-value pairs [62], wherethe value of the pair is typically another SNOMED CTconcept. Attribute-value pairs are considered relevant tothe meaning of a SNOMED CT concept.A locality-based module keeps the SNOMED CT top-level hierarchies for the OWL Class extracted, which isexpected by the clinicians, and is likely to be smallerthan the SNOMED CT ontology. The SNOMED CTontology corresponding to the January 2017 release con-tains a total of 1.5 M axioms (Class count: 325 K; indi-vidual count: 0; Object property count: 80; SubClassOfaxioms count: 246 K; and EquivalentClasses axiomscount: 79 K) and its DL expressivity is ALER.Multiple SPARQL queries can be built seeking togain insights into diseases and syndromes of signifi-cance for both human medical and veterinary health-care, i.e. One Health knowledge. For this study, theSPARQL SELECT queries q1V to q3V presented inStep 6 intend to retrieve reliable knowledge for hu-man medicine (UMLS CUI pairs validated with BMJBest Practice content) about the diagnosis and man-agement of well-known medical conditions that affecthumans and animals. We created the SPARQL SE-LECT queries q1VU to q3VU (see the Additional file4 for details) that combine the results of the queriesq1V to q3V over each dataset VetCN and PMSB.Hence, we report the number of UMLS Metathe-saurus concepts pairs with up-to-date clinically mean-ingful associations for human medicine, although thesource data can be from veterinary medicine (i.e. theSAVSNET veterinary clinical narratives) or from hu-man medical science (i.e. the PubMed SystematicReviews).The results of the queries q1VU to q3VU as well asthe results of the queries q1V to q3V are quantitative.Hence, we can quantify to what extent One Health canprovide added value when compared with a conventionalapproach that will keep both datasets VetCN and PMSBseparated for being part of either veterinary medicine ormedical science.A UMLS Metathesaurus concept can be mapped tonone, one or more than one SNOMED CT concepts.We created the SPARQL SELECT query q1VM toq3VM (see the Additional file 4 for details) to retrievefrom the OBANmod those UMLS CUI pairs validatedwith BMJ Best Practice content, where the candidateconcept is mapped to at least one SNOMED CT con-cept. Using the OBANmod and the asserted informationwithin each locality-based module as the default graph,we created the SPARQL SELECT query q1VS to q1VS(see the Additional file 4 for details) that retrieves thoseSNOMED CT concept pairs (OWL Classes) mapped toUMLS CUI pairs validated with BMJ Best Practice con-tent. For these SNOMED CT pairs, it is possible to gobeyond the knowledge captured in the OBAN some-times true association relationships.Each locality-based module created for a well-knownmedical condition contains asserted as well as inferredknowledge that can expand/enrich the results from thequeries q1VS to q3VS by exploiting the transitive clos-ure of rdfs:subClassOf for the SNOMED CT concepts inOWL. The SPARQL SELECT queries q1VR to q3VR(see the Additional file 4 for details) use as the defaultgraph the inferred model obtained with the DL reasonerFaCT++ for each locality-based module. The queriesq1VR to q3VR retrieve the OWL Classes that areasserted and inferred descendants of the thoseSNOMED CT concepts that are mapped to candidateconcepts of the SNOMED CT pairs retrieved from theSPARQL SELECT queries q1VS to q3VS.ResultsWe start by illustrating and reporting the results ob-tained for each step of the SemDeep pipeline using thePMSB and VetCN datasets. Next, we combine the re-sults from the SemDeep pipeline to investigate to whatextent the One Health approach can provide addedvalue.A SemDeep pipelineStep 1: computing n-grams from unstructured textAs in our previous work [4447], we employ word2-phrase to obtain n-grams and we preserve numbers andpunctuation marks including parenthesis as they appearin the unstructured text. However, the original text ofthe PMSB dataset is not converted to lower case as in[4447]. The PMSB dataset contains 447M termsArguello-Casteleiro et al. Journal of Biomedical Semantics 2019, 10(Suppl 1):22 Page 13 of 28(words and tokens as they appear in the text), and afterobtaining the n-grams, this number reduces significantlyto 46M. This means that a high number of tokens/words appear to be repeatedly collocated.The original text of the VetCN dataset was converted tolower case before computing n-grams as many exampleswere found within the unstructured text of indiscriminatealternation between lowercase and uppercase. The VetCNdataset contains 149M terms (words and tokens as theyappear in the text), and after obtaining the n-grams, thisreduces to 103M. A plausible reason for the modest nu-meric reduction is presence of spelling variations and/orerrors for the same term. To confirm this hypothesis, weutilise a probabilistic spelling corrector [89] that providesalternative spellings for a word or token appearing withina corpus; the hypothesis was confirmed. For example, theterm vomiting appears in VetCN with more than 50spelling variations such as vomiteting or vomittimngor vomirtting or vomikting (to mention just a few),which can be considered spelling errors. Furthermore, byclose inspection of the unstructured text, it can be ob-served that short forms like v are used instead of thelong form vomiting.Step 2: creation of neural embeddingsWe use the word2vec implementations for CBOW andSkip-gram and apply the same hyperparameter configur-ation as our previous study [55]. To compute the neuralembeddings, we use a Dell PowerEdge R430 with 100GBRAM and 32 virtual CPUs Intel Xeon E52690 v4 at 2.6GHz. With this, creating the neural embeddings withTable 2 The target terms for PMSB and VetCN datasetsTarget terms for this study and their concept identifiers in UMLS and SNOMEUMLS CUI SNOMED CT identifier VetCN datasetn-gram (frequency count)C0018801 84,114,007 heart_failure (1292)C0004096 195,967,001 asthma (1194)C0014544 84,757,009 epilepsy (1164)C0017601 23,986,001 glaucoma (1657)C1561643 709,044,004 ckd (2698)C0029408 396,275,006 osteoarthritis (1765)C0002871 271,737,000 anaemia (1414)C0003864 3,723,001 arthritis (8276)C0011849 73,211,009 diabetes (3660)C0020538 38,341,003 hypertension (1132)C0028754 414,916,001 obesity (1763)SOFTWARE Open AccessSeeing the whole picture: integrated pre-surgery reports with PreOptiqueGuillermo Vega-Gorgojo1,2, Laura Slaughter1 and Martin Giese1*AbstractBackground: Information technology has transformed the way healthcare is conducted. There is a deluge of patientdata dispersed in different systems that are commonly not interoperable. As a result, access to patient data has becomea major bottleneck for healthcare professionals that struggle to find the relevant information in a timely way and withoutmissing critical clinical information.Results: We implemented PreOptique, a novel hybrid semantic and text-based system that was commissioned by alarge hospital in Norway for providing integrated access to patient health records scattered over several databases anddocument repositories.We use ontology-based data access (OBDA) for the seamless integration of the structured databases at the hospitalthrough the Optique platform. We employ text analysis techniques to extract vital sign measures and clinical findingsfrom patient documents.PreOptique was developed and deployed at the hospital. This solution demonstrates how OBDA technology canprovide integrated data access to disparate structured sources in healthcare, without requiring the replacementof existing databases. Unstructured clinical texts are also mined to extract patient findings, while the graphicaluser interface (GUI) provides a single access point that hides the underlying complexity of the system. We ran ausability study with 5 target users, obtaining a system usability score (SUS) of 86.0. Further, participants in the studystressed the simplicity of the GUI and the integration of data sources enabled by the system.Conclusions: This pilot study showcases the use of OBDA technology and text analysis to enable the integration ofpatient data for supporting clinical surgery operations. PreOptique is usable and can be easily employed by medicalpersonnel to find patient data in a timely way.Keywords: Electronic health records, Systems integration, Biological ontologies, Ontology-based data access, Text analysisBackgroundMedical practice generates a deluge of patient data,including diagnostic codes, medication orders, labora-tory test results, and medical imaging. Typically, severalvendors supply systems to document and collect datarelated to patient care. Medical professionals use thesesystems for care planning and documentation purposesrelated to patient encounters with the healthcare system.When a patient is referred to a unit, the physician mayorder tests and imaging prior to seeing a patient. Health-care professionals often use the system to access pre-viously recorded clinical notes that can provide relevantbackground including diagnosis and even status regardingprevious health-related assessments such as whether thepatient has had a drivers license revoked for medicalreasons. Tracking all the data and relating it to thepatients current status involves accessing the right system,evaluating the data that is there, checking date/time ofdocumentation, assessing whether this is the same ordifferent incident of a certain condition, and also con-textual information like the type of medical encounter,e.g. a routine examination, or even the role of the reporter.Despite the wealth of patient data and the omnipre-sence of healthcare systems, use of these systems doesnot necessarily equate to an increase of efficiency orimprovements in quality of care [1]. One key issue is thelack of information exchange between systems whichresults in healthcare professionals using a great deal oftime jumping between multiple different information* Correspondence: martingi@ifi.uio.no1Department of Informatics, University of Oslo, Oslo, NorwayFull list of author information is available at the end of the article© The Author(s). 2019 Open Access This article is distributed under the terms of the Creative Commons Attribution 4.0International License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, andreproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link tothe Creative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver(http://creativecommons.org/publicdomain/zero/1.0/) applies to the data made available in this article, unless otherwise stated.Vega-Gorgojo et al. Journal of Biomedical Semantics            (2019) 10:5 https://doi.org/10.1186/s13326-019-0197-1technology (IT) systems in an attempt to tie togetherpatient information. In this regard, [2] reports physiciansfrustration and professional dissatisfaction with electronichealth record (EHR) systems due to insufficient healthinformation exchange.The interoperability of hospital IT systems is impactedby the many underlying policies, organizational con-straints and culture, and understanding of hospital work-flow reflected in the architecture and design of eachsystem in use. To address this challenge, ontology-baseddata access (OBDA) technology can be used to seamlesslyintegrate structured data and information from thesesystems [3]. The role of an ontology is to define the princi-ples ruling real-world entities and their interrelations,describing a domains inherent structure and behavior [4].Semantic data integration involves the use of such a repre-sentation of entities and relationships to eliminate possibleheterogeneities. The Optique project [5] has developed anumber of tools and methods to support OBDA, inclu-ding tools for enabling users to formulate queries usingfamiliar vocabularies and conceptualizations, and inte-grating data spread across multiple distributed data sources.Ahus case studyAccess to patient data is the chief complaint of thehealthcare personnel at the day surgery unit in AkershusUniversity Hospital (Ahus). Medical staff described anenvironment where they were allocated 20 min to checkall patient information before surgery, but they wereactually investing much longer times to prevent missingrelevant information. We reproduce here some of theirquotes:«We use too much time to search for information»«We are not sure that we have checked all»«We should rather spend the time on patients than onthe computer systems»The underlying problem is that patient data is scat-tered across different hospital IT systems, i.e. the registryof medical encounters, the archive of clinical notes, therepository of patient measures, the registry of laboratorytests, and the pharmacy system. Furthermore, some ofthese systems lack the necessary functionalities to facili-tate data access. As an example, Ahus staff can browsethe clinical notes of a particular patient, but text searchis not provided.In this paper we present a novel hybrid semantic andtext-based system that was commissioned by Ahus forproviding integrated access to patient health recordsscattered in several databases and document reposito-ries. The system makes use of the results from theOptique project and is based on reuse and extension ofthe OBDA tools available. The test case was the surgeryplanning process that involves surgeons, anesthesiolo-gists, and nurses. The proposed system is named PreOp-tique (Pre-Op support with Optique). We showcase thebenefits of this solution and present the results of apreliminary usability study.ImplementationAhus requirementsAhus provides healthcare services to approximately500,000 inhabitants in the county of Akershus, east ofOslo, Norway. Ahus is a mid-size/large hospital with 953beds, 62,489 admitted patients, and 28,300 day patientsregistered in 2015. Patient data at Ahus is scatteredacross several systems  the main information systemsemployed by the day surgery unit are shown in Table 1.However, these systems are not integrated and access topatient data is not easy; for instance, there is no searchfacility for the DIPS document archive (DIPS stands forDistributed Information and Patient Data System inHospital). As a result, medical professionals at Ahuscomplain about too much time spent searching patientinformation, and they fear missing critical informationrelated to surgical preparation.We started a pilot project with the day surgery unit atAhus aiming to improve the access to existing patientinformation. More specifically, Ahus requested supportfor the surgery planning process in which surgeons,anesthesiologists, and nurses collaboratively fill in apaper form with the operation plan. In a first stage, sur-geon and patient agree on the surgery to be performed.Resources are then allocated and the preparations forthe operation begin. There is a patient safety procedurebefore and after the operation to assess that theoperation plan has been followed.To complete the form, patient data has to be collectedmanually from the systems in Table 1, requiring asignificant effort to find patient information and withconcerns about missing critical pieces of information forTable 1 Main information systems employed by the day surgery unit at AhusSystem Provider Type Data descriptionDIPS DIPS Electronic health record system SQL database with administrative data, medical encounters and patient measuresMetavision Evry Physician order entry system SQL database with administrative data and patient measuresDocument archive of laboratory tests and medical imagesDIPS archive DIPS Document repository Document archive of unstructured clinical notesVega-Gorgojo et al. Journal of Biomedical Semantics            (2019) 10:5 Page 2 of 15the planned operation, e.g. an allergy. Therefore, the goalof the project was to provide an IT solution for suppor-ting the surgery planning process with the followingrequirements: Integrate patient data coming from structuredsources, i.e. the SQL databases of DIPS andMetavision. Perform text analysis of the DIPS document archiveand provide access for the operation planning. Offer a single easy-to-use access point to patient data. Provide provenance information for every piece ofpatient data. Design a non-invasive solution, i.e. no replacementof the existing IT systems at Ahus. Provide adaptation to emerging user needs and newdata sources such as the laboratory tests and medicalimages in Metavision that were not part of this pilot.The Optique platformOptique is a solution for unlocking access to corporatedata sources by enabling end users to formulate theirinformation needs through an intuitive visual queryinterface [5]. The platform is based on OBDA techno-logy [3] that provides an automated connection betweencomplex information requirements and relational datastores. More specifically, an ontology is employed todescribe the end users domain with familiar and com-prehensible terms that are translated into queries overthe data sources through a set of mappings.Optique provides access to data in a non-invasive way,since the data sources do not need to be replaced orconverted to another format. Instead, the platformmanages the ontology and mappings, giving the illusionof a virtual integrated semantic store. In this way, aquery formulation component such as OptiqueVQS [6]or PepeSearch [7] can directly plug in, enabling endusers to pose ad hoc queries without requiring special-ized IT skills.Optique relies on open standards such as SPARQL [8] forquerying the virtual triple store, OWL [9] for ontology spe-cification, and R2RML [10] for the definition of mappings.Open standards avoid vendor lock-in situations andfacilitate adaptation to diverse scenarios. For instance,Optique has been successfully deployed on Statoilscorporate exploration and production data store [11],as well as on Siemens service centers for monitoringpower plants [12, 13].Text analysisWhile the Optique platform can be used to provideflexible access to structured data sources, it cannot bedirectly used with unstructured data. Instead, naturallanguage processing (NLP) can be applied to analyzeclinical text, the most common and abundant data typein the healthcare domain.Text search engines [14] have become prevalent fordealing with unstructured data, e.g. Web search. Searchengines maintain an index of the document corpus.Queries are evaluated against the index and results arethen returned to the user. A query is typically composedof one or more keywords, although explicit phrases canalso be supported. Potential answers are ranked using asimilarity measure to estimate the relevance of a docu-ment for a query. The index is a data structure thatmaps terms to the documents that contain them, thusenabling fast query evaluation. Several parsing tech-niques are commonly applied in the construction of theindex and in query evaluation, such as stemming(removal of variant endings from words), case folding(conversion to lowercase), or stopping (removal of commonwords such as the).Besides regular text search, clinical documents can bemined to extract structured information about patients.This is typically done using NLP tools, which combine arange of linguistic, statistical and heuristic methods [15].Deriving structured information from clinical textinvolves entity extraction algorithms that commonlyemploy medical vocabularies and ontologies such asSNOMED CT [16] to drive the entity extraction task.Difficulties in entity extraction include the presence ofnegating terms such as no or never [15]. cTAKES [17]is an example of an NLP tool for entity extraction fromclinical text.PreOptique, integrated access to patient dataWe aimed to support the surgery planning process byoffering a single easy-to-use access point to patient datawithout replacing the existing IT systems at Ahus. Inorder to comply with the requirements, we developed ahybrid semantic and text-based system named Pre-Optique. The logical architecture is sketched in Fig. 1and has three main parts: the semantic backbone (tealcolor), the text search engine (pink), and the graphicaluser interface (GUI) that glues all the components andserves as entry point to the medical personnel (blue).The semantic backbone is based on the Optique plat-form and deals with the integration of patient datacoming from structured sources. The key artefact is theontology that was developed to support this setting. Thedevelopment of the ontology was thus driven by thedatabase schemata of the structured sources employedat Ahus, i.e. DIPS and Metavision. We also used ano-nymized screenshots of the DIPS user interface toinform the design. In addition, we interviewed membersof the medical staff at Ahus in order to gather the mainlimitations of the existing solution (see the reproducedVega-Gorgojo et al. Journal of Biomedical Semantics            (2019) 10:5 Page 3 of 15quotes in Section 1.1). With these inputs, we identifiedthat the main components the ontology should include:administrative patient data, medical diagnoses anddiseases, healthcare encounters, data items such asdocuments, and measurements of vital signs.For constructing the ontology we decided to reuseexisting medical ontologies in the OBO Foundry suite[18]. OBO Foundrys Basic Formal Ontology (BFO) [19]is an upper-level ontology that provides a commontop-level structure to support the interoperability of themultiple domain ontologies. BFO forms the basis ofnumerous medical ontologies such as the NCBI organis-mal classification (NCBItaxon), Ontology of MedicallyRelated Social Entities (OMRSE), Disease Ontology (DO),Ontology for General Medical Science (OGMS), ClinicalMeasurement Ontology (CMO), and the InformationArtifact Ontology (IAO), or Relation Ontology (RO)  wereused classes from all these OFO Foundry ontologies.The starting point was the definition of patient as a sub-class of human being (NCBItaxon) that has a patient role(OMRSE). We borrowed properties from the FOAF vo-cabulary [20] to model basic patient data such as names,gender or image, while we defined local properties to rep-resent the Norwegian social security number and the dateof birth. We were therefore able to describe all the admin-istrative patient data coming from DIPS and Metavision.In Norway, medical diagnoses in the source DIPS EHRdataset are tagged using version 10 of the standardInternational Statistical Classification of Diseases andRelated Health Problems diagnostic coding schema(ICD-10) [21]. DO is a domain ontology of humandiseases based on BFO and organized from a clinicalperspective of disease etiology and location [22]. DO isthus more closely aligned with how medical personnelwork and think than ICD-10, so we decided to employthis ontology using disease from OGMS as the top con-Holderness et al. Journal of Biomedical Semantics           (2019) 10:19 https://doi.org/10.1186/s13326-019-0210-8RESEARCH Open AccessAnalysis of risk factor domains inpsychosis patient health recordsEben Holderness1,1, Nicholas Miller1, Philip Cawkwell1, Kirsten Bolton1, Marie Meteer2, James Pustejovsky2and Mei-Hua Hall1*AbstractBackground: Readmission after discharge from a hospital is disruptive and costly, regardless of the reason. However,it can be particularly problematic for psychiatric patients, so predicting which patients may be readmitted is criticallyimportant but also very difficult. Clinical narratives in psychiatric electronic health records (EHRs) span a wide range oftopics and vocabulary; therefore, a psychiatric readmission prediction model must begin with a robust andinterpretable topic extraction component.Results: We designed and evaluated multiple multilayer perceptron and radial basis function neural networks topredict the sentences in a patients EHR that are associated with one or more of seven readmission risk factor domainsthat we identified. In contrast to our baseline cosine similarity model that is based on the methodologies of priorworks, our deep learning approaches achieved considerably better F1 scores (0.83 vs 0.66) while also being morescalable and computationally efficient with large volumes of data. Additionally, we found that integrating clinicallyrelevant multiword expressions during preprocessing improves the accuracy of our models and allows for identifyinga wider scope of training data in a semi-supervised setting.Conclusion: We created a data pipeline for using document vector similarity metrics to perform topic extraction onpsychiatric EHR data in service of our long-term goal of creating a readmission risk classifier. We show results for ourtopic extraction model and identify additional features we will be incorporating in the future.Keywords: Natural language processing, Risk prediction, Machine learning, Electronic health record, PsychoticdisordersBackgroundPsychotic disorders typically emerge in late adolescenceor early adulthood [1, 2] and affect approximately 2.5-4% of the population [3, 4], making them one of theleading causes of disability worldwide [5]. A substantialproportion of psychiatric inpatients are readmitted afterdischarge [6]. Readmissions are disruptive for patientsand families, and are a key driver of rising healthcarecosts [7, 8]. Reducing readmission risk is therefore amajor unmet need of psychiatric care. Developing clin-ically implementable machine learning tools to enableaccurate assessment of risk factors associated with read-mission offers opportunities to inform the selection of*Correspondence: mhall@mclean.harvard.edu1Psychosis Neurobiology Laboratory, McLean Hospital, Harvard MedicalSchool, Mill St, Belmont, MA, USAFull list of author information is available at the end of the articletreatment interventions and implement appropriate pre-ventive measures.In psychiatry, traditional strategies to study readmissionrisk factors rely on clinical observation and manual ret-rospective chart review [9, 10]. This approach, althoughbenefitting from clinical expertise, does not scale wellfor large data sets, is effort-intensive, and lacks automa-tion. An efficient, more robust, and cheaper alternativeapproach based on Natural Language Processing (NLP)has been developed and met with some success in othermedical fields [11]. However, this approach has seldombeen applied in psychiatry because of the unique charac-teristics of psychiatric medical record content.There are several challenges for topic extraction whendealing with clinical narratives in psychiatric EHRs. First,the vocabulary used is highly varied and context-sensitive.A patient may report feeling really great and excited symptoms of mania  without any explicit mention© The Author(s). 2019 Open Access This article is distributed under the terms of the Creative Commons Attribution 4.0International License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, andreproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to theCreative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver(http://creativecommons.org/publicdomain/zero/1.0/) applies to the data made available in this article, unless otherwise stated.Holderness et al. Journal of Biomedical Semantics           (2019) 10:19 Page 2 of 10of keywords that differ from everyday vocabulary. Also,many technical terms in clinical narratives are multiwordexpressions (MWEs) such as obsessive body image, lin-ear thinking, short attention span, or panic attack. Thesephrasemes are comprised of words that in isolation do notimpart much information in determining relatedness to agiven topic but do in the context of the expression.Second, the narrative structure in psychiatric clini-cal narratives varies considerably in how the same phe-nomenon can be described. Hallucinations, for example,could be described as the patient reports auditory hal-lucinations, or the patient has been hearing voices forseveral months, amongst many other possibilities.Third, phenomena can be directly mentioned with-out necessarily being relevant to the patient specifically.Psychosis patient discharge summaries, for instance, caninclude future treatment plans (e.g. Prevent relapse of amanic or major depressive episode., Prevent recurrenceof psychosis.) containing vocabulary that at the word-level seem strongly correlated with readmission risk. Yetat the sentence-level these do not indicate the presenceof a readmission risk factor in the patient and in factindicate the absence of a risk factor that was formerlypresent.Lastly, given the complexity of phenotypic assessmentin psychiatric illnesses, patients with psychosis exhibitconsiderable differences in terms of illness and symp-tom presentation. The constellation of symptoms leadsto various diagnoses and comorbidities that can changeover time, including schizophrenia, schizoaffective disor-der, bipolar disorder with psychosis, and substance useinduced psychosis. Thus, the lexicon of words and phrasesused in EHRs differs not only across diagnoses but alsoacross patients and time.Taken together, these factors make topic extraction adifficult task that cannot be accomplished by keywordsearch or other simple text-mining techniques.To identify specific risk factors to focus on, we notonly reviewed clinical literature of risk factors associatedwith readmission [12, 13], but also considered researchrelated to functional remission [14], forensic risk factors[15], and consulted clinicians involved with this project.Seven risk factor domains  Appearance, Mood, Interper-sonal, Occupation, Thought Content, Thought Process,and Substance  were chosen because they are clini-cally relevant, consistent with literature, replicable acrossdata sets, explainable, and implementable in NLP algo-rithms. These seven risk factor domains collectively coverthe essential clinical aspects of a patients symptoms andfunctioning. Although hospitals may differ in terms ofnarrative structure, all of a patients admission notes anddischarge summaries typically include text of these sevendomains. Many hospitals in the US include each of theserisk factors as a heading or subheading.In our present study, we evaluate multiple approaches toautomatically identify which risk factor domains are asso-ciated with which sentences in psychotic patient EHRs1.We perform this study in support of our long-term goal ofcreating a readmission risk classifier that can aid cliniciansin targeting individual treatment interventions and assess-ing patient risk of harm (e.g. suicidal risk, homicidal risk).Unlike other contemporary approaches in machine learn-ing, we intend to create a model that is clinically explain-able and flexible across training data while maintainingconsistent performance.To incorporate clinical expertise in the identification ofrisk factor domains, we undertake an annotation project,detailed in the Annotation task subsection of theMethods section. We identify a test set of over 5000EHR sentences which a team of three domain-expertclinicians annotate sentence-by-sentence for relevant riskfactor domains. The Inter-Annotator agreement sub-section of the Methods section describes the results ofthis annotation task. We then use the gold standard fromthe annotation project to assess the performance of mul-tiple neural classification models trained exclusively oninstitutional EHR data, described in the Results section.To further improve the performance of our model, weincorporate domain-relevant MWEs identified using allin-house data.Related workMcCoy et al. [16] constructed a corpus of web data basedon the Research Domain Criteria (RDoC)[17], and usedthis corpus to create a vector space document similaritymodel for topic extraction. They found that the negativevalence and social RDoC domains were associated withreadmission. Using web data (in this case data retrievedfrom the Bing API) to train a similarity model for EHRtexts is problematic since it differs from the target datain both structure and content. Based on reconstruction ofthe procedure, we conclude that many of the informativeMWEs critical to understanding the topics of sentencesin EHRs are not captured in the web data. Additionally,RDoC is by design a generalized research construct todescribe the entire spectrum of mental disorders and doesnot include domains that are based on observation orcauses of symptoms. Important indicators within EHRsof patient health, like appearance or occupation, are notincluded in the RDoC constructs.Rumshisky et al. [18] used a corpus of EHRs frompatients with a primary diagnosis of major depressivedisorder to create a 75-topic Latent Dirichlet Allocation(LDA) topic model that they then used in a readmissionprediction classifier pipeline. Like with McCoy et al. [16],the data used to train the LDA model was not ideal as1This study has received IRB approval.Holderness et al. Journal of Biomedical Semantics           (2019) 10:19 Page 3 of 10the generalizability of the data was narrow, focusing ononly one disorder. Their model achieved readmission pre-diction performance with an area under the curve of .784compared to a baseline of .618. To perform clinical valida-tion of the topics derived from the LDAmodel, they man-ually evaluated and annotated the topics, identifying themost informative vocabulary for the top ten topics. Withtheir training data, they found the strongest coherenceoccurred in topics involving substance use, suicidality, andanxiety disorders. But given the unsupervised nature ofthe LDA clustering algorithm, the topic coherence theyobserved is not guaranteed across data sets.MethodsDataTwo non-overlapping but highly compatible datasets wereused for training (Research Patient Data Registry, RPDR)and for testing (McLean Meditech) of our models. Ourtest set (McLean) consists of a corpus of discharge sum-maries, admission notes, individual encounter notes, andother clinical notes from 220 patients in the OnTrackTMprogram at McLean Hospital. OnTrackTM is an outpa-tient program, focusing on treating adults ages 18 to 30who are experiencing their first episodes of psychosis. Thelength of time in the program varies depending on patientimprovement and insurance coverage, with an average oftwo to three years. The program focuses primarily onearly intervention via individual therapy, group therapy,medication evaluation, and medication management. SeeTable 1 for a demographic breakdown of the 220 patients,for which we have so far extracted approximately 240,000total EHR sentences spanning from 2011 to 2014 usingMeditech, the software employed by McLean for storingand organizing EHR data.These patients are part of a larger research cohort ofapproximately 1800 psychosis patients, which will allowus to connect the results of this EHR study with otherongoing research studies incorporating genetic, cognitive,neurobiological, and functional outcome data from thiscohort.Table 1 Demographic breakdown of the target cohortMean Age (2014) 20.7Gender (Male) 79%RaceAsian 6%Black 7%Caucasian 77%Latino 5%Multiracial 5%Insurance (Public)2 5.5%30-day Inpatient Readmission Rate 14%We also use an independent, non-overlapping data setfor identifying training data for our vector space model,comprised of EHR texts queried from the RPDR, a cen-tralized regional data repository of clinical data fromall institutions in the Partners HealthCare network (e.g.,Massachusetts General Hospital, Brigham and WomensHospital). These records are highly comparable in styleand vocabulary to the McLean data set. The corpus con-sists of discharge summaries, encounter notes, and visitnotes of patients admitted to the systems hospitals withpsychiatric diagnoses and symptoms, totaling approxi-mately 8,000,000 EHR sentences consisting of 340,000,000tokens. This breadth of data captures a wide range of clin-ical narratives, creating a comprehensive foundation fortopic extraction.After using the RPDR query tool to extract EHR sen-tences from the RPDR database, we created a trainingcorpus by categorizing the extracted sentences accordingto their risk factor domain using a lexicon of 120 key-words that were identified by the clinicians involved in thisproject. Certain domains  particularly those involvingthoughts and other abstract concepts  are often iden-tifiable by MWEs rather than single words. The sameclinicians who identified the keywords manually exam-ined the bigrams and trigrams with the highest Term Fre-quency  Inverse Document Frequency scores (TF-IDF)for each domain in the categorized sentences, identifyingthose which are conceptually related to the given domain.We then used this lexicon of 775 keyphrases to iden-tify more relevant training sentences in RPDR and treatthem as (non-stemmed) unigrams when generating thematrix (see supplementary data). By converting MWEssuch as shortened attention span, unusual motor activity,wide-ranging affect, or linear thinking to non-stemmedunigrams, the predictive value of these terms is magnified.In total, we constructed a corpus of roughly 85,000,000tokens across 2,100,000 EHR sentences for training ourmodel.Annotation taskIn order to evaluate our models, we created an anno-tated test corpus McLean-specific EHR data extractedfrom Meditech. 5154 sentences were annotated by threelicensed clinicians for the clinically relevant domainsdescribed in Table 2. The corpus was selected by clinicians(P. C. and K. B.) who treat patients at McLlean OnTrackprogram and M.H.H who conducts clinical research atthe McLean Psychotic Disorders Division. It is comprisedentirely of McLean-specific EHR data, which are disjointfrom the RPDR but are highly compatible in style andvocabularies with the RPDR dataset.All sentences were removed from the surroundingEHR context to ensure annotators were not influencedby the additional contextual information. Our domainHolderness et al. Journal of Biomedical Semantics           (2019) 10:19 Page 4 of 10Table 2 Annotation scheme for the domain classification taskDomain Description Example Example KeywordsAppearance Physical appearance, gestures,and mannerismsA well-appearing, cleanyoung woman appearingher stated age, pleasant and cooperative. Eye contactwas good."Disheveled, clothing,groomed, wearing, cleanThought Content Suicidal/homicidal ideation,obsessions, phobias, delusions,hallucinationsNo SI, No HI, No hallucinations, Ideas of reference, Paranoiddelusions"Obsession, delusion,grandiose, ideation, suicidal,paranoidInterpersonal Family situation, friendships,and other social relationshipsPt. overall appears to be functioning very well despite thisconflict with a romantic interest of hers."Boyfriend, relationship, peers,family, parents, socialMood Feelings and overall disposition Pt. indicates that his mood is becoming more depressed." Anxious, calm, depressed,labile, confused, cooperativeOccupation School and/or employment Pt. followed through with decision to leave college at thispoint in time."Boss, employed, job, school,class, homework, workThought Process Pace and coherence ofthoughts. Includes linear,goal-directed, perseverative,tangential, and flight of ideasDisorganized (Difficult to communicate with patient.), Paucityof thought, Thought-blocking."Linear, tangential, prosody,blocking, goal-directed,perseverantSubstance Drug and/or alcohol use Patient used marijuana once which he believes triggered thecurrent episode."Cocaine, marijuana, ETOH,addiction, narcoticOther Any example that does not fallinto any of the other sevendomainsMaintain mood stabilization, prevent future episodes ofmania, improve self-monitoring skills."classification models consider each sentence indepen-dently and thus we designed the annotation task to mirrorthe information available to the models.The annotators were instructed to label each sentencewith one or more of the seven risk factor domains. Ininstances where more than one domain was applicable,annotators assigned the domains in order of prevalencewithin the sentence. An eighth label, Other, was includedif a sentence did not align with any of the seven risk factordomains. The annotations were then reviewed by a teamof two clinicians who adjudicated collaboratively to createa gold standard. Basic statistics on the corpus, includingthe number of sentences labeled for greater than one riskfactor domain are listed in Table 3. The gold standardand the clinician-identified keywords and MWEs haveTable 3 Distribution of gold standard sentences and tokensacross risk factor domainsTotal Sentences Total TokensAppearance 670 11648Mood 793 17672Interpersonal 574 11674Occupation 664 14166Thought Content 756 18785Thought Process 663 11203Substance Use 727 14793Totals 4847 99941Sentences With >1 Domain 222 8912received IRB approval for release to the community. Theyare available as supplementary data to this paper.Inter-Annotator agreementInter-annotator agreement (IAA) was assessed using acombination of Fleisss Kappa (a variant of Scotts Pi thatmeasures pairwise agreement for annotation tasks involv-ing more than two annotators) [19] and Cohens Multi-Kappa as proposed by Davies and Fleiss [20]. Table 4shows IAA calculations for both overall agreement andagreement on the first (most important) domain only. Fol-lowing adjudication, accuracy scores were calculated foreach annotator by evaluating their annotations against thegold standard.Overall agreement was generally good and alignedalmost exactly with the IAA on the first domain only.Out of the 1654 annotated sentences, 671 (41%) hadtotal agreement across all three annotators. We definedtotal agreement for the task as a set-theoretic completeintersection of domains for a sentence identified by allannotators.98% of sentences in total agreement involved onedomain. Only 35 sentences had total disagreement, whichwe defined as a set-theoretic null intersection betweenTable 4 Inter-annotator agreementLabels Fleisss Kappa Cohens Multi-Kappa Mean AccuracyOverall 0.575 0.571 0.746First Domain Only 0.536 0.528 0.805Holderness et al. Journal of Biomedical Semantics           (2019) 10:19 Page 5 of 10the three annotators. An analysis of the 35 sentences withtotal disagreement showed that nearly 30% included theterm blunted/restricted. In clinical terminology, theseterms can be used to refer to appearance, affect, mood,or emotion. Because the sentences being annotated wereextracted from larger clinical narratives and examinedindependently of any surrounding context, it was diffi-cult for the annotators to determine the most appropriatedomain. This lack of contextual information resulted ineach annotator using a different default label: Appear-ance, Mood, and Other. During adjudication, Other wasdecided as the most appropriate label unless the sentencecontained additional content that encompassed otherdomains, as it avoids making unnecessary assumptions.A Fleisss Kappa of 0.575 lies on the boundary betweenModerate and Substantial agreement as proposed byLandis and Koch [21]. This is a promising indicationthat our risk factor domains are adequately defined byour present guidelines and can be employed by cliniciansinvolved in similar work at other institutions.The fourth column in Table 4, Mean Accuracy, was cal-culated by averaging the three annotator accuracies asevaluated against the gold standard. This provides us withan informative baseline of human parity on the domainclassification task.Topic extractionFigure 1 illustrates the data pipeline for generating ourtraining and testing corpora, and applying them to ourclassification models.We use the Universal Sentence Encoder (USE) [22], adeep averaging neural network that is pretrained on avery large volume of general-domain web data, to convertsentences to 512-dimensional embedding vectors, stem-ming tokens with the Porter Stemmer tool provided bythe NLTK library [23]. USE has the advantage of beingsensitive to word ordering and can encode sequences ofvariable lengths, in addition to being integrated directlyinto TensorFlow. We have found in previous unpub-lished observations performed by Holderness, Meteer,Pustejovsky, and Hall that despite being pretrained ongeneral-domain web data, USE outperforms other state-of-the-art embedding models such as ELMo, FastText, orDoc2Vec.Starting with the approach taken by McCoy et al. [16],who used aggregate cosine similarity scores to computedomain similarity directly from a TF-IDF vector spacemodel, we extend this method by training a suite ofthree-layer multilayer perceptron (MLP) and radial basisfunction (RBF) neural networks using a variety of param-eters to compare performance. We employ the Keras deeplearning library [24] using a TensorFlow backend [25] forthis task. The architectures of our highest performingMLP and RBF models are summarized in Table 5. Pro-totype vectors for the nodes in the hidden layer of ourRBF model are selected via k-means clustering [26] oneach domain megadocument individually. The RBF trans-fer function for each hidden layer node is assigned thesame width, which is based off the maximum Euclideandistance between the centroids that were computed usingk-means.To prevent overfitting to the training data, we utilize adropout rate [27] of 0.2 on the input layer of all modelsand 0.5 on the MLP hidden layer.Since our classification problem is multiclass, multil-abel, and open-world, we employ seven nodes with sig-moid activations in the output layer, one for each riskfactor domain. This allows us to identify sentences that fallinto more than one of the seven domains, as well as deter-mine sentences that should be classified as Other. Unlikethe traditionally used softmax activation function, whichis ideal for single-label, closed-world classification tasks,sigmoid nodes output class likelihoods for each node inde-pendently without the normalization across all classes thatoccurs in softmax.We find that the risk factor domains vary in the degreeof homogeneity of language used, and as such certaindomains produce higher similarity scores, on average,than others. To account for this, we calculate thresh-old similarity scores for each domain using the formulamin=avg(sim)+?*? (sim), where ? is standard deviationand ? is a constant, which we set to 0.5 for our P modelFig. 1 Data pipeline for training and evaluating our risk factor domain classifiersHolderness et al. Journal of Biomedical Semantics           (2019) 10:19 Page 6 of 10Table 5 Architectures of our highest-performing MLP and RBFnetworksNetwork MLP RBFInput LayerNodes 512 512Dropout 0.2 0.2Activation ReLU ReLUHidden LayerNodes 250 700Dropout 0.5 0.0Activation ReLU RBFOutput LayerNodes 7 7Activation Sigmoid LinearOptimizer Adam AdamLoss Function Categorical Cross Entropy Mean Squared ErrorTraining Epochs 60 50Batch Size 128 128and 1.25 for our RBF model through trial-and-error.Employing a generalized formula as opposed to manuallyidentifying threshold similarity scores for each domainhas the advantage of flexibility in regards to the targetdata, which may vary in average similarity scores depend-ing on its similarity to the training data. If a sentence doesnot meet threshold on any domain, it is classified as Other.ResultsTable 6 shows the performance of ourMLP and RBFmod-els on classifying the sentences in our gold standard. Toassess relative performance of feature representations, wealso include performance metrics of our models withoutMWEs. Because this is a multilabel classification task wecompute precision, recall, and F1 scores for each sentencein the test set usingmacro-averaging, where performancesare calculated for each risk factor domain individually andthen averaged. In identifying the seven risk factor domainsindividually, our models achieved the highest per-domainscores on Substance (F1 ? 0.9) and the lowest score onMood (F1 ? 0.75).Despite prior research indicating that similar classifica-tion tasks to ours are more effectively performed by RBFnetworks [2830], we find that our MLP model performsmarginally better with significantly less computationalcomplexity (i.e. k-means and width calculations). Figure 2illustrates the distribution of sentences in vector spaceusing 2-component Linear Discriminant Analysis (LDA)[31], and shows that Thought Process, Appearance, Sub-stance, and  to a certain extent  Occupation clearlyoccupy specific regions, whereas Interpersonal, Mood,Table 6 Overall and domain-specific Precision, Recall, and F1scores for our modelsPrecision Recall F1Aggregate Cosine Similarity Scores 0.626 0.692 0.657MLP Baseline (No MWEs) 0.816 0.830 0.823RBF Baseline (No MWEs) 0.795 0.808 0.801MLP (w/ MWEs) 0.821 0.835 0.828Appearance 0.953 0.825 0.884Interpersonal 0.843 0.897 0.869Mood 0.723 0.816 0.767Occupation 0.945 0.834 0.886Substance 0.898 0.946 0.921Thought Content 0.830 0.685 0.751Thought Process 0.792 0.878 0.833Other 0.509 0.614 0.557RBF (w/ MWEs) 0.814 0.799 0.806Appearance 0.952 0.803 0.871Interpersonal 0.929 0.882 0.905Mood 0.748 0.759 0.754Occupation 0.956 0.847 0.898Substance 0.826 0.927 0.874Thought Content 0.866 0.685 0.765Thought Process 0.958 0.818 0.883Other 0.405 0.411 0.408and Thought Content occupy the same noisy region wheremultiple domains overlap. In RBF networks, the magni-tude of activation for a given hidden layer neuron is basedon the Euclidean distance from the input vector to theprototype centroid associated with that neuron. Smallerdistances lead to more robust activations. To identifythese prototype centroids, we apply the k-Means cluster-ing algorithm to identify the training examples for eachclass that most closely describe the distribution of theexamples in vector space. With large training sets such asours, the RBF prototype centroids will be more preciseand therefore the RBF model is more powerful in differ-entiating between classes in crowded regions of vectorspace. This is reflected by the results in Table 6, wherethe RBF network performs as well as or stronger than theMLP network in the four overlapping domains (0.905 vs0.869 for Interpersonal, 0.754 vs 0.767 for Mood, 0.898vs 0.886 for Occupation, and 0.765 vs 0.751 for ThoughtContent) whereas the MLP network  with the exceptionof Thought Process  performs as well as or stronger thanthe RBF network when predicting the non-overlappingdomains (0.874 vs 0.921 for Substance, 0.871 vs 0.884for Appearance, and 0.883 vs 0.833 for Thought Process).We also observe a similarity in the words and phrasesHolderness et al. Journal of Biomedical Semantics           (2019) 10:19 Page 7 of 10Fig. 2 2-component linear discriminant analysis of the RPDR training datawith the highest Term Frequency  TF-IDF scores acrossthe overlapping domains: many of the Thought Contentwords and phrases with the highest TF-IDF scores involveinterpersonal relations (e.g. fear surrounding daughter,father, family history, familial conflict) and there is ahigh degree of similarity between high-scoring words forMood (e.g. meets anxiety criteria, cope with mania, ocd)and Thought Content (e.g. mania, feels anxious, feelsexhausted). Please refer to the Methods section of thispaper for more information on our TF-IDF analysis andits implications in building our training corpus.The most significant discrepancy in model perfor-mances is in classifying sentences that do not involve anyof the seven risk factor domains. While both are fairlyinaccurate at identifying these Other sentences, ourMLPmodel has a markedly higher F-score (0.557) compared toour RBF model (0.408).DiscussionResults clearly indicate that our MLP and RBF deeplearning models outperform the cosine similarity base-line. Additionally, our models are more scalable andcomputationally efficient to handle large volumes of data.In our initial work on risk factor domain topic extrac-tion with a training data set of only 100,000 sentences,we found performance to increase by 15% when factor-ing in MWEs, a marked improvement over our modelsthat did not incorporate them. However, with our cur-rent training data set of 2,100,000 sentences, factoringMWEs into our models increased classification perfor-mance by only 1% uniformly across all risk factor domains,both overlapping and non-overlapping. This aligns withour expectations that MWEs comprised of a quotidianvocabulary hold more clinical significance than whenthe words in the expressions are treated independentlybut that as the amount of training data increases, theseMWEs are captured organically. Even with the larger vol-ume of training data, the clinician-identified keywordsand MWEs continue to play an important role when gen-erating the training data set, as training sentences areidentified by regular expression pattern matching of thesekeywords and MWEs. Therefore, including MWEs at thisstep increases the scope and variety of training sentences,leading to more robust downstream performance.Holderness et al. Journal of Biomedical Semantics           (2019) 10:19 Page 8 of 10The wide variance in per-domain performance is dueto a number of factors. Most notably, the training sen-tences we extracted from RPDR  while very comparablein structure and style to our target OnTrackTM data may not have an adequate variety of content and range ofvocabulary. Although using keyword and MWE matchingto create our training corpus has the advantage of beingsignificantly less labor intensive than manually labelingevery sentence in the corpus, it is likely that the homo-geneity of language used in the training sentences is higherthan it would be otherwise. Additionally, all of the sen-tences in the training data are assigned exactly one riskfactor domain even if they actually involve multiple riskfactor domains, making the clustering behavior of thesentences more difficult to define.Threshold similarity scores also play a large role indetermining the precision and recall of ourmodels: settinghigher classification thresholds leads to a smaller numberof false positives and a greater number of false negativesfor each risk factor domain. Conversely, more sentencesare incorrectly associated with one or more risk factordomains when thresholds are set lower. Since our classi-fier will be used in future work as an early step in a dataanalysis pipeline for determining readmission risk, mis-classifying a sentence with an incorrect risk factor domainat this stage can lead to greater inaccuracies at later stages.Sentences misclassified as Other, however, will be dis-carded from the data pipeline. Therefore, we intentionallyset a conservative threshold where only the most confi-dently labeled sentences are assigned membership in aparticular domain. In addition to the challenges associ-ated with fine-tuning threshold similarity scores, Other asa domain is much broader in scope than the seven risk fac-tor domains, encompassingmost of the space surroundingthe clusters in Fig. 2. Because the function describing thisspace is more complex than the functions delineating theregions of vector space occupied by the specific risk fac-tor domains, model accuracy is predictably lower whenclassifying these out-of-domain examples.The IAA that we report on our annotation task falls inthe upper end of Moderate agreement and is only 0.03away from being considered Substantial agreement asproposed by Landis and Koch [21]. From a clinical psy-chiatric perspective, it is in fact satisfactory and the firstof its kind in the psychosis clinical NLP literature. Asdescribed in the Background Section, dealing with clinicalnarratives in psychotic EHRs are challenging for a num-ber of reasons. Also, our annotation task is multiclass,multilabel, and open-world (i.e., 7 risk factor domainsplus other for sentences that are not relevant to thosedomains), making high IAA very difficult to achieve. Thedegree of difficulties specific to each domain also affectthe overall IAA. Some domains such as Substance pro-duced high IAA because it is easy for annotators to agreeon sentences involving substance (e.g., cocaine, cannabis).Whereas other domains with a larger vocabulary over-lap, such as Mood, Thought Content, and Interpersonalare more challenging (see Fig. 2). For example, Pt is a 32year old single Caucasian male with a history of Schizoaf-fective Disorder, two prior psychiatric hospitalizations,with increasing disorganized thought process, paranoia,and command auditory hallucinations in the context ofdiscontinuing his psychiatric medications was annotatedto be Thought Process & Thought Content by twoannotators and Appearance & Thought Content &Thought Process by the third annotator, resulting inpartial agreement among annotators. For each sentence,the gold standard was created by a majority agreementamong annotators when two or more annotators were intotal agreement. For the remaining sentences, high qual-ity, domain-expert adjudications were made by a team oftwo clinicians who worked collaboratively. Therefore, webelieve that the resulting corpus can be used as a goldstandard.In terms of computational complexity, our MLP modelsignificantly outperforms our RBF model during trainingand outperforms both the RBF model and the cosine sim-ilarity baseline at evaluation. Whereas our MLP modeltrains in O(n) time, requiring only one pass through eachdatapoint for each epoch of training, our RBF modeltrains in O(nw) time, where w is equivalent to the num-ber of prototype centroids in the hidden layer, as eachtraining example is evaluated against each prototype cen-troid in the network. In addition, the k-Means clusteringthat must be performed before training the RBF networkto identify the prototype centroids runs in O(n) time.Although the cosine similarity baseline model does nothave a training phase, it runs in O(n2) at evaluation sincethe distance between each element in the test corpus andeach element in the training corpus must be computed.Although both the RBP and MLP models performedroughly equivalently, the MLP is a simpler model and isfaster to train and evaluate compared to an RBF network.Given the intention of implementing this model in a largerclinical NLP pipeline, the lower latency MLP model ispreferred.ConclusionsTo achieve our goal of creating a framework for a readmis-sion risk classifier, the present study performed necessaryevaluation steps by updating and adding to our modeliteratively. In the first stage of the project, we focusedon collecting the data necessary for training and testing,and on the domain classification annotation task. At thesame time, we began creating the tools necessary for auto-matically extracting domain relevance scores at the sen-tence and document level from patient EHRs using sev-eral forms of vectorization and topic modeling. In futureHolderness et al. Journal of Biomedical Semantics           (2019) 10:19 Page 9 of 10versions of our risk factor domain classification modelwe will explore increasing robustness through sequencemodeling that considers more contextual information.Our current feature set for training a machine learn-ing classifier is relatively small, consisting of sentencedomain scores, bag-of-words, length of stay, and numberof previous admissions, but we intend to factor in manyadditional features that extend beyond the scope of thepresent study. These include a deeper analysis of clini-cal narratives in EHRs: in a different line of development,we have extended our EHR data pipeline by distinguish-ing between clinically positive and negative phenomenawithin each risk factor domain [32]. This involved aseries of annotation tasks that allowed us to generatelexicon-based and corpus-based sentiment analysis tools.In future work, we intend to use these clinical sentimentscores to generate gradients of patient improvement ordeterioration over time with respect to each of the sevenrisk factor domains for readmission.We will also take into account structured data thathave been collected on the target cohort throughout thecourse of this study such as brain based electrophysiologi-cal (EEG) biomarkers, structural brain anatomy fromMRIscans, social and role functioning assessments, personal-ity assessments (NEO-FFI), and various symptom scales(PANSS, MADRS, YMRS). For each feature we consideradding, we will evaluate the performance of the classifierwith and without the feature to determine its contributionas a predictor of readmission.AbbreviationsAdam: Adaptive Moment Estimation [33]; EHR: Electronic Health Record; ETOH:Ethyl alcohol and ethanol; HI: Homicidal ideation; IAA: Inter-AnnotatorAgreement; MADRS: Montgomery-Asperg Depression Rating Scale [34]; MLP:Multi-Layer Perceptron; MWE: Multi Word Expression; NEO-FFI: NEOFive-Factor Inventory [35]; NLTK: Natural Language Toolkit; OCD:Obsessive-compulsive disorder; PANSS: Positive and Negative Syndrome Scale[36]; RBF: Radial Basis Function; ReLU: Rectified Linear Units, f (x) = max(0, x)[37]; RPDR: Research Patient Data Registry; SI: Suicidal ideation; TF-IDF: TermFrequency  Inverse Document Frequency; USE: Universal Sentence EncoderYMRS: Young Mania Rating Scale [38]AcknowledgmentsNot applicable.Authors contributionsEH and Nicholas Miller and M-HH prepared this manuscript and wrote thecode for data extraction, model training, and algorithm evaluation. KB and PCannotated the sentences in our test corpus. MM and JP consulted onmethodologies in computational linguistic analysis of the data. M-HH workedon all aspects of the project, is the principal investigator of this project, and isdirector of the Psychosis Neurobiology Laboratory at McLean Hospital, wherethis research was undertaken. All authors read and approved the finalmanuscript.FundingThis work was supported by a grant from the National Institute of MentalHealth (grant no. 5R01MH109687 to Mei-Hua Hall).Availability of data andmaterialAll data generated or analyzed during this study are included in this publishedarticle and its Additional files.Ethics approval and consent to participateNot applicable.Consent for publicationNot applicable.Competing interestsThe authors declare that they have no competing interests.Author details1Psychosis Neurobiology Laboratory, McLean Hospital, Harvard MedicalSchool, Mill St, Belmont, MA, USA. 2Brandeis University Department ofComputer Science, South St, Waltham, MA, USA.Received: 1 May 2019 Accepted: 9 September 2019DATABASE Open AccessComprehensive anatomic ontologies forlung development: A comparison ofalveolar formation and maturation withinmouse and human lungHuaqin Pan1, Gail H. Deutsch2, Susan E. Wert3* , On behalf of the Ontology Subcommittee and NHLBIMolecular Atlas of Lung Development Program ConsortiumAbstractBackground: Although the mouse is widely used to model human lung development, function, and disease, ourunderstanding of the molecular mechanisms involved in alveolarization of the peripheral lung is incomplete.Recently, the Molecular Atlas of Lung Development Program (LungMAP) was funded by the National Heart, Lung,and Blood Institute to develop an integrated open access database (known as BREATH) to characterize themolecular and cellular anatomy of the developing lung. To support this effort, we designed detailed anatomic andcellular ontologies describing alveolar formation and maturation in both mouse and human lung.Description: While the general anatomic organization of the lung is similar for these two species, there aresignificant variations in the lungs architectural organization, distribution of connective tissue, and cellularcomposition along the respiratory tract. Anatomic ontologies for both species were constructed as partonomichierarchies and organized along the lungs proximal-distal axis into respiratory, vascular, neural, and immunologiccomponents. Terms for developmental and adult lung structures, tissues, and cells were included, providingcomprehensive ontologies for application at varying levels of resolution. Using established scientific resources,multiple rounds of comparison were performed to identify common, analogous, and unique terms that describethe lungs of these two species. Existing biological and biomedical ontologies were examined and cross-referencedto facilitate integration at a later time, while additional terms were drawn from the scientific literature as needed.This comparative approach eliminated redundancy and inconsistent terminology, enabling us to differentiate trueanatomic variations between mouse and human lungs. As a result, approximately 300 terms for fetal and postnatallung structures, tissues, and cells were identified for each species.(Continued on next page)© The Author(s). 2019 Open Access This article is distributed under the terms of the Creative Commons Attribution 4.0International License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, andreproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link tothe Creative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver(http://creativecommons.org/publicdomain/zero/1.0/) applies to the data made available in this article, unless otherwise stated.* Correspondence: susan.wert@cchmc.orgHuaqin Pan, Gail H. Deutsch and Susan E. Wert contributed equally to thiswork.3Department of Pediatrics, Perinatal Institute, Section of Neonatology,Perinatal and Pulmonary Biology, Cincinnati Childrens Hospital MedicalCenter/Research Foundation, University of Cincinnati College of Medicine,3333 Burnet Ave, MLC7029, Cincinnati, OH 45229, USAFull list of author information is available at the end of the articlePan et al. Journal of Biomedical Semantics           (2019) 10:18 https://doi.org/10.1186/s13326-019-0209-1(Continued from previous page)Conclusion: These ontologies standardize and expand current terminology for fetal and adult lungs, providing aqualitative framework for data annotation, retrieval, and integration across a wide variety of datasets in the BREATHdatabase. To our knowledge, these are the first ontologies designed to include terminology specific fordevelopmental structures in the lung, as well as to compare common anatomic features and variations betweenmouse and human lungs. These ontologies provide a unique resource for the LungMAP, as well as for the broaderscientific community.Keywords: Alveolarization, Biomedical ontology, Data annotation, Database, Lung-specific cell types, Molecularanatomy, LungMAP, OWL, Single-cell analysis, Web-based atlas,BackgroundOntologies are formal representations of knowledge usedto handle big data sets and information retrieval. Ontol-ogies consist of standardized vocabularies of terms forindividual entities (or objects) that are associated with aspecific domain or field of knowledge. Anatomy ontol-ogies are designed to capture biological concepts and de-scriptions in a way that can be easily categorized andanalyzed with computer technology. The most visiblebiological application today is the Gene Ontology project[1], which provides a controlled vocabulary for cross-species comparisons of genes and gene products that areassociated with biological processes, molecular func-tions, and cellular components. In recent years, ontol-ogies have become indispensable tools for variousmolecular anatomy and atlas projects, including GUD-MAP, molecular anatomy of genitourinary tract develop-ment in the mouse [2, 3]; Brain Maps 4.0, neuroanatomyof the rat brain [4]; Xenbase, Xenopus anatomy and de-velopment [5]; and FaceBase, craniofacial anatomy, de-velopment and malformations in a variety of species [6].Ontologies also extend our ability to access prior know-ledge from other model organisms, using cross-referenced linkages to existing ontologies or databases.Together, these ontologies provide innovative tools forknowledge representation and modeling of biologic anddevelopmental relationships, as well as cellular and mo-lecular processes.While extensive research has been published on themolecular regulation of early lung formation andbranching morphogenesis of the conducting airways(reviewed in [710]), less is known about the molecularmechanisms regulating expansion and maturation of thealveolar parenchyma during the later stages of lung de-velopment (reviewed in [1116]). This period of lung de-velopment is critical for the formation of the distal gas-exchange region of the lung, which is marked by thegeneration of millions of highly vascularized alveoli thatare the lungs primary gas-exchange units (reviewed in[17, 18]). This process, termed alveolarization (or alveo-logenesis), increases the surface area and diffusion cap-acity of the lung, which are required for efficientexchange of oxygen and carbon dioxide after birth. Dis-ruption of this process has significant clinical relevancefor managing neonatal lung disease related to prematur-ity, neonatal respiratory distress, and abnormal lunggrowth [1921].The mouse is an important animal model for investi-gating human lung development, function, and disease[2226]. Although there are many anatomic, histologic,and developmental similarities between these two spe-cies, significant variations exist in the architecturalorganization, connective tissue elements, and cellularcomposition of their lungs [2729]. Lung developmentin both species proceeds in an orderly fashion in re-sponse to molecular mechanisms that control the initialformation and subsequent proliferation, differentiation,growth and maturation of the lung (reviewed [710]).Development of the lung is divided into several stagesthat extend throughout the fetal and postnatal periods oflife [17, 30]. These stages include the embryonic, pseudo-glandular, canalicular, saccular, and alveolar stages,which describe the histologic changes observed duringdevelopment of the lung [17, 3035]. Vascular matur-ation of the alveolar capillary bed in both species takesplace during the last stage of lung development and iscoincident with alveolar septation [17, 3638]. Althoughlung development is similar in all mammalian species,the relative timing and/or length of each developmentalstage varies from one species to another [17, 39, 40].While maturation of the peripheral alveoli is initiatedprior to birth in the human lung [30, 34, 41, 42],similar histological changes in the mouse do notbegin until after birth [17, 43]. In both species, on-going formation of additional alveoli continues intoyoung adulthood [36, 37, 41, 43, 44].Recently, a cooperative research project, the MolecularAtlas of Lung Development Program (LungMAP), wasinitiated by the National Heart, Lung, and Blood Insti-tute to characterize and compare the molecular anatomyof mouse and human lungs, focusing on the later stagesof lung development and maturation [45, 46]. LungMAPis a consortium composed of four research centers, amouse hub, a human tissue repository, a centralPan et al. Journal of Biomedical Semantics           (2019) 10:18 Page 2 of 21database termed Bioinformatics REsource ATlas for theHealthy lung (BREATH), and a data-coordinating centerwith a public web site (www.lungmap.net) [45, 46]. TheBREATH database is an integrated open-access databasethat contains multiple datasets generated by a variety ofanalytical approaches to detect temporal-spatial changesin the developing lung. These include changes in 1)mRNA and microRNA expression, using microarraysand mRNA sequencing; 2) epigenetic control of gene ex-pression, based on DNA methylation patterns; 3)protein, lipid and metabolite expression, using massspectrometry imaging; 4) protein and mRNA expression,using high-resolution immunofluorescence confocal mi-croscopy and high-throughput in situ hybridization; and5) structural features, using three-dimensional (3-D) im-aging [4751]. Annotation and retrieval of informationfrom these diverse datasets require a standardized vo-cabulary to integrate the molecular data with anatomic,histologic, and cellular imaging, in order to identifyfunctionally and/or anatomically defined cell types in thedeveloping lung.To support this effort, we developed a comprehensive,high-resolution ontology, incorporating terms for well-defined anatomic structures, tissues, and cells found inthe late fetal and postnatal mouse lung. Likewise, a de-tailed anatomic ontology for the late fetal and postnatalhuman lung was constructed and then harmonized withthe mouse ontology in order to compare normal devel-opmental processes between the two species. To ourknowledge, this is the first ontology to include termin-ology specific for developmental structures in the mouseand human lung, including pulmonary, vascular, neuraland immunologic components critical for lung function.It is also the first time that specific cell types have beenincorporated into an anatomic ontology for the lung.Content and constructionMethodsThe abstract version of these anatomic ontologies wasconstructed using Protégé1 version 5.0.0 [52, 53](https://protege.stanford.edu/about.php) and WebOntology Language (OWL 2). This approach supportsintegration with other biological and biomedical ontol-ogies. Scientific content was informed by review of thepublished literature (peer-reviewed research, reviews,textbooks, atlases, and medical dictionaries), by the au-thors expertise in lung development, anatomy, histo-pathology, and cell biology, and by annotationrequirements for the BREATH database. Terminologyand definitions already in use were adopted from exist-ing ontologies, including the Mouse Gross Anatomy andDevelopment Ontology (EMAP) [54] (https://bioportal.bioontology.org/ontologies/EMAP); the Mouse AdultGross Anatomy Ontology (MA) [55, 56] (http://bioportal.bioontology.org/ontologies/MA); the Founda-tional Model of Anatomy (FMA) [57] (http://bioportal.bioontology.org/ontologies/FMA); the Uber AnatomyOntology (UBERON) [58] (http://bioportal.bioontology.org/ontologies/UBERON); and the Cell Ontology (CL)[59, 60] (http://bioportal.bioontology.org/ontologies/CL).Additional resources for terms and definitions includedthe National Cancer Institute Thesaurus (NCIT)(https://ncit.nci.nih.gov/ncitbrowser/) and NationalInstitute of Health (NIH) Medical Subject Headings(MeSH) (https://www.nlm.nih.gov/mesh/). Definitionsderived from existing ontologies and resources wereoften modified to reflect lung-specific knowledge and ex-pertise. Synonyms commonly used in the literature andin other ontologies were included to improve querysearching. Where additional terms were required (i.e.,terms that could not be drawn from existing ontologies),the published literature was reviewed for the mostwidely accepted terms, synonyms, and definitions. Mul-tiple revisions were performed to refine both existingand newly introduced terms, as well as term definitionsand synonyms. Construction of these ontologies is open-ended, so that additional anatomic terms and newlydefined or molecularly distinct cell types can be incorpo-rated as needed for annotation and linkage at a laterdate.Design of the ontology framework for the mouse lungA review of existing anatomic ontologies for the mouse,including UBERON, MA and EMAP, demonstrated thatthese ontologies had limited coverage of the fetal andpostnatal mouse lung, especially for the later stages oflung development when alveolar growth, vascularization,septation, and maturation are initiated. In addition, devel-opmental staging, specific terminology, and definitions forfetal lung structures and cells were often lacking in theseestablished ontologies. As a result, we decided initially toorganize the anatomic ontology for the mouse lung intofour separate developmental time periods, or age_range(s)(Fig. 1), beginning with the canalicular stage, embryonicday (E) 16.5-E17.5, and ending with the alveolar stage,postnatal day (P) 436, of lung development. Since theintervening saccular stage (E17.5-P3) of lung developmentspans the perinatal period in the mouse, this stage is sub-divided into two age_range(s), i.e., a prenatal (or early)saccular stage (E17.5-E19.5) and a postnatal (or late) sac-cular stage (P0-P3) (Fig. 1). During these periods, termsassociated with the formation and maturation of the al-veolar parenchyma differ as this region evolves over time(enclosed boxes, Fig. 1).Within each age_range, anatomic structures, tissues,and cells were organized into six major classes: trachea,bronchi, lung, vascular structures (including the pul-monary, bronchial, and lymphatic circulations), thePan et al. Journal of Biomedical Semantics           (2019) 10:18 Page 3 of 21autonomic nervous system, and the immune system (seehttps://www.lungmap.net/breath-ontology-browser/). Asa rule, fetal lung development proceeds both spatiallyand temporally along the proximal-distal axis of thelung, so that formation, growth and differentiation of theproximal conducting airways, vasculature and nervesprecede that of the distal alveolar parenchyma [6166].Therefore, each system was organized along theproximal-distal axis of the lung with increasing levels ofgranularity, i.e., from larger, lower resolution, extra-pulmonary structures (trachea, bronchi and pulmonaryvessels) to smaller, higher resolution, intra-pulmonarystructures (bronchioles, alveoli and alveolar capillaries),tissues, and cells. Microvascular structures of thealveolar-capillary bed were integrated into the alveolarparenchyma of the lung, since close apposition of thealveolar epithelium and adjacent capillary endotheliumis critical for gas-exchange.Considering the lung has over 40 different cell typesthat have been classified primarily by location, histology,function, and ultrastructural features [6771], we inte-grated both general (e.g., epithelial, endothelial, intersti-tial cells) and specific (e.g., basal, ciliated, mucous,alveolar type II cells) cell types into the anatomic ontol-ogy. Recently, the availability of cell-specific markers,such as antibodies to transcription factors, intracellularproteins, and cell surface markers [7], has augmentedour ability to detect and isolate lung-specific cell typesand subpopulations, while advances in single-cell tech-nology have identified molecularly distinct cells previ-ously classified together as a single, specific, cell type[51, 7275]. In order to improve data linkage andFig. 1 Terms associated with prenatal and postnatal development of the alveolar parenchyma organized by age_range. Development of thealveolar parenchyma is organized into 4 developmental stages, or age_range(s), each with unique terminology for pre- and post-natal alveolarstructures. These age_range(s) are E16.6-E17.5 (canalicular stage); E18.5-E19.5/birth (saccular stage, prenatal period); P0-P3 (saccular stage, postnatalperiod); P4-P36 (alveolar stage). Terms for the alveolar parenchyma (enclosed in boxes) differ with developmental stage as these structures evolveover timePan et al. Journal of Biomedical Semantics           (2019) 10:18 Page 4 of 21website queries based on single-cell data, a class termedisolated lung cell types was created for experimental celltypes, i.e., newly defined cell types identified by single-cell RNA sequencing (scRNA-seq) analysis of isolatedcells. The inclusion of general, specific, and isolated celltypes is a major feature of this ontology that is not com-monly found in many traditional anatomic and histo-logic ontologies.Construction of the mouse lung ontologyThe anatomic ontology for the mouse lung is con-structed as a partonomic (X is a part of Y, or part_of) hierarchy with separate trees for the different de-velopmental stages or corresponding age_range(s) [3,55, 76]. Age_range is an annotation property that isassigned to each term in the ontology. Each age_rangeis subdivided into separate respiratory, vascular,neural, and immunologic components that are orga-nized along the proximal-distal axis of the lung. Eachorgan system, in turn, is populated with terms forwell-characterized fetal, postnatal, and adult anatomicstructures, distinct tissue compartments, and specificcell types. General and specific cell types incorporatedinto the anatomic ontology are also organized into aseparate cell ontology, which is constructed using theis_a (subtype) relation. Within each age_range, celltypes are listed alphabetically by class (major generalcell types) and then by subclass (specific cell types)(Fig. 2). This strategy provides a comprehensive ana-tomic ontology that can be used at varying levels ofresolution, i.e., with whole mounts, sectioned materialor isolated tissues and cells.This ontology for the mouse contains 283 terms, in-cluding 167 for anatomic structures, 48 for tissues, and68 for cells, which are distributed by developmental ageand organ system (Table 1). It is displayed in the Lung-MAPs website browser as a tree structure that can beexpanded and collapsed as desired (see https://www.lungmap.net/breath-ontology-browser/). Access to termdetails is achieved by selecting or highlighting any termFig. 2 Cell ontology. General and specific cell types are organized into a separate tree of the ontology by developmental age (age_range) andthen alphabetically. a There are 13 general cell classes for the mouse at P0-P3. The general cell type, epithelial cell, has four major subclasses:alveolar, bronchial, bronchiolar, and tracheal epithelial cells. b Each of these subclasses can be expanded into specific cell types, illustrating theirdistribution in the conducting airway and alveoli. A subclass termed isolated lung cell types was created for experimental cell types/subtypesidentified by scRNA seq analysisPan et al. Journal of Biomedical Semantics           (2019) 10:18 Page 5 of 21in the browser. This brings up the term detail box,which displays a unique identifier (i.e., a LungMAPMouse Anatomy ID: LMMA_00XXX), a name (term orlabel), synonyms, and a definition for each individual en-tity (or object) (Fig. 3). This information, along with an-notation properties and relations, are then incorporatedinto the formal ontology (Additional file 1). Annotationproperties, i.e., specific attributes, features, characteris-tics or values that are associated with each individual ob-ject, are displayed in Table 2. The annotation property,evidence, was created to indicate terms that are either 1)well-established published terms or 2) experimentalterms based on gene expression profiles generated bymRNA analysis of isolated cells or by scRNA-seq data.The special annotation property of display_order en-abled proximal-distal organization of anatomic struc-tures and tissues. Relations, or attributes describing howa class or an individual object relates to other classesand/or objects in the ontology [77], are displayed inTable 3. Although the primary relation used to constructthis ontology is part_of, five additional relations are in-cluded to enrich the terms in the ontology. These in-cluded both spatial (adjacent_to, continuous_with,branching_part_of) and developmental (develops_from)relations, whose inclusion is designed to empower web-based queries related to complex molecular and cellularinteractions.Existing terms from relevant ontologies were adoptedwhere applicable. Terms were classified as existing if theycould be mapped to current ontologies and/or to add-itional vocabularies (e.g., NCIT or NIH MeSH) found inthe National Center of Biomedical Ontology (NCBO) Bio-portal (https://www.bioontology.org) [78, 79]. In general,terms drawn from other ontologies describe well-knownanatomic structures, tissues and cells, but rarely include acomplete description of lung-specific tissues and cells.Where additional terms were required, the scientific litera-ture was reviewed for the most widely accepted terms,synonyms, and definitions. Additional terms most oftenincluded tissue structures and cells specific for the lung,such as alveolar lumen, alveolar capillary bed, and lipofi-broblast, or for lung-specific developmental structures andcells, such as acinar tubule, alveolar septal crest, and im-mature club cell. Many of these developmental terms havebeen used for years in the literature to describe the hist-ology of the developing lung [30, 34] and were incorpo-rated into the ontologies, where possible, due to their longand extensive use in the literature. As a result, there are159 (56%) terms cross-referenced to existing ontologiesand 124 (44%) additional terms drawn from the literaturefor the mouse anatomic ontology (Table 4). This repre-sents a significant expansion of current anatomic ontol-ogies for the developing and adult mouse lung.Development of the human lung ontologyAs for the mouse, review of existing human anatomicand developmental ontologies, such as FMA, UBERON,and the Human Developmental Anatomy Ontology(http://bioportal.bioontology.org/ontologies/EHDAA2)[80], revealed limited coverage of fetal and postnatal hu-man lung structures, especially those associated with thelate stages of lung development when alveolar growth,vascularization, septation and maturation are initiated.In the mouse, the alveolar stage of lung development be-gins postnatally around P4 and is complete by P36 [32,36]. In contrast, this stage of human lung developmentbegins prior to birth, at approximately 36 weeks of gesta-tional age (GA), and continues after birth into the firstfew years of life [41]. The human lung ontology was pat-terned initially on the alveolar stage of mouse lung de-velopment and then revised to reflect the uniquedifferences in architectural organization, anatomic struc-tures, tissue components, and cellular composition be-tween the two species. Commonly used synonyms wereincluded to improve harmonization search capabilitiesacross the two species. As was done for the mouse, gen-eral and specific cell types were incorporated in to theanatomic ontology, and an additional cell ontology wasconstructed in which the cells were listed alphabeticallyby class (major general cell type) and then by subclass(specific cell type) using the primary relation, is_a. An-notation properties (Table 2) and class relations (Table3) were harmonized with those developed for the mouselung ontology.Table 1 Distribution of terms for the mouse lung by anatomy,organ system, and developmental stageCategory Number of termsDomainAnatomy 167Tissue 48Cell 68Organ systemTrachea 40Bronchus 44Lung 94Vascular system 74Autonomic nervous system 20Immune system 41Developmental stage (age_range)aCanalicular Stage (E16.5-E17.5) 231Prenatal (early-mid) Saccular Stage (E17.5-E19.5) 229Postnatal (mid-late) Saccular Stage (P0-P03) 253Alveolar Stage (P04-P36) 262a, includes terms for all organ systems at each developmental stagePan et al. Journal of Biomedical Semantics           (2019) 10:18 Page 6 of 21Comparison of mouse and human lung anatomyAlthough the general anatomic organization of the ma-ture human and mouse lung is similar, there are signifi-cant variations in the gross architecture, as well as in thedistribution of connective tissue elements and in cellularcomposition along the airways (Additional file 2). Thesevariations are due primarily to differences in size be-tween the two species and partly to differences in theFig. 3 Term Details. Access to the Term Details box is achieved by selecting, or highlighting, any term in the Ontology Browser. The Term Detailsbox contains the name of the term, a unique identifier (LungMAP ID), age range, Theiler stage, developmental stage, synonyms (if applicable),definition, developmental relationships (if known), evidence (experimental or published term), and ontology path, known database crossRESEARCH Open AccessFinding relevant free-text radiology reportsat scale with IBM Watson Content Analytics:a feasibility study in the UK NHSAlicja Piotrkowicz1,2*, Owen Johnson3,4 and Geoff Hall2,4From UK Healthcare Text Analysis Conference (HealTAC 2018)Manchester, UK. 18-19 April 2018AbstractBackground: Significant amounts of health data are stored as free-text within clinical reports, letters, dischargesummaries and notes. Busy clinicians have limited time to read such large amounts of free-text and are at risk ofinformation overload and consequently missing information vital to patient care. Automatically identifying relevantinformation at the point of care has the potential to reduce these risks but represents a considerable researchchallenge. One software solution that has been proposed in industry is the IBM Watson analytics suite whichincludes rule-based analytics capable of processing large document collections at scale.Results: In this paper we present an overview of IBM Watson Content Analytics and a feasibility study usingContent Analytics with a large-scale corpus of clinical free-text reports within a UK National Health Service (NHS)context. We created dictionaries and rules for identifying positive incidence of hydronephrosis and brain metastasisfrom 5.6 m radiology reports and were able to achieve 94% precision, 95% recall and 89% precision, 94% recallrespectively on a sample of manually annotated reports. With minor changes for US English we applied the samerule set to an open access corpus of 0.5 m radiology reports from a US hospital and achieved 93% precision, 94%recall and 84% precision, 88% recall respectively.Conclusions: We were able to implement IBM Watson within a UK NHS context and demonstrate effective resultsthat could provide clinicians with an automatic safety net which highlights clinically important information withinfree-text documents. Our results suggest that currently available technologies such as IBM Watson ContentAnalytics already have the potential to address information overload and improve clinical safety and that solutionsdeveloped in one hospital and country may be transportable to different hospitals and countries. Our study waslimited to exploring technical aspects of the feasibility of one industry solution and we recognise that healthcaretext analytics research is a fast-moving field. That said, we believe our study suggests that text analytics issufficiently advanced to be implemented within industry solutions that can improve clinical safety.Keywords: Information retrieval, Natural language processing, Radiology, Feasibility study, Rule-based system© The Author(s). 2019 Open Access This article is distributed under the terms of the Creative Commons Attribution 4.0International License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, andreproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link tothe Creative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver(http://creativecommons.org/publicdomain/zero/1.0/) applies to the data made available in this article, unless otherwise stated.* Correspondence: A.Piotrkowicz@leeds.ac.uk1Leeds Institute of Medical Education, University of Leeds, Leeds, UK2Leeds Teaching Hospitals Trust, Leeds, UKFull list of author information is available at the end of the articlePiotrkowicz et al. Journal of Biomedical Semantics 2019, 10(Suppl 1):21https://doi.org/10.1186/s13326-019-0213-5BackgroundA wealth of healthcare data is stored in unstructured free-text reports [1]. These include narrative reports from diag-nostic services such as radiology and pathology, consultantsletters, discharge summaries and clinical notes. For example,Capurro et al. [2] found that in two US health IT systemsonly about 25% of the data required to phenotype patientswas available in a structured and easily extractable format.Clinicians, researchers, and administrators often need to re-trieve and read these clinical reports to understand the de-tails of patient care. For busy clinicians with limited time therequirement to read large amounts of free-text presents arisk of information overload and consequently missing infor-mation vital to the care of their patients. In the past suchdocuments were often handwritten and stored on paper butin parallel with advances in electronic health records (EHR)many of these free text documents are now generated digit-ally and stored within, or linked to, the EHR [1].Automatically identifying critical information at the pointof care has the potential to reduce the clinical risks associ-ated with missing this information but also represents aconsiderable challenge [3]. The current range of commer-cially available tools such as IBM Watson claim to offersupport that will improve clinical outcomes through moreefficient and accurate document search and text analytics.More generally, there has been considerable research effortto create systems which can reliably identify and extractrelevant information from clinical text. Implementing suchsystems at scale in a clinical environment is difficult. As wesee it, the challenge is twofold. Firstly, from the techno-logical perspective we need reliable and accurate means ofautomatically extracting information using natural languageprocessing methods, and this automatic extraction needs tohappen at scale and be readily available for querying. Sec-ondly, from an operational perspective, such a text analyticssystem would need to be integrated into clinical practice ina way that preserves data security and delivers informationin real-time at point of care.In this paper we present a feasibility study of imple-menting one specific commercial text processing system,IBM Watson Content Analytics,1 using data from theUK National Health Service (NHS). IBM Watson Con-tent Analytics provides an architectural framework forloading, querying, and searching free-text documents atscale. The Content Analytics suite belongs to the familyof IBM Watson products, however unlike some of theother products such as IBM Watson Developer Cloud,2this is a system which can be installed locally. Patientsare rightly concerned that their personal medical datadoes not leave the security of their healthcare providerand local installation is seen as crucial to supporting thedata protection policies that safeguard clinical data. Inprevious work we have argued that this is especially im-portant for free text where the risk of disclosure of sen-sitive information within the text is ever present [4]. Wedesigned [4] and then implemented the Integrated Re-search Campus (IRC) [5], a large scale infrastructure forhealth data analytics to help address these concerns.AimThe aim of our feasibility study was to understand thepotential contributions that a commercial text analyticssystem such as IBM Watson Content Analytics couldmake within Leeds Teaching Hospitals Trust (LTHT), alarge UK NHS hospital. We adopted a case study ap-proach and used IBM Watson to find all radiology re-ports within the hospital database with the incidence oftwo conditions: hydronephrosis and brain metastasis, de-fined as those reports that indicate a positive diagnosisof one of the two conditions (for example we excludepositive mentions from clinical history). We hoped touse this study to identify the range of institutional, tech-nical, and algorithmic factors which could influence theimplementation of clinical text analytics more widely inthe NHS. To understand the generalisability we used thesame architecture on a similar set of radiology reportsextracted from the MIMIC-III open access dataset whichcomes from the Beth Israel Deaconess Hospital in Bos-ton, USA - a different hospital in a different countrywith a very different healthcare system [6]. For this studywe agreed that we would not attempt to benchmarkIBM Watson Content Analytics against alternative toolsor conduct a financial evaluation of its costs andbenefits.Project setupThis feasibility study took place over a three-monthperiod in 2016. The person commitment included onefull-time PhD student in computer science with an hon-orary NHS contract for the duration of the project, anIBM Watson training expert for 1 week, and part-timecommitment from senior academics, including a clinicalexpert. Our IRC information security management infra-structure is ISO 27001 certified and provides secure datastorage and processing facilities in a research environ-ment directly connected to LTHT. Datasets were trans-ferred in anonymised formats under appropriate ethicsand information governance frameworks, and within theIRC data safe facilities. Access was restricted to NHSstaff located within the secure facilities using a secureCitrix connection to an audited, secure Virtual Machinerunning within the IRC on which we installed IBM Wat-son Content Analytics.1https://www.ibm.com/support/knowledgecenter/en/SS5RWK[Accessed 7th June 2018]2https://www.ibm.com/smarterplanet/us/en/ibmwatson/developercloud/ [Accessed 7th June 2018]Piotrkowicz et al. Journal of Biomedical Semantics 2019, 10(Suppl 1):21 Page 2 of 9LimitationsThere were several limitations to our study. Firstly, weuse a case study in a research environment connected toclinical systems, instead of directly within a live clinicalsystem. Secondly, we used historical data, not a livestream. Thirdly, our case study was limited to a smallnumber of report types and clinical conditions, whereasan actual implementation would be a part of a largerpipeline.ContributionsOur contributions are as follows: (i) we present an im-plementation of a large-scale commercial text analyticssystem which uses NHS data, (ii) we present an overviewof IBM Watson Content Analytics and the results of acase study in the radiology domain, and (iii) we showthat a task-specific model generalises across radiologyreports in two different countries (US and UK) for thetwo conditions we chose.Information retrieval (IR) approachesSome of the existing clinical search systems resemblecommonly used search engines like Google. They sharesome traits with most IR systems, such as relying onstring matching and using indexing for quick retrieval ofdocuments from a large repository. Examples includeSTRIDE [7] and CISearch [8]. One issue encountered inthe clinical domain is that the same clinical concept canbe expressed by a wide variety of lexical forms and theiracronyms. In the case of search engines that requiressubmitting multiple queries in order to retrieve as manyrelevant documents as possible. Hanauer et al. [9] ad-dressed this by already identifying UMLS concepts intext (which allows searching concepts, not just lexicalforms), as well as providing the facility to create searchbundles which allow to group appropriate search terms.The advantage of keyword-based clinical IR systems istheir generalisability  since the indexing works on atoken (i.e. individual word) level (more rarely conceptlevel), any type of clinical report can be processed by thesystem. However, the downside of using keyword match-ing without looking at the context is that in many casesirrelevant documents are returned (e.g. when the rele-vant keyword is negated). Taking context into consider-ation requires a deeper linguistic analysis, which is whythere is an increasing drive to use and develop NLPmethods with clinical text.Natural language processing (NLP) approachesThere have been a significant number of research effortsin the domain of natural language processing of clinicaltext. An example of continuing research interest in thisdomain is the inclusion of a biomedical and clinical textanalysis task in the i2b2 [3] and SemEval (SemanticEvaluation) challenges, which are a widely used evalu-ation and benchmarking systems in the field of naturallanguage processing.3 The majority of NLP architecturesto date have relied on a combination of lexical dictionar-ies and rules. More recently, supervised machine learn-ing approaches have also been used.Many of these clinical NLP tasks concern themselveswith the automatic annotation of clinical text, which goesfurther than simple string matching of relevant lexicalforms from medical ontologies. These approaches need toaddress the challenges of clinical text annotation includingmisspellings, context-sensitive abbreviations, and neg-ation. Some of these are already handled by more sophisti-cated IR systems (e.g. handling of misspellings by Hanaueret al. [9]). ConText [10] is an example of an NLP systemthat employs shallow, surface-based methods to annotatea variety of linguistic aspects in clinical documents. Specif-ically, ConText evaluates whether a mention of a clinicalcondition is negated, hypothetical, historical, or experi-enced by someone other than the patient. This is done bymatching certain keywords in text by using dictionariesand using rules to infer the relation between matched key-words. This approach of using dictionaries and rules isquite common for clinical NLP tasks. Unlike machinelearning approaches where patterns are learnt from thedata, rule-based systems are preferred because they pro-vide decision provenance [11]. Furthermore, training ofsupervised machine learning models requires considerablemanual effort to provide annotations [12]. However, anannotated dataset could be reused for training differentmachine learning models, as well as different tasks (e.g.entity recognition, coreference resolution).Hybrid (NLP and IR) systemsHybrid systems combine the strengths of IR and NLPapproaches to allow accurate processing of clinical docu-ments at scale. One of the most successful being thecaTIES system [13] which employs a query-based archi-tecture to process pathology reports within a live clinicalsetting. cTAKES [14] is an open-source toolkit for anno-tating clinical documents that can be customised by add-ing relevant dictionaries.IBM Watson in healthcareIBM Watson is one of a number of commercially availablecognitive computing products that are exciting popularinterest in the transformative potential of artificialintelligence and big data [15], including in the UK NHS[16]. Despite the interest, there is relatively little academicliterature on IBM Watson and its application to healthcare.The most widely cited example of IBM Watson in3See an example here: http://alt.qcri.org/semeval2015/task14/[Accessed 7th June 2018]Piotrkowicz et al. Journal of Biomedical Semantics 2019, 10(Suppl 1):21 Page 3 of 9healthcare is IBM Watson for Oncology [17, 18] developedwith Memorial Sloan Kettering hospital in the USA [19]and focused on providing clinical decision support bymatching patient conditions to those in scientific oncologypublications using NLP. The more widely available NLPtool within the IBM Watson product set is IBM WatsonContent Analytics. This has been used for dermatology[20] and patient safety research and risk management [21].In the UK, IBMWatson is being used on patient generatedtext at Alder Hey NHS Trust [22] but as far as we areaware this paper is the first to explore the possibility ofimplementing IBM Watson on clinical free text in theNHS. In addition, we extended our work to an open accesscorpus from the USA to explore the generalisability of ourrule-based approach to other hospitals and English speak-ing countries.Overview of IBM Watson Content AnalyticsWe present an overview of the IBM Watson ContentAnalytics system in Fig. 1.The system consists of three main components, which(i) import, (ii) parse and index, and (iii) search documents.The Unstructured Information Management Architecture(UIMA) [23] is implemented throughout the system andallows for adding of further components into the pipeline.We will now describe each component in more detail.ImportThe importing of documents can be done as a one-off task(ingestion), or continuously using a crawler in a specifieddirectory. A variety of data formats are handled, includingflat tables, databases, and XML.Parse and indexThe raw documents are first processed. Built-in methodsseparate the documents into smaller chunks (paragraphs,sentences, tokens). Like in standard IR systems, this systemrelies on matching keywords against document text.Keywords can be grouped into dictionaries. For example,any words or phrases describing cancer can be grouped intoa Cancer dictionary. Existing dictionaries can also beuploaded. Dictionary matches in text (optionally with sur-rounding tokens) can be turned into annotation. Each an-notations can be tagged with additional information, e.g.length = n characters, word category = noun. Annotationscan be combined with context information (e.g. tokens orother annotations) into rules. Rule building uses a syntaxsimilar to regular expressions, including grouping and re-peats. The order of annotations or tokens in a group can becontrolled by using ordered or disordered groups. Rules canalso act on different levels of the document, e.g. tokens, sen-tences, or the whole document. For example, a simple rulefor annotating a mention of cancer location could say thatwithin a single sentence there should be an annotation for abody organ and an annotation for a cancer keyword (bothannotations identified using dictionaries) with at most fivetokens in between them. This would match breast cancer,and cancer has metastasized to the brain. Finally, individualrules can be combined into rule sets, which perform a spe-cific language task, e.g. Negation. Finally, any annotationscan be turned into facets, i.e. searchable indices.SearchOnce the documents are processed, they can be searchedusing the index. The use of the index allows for a quick andefficient searching through very large document collections.Specific annotations (e.g. Age, Gender, Condition) from theparsing stage can be used as facets. These facets can beused to search and filter documents. A helpful feature isthe search results view with text snippets with the facetshighlighted in different colors, which allows an at-a-glanceoverview of results without having to open every documentseparately. Facets can also be combined. For example, firstselect all documents which mention a specific condition,then add the Gender facet. Depending on the contents andprocessing of the document some further analytics (e.g.time series) are also available.ResultsIn this section we present the results of our investigationusing IBM Watson Content Analytics for processing thefree-text clinical reports in our case study. We used 5.6Fig. 1 Overview of IBM Watson Content AnalyticsPiotrkowicz et al. Journal of Biomedical Semantics 2019, 10(Suppl 1):21 Page 4 of 9m radiology reports from LTHT in the UK and repeatedour experiments using 0.5 m radiology reports fromsimilar set of radiology reports extracted from theMIMIC-III dataset from the USA [6]. MIMIC-III is anopen access dataset and can therefore be used by otherresearchers interested in reproducing or improving onour approach.Task definitionOur goal is to identify all clinical reports with a positiveincidence of a particular condition. By positive instancewe mean that the condition is diagnosed or identified inthe report (X is noted), and negated instances (withoutX) or historical instances (on admission the patient pre-sented with X) should be excluded.ConditionsWe chose two conditions for the case study: (i) hydrone-phrosis (swelling of a kidney), and (ii) brain metastasis(cancer cells which have spread to the brain from anotherprimary tumour). By looking at two different conditionswe can investigate to what extent the resources andmodels for one condition generalize to another (i.e. whichresources can be reused for different conditions and whichhave to be adjusted or developed from scratch).DataWe used two different radiology datasets. Our primarydataset were the radiology reports from Leeds Patient Path-way Manager (Leeds PPM), the EHR system used by LTHT[24]. We were also interested in using a more widely ac-cessible clinical dataset, which would allow us to comparemethods. Sharing data in the healthcare domain has been alongstanding issue due to the highly sensitive nature ofhealth records and this is especially the case for clinical re-ports, since removing identifiable patient information fromtext is complex and time consuming. The MIMIC-III data-set4 [6] is therefore a very valuable research resource in thatit provides researchers access (subject to conditions) to alarge number of English language free text clinical docu-ments linked to a full set of EHR records and already de-identified and prepared for research use. An overview ofthe two datasets is presented in Table 1.MethodsThe following metaprocess was used in our pilot study.(1) Set up IBM Watson Content Analytics: prepare theserver, training and familiarization(2) Obtain datasets and prepare overview(3) Initial processing: segment all documents intotokens which allows for a simple keyword search(4) Data exploration: using keyword search findconcordances of a condition and study the context(5) Create a random sample of 1000 documents for in-depth analysis and initial development(6) Iterative development of a model: creation ofdictionaries and rule sets(7) Initial evaluation: evaluate precision (i.e. are theannotations and rules correct) using the Watsonanalytics and highlights features(8) Extend model to a bigger sample, and then to thefull dataset(9) Evaluation against a manually annotated goldstandardDictionariesDictionaries of clinical terms for the two conditions(hydronephrosis and brain metastasis) were created by amedical domain expert. Potential additions found in thecorpus during model development were consulted. Wedeveloped separate dictionaries of negative instance indi-cators: negation (e.g. no, without), evaluation (e.g. query,evaluate), clinical history (e.g. admitted, history), reso-lution (e.g. resolved, cleared). These dictionaries wereconsiderably expanded during the iterative developmentprocess by analysing the false positive cases.RulesThe general design behind the rules for this task is that acondition mention is presumed a positive instance, unlessexplicitly negated using a negative instance indicator. Wenow present a simplified rule set for hydronephrosis.Rule set for hydronephrosis (cohesive ConditionKeyword):(1) Create annotations from dictionaries:ConditionKeyword, EvaluationIndicator,NegationIndicator, HistoryIndicator,ResolutionIndicator. Additional dictionaries (e.g.Age, Gender, ICD-9 codes) can be added to use foranalytics in data exploration and search stage.(2) For the ConditionKeyword annotation, create someindication of condition incidence, e.g. present =unknown, polarity = unknown4https://mimic.physionet.org/ [Accessed 7th June 2018]Table 1 Summary of the two radiology data sourcesLTHT PPM MIMIC-IIIEHR datasourceLeeds Teaching Hospitals NHSTrust, Leeds, UKBeth Israel Deaconess,Boston, MA, USAPeriod 19962016 20012012# Patients ~ 1 million ~ 37,000#Documents~ 5.6 million ~ 0.5 millionAv. reportlength70 tokens 206 tokensPiotrkowicz et al. Journal of Biomedical Semantics 2019, 10(Suppl 1):21 Page 5 of 9(3) For each negative instance indicator dictionary(evaluation, negation, history, resolution), create thefollowing rules, where [S ] indicates that thescope of the rule is a sentence:a. If [S NegIndicator ConditionKeyword] thenConditionKeyword/Presence = falseb. If using an ordered group then optionallydepending on data: [S ConditionKeywordFalseInd](4) For any other instance of ConditionKeyword,ConditionKeyword/Presence = true(5) Optional: add lastOccurrence = unknown toConditionKeyword annotation and set to true/false.In the evaluation consider only true instances ifthey are also the last occurrence of theConditionKeyword in the document (this helpswith eliminating historical incidence and ambiguouscases)Extending the hydronephrosis model to brain metastasisThe main difference between the hydronephrosis and brainmetastasis case studies are the keywords indicating the con-dition. Firstly, the dictionary of hydronephrosis keywords is(as far as we know) complete for our case study and thesekeywords point unambiguously at this particular condition.Furthermore, in cases of multiword expressions (e.g. dilatedrenal pelvis), the words occur together, so simple stringmatching is sufficient to create annotations. However, forthe brain metastasis case the condition keywords are some-times non-contiguous (e.g. Within the brain multiple ringenhancing metastatic deposits noted). As they occur separ-ately, two different dictionaries need to be built (Dict1 =brain-related keywords, Dict2 =metastasis-indicatingkeywords), and what follows is that the annotation needs tobe built on the sentence level. Secondly, both brain metasta-sis dictionaries have some issues. The brain-indicating key-words can be ambiguous. Some keywords refer to differentbody parts (e.g. parenchymal, lobe) and it is sometimes diffi-cult to tell definitely just from the report text (however thereport title can be help in disambiguating, e.g. CT Head willpoint to brain parenchyma, but CT Abdomen would not).The metastasis-indicating keywords can be quite generic(e.g. tumour which can indicate both primary and metastatictumours). For example, if brain metastasis is queried expli-citly, then in the findings section the radiologist might notsay brain mets found, but rather multiple lesions found.Because of the context a human will be able to tell that thismeans metastatic lesions in the brain, but it is challenging toimplement computationally because of the long-range refer-ence. The long-range reference is also an issue when infer-ring the location of the tumour (e.g. There are twoenhancing lesions with a moderate degree of surroundingoedema. The largest measures 2.7 cm and is in the leftfrontal lobe. The second measures 1.5 cm and is located inthe right occipital lobe.). While the models for the two con-ditions differ, some elements (e.g. negative instance diction-aries) can be effectively reused, saving development time.Extending the model to a different datasetWhile each condition required a customised model, wefound that once models had been developed they were ef-fective on both the data from the UK and from the USA,two very different hospitals, countries and healthcare envi-ronments. We believe this is because there is a significantoverlap in medical training and terminology across the Eng-lish speaking world, especially in the case of technical clin-ical reports such as those written in radiology. Weacknowledge that despite similarities in jargon, there are stillcountry- or institution-specific conventions (e.g. use of cer-tain acronyms) and differences of spelling between UK Eng-lish (e.g. tumour) and US English (e.g. tumor). Someconventions are more localised (e.g. frequent use of assessfor Report Indication in the US dataset), but these were eas-ily resolved by adding some new terms to the relevant dic-tionary. This addresses the point made by Pons et al. [25]that most clinical NLP systems are specific to an institution,which hinders their wider implementation. We showed thatfor the same task our models work across two very differentsources. Moreover, the evaluation using MIMIC-III can leadto models being more commonly shared and compared.ResultsFor this preliminary investigation we report the resultsof our models on a small sample of radiology reports.For each condition we randomly sampled from the train-ing set 50 reports predicted positive and 50 reports pre-dicted negative. Without indicating the labels we asked aclinical oncologist to annotate the reports as a positive/negative instance. We report the results in Table 2.Overall, we achieved very high results  at least 84% pre-cision and 88% recall. The models perform better forhydronephrosis, which can be due to the challenges wenoted above for the brain metastasis model.DiscussionResults of this three-month pilot project for the task ofclinical document retrieval were very promising. Wetook a simple, shallow NLP approach, which combinedwith the IBM Watson Content Analytics architectureand functionalities allowed us to process millions of doc-uments in a relatively short period of time (e.g. a subsetof 50,000 documents used to develop initial rule setstook approx. 30 min to process). We tested our modelson a small manually annotated sample and obtainedhigh precision and recall values. We made the followingobservations during the study.Piotrkowicz et al. Journal of Biomedical Semantics 2019, 10(Suppl 1):21 Page 6 of 9GeneralisabilityWe found that the models worked best when they weretask-specific. In the case of hydronephrosis the conditionkeywords are both cohesive and specific, which allows us toaccurately identify the condition mentions in text. For thebrain metastasis case study we observed that the conditionkeywords are often separated, sometime across sentences.They are also fairly generic and ambiguous keywords, whichmakes finding relevant documents difficult. In terms of ex-tending our methods to other conditions, we hypothesisethat as long as the new condition follows the same patternsas an implemented model, then it should be the simple caseof replacing the condition dictionary and running the modelfor the same type of report (e.g. a condition with very spe-cific keywords could reuse the hydronephrosis model). Evenfor the more challenging cases like brain metastasis, themodel might be re-implemented for similar conditions (e.g.lung metastasis), where only the tumour location dictionarywould need to be replaced. More broadly, the negative in-stance indicators can be reused across conditions. However,this probably would not hold for more distinct types of clin-ical reports, e.g. negation in radiology is very explicit (no, noevidence of, without), but in clinical notes implicit negationcould be present as well (e.g. patient denies feeling numb-ness). Finally, the dictionaries we used were only developedand evaluated within a single institution. When applied toother collections of radiology reports, our dictionaries mightaccount for the standard set of terms and their spelling, butthere might be some further institution- or country-specificterms or acronyms which would need to be added.Handling difficult casesWhen conducting the error analysis we noted somecases which present a significant challenge for the auto-matic processing of clinical reports (cf. Table 3). Thefirst case can be ambiguous depending on the task set-ting  if looking at condition incidence in reports, thenit should be treated as negative according to our defin-ition, however if looking at patient incidence, then thiswould be considered as a positive cases. Clear task defi-nitions based on requirements are needed to avoid falsepositives. The second case is ambiguous due to the radi-ologists phrasing  without frank hydronephrosis, inthis case a system which values recall over precision (e.g.if the goal was to find any and all potentially positivecases for quality assurance) would need to treat this as apositive case. Although rare, these cases still need to beaccounted for and clinical domain experts should decidewhether such a case should be considered positive ornegative. Finally, the third case shows how modality(raised the possibility) can lead to false positives. Forsuch cases we introduced an optional rule, whereby thelast condition mention in a report is treated as the oneto be used for indexing. Overall, we recommend a thor-ough error analysis, which can point to such cases andthus help to refine the models.Technical notes about the systemThe processing speeds were monitored throughout theproject, however due to technical problems with the ser-ver infrastructure, the performance of the system varied.We noted that on average simple indexing (i.e. tokenisa-tion which enabled free-text search) of documents wasabout 200 documents per second. More sophisticatedindexing which included multiple dictionaries and rulesets took on average about 30 documents per second.We also noted that the data ingestion is quite sensitiveto the formatting, which necessitates robust data clean-ing. This is a considerable issue, since in our experienceclinical text data does not have high-quality formatting.Similarly, the data export in CSV format failed, becausethere was no way to protect the text data, which resultedin misaligned data. Exports in other formats had no suchissues, so post-processing to derive data in CSV formatis possible. Finally, we noted the advantage of the paral-lel architecture implemented in the system, which allowsfor simultaneous importing, parsing and searching ofdocuments, resulting in significant time savings.LimitationsThis feasibility study aimed to provide feedback to NHSstakeholders and IBM about advantages/disadvantagesand issues in implementing a commercial text analyticssystem for use with clinical free-text reports. Our focuswas on the technical infrastructure needed to set up acommercial system that could use NHS data in a waythat preserves best data governance practices. We estab-lished that this is possible through the use of data safefacilities between the NHS trust and the IRC howevermost hospitals do not have access to such a researchTable 2 Precision and recall results for the preliminaryexperimentsHydronephrosis Brain metastasisLTHT PPM MIMIC-III LTHT PPM MIMIC-IIIPrecision 94% 93% 89% 84%Recall 95% 96% 94% 88%Table 3 Examples of challenging cases of hydronephrosisincidenceReason: Evaluate for effusion; Admitting Diagnosis: HYDRONEPHROSISThe right kidney is considerably lower in location than the left withslight pelviectasis but without frank hydronephrosisFINDINGS: [] Initial images raised the possibility of mild bilateralhydronephrosis; however, repeat imaging with a different probe and indifferent positions suggests that this is likely fat hypertrophy within therenal sinus bilaterally. [] IMPRESSION: No definite hydronephrosis.Piotrkowicz et al. Journal of Biomedical Semantics 2019, 10(Suppl 1):21 Page 7 of 9environment. A limitation of our study is therefore thatwe conducted our case study in a research environmentconnected to clinical systems rather than in the live clin-ical system itself. This was for the obvious reason thatwe needed to avoid any possibility of the researchimpacting on the care of patients within the hospital, forexample by data processing demands slowing down thelive servers. Similarly, we used the full set of availablehistorical data collected over many years recognisingthat there may be temporal drift in the use of languageand terms over the 10 year time period. Our case studywas limited to a small number of report types and clin-ical conditions, whereas an actual implementation wouldbe a part of a larger pipeline. In addition to technicalfactors of such integration, there are also the significantissues of acceptability and usability by NHS staff.ConclusionsIn this paper we presented the results and observationsfrom a feasibility study on implementing a commercialtext analytics system  IBM Watson Content Analytics with free-text clinical reports obtained from the NHS. Wefirst presented an overview of the IBM Watson ContentAnalytics architecture. We then described our methodsand results using this architecture for two examples fromradiology: hydronephrosis and brain metastasis. The IBMWatson Content Analytics system allowed us to build arule-based NLP model and apply it to millions of docu-ments. Although the system scaled up to large datasets, itstill required considerable manual input to create diction-aries and rule sets. However, we found that although weneed to customise the models for each task, some re-sources and models could be reused between the twodatasets with only some adjustments. We believe it is sig-nificant that our task-specific models generalise acrossradiology reports from two very different countries (UKand USA) for the two conditions we chose.Our approach does allow us to reflect on the remainingimplementation challenges. IBM Watson Content Analyt-ics has the functionality to continuously ingest new dataas a live data stream and output results through its userinterface or as an output data stream. We therefore envis-age a live data stream of radiology reports into the text an-alytics engine which returns a stream of coded resultsback into the EHR in the form of coded events and asalerts. In common with many other EHRs, LTHTs PPMsystem has a) the ability to store and display such codedevent data so that it can be reviewed by clinicians at pointof care and b) an alerts system that can be set to notify cli-nicians of events of concern. Arguably, now that the textprocessing rules have been developed there is a case thatthey could be implemented directly as programme codewithin the EHR itself and this would reduce costs and im-prove processing speed. However, processing speeds of 30documents per second suggests that system will alreadyperform significantly faster than both human interpret-ation and the rate of production of new reports. Inaddition, IBM Watson Content Analytics provides a richset of features for the continuous evaluation and improve-ment of NLP text analytics rules and we envisage a learn-ing health system [26] where there is an ongoingrequirement for text analytics rules that are extended, re-fined and improved on to account for temporal drift andmake continuous improvements in patient safety. The im-plementation of user interface changes and alerts toachieve this within clinical settings is, in itself, a complexdomain and is beyond the scope of this study.In our study we found it was feasible to use IBM Wat-son Content Analytics within the UK NHS but there areother good large-scale text analytics systems availablesuch as cTAKES, GATE and other commercial plat-forms. We note that IBM Watson Content Analyticsuses the UIMA content analytics standards to supportthe transfer of dictionaries and models between differentsystems and we believe this presents an opportunity toseparate the discussion on tools and rules from the dis-cussion on implementation. We therefore envisage fur-ther work along three lines of investigation: a) whattools and techniques are best for generating and refininghealthcare text analytics dictionaries and models? b)what are the optimum rules, dictionaries and models foreach clinical condition given the inevitable trade-off be-tween global generalisability and local language, cultureand custom as clinical text evolves over time? and c)how best to implement text analytics rules, dictionariesand models within real time live clinical environments?Our feasibility study suggests that healthcare text analyt-ics is sufficiently advanced to be operationalised withinEHR solutions. The biggest challenge ahead is likely tobe the design and implementation of real time process-ing solutions which will demonstrate the promised stepchange in clinical safety.AbbreviationsEHR: Electronic Health Record; IR: Information Retrieval; IRC: IntegratedResearch Campus; LTHT: Leeds Teaching Hospitals Trust; NHS: NationalHealth Service; NLP: Natural Language Processing; PPM: Patient PathwayManager; UIMA: Unstructured Information Management Architecture;UMLS: Unified Medical Language SystemAcknowledgementsThe authors would like to thank the Leeds Teaching Hospitals Trust and IBMUK for their support in this project. An initial version of this paper has beenpresented at the Healthcare Text Analytics Conference 2018 (HealTAC) inApril 2018.About this supplementThis article has been published as part of the Journal of BiomedicalSemantics Volume 10 Supplement 1, 2019: HealTAC-2018: Unlocking Evi-dence Contained in Healthcare Free-text. The full contents of the supple-ment are available online at https://jbiomedsem.biomedcentral.com/articles/supplements/volume-10-supplement-1.Piotrkowicz et al. Journal of Biomedical Semantics 2019, 10(Suppl 1):21 Page 8 of 9Authors contributionsAP preprocessed the data, and developed and analysed the models. OJ andGH made substantial contributions to conception and design, acquisition ofdata, and result interpretation. AP and OJ wrote the manuscript. All authorsread and approved the final manuscript.FundingThe work was commissioned by Leeds Teaching Hospitals Trust (LTHT) aspart of an evaluation of IBM Watson. Funding was provided by Leeds Cares,a charitable trust that supports research and innovation at LTHT. IBM UKsupported the project with access to software and supporting consultancybut did not provide or receive any funding. AP is also supported by theUniversity of Leeds Wellcome Trust Strategic Support Fund. Publication costsare funded by the Wellcome Trust.Availability of data and materialsNot applicable.Ethics approval and consent to participateThe work was conducted by research and informatics staff contracted toLeeds Teaching Hospitals Trust Informatics Department using anonymisedretrospective data from the Trust. Approval to perform the study wasobtained from Leeds Teaching Hospitals Trust Research and InnovationDirector and the Trusts Information Governance lead.Consent for publicationNot applicable.Competing interestsThe authors declare that they have no competing interests.Author details1Leeds Institute of Medical Education, University of Leeds, Leeds, UK. 2LeedsTeaching Hospitals Trust, Leeds, UK. 3School of Computing, University ofLeeds, Leeds, UK. 4School of Medicine, University of Leeds, Leeds, UK.Published: 12 November 2019RESEARCH Open AccessPhenotype annotation with the ontology ofmicrobial phenotypes (OMP)Deborah A. Siegele1, Sandra A. LaBonte2, Peter I-Fan Wu2, Marcus C. Chibucos3, Suvarna Nandendla3,Michelle G. Giglio3 and James C. Hu2*AbstractBackground: Microbial genetics has formed a foundation for understanding many aspects of biology. Systematicannotation that supports computational data mining should reveal further insights for microbes, microbiomes, andconserved functions beyond microbes. The Ontology of Microbial Phenotypes (OMP) was created to support suchannotation.Results: We define standards for an OMP-based annotation framework that supports the capture of a variety ofphenotypes and provides flexibility for different levels of detail based on a combination of pre- and post-composition using OMP and other Open Biomedical Ontology (OBO) projects. A system for entering and viewingOMP annotations has been added to our online, public, web-based data portal.Conclusions: The annotation framework described here is ready to support projects to capture phenotypes fromthe experimental literature for a variety of microbes. Defining the OMP annotation standard should support thedevelopment of new software tools for data mining and analysis in comparative phenomics.Keywords: Annotation, Phenotypes, Ontology, Biomedical ontologies, Curation, Microbial phenotypes, Microbialgenetics, MicrobiologyBackgroundPhenotypes are the result of the interaction of a particulargenotype with an environment. An organisms phenotypeswill vary in different environments or life stages. Just as wesee the arctic foxs fur change in color and thickness assummer warmth changes to winter cold [1], we can alsoobserve changes in microbes as their environments change.For example, when faced with nutrient depleted environ-ments some bacteria will change their phenotype fromvegetative cells and become spores that can survive adverseenvironments [2]. Other bacteria switch from swimming toswarming motility in viscous environments or when mov-ing across a surface [3, 4]. Likewise, if a change occurs inthe underlying DNA sequence of an organism, creating anew genotype, a change in the phenotype may be observed.Linking particular phenotypic changes to changes in spe-cific genes provides the raw material for understanding thevast variety in biological form and function and is key togenetic dissection of biological processes. Microbial genet-ics has played a central role in the history of molecular biol-ogy. The unity of biology is reflected in how insights basedon microbial model systems have informed the understand-ing of the biology of other clades, including humans.The Ontology of Microbial Phenotypes (OMP) [5] wascreated for the systematic annotation of the phenotypes ofmicrobes (e.g. bacteria, archaea, viruses, protists, etc.) in acommon framework that supports computational datamining and analysis. The current release of OMP contains1880 terms describing phenotypes associated with all as-pects of microbial life (e.g. morphology, growth, metabol-ism). Each OMP term consists of a term name (or label),definition, and unique identifier. For example, the termwith id OMP:0000041 has the name increased cell sizeand the definition An altered cell size phenotype wherethe volume of a cell or cells is increased relative to a desig-nated control. The association of an OMP term id with aparticular gene variant or allele indicates that the genotypein question, when found in a particular environment, leadsto the phenotype described by the OMP term.© The Author(s). 2019 Open Access This article is distributed under the terms of the Creative Commons Attribution 4.0International License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, andreproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link tothe Creative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver(http://creativecommons.org/publicdomain/zero/1.0/) applies to the data made available in this article, unless otherwise stated.* Correspondence: jimhu@tamu.edu2Department of Biochemistry and Biophysics, Texas A&M University andTexas AgriLife Research, College Station, TX, USAFull list of author information is available at the end of the articleSiegele et al. Journal of Biomedical Semantics           (2019) 10:13 https://doi.org/10.1186/s13326-019-0205-5Previously, Chibucos et al. [5] described the ontology de-sign principles we incorporated into developing OMP. Here,we provide a formal description of OMP annotations, ex-tending the concepts initially proposed in Chibucos et al.[5]. The annotation system to be described here can capturea broad variety of phenotypes from type strains, mutants,and genetic suppressors and enhancers in all kinds of micro-bial systems. The OMP annotation framework and a wiki-based online interface are being used to collect and displaymicrobial phenotype annotations using OMP terms.ResultsThe elements of an OMP annotationFigure 1 lists the components of an OMP annotation, eachof which will be discussed below. Specific fields in Fig. 1 willbe referred to in parentheses. We maximize the use of inter-operable ontologies and computable identifiers in OMP an-notations, however, for some information types we currentlyuse free text content if other more systematic solutions arenot yet available.Annotation IDAll OMP annotations are assigned a unique ID (1.1),which consists of an OMP_AN prefix followed by aninteger and an optional suffix used for annotations madeby other groups. These are currently created through theannotation web interface (described below). We assignstable identifiers to each annotation for two reasons: totrack corrections to an annotation if needed, and toallow one annotation to make reference to another an-notation as described in more detail below.Annotation objectAlthough phenotypes are often discussed in terms of as-sociation with genes, in fact phenotypes are manifesta-tions of the combination of genotype, environment, anddevelopmental stage or cell type. In an OMP annotation,genotype and environment information is captured inthe Genotype and Environment fields of the phenotypedescriptors, while life stage or cell type is captured inthe Annotation Extension field.In this context we need a stable identifier for anygenotype that will be subject to phenotype annotation.Ideally, we would reuse an existing resource in the waythat GO annotation can reuse identifiers from global re-sources such as UniProt. A variety of stock centers andcollections such as ATCC associate genotypes with astable identifier. Also, genome accessions at GenBankFig. 1 Phenotypes in the OMP wiki. a An Annotations table on a Strain page. Two annotations are shown. The interface calculates differences in thegenotype and conditions for each annotation compared to the reference annotation. In the second row, the comparison is to a strain that is not isogenic,so multiple allele differences are shown where only one is likely to be causative. b Editing interface using TableEdit. This shows how an existing annotationcan be edited. OMP and ECO term names are filled in from the IDs by a database lookup. Conditions are entered as multiple key-value pairs where allowedkeys are selected from a pull-down menu. These include, ENVO term, temperature, pH, medium, and other. Extensions and Notes are entered as free textSiegele et al. Journal of Biomedical Semantics           (2019) 10:13 Page 2 of 8are available for microbial genomes that have been se-quenced. However, these external resources are not suffi-cient, because a substantial fraction of the literatureinvolves strains that have not been sequenced or have notbeen deposited in any collections. Because there is no ex-ternal resource that provides unique identifiers to the widerange genotypes that OMP will be used to annotate, webuilt this capability into the OMP annotation infrastruc-ture. Genotype ID (2.1) is a unique stable ID that hasOMP_ST: as a prefix followed by an integer. Each ID is as-sociated with information about a particular microbialsubstrain, including known alleles, episomes, and ancestry.If available, a source for obtaining the strain is included,along with a reference for where the strain was describedin the literature. Where available, stable identifiers fromgenomes or other resources can be added.In many high-throughput microbial phenotype studies,where the fitness of a large number of mutants are beingcompared across a large number of growth conditions,the fitness of each individual mutant is measured relativeto the average fitness of all the mutants in the collectionrather than to the fitness of the parental strain [68]. Tocapture these relative phenotypes in OMP, we have cre-ated special virtual strains that represent the average be-havior of the particular collection of mutants used in aparticular study. The virtual strain is used as the refer-ence strain that each individual mutant is compared to.For capture of environment (2.2), we prefer to useontology-based descriptors such as ENVO terms [9, 10].However, ENVO does not currently contain the termsneeded for microbial phenotype annotations. While termdevelopment and annotation practice are being workedout with the ENVO team, we use the placeholder condi-tions field (2.3) for a free text description of the environ-mental conditions where the phenotype was observed.PhenotypeFour fields (OMP term, Relative to, Qualifier, and Exten-sions) combined together form an ontology-basedphenotype description.An OMP term (3.1) and Extensions (3.2), if any, de-scribe the phenotype. Mungall et al. [11] describe howpre-composition and post-composition of phenotype de-scriptions are used by different phenotype annotation pro-jects. Briefly, pre-composition consists of using ontologyterms with sufficient granularity to capture the desiredlevel of specificity in the annotation system, while in post-composition curators can extend the specificity ofannotations by combining less specific terms at annota-tion time from interoperable ontologies.The OMP term (3.1) is a pre-composed phenotype de-scription defined by the ontology. Extensions (3.2) is anoptional field that can hold zero to many entries to pro-vide more information about the phenotype. Each exten-sion entry is a pairing of a relationship based on the OBOrelations ontology [12] and one or more identifiers.The Relative to field (3.3) is used in a specific kind of an-notation. There are two kinds of OMP terms to supporttwo kinds of phenotype annotations: independent anddependent [5]. Independent phenotypes are phenotypes ofmicrobes that can be described without reference to an-other observation. For example, a microbe either has theability to become motile or is nonmotile. By contrast, de-scription of a dependent phenotype requires reference toanother annotation. For example, increased or decreasedmotility might be observed when comparing a mutant vswild-type strain or a single strain in different environments.To capture dependent phenotypes, the optional Relative tofield holds the OMP_AN identifier for the reference pheno-type used in the comparison. In many instances, the curatorwill need to start with creating the annotation for the refer-ence phenotype.Qualifier (3.4, optional) can modify the meaning ofthe observation. There are currently three allowed valuesfor qualifiers (Table 1).EvidenceOMP annotation captures the evidence for a phenotypeobservation with two fields. Evidence (4.1) uses termsfrom the Evidence and Conclusion Ontology (ECO) [13]to capture the type of experiment used and Reference(4.2) provides an identifier for the source of the observa-tion in the literature, usually in the form of a PubMed ID.MetadataHistory (5.1) records revision history of the annotation,including a timestamp for when an annotation was cre-ated or changed and who made the changes.Finally, the annotation system provides an optionalfree text notes (5.2) field for information that could beof value that does not fit into the fields described above.For example, notes could be used to explain revisions orspecify where a phenotype is described in a paper. Notescould include links to term requests at OMP, ENVO,ECO, or ChEBI needed to refine the annotation.Table 1 Allowed qualifiers and when to use themNot Indicates that a phenotype was tested for, but was not observed.Same phenotype as reference strain Indicates that a change in genotype does not change the observed phenotype.Same phenotype as in reference condition Indicates that a change in environment does not change the observed phenotype.Siegele et al. Journal of Biomedical Semantics           (2019) 10:13 Page 3 of 8Online system for viewing, creating and editingannotationsOMP annotations have been added to the OMP wiki [14],which previously focused on pages for OMP and ECOterms [5]. A system for managing strains and substrains(unpublished) was developed that creates pages for eachstrain/genotype used in OMP annotation. Strain pages areassigned OMP_ST unique identifiers upon page creation,and the pages include a table for annotations based on theTableEdit Mediawiki extension (unpublished) combinedwith extra capabilities written specifically for OMP anno-tation tables. Figure 2 shows an example of an annotationtable in the wiki and the editing interface.Each row in the table represents one annotation, whereall the annotations in that table share the OMP_ST ID forthe page bearing the table. In addition to the specified an-notation component fields described above, the user inter-face fills in the term name for an entered OMP_ID and anextension to the MediaWiki software calculates differ-ences in the genotype and conditions relative to the refer-ence annotation in the relative_to field as described inMethods. An auto-incremented OMP_AN ID is createdwhen the annotation is saved.DiscussionWhile developing the annotation system for OMP, weexamined the annotation formats used by other species-specific microbial phenotype projects. The systems usedfor Saccharomyces cerevisiae [15], Schizosaccharomycespombe [16], and Dictyostelium discoideum [17] appear tobe different from one another. The MicrO project [18]provides an alternative ontology for bacterial and ar-chaeal phenotypes and related concepts (e.g. media) butappears to currently emphasize supporting MicroPIE[19] natural language processing, and we did not find acomparable annotation format for use of MicrO. Thus,we decided that developing a distinct universal system tounify annotation would be beneficial.Insofar as we are building OMP to allow data miningacross studies and across microbial species, our annotationsystem does not capture quantitative fitness scores or mea-sures of growth rates, mutation rates, or other numeric data.Pre vs post-composition in OMPOMP uses a combination of pre- and post-composed ap-proaches to describe phenotypes in annotations. TheOMP ontology [5] consists of pre-composed terms thatrange from broad classification of phenotypes to termsof intermediate specificity where groupings are poten-tially useful. For example, OMP:0000336 beta-lactam re-sistance phenotype and its child terms are used whenthe chemical described in the extension is a beta-lactam,such as penicillin, ampicillin, methicillin etc. Beta-lactamantibiotics are defined by the presence of a beta-lactamring, which is important for their biological effects onpeptidoglycan synthesis in the Bacteria [20]. Phenotypesfound for a particular beta-lactam are likely to be in-formative for the effects of other beta-lactams. Retriev-ing annotations to these intermediate terms wouldsupport analyses that compare and contrast resistance todifferent members of the antibiotic class, such as thesubstrate specificity of beta-lactamases [21].The OMP consortium policy is to limit pre-compositionto these intermediate levels, rather than pre-compose a dif-ferent OMP term for every different beta-lactam antibiotic,even though differences in antibiotic resistance spectrum arepotentially useful. Similarly, we do not pre-compose OMPterms for other detailed phenotypes, such as resistance to aparticular species of phage, or utilization of a specific nutri-ent. In these cases, a pre-composed set of terms for everyphage and every chemical utilized by a microbe would leadto an astronomical explosion in the size of the ontology.By contrast, the purpose of the annotation extensionfield in the system described here, which is modeled onthe similar extensions used in Gene Ontology Annota-tion [2224], is to increase our ability to express specificphenotypes at annotation time without creating newpre-composed OMP terms. Extensions can be used tospecify the drug used in an antibiotic resistance pheno-type, the cell type where a phenotype is observed (e.g. le-thal during spore germination), or other relevantinformation such as penetrance.For example, to describe phenotypes relating to resist-ance or sensitivity to a chemical, OMP contains a varietyof pre-composed terms including those shown in Fig. 3a.To identify the specific chemical used in a study, the an-notator would add to the annotation extension field aCHEBI ID (or other stable identifier for the chemical), andlink the OMP term to the chemical with a towards rela-tionship (RO:0002503) from the Relationship Ontology(RO) [12] (Fig. 3b). Figure 3c shows additional examplesof how the annotation extension field is used in OMP.Many microbial phenotypes can be described withpre-composed terms, and some species-specific pheno-type annotation systems, such as FYPO [16], are basedon extensive pre-composition. The availability of pre-composed terms facilitates community annotation, butcan lead to the creation of large numbers of highly spe-cific terms, which can make the ontology unwieldy, es-pecially in an ontology like OMP that coordinatesannotation across many taxa.Post-composition with extensions does not alter theontology itself. Editing the OMP ontology itself is doneas described in Chibucos et al. [5]: term-related requestsare gathered via a GitHub issue tracker and changes inthe ontology are done using standard ontology editingtools to generate .obo and .owl files, which are periodic-ally released.Siegele et al. Journal of Biomedical Semantics           (2019) 10:13 Page 4 of 8Fig. 2 (See legend on next page.)Siegele et al. Journal of Biomedical Semantics           (2019) 10:13 Page 5 of 8Future directionsPopulating the corpus of microbial phenotype dataAlthough we expect that collaborations with otherontology projects and other work in our group will leadto refinements that decrease the use of free text, theannotation system described here should be sufficient tosupport curation of microbial phenotypes from the lit-erature. Curation projects are ongoing to add pheno-types from high-throughput studies from E. coli, B.subtilis, S. pombe, and S. cerevisiae. As each of these(See figure on previous page.)Fig. 2 Phenotypes in the OMP wiki. a An Annotations table on a Strain page. Two annotations are shown. The interface calculates differences inthe genotype and conditions for each annotation compared to the reference annotation. In the second row, the comparison is to a strain that isnot isogenic, so multiple allele differences are shown where only one is likely to be causative. b Editing interface using TableEdit. This shows howan existing annotation can be edited. OMP and ECO term names are filled in from the IDs by a database lookup. Conditions are entered asmultiple key-value pairs where allowed keys are selected from a pull-down menu. These include, ENVO term, temperature, pH, medium, andother. Extensions and Notes are entered as free text.ABCFig. 3 Post-composition with the extensions field. a Example of OMP terms with pre-composed groupings at the level of resistance to chemicals.b Use of an extension to specify increased resistance to acriflavine hydrochloride using the Relations Ontology term RO:0002503 (towards) to linkthe ChEBI term CHEBI:74728 (acriflavine hydrochloride) to the OMP term for increased resistance to a chemical. c Other uses of the RO:0002503(towards) relationship include specifying increased resistance to a beta-lactam (ampicillin), decreased organic carbon source utilization (lactose),and decreased sensitivity to a bacteriophage (bacteriophage Chi)Siegele et al. Journal of Biomedical Semantics           (2019) 10:13 Page 6 of 8presents specific challenges and issues, the details ofthese contributions to the overall corpus will be de-scribed elsewhere.Export formatsA goal for OMP is to provide phenotype data consistentwith FAIR principles [25]. Toward the goal of improvinginteroperability and reuse, we are working on a systemfor regular releases of the corpus of OMP annotations.We are modeling our first data release specification onthe GPAD+GPI system used by GO [22, 26]. For OMP,we would generate a pair of tab-delimited files. One ofthese would contain the annotation fields specified here,while the second would include information associatedwith the genotype in the annotation object. The geno-type representation system is under development.As an alternative to tab-delimited text, it should bepossible to export OMP annotations and the associatedgenotype information as JSON or JSON-LD [27].ConclusionsWe describe a framework for the use of OMP to makephenotype annotations. This system is in active use forthe annotation of phenotypes for Escherichia coli, Bacil-lus subtilis, Saccharomyces cerevisiae, Schizosaccharo-myces pombe,and other microbes.. A wiki-based onlineinterface allows viewing of annotations and community/collaborative curation of phenotype annotations.The OMP annotation standard, as defined here, willsupport the development of new software tools for datamining and analysis in comparative phenomics.MethodsThe annotation system as described here is a platform-independent specification.The OMP wiki [14] implementation of the annotationsystem is based on the open source Mediawiki softwareplatform [28]. The OMP wiki is currently running onMediawiki 1.31 using php7.2 and MySQL 5.7 with cus-tomized extensions to support biological wikis andontology projects [29] and additional software exten-sions developed specifically to support OMP projects.The OMP wiki is currently a virtual host on a singleLinux server at Texas A&M shared with other projects.Extension code is open source and available at ourGitHub repository [30].The OMP and ECO ontologies are downloaded fromour central repositories daily and parsed into a localmysql database, obo_archive, with a custom schema thatincorporates version history for every ontology term.The annotation system within the wiki is controlled bya custom extension for the OMP project, which in turnbuilds on TableEdit [31], an extension for managingstructured tabular data in MediaWiki, and TableEdit-based code modules developed for ontology wiki pro-jects [29]. The template for the annotation form isdefined by a page in the wiki, Template:OMP_annota-tion_table, which controls formatting and callbacks forthe displays in Fig. 2a (viewing mode) and b (editingmode). The annotation editing form (Fig. 2b) uses obo_archive to look up current term names when a curatorenters OMP or ECO ids.Each phenotype annotation is stored as a TableEditrow associated with a specific TableEdit table on agenotype page. Each genotype page also contains aTableEdit table with genotype information defined bya different TableEdit template: Template: Strain_info_table. To calculate possibly relevant differencesin genotype and conditions, the extension uses theunique annotation id in the Relative to field to findthe content of the conditions field in the referenceannotation, and the genotype on the page where thereference annotation is stored. The genotype andconditions fields for the reference and dependent an-notation are then tokenized with a regular expres-sion and the differences are calculated by comparingarrays of unique tokens for each field.AbbreviationsChEBI: Chemical Entities of Biological Interest; ECO: Evidence and ConclusionsOntology; ENVO: Environment Ontology; FYPO: Fission Yeast Phenotype Ontology;GO: Gene Ontology; OBO: Open Biomedical Ontologies; OMP: Ontology ofMicrobial Phenotypes; RO: Relations OntologyAcknowledgementsThe authors thank Oliver He for encouraging us to submit to this special issue, andSuzi Lewis for including us in the Phenotype RCN conferences, and participants inthe Phenotype RCN for many helpful discussions.Authors contributionsJH, MG, and DS oversee the OMP project. JH, DS, and SL wrote the manuscript withinput from the other authors. JH, DS, SL, and PW worked on annotation standardsand examples. DS, MC, SN, and MG manage OMP ontology development. MC, SN,and MG coordinate with the ECO project for evidence capture in the annotationsystem. JH and SL performed mediawiki extension development. All authors readand approved the final manuscript.FundingThis work was supported by a grants from the National Science FoundationDivision of Biological Infrastructure [1458400] and the National Institutes ofHealth [R01GM089636, U41HG008735].Availability of data and materialsData sharing is not applicable to this article as no primary datasets weregenerated or analyzed during the current study. Individual annotations can beviewed at the OMP wiki [14]. Plans for dissemination of the annotation setsgenerated using the annotation system described here are discussed in the text.Software developed for the work described in this article (Mediawikiextensions) are available from our GitHub repository [14].Ethics approval and consent to participateNot applicable.Consent for publicationNot applicable.Competing interestsThe authors declare that they have no competing interests.Siegele et al. Journal of Biomedical Semantics           (2019) 10:13 Page 7 of 8Author details1Department of Biology, Texas A&M University, College Station, TX, USA.2Department of Biochemistry and Biophysics, Texas A&M University andTexas AgriLife Research, College Station, TX, USA. 3Institute for GenomeSciences, University of Maryland School of Medicine, Baltimore, MD, USA.Received: 18 September 2018 Accepted: 19 June 2019