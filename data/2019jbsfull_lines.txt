RESEARCH Open Access
Ontology-based specification and
generation of search queries for
post-market surveillance
Alexandr Uciteli1*, Stefan Kropf1*, Timo Weiland2, Stefanie Meese2, Klaus Graef2, Sabrina Rohrer2, Marc O. Schurr2,
Wolfram Bartussek3, Christoph Goller4, Philipp Blohm4, Robin Seidel5, Christian Bayer5, Manuel Kernenbach5,
Kathrin Pfeiffer5, Wolfgang Lauer5, Jörg-Uwe Meyer6, Michael Witte6 and Heinrich Herre1*
Abstract
Background: The vigilant observation of medical devices during post-market surveillance (PMS) for identifying
safety-relevant incidents is a non-trivial task. A wide range of sources has to be monitored in order to integrate all
accessible data about the safety and performance of a medical device. PMS needs to be supported by an efficient
search strategy and the possibility to create complex search queries by domain experts.
Results: We use ontologies to support the specification of search queries and the preparation of the document
corpus, which contains all relevant documents. In this paper, we present (1) the Search Ontology (SON) v2.0, (2) an
Excel template for specifying search queries, and (3) the Search Ontology Generator (SONG), which generates
complex queries out of the Excel template. Based on our approach, a service-oriented architecture was designed,
which supports and assists domain experts during PMS. Comprehensive testing confirmed the correct execution of
all SONG functions. The applicability of our method and of the developed tools was evaluated by domain experts.
The test persons concordantly rated our solution after a short period of training as highly user-friendly, intuitive and
well applicable for supporting PMS.
Conclusions: The Search Ontology is a promising domain-independent approach to specify complex search
queries. Our solution allows advanced searches for relevant documents in different domains using suitable domain
ontologies.
Keywords: Ontology, Information retrieval, Search queries, Spreadsheet-based ontology specification, Ontology
generation, Post-market surveillance
Background
According to the provisions of the current European
Medical Device Directive 93/42/EEC [1, 2] and the new
European Medical Device Regulation (applicable as from
May 2020) [3], each manufacturer of medical devices
has to set up a comprehensive system in order to iden-
tify, evaluate and integrate clinical data derived from the
field application of a medical device after market access
during post-market surveillance (PMS). Small and
medium-sized enterprises in the field of medical devices
are in need for operable systems for post-market data re-
trieval in order to enhance their PMS strategies and to
be prepared for the growing requirements of the new
European Medical Device Regulation.
A wide range of both internal (own quality manage-
ment and compliant system) and external (scientific da-
tabases, medical congresses, internet-based knowledge &
experiences, PMS by competent authorities) sources
have to be monitored in order to integrate all accessible
data about a medical devices safety and performance.
Currently, these detailed, continuous searches are still
performed manually with a high input of time and
personnel resources, making PMS a daunting task.
© The Author(s). 2019 Open Access This article is distributed under the terms of the Creative Commons Attribution 4.0
International License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and
reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to
the Creative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver
(http://creativecommons.org/publicdomain/zero/1.0/) applies to the data made available in this article, unless otherwise stated.
* Correspondence: auciteli@imise.uni-leipzig.de; stefan.kropf@imise.uni-
leipzig.de; heinrich.herre@imise.uni-leipzig.de
1Institute for Medical Informatics, Statistics and Epidemiology (IMISE),
University of Leipzig, Leipzig, Germany
Full list of author information is available at the end of the article
Uciteli et al. Journal of Biomedical Semantics            (2019) 10:9 
https://doi.org/10.1186/s13326-019-0203-7
Literally, an employee has to type all search queries (e.g.,
safety AND coronary stent) into the input fields of a
large number of different databases, congress sites and
public search engines in order to gain a broad, unspecific
hit list, interspersed with single, relevant content. This
strategy of data retrieval reaches its limits assuming that
several search strings have to be applied in order to moni-
tor a whole range of medical devices, each featured by a
variety of decisive search questions.
Additionally, each notable medical database uses its
own, inherent syntax to specify search queries. This in-
compatibility between databases and the amount of differ-
ent search tasks combined with the manual application to
a multitude of databases results in low efficiency and a
high potential for human error.
Setting up more complex queries in a simple manner
by domain experts enables the definition of the topic of
interest in a more specific way and circumvents the
problem of retrieving irrelevant content.
In the OntoVigilance project (predecessor project of
OntoPMS), we developed the Search Ontology (SON)
v1.0 [4], a promising approach for an ontology-based
specification of complex search queries. The modular
architecture of the SON enables the re-use of ontology
parts in different use cases as well as a quick and easy
adaptation and extension of the ontology according to
the specific requirements.
The developed Search Ontology and its application was
evaluated in the OntoVigilance project by domain experts.
This previous study has proven that the SON is a suitable
method for modelling complex queries, but it needed to
be optimized to face further requirements of domain ex-
perts. On the one hand, the structure of the Search Ontol-
ogy can be simplified to improve the usability by domain
experts. On the other hand, certain extensions are neces-
sary to model all relevant query types. Based on these
findings, we further developed and optimized the Search
Ontology in the OntoPMS project. The Search Ontology
v2.0 is presented in this paper. The SON is generic and
can be used in any domain. For the application of the
SON in a particular domain, it has to be extended by a do-
main ontology, such that the classes of the domain ontol-
ogy are subclasses of the SON classes. We call such
domain ontologies Domain-specific Search Ontologies
(dSON). Whereas SON stands for exactly one ontology
(namely the Search Ontology presented in this paper),
dSON represents a class or a type of ontologies. Various
Domain-specific Search Ontologies can be developed,
such as dSON-PMS for the whole PMS domain or dSON-
Niti for modelling queries regarding the material Nitinol.
In addition, we developed an Excel template to specify the
information required to create a dSON, which signifi-
cantly simplifies the ontology development by domain ex-
perts. For the automatic generation of a dSON from the
Excel template, we implemented the Search Ontology
Generator (SONG). In contrast to the OntoQueryBuilder
(OQB) [4], the SONG generates the complete dSON in-
cluding all specified queries in the correct query syntax
from the Excel template and provides it for external tools
(e.g., the search engine). In this way, the search engine can
get the complete dSON by accessing the SONG service
without any requests or generating queries at search time.
Methods
In Europe, market access of a medical device based on a
CE-mark is granted after a successful so-called con-
formity assessment process, which includes passing an
extensive series of tests, risks analyses and evaluations of
clinical data on the medical devices safety and efficacy.
Nevertheless, the behaviour of a medical device over
time in broad application can be investigated a priori
only in a limited manner. Thus, PMS strategies are set
up in order to retrieve and summarize application data
of medical devices and to identify residual risks. Expres-
sive search queries are needed to precisely define the
topic of interest. The problem is that the manual cre-
ation of complex queries requires knowledge of the cor-
rect query syntax and is time-consuming and error-
prone. This paper focusses on developing the Search
Ontology Generator (SONG), a framework for ontology-
based specification and generation of powerful search
queries by domain experts with less effort and without
knowing the query syntax.
Example PMS question
Reports on unfavourable interactions between implant
material and patients tissue have to be identified and
evaluated in order to a) control residual and/or unex-
pected risk, b) determine vulnerable patient subpopula-
tions and c) improve the respective medical implant or
material, respectively.
An example PMS question could be to find out the un-
expected side effects of the metal alloy Nitinol used for
construction of endoscopic clipping systems. A search
query has to be constructed covering the different aspects
of the PMS question such as unexpected complication,
type of medical device (endoscopic clipping system) and
used material (Nitinol) by suitable search terms (e.g.,
Nitinol, Nickel Titanium and NiTi as synonyms of
Nitinol or unexpected complication, unforeseeable risk,
adverse event, etc. to describe the complication). Further-
more, it can be necessary to specify terms that should not
appear in the text (negation), for instance, to exclude de-
scriptions of preclinical tests or studies (e.g., terms like
animal, study and preclinical). Finally, the desired
terms have to be assembled to a valid search query using
supported operators and brackets.
Uciteli et al. Journal of Biomedical Semantics            (2019) 10:9 Page 2 of 13
This example is used in the paper for further
explanations.
Approach
Figure 1 illustrates the overall architecture of the
SONG environment.
The Domain Expert specifies information required to
generate a dSON (including search queries) using an
easily applicable Excel template.
The SONG Manager uploads/downloads files and tests
the service using the SONG Config App. The SONG
service generates the dSON (in our example the dSON-
Niti) in OWL and JSON format out of the Excel tem-
plate, allows adding new entities to the ontology and
provides the generated dSON for external tools, espe-
cially for search apps. After each file upload (Excel or
OWL) or after an adding of a new entity, the new ontol-
ogy (OWL and JSON) is generated.
The SONG manages the generation of OWL and
JSON from Excel as well as JSON from OWL. The
OWL format is used for a possible optimization of the
generated ontology with an ontology editor or for an in-
tegration of external ontologies. Any ontology that con-
tains concepts and their labels can be considered as a
dSON and can be easily integrated with our approach.
JSON is utilized for communication with external tools.
The Searcher uses the SONG Search App, which visu-
alizes the dSON, and can select desired concepts or
queries for the execution by a search engine.
The next sections introduce the two additional com-
ponents, search engine and Corpus Builder that were
used in the OntoPMS project in combination with
SONG.
Search engine
The SONG can be used with any Lucene-based search
engine for the generation of queries in the Lucene query
syntax out of the Excel template. In addition, new ex-
pressive query operators were implemented in the
OntoPMS project, which significantly extend the Lucene
query syntax.
To identify risks or complications (for PMS) in un-
structured documents, complex patterns have to be de-
tected. Such patterns go beyond the standard capabilities
of state-of-the-art search engines such as Elasticsearch
[5]. Therefore, we extended these capabilities by creating
our own search plugin, providing the required function-
alities and improving search quality. The extension was
realized as an Elasticsearch plugin and contains, among
Fig. 1 SONG and its application. The Domain Expert specifies the dSON in Excel. The SONG Manager uploads/downloads files and tests the
service. The SONG Service generates the dSON (including complete search queries) and offers different methods for external applications. The
Searcher uses the SONG Search App and can select desired concepts or queries for the execution by a search engine
Uciteli et al. Journal of Biomedical Semantics            (2019) 10:9 Page 3 of 13
others, the following additional features: improved toke-
nization, lemmatization and word decomposition; build-
in support for several normal forms / term types; im-
proved quality for ambiguous searches; named entity,
date and measurement recognition; additional search
modes; NEAR operators.
In particular, the search modes and new search opera-
tors are extensively used in our dSONs to produce more
precise queries. The search modes correspond to the dif-
ferent types of terms (exact [E], diacritics-normalized
[D], lemmatized baseforms [B], compounds-parts [C])
that we use in our index. For example, with the query
MODE/E (SafeSet) we only search for SafeSet with two
upper case S. Words within a NEAR/n query must not
have a token-distance greater than n. With NEAR/S and
NEAR/P, words must occur within one sentence or one
paragraph. These new NEAR-Operators can be com-
bined and nested with other queries in an arbitrary way.
Corpus Builder
PMS requires information from several types of sources
including proprietary manufacturer data and information
from the web. Getting information from the web re-
quires some knowledge on what to look for, how to look
for it, how to access it and which parts to extract. Add-
itionally, following the links found on a page identified
by a given URL quickly turned out to be a potential trap,
since the referenced pages may be completely out of
scope. Therefore, we concluded that an ontology would
help to define the scope and thereby control the auto-
mated data acquisition process.
For data acquisition, we developed the Corpus Builder
[6, 7]. Its input component, the Prospector, metaphoric-
ally speaking, roams the internet in order to identify
suitable data to feed the OntoPMS Corpus. To achieve
this, it uses a set of special corpus queries, which are
part of our dSON. Currently, the Prospector delivers its
documents to a NLP pipeline, which analyses the con-
tents to identify documents that are important to the re-
spective projects and rejects (i.e. blacklist) documents
that shall not be included into the OntoPMS corpus.
This processing is done by a kind of control circuit. The
plant of the feedback loop is controlled by a seed list,
produced by the prospector and by the feedback compo-
nent. It does the crawling and gathering of new URLs by
following forward and backward links and reading the
contents identified by the URLs. Then, the output is
checked by the sensor. The sensor is controlled by the
corpus queries and allows a deep analysis of the content.
After that, questionable content is fed back to a splitter
component which sorts out garbage (blacklist) and
boosts domains with a high amount of documents we
want to include (whitelist). URLs, based on those white
listed domains are then included if not yet part of the
seed list. If the output contains unwanted documents,
we have to improve the corpus queries. Hence, we have
a semi-supervised learning component, with which the
manual part of supervision is made on the abstract level
of ontologies. This enables us to change the behaviour of
the corpus builder by changing the underlying ontology
instead of changing the software.
Results
Search Ontology (SON) v2.0
The Search Ontology (SON) provides a general structure
for all dSONs (the classes of the dSONs have to be sub-
classes of the SON classes; only relations and properties
defined in the SON are allowed). This section presents the
optimized Search Ontology v2.0, which contains some im-
provements compared to the v1.0. One of the advantages
of the new version is that the SON-based dSONs can be
specified in a specially developed Excel template rather
than with an ontology editor. Furthermore, the keywords
for the search (search terms) are directly associated with
search concepts as annotations. In the v1.0, the search
terms had to be defined as instances of the search term
classes (with different labels) and linked to the search con-
cepts using the property restrictions (based on the prop-
erty described_by). Both aspects simplify the structure of
the ontology. Other extensions include negated concepts
and direct storage of queries in the ontology. The ontol-
ogy contains 9 classes and 13 properties.
The SON models three types of entities: search con-
cepts, search terms, and search queries (Fig. 2). The
search concepts are concepts (in the sense of General
Formal Ontology, GFO [8, 9]), whose descriptions or
designations have to be found in texts. The other two
entities are symbolic structures (gfo: Symbolic_Struc-
ture) and serve to model single keywords or phrases of
the concept description as well as queries.
Search terms
The search terms are descriptions or designations of
search concepts. A distinction is made between sim-
ple and composite terms. The simple terms are ei-
ther single words (e.g., clip, Nitinol) or fixed
(defined by the user) phrases (e.g., endoscopic clip-
ping system). The composite terms are combina-
tions (has_part) of simple terms of two search
concepts (has_terms_of_concept_as_part). They are
defined by the user by choosing the two concepts
(e.g., Unexpected and Complication) and are gener-
ated by the generator as an AND-connection of the
OR-linked simple terms of the selected concepts
(e.g., (unexpected OR unforeseeable OR unknown)
AND (complication OR failure OR incident)).
Uciteli et al. Journal of Biomedical Semantics            (2019) 10:9 Page 4 of 13
Search concepts
The search concepts are described or designated by
search terms (described_by, simple_term, composite_
term). We distinguish between standard (e.g., Complica-
tion) and negated (e.g., No_Preclinical) concepts. While
the terms of the standard concepts (e.g., complication,
failure, incident) have to be contained in the result-
ing documents, the terms of the negated concepts (e.g.,
animal, study, preclinical) have to be excluded/ne-
gated. Each concept is additionally associated with a
Fig. 2 SON. The SON models three types of entities: search concepts, search terms, and search queries as well as several relations between them
Fig. 3 Excel template (excerpt). The different aspects of the PMS question such as unexpected complication, type of medical device and used
material were modelled within the easily applicable Excel template
Uciteli et al. Journal of Biomedical Semantics            (2019) 10:9 Page 5 of 13
single concept query (see Search queries), which is used
for the search for descriptions of the concept.
Search queries
The single concept query is an OR-connection of all
terms (simple and composite) for a standard concept or
a negated OR-connection of all terms for a negated con-
cept. The query can additionally contain specified search
operators and brackets. The multiple concept query is
an AND-connection of single concept queries of selected
concepts (has_query_of_concept_as_part).
Excel template
The design of the Excel template was derived from the
SON structure. Sheets, tables and fields were created
allowing the specification of all the information required
for generating a valid dSON (including search queries).
Figure 3 illustrates our example by screenshots of the
several sheets.
The Excel template consists, on the one hand, of the
predefined data sheets (Negated_Concept, Composite_
Term and Multiple_Concept_Query) and, on the other
hand, of the user-defined sheets (facet sheets) for the
specification and classification of the search concepts
and simple terms. For the observation of medical devices
during PMS, we introduced among others the following
facets: Medical_Device, Medical_Area, Medical_Prob-
lem, Incident, Material and Risk. In our example, the dif-
ferent facets of the search are represented by the Excel
sheets Material, Medical_Device and Incident.
In every facet sheet, a subclass structure represents a
categorization of the knowledge within the appropriate
area. For instance, we subdivided medical devices in clip,
stent, occluder and implant; moreover, these device cat-
egories can be subdivided into special types, e.g., endo-
scopic clipping system, PFO occluder, PDA occluder,
and so on. Next to the nodes of the subclass hierarchy,
the domain expert can enter simple terms; two columns
(Simple Terms (en) and Simple Terms (de)) are used
for enabling the separation of English and German sim-
ple terms. Several types of query operators, such as the
wildcard or boost (e.g., incident^5), can be applied to
simple terms in order to refine the search query.
For excluding documents that contain descriptions of
certain concepts (e.g., complications in preclinical tests),
the Negated_Concept sheet is used. The concept is spe-
cified (e.g., No_Preclinical) and described by simple
terms to be excluded (e.g., animal, study, preclin-
ical) in the column Excluded Simple Terms.
The Composite_Term sheet is used for the specifica-
tion of terms based on other concepts. The composite
terms for describing the search concept Unexpected_
Complication (column: Concept) are combined from
the simple terms of Unexpected (column: part1) and
Complication (column: part2).
For the creation of complex (multiple concept) quer-
ies, which are based on the conjunction of queries of
multiple search concepts (e.g., Unexpected_Complica-
tion, Nitinol, Endoscopic_Clipping_System and No_Pre-
clinical), the Multiple_Concept_Query sheet is used. The
name of the query is specified in the column Query.
The definition of the improved MODE or NEAR (e.g.,
NEAR/S) operators (columns: MODE and NEAR) is
possible for both, composite terms and multiple concept
queries. Concepts that should be combined to a multiple
concept query are specified in the columns Concept.
Generating a dSON by SONG
By the generation of the ontology from the Excel tem-
plate, the model presented in Fig. 2 is not applied one-
to-one, but rather simplified. For example, simple terms
and single concept queries are defined as annotations of
the search concept classes.
Firstly, the SONG generates the class hierarchy. The
search concept trees from the user-defined sheets (facet
sheets) are placed under Search_Concept and the ne-
gated concept tree under Negated_Concept. Next, the
simple terms (from the columns Simple Terms (en)
and Simple Terms (de)) are linked to their concepts
using the annotation property simple_term.
For each row in the Composite_Term table, a compos-
ite term class is generated as subclass of Composite_
Term. The annotation properties has_term_of_concept_
as_part_1 and has_term_of_concept_as_part_2 (shortly:
part_1 and part_2) are used to specify the two search
concepts whose simple terms have to be put together. In
addition, the specified MODE or NEAR operators are
generated as annotations. Then, for each composite term
class, the corresponding term is generated as an AND-
connection of the OR-linked simple terms of the se-
lected concepts, and is associated to the composite term
class using the annotation property query. The possibly
specified query operators for composite terms are taken
into account in the correct syntax. The composite term
classes are referenced in the search concept classes by
the annotation property composite_term.
After that, the single concept queries of all search con-
cepts are generated as an OR- connection for standard
concepts or a negated OR-connection for negated con-
cepts from all their terms, and are associated with the re-
spective concept using the annotation property query. For
negated concepts, the standard concepts can also be speci-
fied, whose terms have to be excluded (excluded_concept).
The multiple concept queries specified on the Mul-
tiple_Concept_Query sheet are generated as subclasses
of Multiple_Concept_Query. The multiple concept query
classes are associated with the concepts whose single
Uciteli et al. Journal of Biomedical Semantics            (2019) 10:9 Page 6 of 13
concept queries are to be combined using the annotation
property has_query_of_concept_as_part (shortly: search_
concept). The single concept queries are AND-linked and
stored using the annotation property query. Similar to
composite terms, the possibly specified operators for quer-
ies are taken into account during the generation process.
In Fig. 4, some parts of the generated dSON-Niti are
illustrated. The upper part shows the search concept
Unexpected_Complication, which is described by the
composite term Unexpected__Complication (with two
underscore characters), and the search concept Nitinol.
In the lower left corner, the search concept Endoscopic_
Clipping_System is presented. The lower middle part
demonstrates the negated concept No_Preclinical, which
is used for the exclusion of several simple terms. In the
lower right corner, the complete (multiple concept)
query is illustrated, which consists of different search
concepts. In the annotation property query is the gener-
ated query, which can be executed by a search engine.
The query parts (single concept queries) of the multiple
concept query are highlighted.
SONG Search App
The SONG Search App accesses the SONG service and
receives the generated dSON in JSON format (using the
getDSON method of the service). The search concepts
and multiple concept queries are visualized on the GUI
of the app as a tree with checkable nodes (Fig. 5). The
searcher can select desired concepts or multiple concept
queries by checking the corresponding checkboxes. The
overall query appears in the boxes English Query or
German Query (depending on which language was
used for specifying simple terms). The user can enter a
search engine URL directly or can select an available
search engine via the dropdown list. In Fig. 5, the
OntoPMS search engine was selected. After pressing the
buttons Run English Query or Run German Query,
the query is forwarded to the search engine URL as GET
parameter. On the website of the OntoPMS search en-
gine (Fig. 6), the search results are displayed. Matching
terms are highlighted. When minor changes are needed
(e.g., deleting the NEAR or boost operators), the
searcher can modify the query in the input field. How-
ever, the important changes of the query that should be
available for further searches have to be made in Excel
(see Modifying dSON in Fig. 7).
Additionally, the app supports the creation of new
multiple concept queries. To achieve that, the user has
to select desired concepts, to define the query name and
to press the Create Query button. The app sends this
Fig. 4 Parts of the dSON-Niti in Protégé. The upper part shows the search concept Unexpected_Complication, the composite term
Unexpected__Complication and the search concept Nitinol. In the lower part, the search concept Endoscopic_Clipping_System, the negated
concept No_Preclinical and the complete (multiple concept) query are illustrated
Uciteli et al. Journal of Biomedical Semantics            (2019) 10:9 Page 7 of 13
information to the SONG service (using the method
addQuery). After that, the SONG adds the new query to
the ontology und transmits the updated dSON back to the
GUI. The query is then available for further searches.
Figure 7 summarizes the different steps of the ontology-
based search.
Evaluation
Comprehensive testing confirmed the correct execution
of all SONG functions. The applicability of our method
and developed tools was evaluated by domain experts.
In the OntoVigilance project, development and editing
of specific ontologies was conducted in Protégé [10]. For
commercial use (in our case post-market surveillance
purposes for medical devices), ontologies are rather dy-
namic constructs with a constant pace of re-editing to
react upon changing search parameters. Designated key
operators are Regulatory Affairs and/or Quality man-
agers positioned at the respective departments of med-
ical device manufacturers. Hence, the prototypical
domain expert will be rather untrained in deep informat-
ics/ontology processing. It turned out that Protégés
basic functionality can be learned by a domain expert.
However, the ontology editor was considered cumber-
some and complex to operate. Consequently, in the
OntoPMS project, an Editor easy to learn and at once
applicable was formulated as an essential requirement.
Due to the broad application of MS office in business
application, an Excel-based platform was highly appreci-
ated by domain experts involved in the project. Three
naïve domain experts were shortly instructed in the
structure and function of the SON as well as the SON-
based Excel template and equipped with a manual writ-
ten by the SON developers.
Then each domain experts had to fulfill seven pre-
defined tasks using the Excel template:
 Specification of a new facet Equivalent product
(task 1.1)
 Specification of a new search concept Clip XY in
the respective facet (task 1.2)
 Linking the search concept with pre-defined search
terms in form of several simple terms (task 1.3)
 Specification of a new facet Safety (task 2.1)
Fig. 5 SONG Search App. The searcher clicks the checkboxes of desired concepts or multiple concept queries, selects a search engine and
submits the generated query
Uciteli et al. Journal of Biomedical Semantics            (2019) 10:9 Page 8 of 13
 Specification of a new search concept Unexpected
Side Effect in the respective facet (task 2.2)
 Linking the search concept with pre-defined search
terms in form of composite terms (adjective-noun-
phrase) (task 2.3)
 Specification of a negated concept No
Preclinical with simple terms to be negated in
the query (task 3)
Afterwards the test persons were introduced to the
SONG and asked to generate a query to search for unex-
pected side effects of the Clip XY that are not related to
preclinical tests (task 4).
Each test was accomplished successfully in a reason-
able time. Table 1 provides the results of processing the
tasks; Table 2 shows the time expenditure. Afterwards
the test persons were briefly interrogated by preformed
Fig. 6 OntoPMS search results page. The search results of the OntoPMS search engine are displayed. Matching terms are highlighted. The query
can be modified in the input field
Fig. 7 Ontology-based search pipeline. The figure summarizes the different steps of the ontology-based search. A recursive optimization of the
query is possible
Uciteli et al. Journal of Biomedical Semantics            (2019) 10:9 Page 9 of 13
questions and asked to provide a general statement
(Table 3). The test persons congruently rated the SON-
based Excel template as clearly structured, featured by
intuitive operator control logic and highly user-friendly.
The Excel platform appears familiar. By application of
the SONG, also complex queries can be generated
quickly, transparent and reproducible. In comparison to
a conventional periodic, manual data search, relevant
content was identified by SONG-based data retrieval in
a more convenient and comprehensive way.
In conclusion, the SONG framework significantly facil-
itates the creation of search queries. According to the
domain experts in charge of the testing, the system is in-
tuitive. Queries once generated can be saved and reused.
This feature fosters transparency of a systematic search
and repeatability, which is a legal imperative in the post-
market surveillance of medical devices.
Additionally, BfArMs Research group Safety of Med-
ical Devices evaluated the applicability of SONG from a
regulatory perspective giving a direct feedback from an
assessors point of view. The evaluation was conducted
based on the FDA coding system for medical device
problems, which is implemented at BfArM to classify re-
ported incidents. The evaluated tasks included not only
adding, editing and deleting facets, concepts, simple and
composite terms within an existing template but also
generating complex queries, a task to be considered as
highly important from a regulatory perspective. Since
none of the assessors had been trained on the concept
of ontologies before participating, the initial test results
showed some minor but expected difficulties at first.
Thereafter a fast learning process was observed, leading
to desired performances within a very short period of
time. Table 4 shows, that no help of any kind was
needed (intuitional), whenever the complete information
required for a given task was presented in one facet.
Tasks including working with more than one facet or
adding new information sometimes lead to mistakes,
which could be corrected quickly and only by use of de-
bug output (easy). Additional information was only re-
quired (explanation needed), when new concepts or
composite terms had to be added. These kind of mis-
takes occurred only if it has been necessary to add new
information while also consider consequences of this ac-
tion to other facets. Notably no task needed to be ex-
plained more than once. Generating complex queries
becomes a very easy task using this tool. One of the ad-
vantages of the current implementation is that it al-
lows quick and easy modification of specified queries
(e.g., by adding new simple terms) if the ontology
needs to be altered due to a better understanding of
the subject. The evaluation showed the fast increase
in understanding the concept of search ontologies as
well as the applicability of SONG to model the risk
classification and to generate powerful search queries
in a very systematic and efficient way.
Table 1 Successful task management
task
1.1
task
1.2
task
1.3
task
2.1
task
2.2
task
2.3
task
3
task
4
Proband
1
2 2 2 2 2 2 2 2
Proband
2
2 2 2 2 2 2 1 2
Proband
3
2 2 2 2 2 1 2 2
0 = task not fulfilled
1 = task fulfilled; additional support required (Minor support was necessary in
form of short explanations of the template structure while processing the
tasks 2.3 and 3)
2 = task fulfilled without further support
Table 2 Expenditure of time in seconds
task 1
complete
task 2
complete
task 3
complete
task 4
complete
Proband
1
72 60 13 20
Proband
2
47 60 20 19
Proband
3
61 89 16 22
Mean 60 70 16 20
SD 13 17 4 2
Table 3 Interview results
Yes No Prefer not to
say
Do you have any previous experiences with
Ontology Editors?
0 3 0
Is Excel a common standard in regular work
environment?
3 0 0
Is the structure of the ontology transparent in
this set-up?
3 0 0
Do you rate Excel as feasible for ontology
editing?
3 0 0
Is this set-up helpful for query generation? 3 0 0
Table 4 BfArMs evaluation results
Add Edit Delete
Facet Easy Intuitional Intuitional
Simple terms Easy Intuitional Intuitional
Concept Explanation needed Intuitional Intuitional
Composite terms Explanation needed Easy Intuitional
Multiple concept query Intuitional Intuitional Intuitional
Intuitional = no help of any kind needed
Easy = quick correction of mistakes only by use of debug output
Explanation needed = additional information required (Explanation was
needed only if it has been necessary to add new information while also
consider consequences of this action to other facets. Notably no task needed
to be explained more than once)
Uciteli et al. Journal of Biomedical Semantics            (2019) 10:9 Page 10 of 13
Related work
Ontology-based information retrieval
Since finding meaningful and intelligent information is
difficult, there are different ontology information re-
trieval techniques and methods available [11]. In the
wide world of semantic searches, the approach of this
paper can be classified as Research Search [12], because
we denoted search queries by concepts. Semantic
searches are usually executed not on plain documents
but on ontologies, which requires expensive manual an-
notation or natural language processing steps (NLP) for
extracting semantic data out of the documents. After
that step, the information of the documents is stored in
a semantic knowledge base [13] or in a semantically
enriched enhanced document index [14], on which se-
mantic searches can be applied by using semantic re-
trieval languages such as SPARQL [15] or SeRQL [16].
The early TAMBIS project [17] provides a foresighted
semantic search approach for accessing multiple bio-
informatics databases, using a complex biological con-
cept model for query formulation. Despite of semantic
knowledge bases or structured data sources, the ap-
proach of this paper builds up on indexed documents
which can be retrieved by complex Boolean expressions,
which are difficult to construct [18]. Using ontologies as
navigation tree structure in form of a Concept-based In-
formation Retrieval Interface (CIRI) seems to be more
effective than a direct interface (input field) [19].
GoPubMed [20] uses the Gene Ontology for search on
PubMed. In contrast to our approach, the user is not able
to increase the precision of the search by simply develop-
ing and using his own dSON, exactly tailored to his needs.
Textpresso [21] is a text-mining system for scientific
literature. It implements categories of terms (an ontol-
ogy) which can be used for a search on a database of ar-
ticles. Regular expressions have to be created for each
category to match the corresponding terms in the text
and the documents have to be labelled according to the
lexicon of the ontology. The documents are then
indexed with respect to labels and words. Our solution
does not use any in the ontology contained information
for pre-processing or indexing of the documents. The
ontology is constantly under development and is adapted
by the domain experts to meet their current needs. Our
approach does not require any additional pre-processing
steps (e.g., labelling) as well as re-indexing the document
collection when the ontology changes.
Excel-based ontology development
Since ontology engineering is difficult for non-
ontologists, there is a need for a rapid and collaborative
ontology engineering methodology and easy to use tools
[22]. The transformation of spreadsheets in OWL is
already used in life science projects [2325]; tools and
plugins enable the population of OWL ontologies out of
spreadsheet templates [26]. The template we developed
differs in that way, that it is not intended for the ontol-
ogy development in general based on modelling certain
OWL constructs. Instead, our template is exactly tai-
lored to the SON-based specification of dSONs in order
to make its use by domain exerts as intuitive as possible.
Discussion
The specification of complex search queries is a recur-
ring task in different domains. The search for complica-
tions in the usage of medical devices within the post-
market surveillance or the classification of the incident
reports are only two examples in this area. Other exam-
ples are the patent examination or the search for rele-
vant information in medical documents (e.g., discharge
letter). Our solution is domain-independent and thus al-
lows advanced search for relevant documents in differ-
ent domains using suitable dSONs. The SON approach
was also already successfully exploited for another use
case in the medical domain to generate complex XPath
expressions for querying archetype-based EHRs [27].
On the other hand, our approach is also generic re-
garding the used search engine. In the OntoPMS project,
an Elasticsearch [5] based search engine was used, which
was extended by developed plugins to provide novel ex-
pressive query operators. In addition, the document cor-
pus was specially prepared and optimized for the PMS
issue. However, other search engines can also be inte-
grated relatively easily with our approach. The corre-
sponding query syntax only needs to be implemented.
For instance, scientists could use our solution to search
in PubMed [28]. Nevertheless, not only scientists can
benefit from our work. An office employee could model
queries, which are relevant in his daily work and use
them for the Google or Bing search.
Additionally, our solution supports the classification of
documents (search results). When a query of a search
concept delivers certain documents, they can be classi-
fied in this concept. The whole taxonomy of search con-
cepts (part of the dSON) can then be considered as a
classification of the entire result document set.
Classification of search results
From the regulatory perspective of the German compe-
tent authority for risk assessment for medical devices,
the Federal Institute for Drugs and Medical Devices
(BfArM), there is an increasing demand to have the risk
assessment process of critical incidents supported by in-
telligent IT solutions. With respect to the exponential
increase in reported incidents with medical devices in
Germany, specific dSONs for different aspects of the in-
cident must be developed. These specific dSONs will
allow the identification of similar incidents and thereby
Uciteli et al. Journal of Biomedical Semantics            (2019) 10:9 Page 11 of 13
an automatic recommendation of classification of new
incidents will become possible. The aspects currently in
focus include dSONs for the resulting health problem,
device problem, root cause and components, all of which
are at present being developed on the basis of the FDA
coding system, which is currently revised by the IMDRF
working group on Adverse Event Terminology and Cod-
ing [29]. Using the SONG approach allows domain ex-
perts to easily create and modify the subsequent search
concepts for each of the FDA/IMDRF Codes. Our ap-
proach will allow for accelerated risk classification,
which in turn allows to create individual views of
device-specific problems as well as to monitor the per-
formance of different manufacturers within certain de-
vice groups such as hip implants, cardiac pacemakers,
instruments for bone surgery or insulin pumps.
Future work
Future work includes the application of our approach to
other domains, especially the search for relevant infor-
mation in medical documents as well as the integration
of further search engines including the implementation
of the corresponding query syntax. Since the PubMed
search engine can process GET parameters, we can for-
ward the generated query strings directly to PubMed. In
future work, we planned to integrate fields such as au-
thor, journal and title as well as the MeSH termin-
ology [30], including the subdivision in main and sub
headings.
After the definition of a sufficiently extensive knowledge
base in form of dSONs, ontology learning can be exploited
for supporting a semi-automatic query creation.
Conclusion
We presented the improved Search Ontology, a promising
domain-independent approach to specify complex search
queries. Our solution allows advanced search for relevant
documents in different domains using suitable dSONs and
supports an automatic classification of search results. The
second version of the Search Ontology includes enhance-
ments such as the inclusion of new search operators, ne-
gated concepts and direct storage of generated queries in
the ontology. For easier handling by non-ontologists, we
developed an Excel template, which facilitates a SON-based
specification of dSONs without the usage of ontology edi-
tors or knowing the query syntax. A service-oriented archi-
tecture was introduced; in the core of the architecture
stands the Search Ontology Generator (SONG), which pro-
vides methods for an access by search engines as well as
dSON administration methods. By the enhancement of the
SON, the Excel template, the SONG Search App and the
service-oriented architecture, we improved the access to
the Search Ontology for domain experts and external tools.
Abbreviations
dSON: Domain-specific Search Ontology; PMS: Post-market surveillance;
SON: Search Ontology; SONG: Search Ontology Generator
Acknowledgements
An earlier version of the paper has been presented at JOWO 2017 (Joint
Ontology Workshops) / ODLS (Ontologies and Data in Life Sciences) in
Bozen-Bolzano, Italy.
This work has been funded by the German Federal Ministry of Education and
Research (BMBF) in the KMU-innovativ funding program as part of the
OntoPMS project (reference number 01IS15056B).
We acknowledge support from the German Research Foundation (DFG) and
Leipzig University within the program of Open Access Publishing.
Authors contributions
AU developed the search ontology method for modelling and generation of
search queries, designed and implemented SON and SONG. SK made
substantial contributions to the design and implementation of SON and
SONG, analyzed the recent related works. HH was responsible for project
management, conception and semantic foundation of developed ontologies.
TW, SM, KG, SR, MOS, acting as domain experts, set up the content design of
the SON, created the evaluation plan and conducted the evaluation. The
main contribution of WB was the designing and implementing the Corpus
Builder with the Prospector component including the integration of the
ontology to control developed components. CG and PB created an
Elasticsearch plugin providing advanced functionalities such as additional
search modes and NEAR operators. RS, CB, MK, KP and WL implemented a
risk classification on the basis of the FDA coding system and performed the
evaluation of the system from the regulatory perspective of the German
Federal Institute for Drugs and Medical Devices (BfArM). JUM and MW
contributed to the design of the overall system. All authors read and
approved the final manuscript.
Funding
This work has been funded by the German Federal Ministry of Education and
Research (BMBF) in the KMU-innovativ funding program as part of the
OntoPMS project (reference number 01IS15056B). The aim of the funding
initiative is the strengthening of innovation capacity of small and medium
sized enterprises in Germany. Nevertheless, the funding body played no role
in the design of the study and collection, analysis and interpretation of data
and in writing the manuscript.
Availability of data and materials
The datasets generated and/or analyzed during the current study as well as
the tools developed and further material used in the OntoPMS project are
not publicly available. They contain information that could compromise
research participants consent and contrast with the projects funding
objective with the aim of strengthening the innovation capacity of small and
medium sized enterprises in Germany. However, are available from the
corresponding author on reasonable request.
Ethics approval and consent to participate
Not applicable.
Consent for publication
Not applicable.
Competing interests
The authors declare that they have no competing interests.
Author details
1Institute for Medical Informatics, Statistics and Epidemiology (IMISE),
University of Leipzig, Leipzig, Germany. 2novineon Healthcare Technology
Partners GmbH, Tübingen, Germany. 3OntoPort UG, Sulzbach, Germany.
4IntraFind Software AG, München, Germany. 5Federal Institute for Drugs and
Medical Devices (BfArM), Bonn, Germany. 6MT2IT GmbH & Co. KG, Ratzeburg,
Germany.
Uciteli et al. Journal of Biomedical Semantics            (2019) 10:9 Page 12 of 13
Received: 5 September 2018 Accepted: 22 May 2019
Lithgow-Serrano et al. Journal of Biomedical Semantics            (2019) 10:8 
https://doi.org/10.1186/s13326-019-0200-x
RESEARCH Open Access
Similarity corpus on microbial
transcriptional regulation
Oscar Lithgow-Serrano1,2* , Socorro Gama-Castro1, Cecilia Ishida-Gutiérrez1, Citlalli Mejía-Almonte1,
Víctor H. Tierrafría1, Sara Martínez-Luna1, Alberto Santos-Zavaleta1, David Velázquez-Ramírez1
and Julio Collado-Vides1,3
Abstract
Background: The ability to express the same meaning in different ways is a well-known property of natural
language. This amazing property is the source of major difficulties in natural language processing. Given the constant
increase in published literature, its curation and information extraction would strongly benefit from efficient
automatic processes, for which corpora of sentences evaluated by experts are a valuable resource.
Results: Given our interest in applying such approaches to the benefit of curation of the biomedical literature,
specifically that about gene regulation in microbial organisms, we decided to build a corpus with graded textual
similarity evaluated by curators and that was designed specifically oriented to our purposes. Based on the predefined
statistical power of future analyses, we defined features of the design, including sampling, selection criteria, balance,
and size, among others. A non-fully crossed study design was applied. Each pair of sentences was evaluated by 3
annotators from a total of 7; the scale used in the semantic similarity assessment task within the Semantic Evaluation
workshop (SEMEVAL) was adapted to our goals in four successive iterative sessions with clear improvements in the
agreed guidelines and interrater reliability results. Alternatives for such a corpus evaluation have beenwidely discussed.
Conclusions: To the best of our knowledge, this is the first similarity corpusa dataset of pairs of sentences for
which human experts rate the semantic similarity of each pairin this domain of knowledge. We have initiated its
incorporation in our research towards high-throughput curation strategies based on natural language processing.
Keywords: Corpus, Similarity, Transcriptional-regulation, Genomics
Background
Expressing the same approximate meaning with different
wording is a phenomenon widely present in the everyday
use of natural language. It shows the richness and poly-
morphic power of natural language, but it also exhibits the
complexity implied in understanding the conveyed mean-
ing. Due to these characteristics, paraphrase identifica-
tion is necessary for many Natural Language Processing
(NLP) tasks, such as information retrieval, machine trans-
lation, and plagiarism detection, among others. Although
strictly a paraphrasis refers to a rewording that states
*Correspondence: olithgow@ccg.unam.mx
1Computational Genomics, Centro de Ciencias Genómicas, Universidad
Nacional Autónoma de México (UNAM). A.P., 565-A Cuernavaca, 62100
Morelos, México
2Instituto de Investigaciones en Matemáticas Aplicadas y en Sistemas (IIMAS),
Universidad Nacional Autónoma de México (UNAM), Mexico City, México
Full list of author information is available at the end of the article
the same meaning, i.e., its evaluation should only result in
true or false, frequently a graded paraphrasing is needed.
This graded paraphrasing is often called Semantic Textual
Similarity (STS).
Textual similarity depends on particular text features,
domain relations, and the applied perspective; therefore,
textual similarity has to be defined according to the con-
text. This context specification presupposes the delin-
eation of the kind of textual similarity desired, e.g., assign-
ing grades of importance to the syntactic parallelism, to
the ontological closeness, to the statistical representations
likeness, etc.
It is not a simple endeavor to explicitly state these grades
of importance. The difficulty stems from the fact that it is
very complicated to envisage all possible language feature
variations to express the same idea, and so to have a broad
perspective and to identify which features or relations are
© The Author(s). 2019 Open Access This article is distributed under the terms of the Creative Commons Attribution 4.0
International License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and
reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to the
Creative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver
(http://creativecommons.org/publicdomain/zero/1.0/) applies to the data made available in this article, unless otherwise stated.
Lithgow-Serrano et al. Journal of Biomedical Semantics            (2019) 10:8 Page 2 of 14
important. It is for these steps that a paraphrase corpus
is a very useful instrument, because it implicitly captures
those nuances.
There are several paraphrase corpora available, both for
general and specific domains. However, as stated before,
these corpora are very sensitive to the aimed task and to
the targeted domain. Hence, when a task or domain is very
specific and the available corpora do not fit, an ad hoc
corpus has to be built. This is the case for the biomedical
curation of the literature about the regulation of transcrip-
tion initiation in bacteria, a specific domain of knowledge
within the biomedical literature.
RegulonDB1 [1] is a manually curated standard
resource, an organized and computable database, about
the regulation of gene expression in the model enterobac-
teria Escherichia coli K-12. It aims at integrating within a
single repository all the scattered information in the lit-
erature about genetic regulation in this microorganism,
including elements about transcriptional regulation, such
as promoters, transcription units (TUs), transcription fac-
tors (TFs), effectors that affect TFs, active and inactive
conformations of TFs, TF binding sites (TFBSs), regula-
tory interactions (RIs) of TFs with their target genes/TUs,
terminators, riboswitches, small RNAs, and their target
genes. We are capable of keeping up to date with the lit-
erature thanks to constant manual curation in an effort
initiated close to 20 years ago. However, the pace of
curation tends to lag behind the number of publications,
motivating the implementation of automatic curation pro-
cesses2. Certainly, biocuration typically accelerates with
the emergence of novel technologies, and furthermore,
we believe that the depth and detail of the description of
what is extracted from the literature could be increased
significantly. As shown in the most recent publication
of RegulonDB [2], the number of curated objects has
increased over the years. Finally, another major motiva-
tion stems from the fact that microbial genomes have been
constructed under similar evolutionary principles as E.
coli; thus, the methods that can be trained with literature
for E. coli should be very well applicable to the litera-
ture on gene regulation in other microbial organisms, for
which the literature has not been subject to curation. Reg-
ulonDB plays an important role in scientific research: it
has been cited in more than 1700 scientific publications.
As an ongoing effort to enrich the already curated infor-
mation and to improve the curation process, we are devel-
opingNLP tools, some of which rely on STS. The goal with
these STS assessment tools is to discover statements, in
different publications, connected by their meaning. One
of the direct contributions to the curation process could
be to facilitate the discovery of supporting evidence for
a piece of curated information. Table 1 shows a pair of
sentences, from different publications, that express very
similar meanings and that provide supporting evidence
Table 1 Examples of sentences of different publications that
express very similar meanings
Sentence Publication title
There is, however, some evidence
that increased rob expression occurs
in glucoseand phosphatelimited
media in the stationary phase of cell
growth, attributable to activation by
factor rpoS.
MarA-mediated transcriptional
repression of the rob promoter.
(PMID: 16478729)
A similar rpoS dependency was
observed for glucose-limited or
phosphate-limited growth in which
rob::lacZ transcription increased 5-fold.
Posttranscriptional activation of
the transcriptional activator Rob
by dipyridyl in Escherichia coli.
(PMID: 11844771)
for each other. These pairs of sentences exemplify what
is intended to be annotated within our corpus and, thus,
the kind of annotations that we expect to produce through
machine learning models trained with this corpus. Due
to the very specific nature of our domain, we built the ad
hoc graded paraphrase corpus to be used as a training and
evaluation source of truth for our NLP tools.
In the following sections, we first describe the method-
ology followed to build our corpus, then we analyze it
quantitatively, and finally we briefly mention the immedi-
ate foreseen uses of the corpus.
Related work andmotivation
STS aims to measure the degree of semantic equivalence
between two fragments of text. To achieve this, it tries
to unveil the meaning conveyed by a textual expression
and compare it with the meaning conveyed by another
one. The comparisons result is a graded similarity score
that ranges from an exact semantic match to a completely
independent meaning, passing through a continuous scale
of graded semantic parallelism. This scale intuitively cap-
tures the notion that a pair of texts can share different
aspects of meaning at different levels [3], i.e., they could
differ in just some minor details, they could share a com-
mon topic and important details, or they could share only
the domain and context, etc. Another characteristic of
STS is that it treats similarities between two texts as bijec-
tive, setting this task apart from textual entailment, where
the relation is directed and cannot be assumed true in the
inverse direction.
Many NLP tasks, such as machine translation, question
answering, summarization, and information extraction,
potentially benefit from this quantifiable graded bidirec-
tional notion of textual similarity. Building this kind of
corpus is difficult and is labor-intensive, and that is why
there are not as many corpora of this kind as might be
expected, given their usefulness.
In recent years, the most notorious efforts on the
STS task and their corresponding corpus constructions
were tackled by the Semantic Evaluation Workshop
Lithgow-Serrano et al. Journal of Biomedical Semantics            (2019) 10:8 Page 3 of 14
(SEMEVAL) [3]. The SEMEVAL corpus consists of 15,000
sentence pairs from different sources, with the Microsoft
Research Paraphrase (MSRP) and PASCAL VOC [4] cor-
pora among them. The SEMEVAL corpus was annotated
through crowdsourcing, using a scale from 5 (identical) to
0 (completely unrelated).
Another corpus that is useful for STS is the User Lan-
guage Paraphrase corpus (ULPC) [5]. This corpus was
built by asking students to rephrase target sentences. As
a result, 1998 sentence pairs were annotated with rat-
ings ranging from 1 to 6 for 10 paraphrasing dimensions;
entailment and lexical, syntactic, and semantic similarities
were among those dimensions.
The SIMILAR corpus [6] is the product of a qualita-
tive assessment of 700 pairs of sentences from the MSRP
corpus; in addition to providing word-to-word semantic
similarity annotations, it also supplies a qualitative simi-
larity relationshipidentical, related, context, close, world
knowledge, or nonebetween each pair of sentences.
Among corpora that do not rely on graded similarity
but instead on binary paraphrases, there are important
corpora, such as the MSRP corpus [7]. It is one of the
first major public paraphrase corpora, comprising 5801
new sentence pairs, of which 67% were judged seman-
tically equivalent by two human judges. In the Q&A
field, another corpus,TheQuestion Paraphrase corpus [8],
was built by collecting from WikiAnswers 7434 sentences
formed by 1000 different questions and their paraphrases.
All these corpora target general domains and were
sourced mainly from the news, making it very difficult
to fit them into a specific topic such as ours: bacterial
transcriptional regulation. Closer to our domain is the
BIOSSES corpus [9]. It is formed by 100 pairs of sentences
from the biomedical domain which were rated following
the guidelines of the STS SEMEVAL task. The candidate
sentences were collected from the set of articles that cited
at least 1 of 20 reference articles (between 12 and 20 citing
articles for each reference article). Those sentence pairs
that cited the same reference article were selected. Articles
were taken from the Biomedical Summarization Track
Training Dataset from the Text Analysis Conference.
Due to the extension of the biomedical domain and
the small size of the BIOSSES corpus, most likely it does
not capture the nuances of our subject of study. For this
reason, we decided to build our own corpus of naturally
occurring non-handcrafted sentence pairs within the sub-
ject of regulation of gene expression in E. coli K-12. The
semantic similarity grade of each pair was evaluated by
human experts of this field.
Methods
Corpus design
A corpus is a collection of pieces of language text in
electronic form, selected according to external criteria
to represent, as far as possible, a language or language
variety as a source of data for linguistic research [10].
Before building a corpus, the textual source set, the evalu-
ation rules, the corpus size, and other characteristics must
be defined. This design should be, as much as possible,
informed and principled so that the resulting corpus ful-
fills the desired goals. The decisions involved within the
axes of consideration [10] for the corpus construction are
the following.
The sampling policy defines where and how the candi-
date texts are going to be selected, following three main
criteria: the orientation, in this case a contrastive corpus
with the aim of showing the language varieties that express
the same meaning (semantic similarity); the selection cri-
teria that circumscribe candidates to written sentences
(origin and granularity) in English (language) taken from
scientific articles (type) on the topic of genetic regulation
(domain), where the sentence attitude3 is irrelevant and a
specific content is not required; finally, the sampling cri-
teria consists of preselection of sentence pairs through a
very basic STS component followed by a filtering process
to keep the same number of exemplars for each similarity
grade, i.e., a balanced candidate set.
The corpus representativeness and balance refer to the
kind of features and to the distribution of those features
in the exemplars; hence, these characteristics determined
the usage possibilities of the corpus. In this sense, sen-
tences containing any biological element or knowledge
were preferred. It was more important that all similarity
grades were represented within the corpus and prefer-
ably in equal proportions. Our main analysis axis was the
semantic similarity between pairs of sentences and not the
topic represented by each sentence, the sentences special-
ization or technical level, nor the ontological specificity of
the terms in the sentence.
The orientation of a corpus topics impacts directly
the variety and size of the resulting vocabulary. Whereas
embracing more topics can broaden the possibilities for
use of the corpus, this can also have negative conse-
quences in the semantic similarity measures due to the
increased chances of the same term having different
meanings for different topics (ambiguity). Consequently,
a limited set of topics was preferred. We intended for
the corpus to be representative of the genetic regulation
literature. It is worth noting that it was not limited to
those sentences specifically about genetic regulation but
all kinds of sentences present in the corresponding litera-
ture. The corpus homogeneitywas tackled by stripping out
those sentences considered too short (less than 10 words)
[11] and those sentences that were not part of the main
body of the article4.
Finally, a corpus size should be dependent on the ques-
tions that it is aimed to answer and the type of tasks where
it can be applied [12, 13]. However, in practice it is largely
Lithgow-Serrano et al. Journal of Biomedical Semantics            (2019) 10:8 Page 4 of 14
restrained according to available resources (time, money,
and people). Our main goals are to train our STS system
and to measure its performance. Because our STS system
is based on the combination of several similarity meth-
ods, it is difficult to estimate the required number of cases
that would make it a significant training source, because
this varies for each type of metric. For example, one of the
most demanding methods on training data is neural net-
works, whose complexity can be expressed based on the
number of parameters (P), and it is common practice to
have at least P2 training cases. This would result in thou-
sands of training cases, which is out of our reach. Thus,
we focused on the second goal, to measure the STS sys-
tem performance. We planned to measure the Pearsons
correlation between the computed system similarity and
that generated by human experts (corpus). According to
[14], considering a medium-size effect (r = 0.30), a sig-
nificance level of 0.05, and a power of 80%, 85 samples
would be enough. However, [15] and [16] suggested amin-
imum sample size of 120 cases in order to allow not only a
Pearsons correlation analysis but also a regression analy-
sis. With this in mind, we decided to generate a corpus of
170 sentence pairs, i.e., a number of pairs just above those
thresholds.
Lastly, as a validity exercise, we compared our design
decisions versus those taken in other corpora, for exam-
ple, the MSRP corpus. In the construction of the MSRP
corpus [7], several constraints were applied to narrow the
space of possible paraphrases. However, in our opinion
and for our specific purpose, these guidelines limit the
aspects of semantic similarity that the corpus could cap-
ture. For example, only those pairs of sentences with at
least 3 words in common and within a range of Leven-
shtein edit distance were considered, but these parameters
constrain similarity, at least to a certain extent, to a tex-
tual one; it was required that for a pair to be a candidate,
the length in words of the shorter sentence be more than
66% of the length of the longer sentence, thus limiting the
possibility for the corpus to represent cross-level semantic
similarity [17], a phenomenon of sentences with different
lengths. It is also noteworthy that theMSRP corpus has an
agreed consensus that 67% of the proposed sentence pairs
are paraphrases, meaning that the majority of sentences
are semantically equivalent and, therefore, other grades of
similarity and even nonsimilarity are underrepresented.
Compiling the corpus
As stated in the sampling criteria of the corpus design,
the selection of candidate pairs was performed using a
basic STS process that automatically assigned continuous
similarity scores between 0 and 1 inclusive, where 1 rep-
resented exact semantic equivalence5 and 0 indicated a
totally unrelated meaning. The referred basic STS process
was performed by a tool that we developed to compare
the semantic similarity of two sentences using only their
word embeddings. The strategy consisted of averaging the
embeddings of the sentence words to produce a sentence
embedding and compute the cosine between both sen-
tence embeddings as a measure of their similarity. This
strategy is well known as a good baseline for this kind
of task. It is worth noting that the embeddings were
trained on RegulonDBs literatureTranscriptional Reg-
ulation domain (further details of this strategy and the
word embedding training are presented in [18]). Next,
the final candidate sentences were selected by a balanced
stratified random sampling from those prerated sentence
pairs.
This process was applied to two different sets: the
anaerobiosis FNR (Fumarate and Nitrate Reductase reg-
ulatory protein) subset formed by articles about anaero-
biosis; and the general set, consisting of sentences taken
by randomly sampling of all of RegulonDBs articles (5963
publications). The former subset was manually built by an
expert curator who selected, from anaerobiosis articles,
sentences that she considered relevant within the subject.
To generate the latter subset, we first extracted the textual
content (sentences) from the 5963 publications (PDFs)
found in the literature of RegulonDB by using a tool that
we built for this purpose. Then, as a naive approach to
only focus on sentences belonging to the articles main
sections (e.g., methods, results, discussion), we discarded
the first 30% and the last 30% of sentences from each arti-
cle. Finally, we randomly chose two sentences from each
article.
The resulting corpus is formed by pairs of sentences,
of which 40% come from the anaerobiosis FNR subset
and 60% from the general subset. A big picture of the
described pipeline is shown in Fig. 1.
Annotation design
In addition to the corpus design, it was necessary to delin-
eate the semantic similarity rating process. We followed
a similar rating scale to the one used in SEMEVAL. This
is an ordinal scale ranging from 0 to 4, where a Sentence
Pair Similarity Score (SPSS) of 0 represents a totally dis-
connected semantic relation between two sentences and
4 conveys an exact semantic match, with the three middle
scores indicating similarity shades, as shown in Table 2.
Seven human experts, who are coauthors of the present
article, comprised the set of annotators for the task.
We decided to apply a non-fully crossed study design6
in which different sentence pairs were rated by differ-
ent subsets of 3 annotators, i.e., each sentence pair would
be rated by 3 annotators selected by chance from the
set of the 7 human experts. Some studies have shown
that 2 evaluations per item can be enough [19], but
we considered that 3 annotators per item would allow
evaluation of a larger number of exemplars, and also
Lithgow-Serrano et al. Journal of Biomedical Semantics            (2019) 10:8 Page 5 of 14
Fig. 1 Corpus compilation pipeline. This pipeline, from bottom to top, shows the steps that were taken to compile the corpus (171 sentence pairs)
that was later evaluated by annotators regarding the semantic similarity between the sentence pairs. First, two subsets, the anaerobiosis-FNR and
the more general one, were compiled using different strategies. Then, a basic STS process was applied to both subsets in order to have a preliminary
semantic similarity evaluation. This preliminary evaluation was used to select candidate sentences, creating a corpus that ended up with 40% of
sentences from the anaerobiosis subset and 60% from the general subset
that 3 is the smallest number to provide a median
when there is no consensus and a discrete final score is
desired.
Due to the fact that what is considered semantically
equivalent is prone to be biased by personal subjective
considerations, it was necessary to homogenize the anno-
tation process among raters. This was done by a training
period of 4 iterative sessions to help annotators become
familiar with the annotation guidelines and the corpora to
be rated, and also to refine annotation guidelines. During
this training, each session consisted of evaluating a small
subset of sentence pairs, and at the end of each session,
disagreements were discussed and solved and annota-
tion guidelines were more precisely defined. This train-
ing period was considered concluded when a minimum
annotator interagreement was achieved or the annota-
tors considered that they fully understood the annotation
guidelines.
General guidelines
In order to make the annotation process less subjective,
some general guidelines were initially given to raters.
These were collected from other corpus-building experi-
ments [20] and from our own observations, including:
 Order. Clauses in a compound sentence can be
arranged in a different order without implying a
change in its meaning.
 Missing clauses. In complex or compound sentences,
if a clause is present in one and missing in the other,
it does not automatically result in a zero similarity. It
depends on the grade of importance of the shared
information.
 Adjectives. Missing adjectives in principle do not
affect similarity.
 Enumerations. Missing elements can produce a
minor decrease in the similarity score unless
Table 2 Rating scale
SPSS Description
4 The two sentences are completely ormostly equivalent, as they
mean the same thing.
3 The two sentences are roughly equivalent, but some important
information differs/is missing.
2 The two sentences are not equivalent but share some details.
1 The two sentences are not equivalent but are on the same
topic.
0 The two sentences are on different topics.
Lithgow-Serrano et al. Journal of Biomedical Semantics            (2019) 10:8 Page 6 of 14
enumeration conveys the main sentence meaning.
Reordering is considered equivalent.
 Abbreviations. Abbreviations are considered
equivalent, e.g. vs and versus.
 Hypernyms and hyponyms. The two forms share a
grade of similarity, e.g., sugar substance vs honey
vs bee honey.
 Compound words. Some terms are semantically
equivalent to multiterm expressions, e.g.,
anaerobiosis and in the absence of oxygen,
oxidative and nitrosative stress transcriptional
regulator and oxyR, or hemorrhage and blood
loss.
 Generalization or abstractions. Consider that two
textual expressions share some grade of semantic
similarity if one is a generalization or abstraction of
the other, e.g., 8 vs one-digit number.
Consensual refinement
General guidelines were subsequently refined and
enriched during the consensus sessions.
As a first approximation to clarify the rating scale in our
context, it was decided we would use the class of Regu-
lonDB objects as topic markers within the sentences. Reg-
ulonDB contains objects of the following classes: Gene,
Gene Product, Protein, Motif, Promoter, Transcription
Unit (TU), Regulatory Interaction (RI), Reaction, Tran-
scription Factor (TF), and Growth Condition (GC). Next,
we provide example cases for each score that help to
clarify our similarity scale.
SPSS of 4. Both sentences have in common the same
objects and express the same meaning. i.e., they are para-
phrases of each other. The following pair of sentences
serve to illustrate this grade:
 This would mean that the IS5 element is able to
provide FNR regulatory sites if inserted at
appropriate positions.
 In any case, insertion of an IS5 element is able to
increase FNR-dependent expression or to place genes
under FNR control.
SPSS of 3. Both sentences share the same objects and
other elements of their meaning. However, one of the sen-
tences lacks relevant elements, does not refer to the same
objects, or arrives at different conclusions. Some cases we
could envision are that both sentences refer to the same
Gene and share all other information, except that in one
the gene is activated and in the other it is repressed; sen-
tences referencing the same RI but that differ in terms
of the RIs conditions; both sentences almost paraphrase
each other, but one has more details.
The relation between the next pair of sentences exem-
plifies the last case:
 These results confirm that the N-terminal domain of
NikR is responsible for DNA recognition.
 In preliminary experiments, we have also found that a
subset of mutations within the DNA region protected
by the N-terminal domain reduce the affinity of NikR
for the operatordata not shown.
SPSS of 2. Both sentences share at least one specific
object and some other similarities, for example, a pair of
sentences that refer to the same TF (see example (a)). An
interesting singularity from the expert evaluation was the
observation that aerobic and anaerobic conditions are
related, since they both refer to oxygen availability. There-
fore, in this corpus, contrasting conditions like these have
a certain degree of similarity (see examples (a) and (b)).
 Example (a)
 The fnr mutant was thus deficient in the
anaerobic induction of fumarate reductase
expression.
 Aerobic regulation of the sucABCD genes of
Escherichia coli, which encode
K-ketoglutarate dehydrogenase and succinyl
coenzyme A synthetase: roles of ArcA, Fnr,
and the upstream sdhCDAB promoter.
 Example (b)
 Aerobic regulation of the sucABCD genes of
Escherichia coli, which encode
K-ketoglutarate dehydrogenase and succinyl
coenzyme A synthetase: roles of ArcA, Fnr,
and the upstream sdhCDAB promoter.
 Transcription of the fdnGHI and narGHJI
operons is induced during anaerobic-growth
in the presence of nitrate.
SPSS of 1. Both sentences have the same object class in
common, but the specific object is different. Since Gene
and GC objects are highly common in RegulonDBs litera-
ture, it was decided that sharing only these classes is not a
sufficient condition for sentences to be rated with an SPSS
of 1. When comparing a sentence that mentions a TF with
another one that mentions any other object (or GC) that
refers to the same process in which the TF is involved, an
SPSS of 1 has to be assigned to the sentence pair. An SPSS
of 1 was also considered in cases when both sentences
referred to sequences and genes, even when neither the
sequences nor the mentioned genes were the same. The
following pair of sentences is an example of this grade:
 The fnr mutant was thus deficient in the anaerobic
induction of fumarate reductase expression.
 To test whether the formate induction of the cyx
promoter could be mediated by the fhlA gene
Lithgow-Serrano et al. Journal of Biomedical Semantics            (2019) 10:8 Page 7 of 14
product, the expression of the cyx-lacZ fusion was
examined in an fhlA deletion strain in the presence
and in the absence of formate.
SPSS of 0. Sentences do not even share objects class. A
possible case is that sentences share Gene and GC class
(the exceptions of SPSS 1 grade) but not the same specific
objects; the following pair of sentences is an example of
this case:
 Carbon metabolism regulates expression of the pfl
(pyruvate formate-lyase) gene in Escherichia coli.
 Later work showed that most mutants lacking either
ACDH or ADH activities of the AdhE protein
mapped in the adhE gene at 27.9 min [1,4].
It was clarified that sentences do not necessarily have to
contain biological content or refer to RegulonDBs objects
to be annotated and have an SPSS above 0. The annotation
assesses the similarity inmeaning irrespective of the topic.
Table 3 is a summary of the above-described guidelines.
Annotation process
To facilitate the annotation process, we decided to pro-
vide annotators with a spreadsheet template (see Fig. 2).
The template was designed so that all needed informa-
tion would be self-contained and the rater did not have to
switch to other files. It consisted of a list of all sentence
pairs that the annotator had to rate; for each sentence pair,
the IDs and text were displayed. The area where the user
wrote the scores was organized into columns where each
column represented an annotation session, with date and
time at the top. A rating scale table was also included as a
reference.
The process consisted in: provide each annotator with a
file, based on the annotation template, containing exclu-
sively the sentence pairs that have to be evaluated by
him/her; annotators had a fixed period of time of one
week to rate all pairs; during that period each annota-
tor could divide the rating task into as many sessions as
Table 3 Refined rating scale
SPSS Description
4 Both sentences have in common the same objects and express
the same meaning.
3 Both sentences share the same objects and other elements of
their meaning. However, one of the sentences lacks relevant
elements or refers to the same objects, and it arrives at different
conclusions.
2 Both sentences share at least one specific object and some
other similarities. In this sense, contrasting conditions are con-
sidered related conditions.
1 Both sentences have the same object class in common, but the
specific object is different.
0 Sentences do not even share objects of the same class.
desired as long as he added the sessions date and time; it
was indicated that sessions should be exclusive and con-
tinuous, i.e., the task should not be interrupted by more
than 5min and annotators should not be performing other
tasks in parallel.
The process consisted of providing each annotator with
a file, based on the annotation template, containing exclu-
sively the sentence pairs that had to be evaluated by
him/her. Annotators had a fixed period of time of 1 week
to rate all pairs; during that period, each annotator could
divide the rating task into as many sessions as desired, as
long as he or she added the sessions date and time. It was
indicated that sessions should be exclusive and continu-
ous, i.e., the task should not be interrupted by more than 5
min and annotators should not be performing other tasks
in parallel.
It is worth noting that the pairs of sentences assigned
to each annotator were randomly selected from the set of
pairs.
Corpus evaluation
The recommended way to evaluate the quality of the
resulting corpus is through the Inter-Rater Agreement,
also known as Inter-Rater Reliability (IRR) [19, 2125].
IRR is a measure of the agreement between two or more
annotators who have rated an item using a nominal, ordi-
nal, interval, or ratio scale. It is based on the idea that
observed scores (O) are the result of the scores that would
be obtained if there were no measurement errortrue
scores (T)plus themeasurement error (E), i.e.,O = T+E
[21]. One possible source of measurement errors is the
measure-instruments instability when multiple annota-
tors are involved. IRR focuses on analyzing how much
of the observed scores variance corresponds to variance
in the true scores by removing the measurement error
between annotators. Thus, the reliability coefficient repre-
sents how close the given scores (by multiple annotators)
are to what would be expected if all annotators had used
the same instrument: the higher the coefficient, the better
the reliability of the scores.
There are multiple IRR statistics, and which one to use
depends on the study design. To select the IRR statistic,
some factors should be considered, such as the type of
measured variable (nominal, ordinal, etc.), if it is a fully
crossed study design or not, and if what it is desired is to
measure the annotators or the ratings reliability.
Our design (see Annotation design section) corre-
sponds to a non-fully crossed study design, where an
ordinal variable is measured and we are interested in mea-
suring the ratings reliability. Having that in mind, the
statistics that better accommodated our study were Fleiss
Kappa (Fleiss) [26], Krippendorff s Alpha (Kripp), Intra
Class Correlation (ICC) [27], Kendall (Kendall) [28], and
Gwets AC1 (Gwet) [22].
Lithgow-Serrano et al. Journal of Biomedical Semantics            (2019) 10:8 Page 8 of 14
Fig. 2 Annotation template. The image shows the spreadsheet template that was used by the annotators. Sentence pairs to be rated are shown in
the rows, one sentence pair per row. The cells to the right of each sentence pair were reserved for the annotators evaluation, with one annotation
session per column. At the top is a rating scale table which was included as a reference
One of the most-used IRR statistics is Cohens Kappa
analysis (k) (5) [29]. It is a relation between the proportion
of units in which the annotators agreed (po) and the pro-
portion of units for which agreement is expected by chance
(pc); thus k = (po ? pc)/(1 ? pc). Originally, this mea-
sure was intended for just two annotators who rated all
items, so variants were developed in order to fit non-
fully crossed study designs with more than two raters per
item. The Fleiss Kappa (1) is a nonweighting measure
that considers unordered categories; it was designed for
cases when m evaluators are randomly sampled from a
larger population of evaluators and each item is rated by
a different sample of m evaluators. In Eq. (1), pa repre-
sents the averaged extent to which raters agree for the
items rate and p is the proportion of assignments to the
categories.
k = pa ? p1 ? p (1)
Krippendorff s Alpha (2) is an IRR measure that is based
on computing the disagreement. It provides advantages
like being able to handle missing data and handling var-
ious sample sizes, and it supports categorical, ordinal,
interval, or ratio measured variable metrics. In (2), Do is
the observed disagreement and D is the disagreement
one would get if rates were by chance. Thus, it is the ratio
between the observed disagreement and the expected
disagreement.
? = 1 ? DoD (2)
Intra-class correlation (3) is a consistency measure that
can be used to evaluate the ratings reliability by com-
paring the items rating variability to the variability of all
items and all ratings. It is appropriate for fully crossed as
well as for non-fully crossed study designs and when there
are two or more evaluators. Another feature is that the
disagreements magnitude is considered in the computa-
tion, as in a weighted Kappa. In (3), var(?) accounts for
variability due to differences in the items, var(?) is from
the variability due to differences in the items reevalua-
tions, and var() is for the variability due to differences
in the rating scale used by annotators. Consistent with
our study design, we selected the ICC variant as: a one-
way model, to avoid accounting for systematic deviations
among evaluators, because annotators for each item were
selected at random. We used the average as the unit of
analysis, because all items were rated by an equal number
of annotators (i.e., 3).
ICC = var(?)var(?) + var(?) + var() (3)
Kendalls coefficient is an associationmeasure that quan-
tifies the degree of agreement among annotators based on
Lithgow-Serrano et al. Journal of Biomedical Semantics            (2019) 10:8 Page 9 of 14
the ranking of the items. As a special case of the correla-
tion coefficient, this coefficient will be high when items
orders (ranked by the given rate) would be similar across
annotators. It is based on the computation of the normal-
ized symmetric distances between the ranks. Because it
relies on the distances instead of the absolute values, it
better handles consistent rater biases, i.e., the bias effect.
In (4), nc refers to the number of concordant and nd to the
number of discordant ranks within a sample of n items.
W = nc ? nd1
2n(n ? 1)
(4)
[30] demonstrated that the Kappa coefficient is influ-
enced by trait prevalence (distribution) and base rates,
thus limiting comparisons across studies. For that rea-
son, [22] proposed an IRR coefficient (6) that, as Cohens
Kappa statistic, adjusts the chance agreementraters
agree based on a random ratingto avoid inflating the
agreement probability with not true intentional raters
agreement. However, Gwets coefficient has the property
of not relying on independence between observations;
weights are based on weighted dissimilarities. This coef-
ficient presents several advantages: it is less sensitive
to marginal homogeneity and positively biases for trait
prevalence (more stable); it can be extended to multiple
raters; as Krippendorff s coefficient it can deal with cat-
egorical, ordinal, interval, or ratio measures and it can
handle missing data; contrary to weighted Kappa, it is not
necessary to provide arbitrary weights when applied to
ordinal data.
Kappa = p ? e(?)1 ? e(?) (5)
AC = p ? e(? )1 ? e(? ) (6)
The difference between Gwet and Kappa is in the way
that the probability of chance agreement is estimated. In
Kappa, e(?) is based on combining the estimates of the
chance that both raters independently classify a subject
into category 1 and estimates the probability of indepen-
dent classification of a subject into category 2 (7), whereas
with Gwet this is based on the chance that any rater (A or
B) classifies an item into a category (8).
e(?) =
(A1
N
) (B1
N
)
+
(A2
N
) (B2
N
)
(7)
e(? ) = 2P1(1 ? P1)
= 2
(
(A1 + B1)/2
N
) (
1 ?
(
(A1 + B1)/2
N
)) (8)
It is important to note that Gwet proposes 2 variants of
its statistic, AC1 and AC2. AC2 is a weighted version
some disagreements between raters are considered more
serious than othersof AC1 and thus a better alterna-
tive for ordinal data. AC2 is intended to be used with any
number of raters and an ordered categorical rating sys-
tem to rate objects, as is our case. In AC2, both chance
Fig. 3 The progress of IRR through the consensus sessions. The chart shows the IRR measured using five different metrics. The IRR score is
represented on the y-axis, and the results for the four sessions are chronologically displayed on the x-axis. IRR scores, in all metrics, improved in each
subsequent consensus session. For example, the IRR measured using Gwets AC2 coefficients improved from 0.545 in the first session to 0.910 in the
last one, that is, the annotators evaluations were much more homogeneous at the end of the consensus sessions
Lithgow-Serrano et al. Journal of Biomedical Semantics            (2019) 10:8 Page 10 of 14
Table 4 IRR through agreement sessions
Session Kendall Fleiss ICC Kripp Gwet
1 0.216 0.024 0.454 0.116 0.545
2 0.208 0.267 0.728 0.268 0.565
3 0.430 0.390 0.813 0.439 0.826
4 0.727 0.546 0.964 0.766 0.910
agreement as well as misclassification errors are adjusted;
thus, it is defined as a bias-adjusted conditional probabil-
ity that two randomly chosen raters agree given that there
is no agreement by chance [22].
Results
Training period
The training period consisted of 4 iterations in each of
which a set of sentence pairs was rated by all annotators.
Afterwards, we had a consensus session where conflicts
were resolved and questions about the guidelines were
answered, resulting in updating the guidelines.
We performed the IRR analysis of each iteration in order
to review the effect of consensus sessions in homogeniz-
ing the annotation process. As can be seen in Fig. 3 and
Table 4, the grade of interagreement increased in each
iteration irrespective of the statistic. In the fourth session,
we reached a Fleiss Kappa of 0.546 as the lowest met-
ric, which is considered amoderate strength of agreement
[31]. However, we have to remember that this metric is a
nonweighting coefficient, for example, when 2 annotators
do not agree on the evaluation of a pair of sentences, for
this metric is equally wrong when one annotator grades
themwith 4 and the other with 0 (i.e., evaluations differ by
4 points) as when one grades them with 2 and the other
with 3 (i.e., evaluations differ by only 1 point). That is why
we reached an almost-perfect IRR in statistics that bet-
ter deals with ordinal scales: ICC (0.964) and Gwets AC2
(0.910). It is noteworthy that Gwets coefficients are much
more highly recommended methods to compute IRR than
those of the Kappa coefficients family.
We also compared the IRR between all combinations of
annotators pairs as a way of detecting consistent bias of
one annotator versus the others (see Fig. 4). We deter-
mined that more guideline clarifications were needed for
annotator 4, who consistently had lower IRR values than
the other raters.
Corpus
After the training period, we built the corpus based on
the proposed design (see Annotation design section). It
resulted in 171 pairs of sentences, each rated by 3 anno-
tators selected by chance from the group of 7 experts.
It is noteworthy that the sentences evaluated during the
training period were not included in these 171 pairs.
Several IRR analyses were performed to assess the
degree that annotators consistently assigned similarity
Fig. 4 IRR between pairs of annotators at the end of the training sessions. This chart shows the IRR (ICC) of each annotator compared with each of
the other annotators. Both x- and y-axes represent annotators; for example, the intersection of the y-value 4 and x-value 5 represents the IRR
between annotator-4 and annotator-5. As shown on the IRR scale to the right, the higher the IRR, the more intense the red color, and so in this case,
there is a moderate IRR between annotator-4 and annotator-5 and higher agreement between annotators 2 and 3. We noted that annotator-4 had a
lower agreement with all others and thus he needed more guideline clarifications
Lithgow-Serrano et al. Journal of Biomedical Semantics            (2019) 10:8 Page 11 of 14
Table 5 Corpus inter-rate agreement for various statistics
Statistic Variable Value p-value
Fleiss Kappa Kappa 0.443 0
Krippendorffs Alpha Alpha 0.745
Kendalls coefficient W 0.741 7.86e-18
Intraclass Correlation ICC 0.919 6.7e-83
Gwets coefficient AC2 0.870 0
ratings to sentence pairs (see Table 5). The marginal dis-
tributions of similarity ratings did not indicate a consid-
erable bias among annotators (Fig. 5), but they did show
a prevalence effect towards lower similarity rates (Fig. 6).
A statistic less sensitive to this effect was Gwets AC,
whichmakes an appropriate index of IRR, in particular the
AC2 variant, due to the ordinal nature of our data. The
resulting coefficient indicated very good agreement [32] of
AC2 = 0.8696 with a 95% confidence interval [0.8399,
0.8993].
For the sake of clarity, we investigated if the non-fully
crossed design caused too-inflated coefficients. To do this,
we first grouped the sentence pairs by the annotators who
rated them (now each of these groups could be considered
a fully crossed study design); next, we computed the IRR
for each group; finally, we computed the arithmetic mean
of all groups. The resulting averages (Table 6) were quite
similar to coefficients computed for the whole corpus,
reconfirming the corpus reliability.
From the individual rating distribution (Fig. 6), we can
see that although the distribution is biased towards no
similarity, we achieved a good amount (> 50%) of sentence
pairs rated within the 1-3 score range.
Discussion
We observed that the IRR increased more significantly
after the third training session. We think that this increase
can be explained mainly by two factors. First, annota-
tors familiarized themselves with the guidelines and they
had a better understanding of what was expected for the
task. Despite task explanations and annotation guidelines,
in the first sessions there was a tendency to grade the
similarity of the biological objects mentioned in the com-
pared texts and to overlook the full semantics conveyed
by those texts. Second, after the first two sessions, anno-
tators had collected a good set of examples along with
the respective explanatory notes from the previous con-
sensus sessions. These examples served as disambiguation
sources when needed. It is interesting that both factors
are related to the hypothesis that although similarity is an
Fig. 5 Ratings distribution per annotator. In this chart, the seven annotators are represented on the y-axis, and on the x-axis the evaluation
proportions for each similarity grade are represented. Similarity grades are ordered from lowest similarity (0) at the left to highest (4) at the right. For
example, it can be seen that both annotator-4 and annotator-5 had the highest proportions of 0-similarity evaluations, but annotator-5 tended to
give higher grades in the rest of the cases
Lithgow-Serrano et al. Journal of Biomedical Semantics            (2019) 10:8 Page 12 of 14
Fig. 6 Individual ratings distribution. This chart shows the distribution of annotators ratings per similarity grade during the evaluation of the corpus
(not the training period). The x-axis shows the five similarity scale values, and the percentage of evaluations within each grade are represented on
the y-axis. More than 40% of the evaluations were rated as no similarities (score of 0); nevertheless, 50% of evaluations were in the similarity value
range between 1 and 3
intuitive process, there is not a perfect consensus, espe-
cially about the grades of similarity [3336]. It depends
on the personal context, and we could confirm the impor-
tance of guidelines and consensus sessions to homogenize,
at a certain grade, the annotators performance.
Another practice that we found helpful during the con-
sensus sessions was the participation of a mediator who
was familiarized with the guidelines and with the tasks
goal but was not part of the annotators group, i.e., a third
party. When needed, the mediators role was limited to
exhort annotators to explain their posture and, if pertinent
and possible, to put the discussion in equivalent terms
through a general context analogy. This helped to avoid
unjustified influence of those annotators who were more
experienced or who upheld more strongly their opinions.
In general, annotators agreed that the sentences with-
out biological objects mentions were more difficult to
assess and that in the candidate sentences there was a clear
bias toward low similarity scores. This similarity dataset
is just the first iteration of an ongoing process. We plan
to repeat this strategy to extend the dataset; instead of
using the basic STS process, now we could use a similarity
model trained with the current corpus [18], and therefore
it is reasonable to expect an improvement in the preselec-
tion step, more likely resulting in a more balanced rating
distribution, i.e., more grades of 3 and 4.
In the spirit of weighing the size and distribution
of our corpus against previous work, we compared it
with BIOSSES. We selected this corpus because, to the
best of our knowledge, it is the only similarity corpus
specialized for the biomedical domain, and setting our
corpus side by side with the general-domain ones (e.g.,
MSRP, SEMEVAL, ULPC) would be unfair. Regarding bal-
ance for these two corpora with respect to the number
of sentence pairs per grade, BIOSSES is better balanced,
with 15% of sentences graded with a value of 0, 12% with
1, 27% with 2, 35% with 3, and 11% graded with 4. Our
corpus has a distribution of 48%, 22%, 15%, 14%, and 1%
corresponding to the 0, 1, 2, 3, and 4 similarity grades.
However, concerning corpora size, although it is still small
our corpus, with 171 sentence pairs, is 70% larger than
the BIOSSES corpus, which consists of only 100 pairs of
sentences. Moreover, even though BIOSSES is special-
ized for the biomedical domain, its coverage is still too
broad for our purpose. This is evidenced by the fact that,
when analyzing terms frequencies in BIOSSES, within
Table 6 IRR by annotators group
Annotators Kendall Fleiss ICC Kripp Gwet
1, 2, 3 0.782 0.597 0.941 0.814 0.864
1, 2, 7 0.641 0.512 0.926 0.705 0.894
1, 6, 7 0.788 0.358 0.912 0.756 0.686
2, 3, 4 0.669 0.442 0.916 0.691 0.907
3, 4, 5 0.712 0.310 0.894 0.708 0.802
4, 5, 6 0.593 0.268 0.753 0.602 0.818
5, 6, 7 0.833 0.409 0.913 0.772 0.784
Mean 0.717 0.414 0.894 0.721 0.822
Lithgow-Serrano et al. Journal of Biomedical Semantics            (2019) 10:8 Page 13 of 14
the top 50 terms we found terms like cell, tumor, cancer,
study, report, human, gene, lung, leukemia, etc., whereas
in our corpus the prevailing terms are site, expression,
activation, gene, protein, strain, regulation, DNA, region,
downstream, upstream, etc.
We believe that our publicly available dataset (see
Availability of data and materials section) can be of
great benefit in several NLP applications. For example, we
are already successfully using it to fine-tune and test a
semantic similarity engine as part of an assisted curation
pipeline. Within these experiments, we used an ensemble
of similarity metrics that were string, distributional, and
ontology based. The individual measures were combined
through different regression models which were trained
using the corpus presented in this publication. Our mod-
els obtained strong correlations (? = 0.700) with human
evaluations, which are far from state-of-the-art in general
domains but are quite good considering our highly spe-
cialized domainMicrobial Transcriptional Regulation.
In the absence of this corpus, the only alternative would
have been to equally weight the different metrics, which
in our experiments results in a Pearsons correlation (?) of
0.342, at best. With these experiments, it was shown that
this corpus is not only relevant but also useful for applied
tasks [18].
Conclusions
We did not obtain a corpus with ratings as balanced as
desired; however, we now have a good representation of
4 of the 5 rates and a corpus with very good IRR. There-
fore, it is going to serve well our purposes, and we think
it can be quite a valuable starting point, with respect to
data and processes to continue building a standard sim-
ilarity corpus in the transcriptional regulation literature.
To the best of our understanding, this is the first similar-
ity corpus in this field, and thus it represents a stepping
stone towards the evaluation and training of NLP-based
high-throughput curation of literature on microbial tran-
scriptional regulation.
Endnotes
1 http://regulondb.ccg.unam.mx/
2 http://regulondb.ccg.unam.mx/menu/tools/nlp/
index.jsp
3Declarative, interrogative, exclamatory, etc.
4 Based on the stylographic tag assigned by our home-
made PDF processing tool.
5Applying a baseline metric.
6 In fully crossed design studies all evaluated items (pairs
of sentences) are rated by the same set of annotators,
whereas in non-fully crossed design studies, different items
are rated by different subsets of annotators.
Abbreviations
DNA: Deoxyribonucleic acid; FNR: Fumarate and nitrate reductase regulatory
protein; Fleiss: Fleiss Kappa coefficient; GC: Growth conditions; Gwet: Gwets
AC1 statistic; ICC: Intraclass correlation; IRR: Interrater reliability; Kendall:
Kendall coefficient; Kripp: Krippendorffs Alpha coefficient; MSRP: Microsoft
Research Paraphrase; NLP: Natural Language Processing; RI: Regulatory
interaction; RNA: Ribonucleic acid; SEMEVAL: Semantic Evaluation workshop;
SPSS: Sentence Pair Similarity Score; STS: Semantic Textual Similarity; TF:
Transcription Factor(s); TFBS: TF binding site; TU: Transcription Unit; ULPC: User
Language Paraphrase Corpus
Acknowledgements
Not applicable.
Funding
We acknowledge funding from UNAM, from FOINS CONACyT Fronteras de la
Ciencia [project 15], and from the National Institutes of Health (grant number
5R01GM110597). CMA is a doctoral student from Programa de Doctorado en
Ciencias Biomédicas, Universidad Nacional Autónoma de México (UNAM), and
is the recipient of Ph.D. fellowship 576333 from CONACYT.
Availability of data andmaterials
The corpus is available at https://github.com/JCollado-NLP/Corpus-
Transcriptional-Regulation.
Authors contributions
OWLS carried out the experiments design, the data analysis, and wrote the
paper. JCV participated in the project design, annotation guidelines, writing
and correction of the paper. All other authors refined the experiment design
and annotation guidelines, participated in the consensus sessions, and
performed the corpus annotation. All authors read and approved the final
manuscript.
Authors information
Not applicable.
Ethics approval and consent to participate
Not applicable.
Consent for publication
Not applicable.
Competing interests
The authors declare that they have no competing interests.
Publishers Note
Springer Nature remains neutral with regard to jurisdictional claims in
published maps and institutional affiliations.
Author details
1Computational Genomics, Centro de Ciencias Genómicas, Universidad
Nacional Autónoma de México (UNAM). A.P., 565-A Cuernavaca, 62100
Morelos, México. 2Instituto de Investigaciones en Matemáticas Aplicadas y en
Sistemas (IIMAS), Universidad Nacional Autónoma de México (UNAM), Mexico
City, México. 3Department of Biomedical Engineering, Boston University,
Boston, Massachusetts, USA.
Received: 9 February 2018 Accepted: 16 April 2019
Wang et al. Journal of Biomedical Semantics           (2019) 10:11 
https://doi.org/10.1186/s13326-019-0202-8
RESEARCH Open Access
Predicting instances of pathway
ontology classes for pathway integration
Lucy Lu Wang1* , G. Thomas Hayman2, Jennifer R. Smith2, Monika Tutaj2, Mary E. Shimoyama2 and John
H. Gennari1
Abstract
Background: To improve the outcomes of biological pathway analysis, a better way of integrating pathway data is
needed. Ontologies can be used to organize data from disparate sources, and we leverage the Pathway Ontology as a
unifying ontology for organizing pathway data. We aim to associate pathway instances from different databases to
the appropriate class in the Pathway Ontology.
Results: Using a supervised machine learning approach, we trained neural networks to predict mappings between
Reactome pathways and Pathway Ontology (PW) classes. For 2222 Reactome classes, the neural network (NN) model
generated 10,952 class recommendations. We compared against a baseline bag-of-words (BOW) model for predicting
correct PW classes. A 5% subset of Reactome pathways (111 pathways) was randomly selected, and the
corresponding class recommendations from both models were evaluated by two curators. The precision of the BOW
model was higher (0.49 for BOW and 0.39 for NN), but the recall was lower (0.42 for BOW and 0.78 for NN). Around 78%
of Reactome pathways received pertinent recommendations from the NN model.
Conclusions: The neural predictive model produced meaningful class recommendations that assisted PW curators in
selecting appropriate class mappings for Reactome pathways. Our methods can be used to reduce the manual effort
associated with ontology curation, and more broadly, for augmenting the curators ability to organize and integrate
data from pathway databases using the Pathway Ontology.
Keywords: Pathway ontology, Ontology-based data integration, Semi-automated ontology curation, Ontology
mapping, Pathway data interoperability
Background
Ontologies can be used to align and integrate data from
multiple sources. In the case of biological pathways,
there are numerous databases collecting and describing
information about pathway networks, but no centralized
schema to organize these various pathways. A shared
organizational scheme would allow researchers to identify
semantically similar pathways, providing a framework for
pathway data integration.
Pathways are a form of graph data describing bio-
logical function. Individual pathway modules describe
the interactions between dozens or hundreds of genes,
*Correspondence: lucylw@uw.edu
1Department of Biomedical Informatics and Medical Education, University of
Washington, 850 Republican St, 98109 Seattle, WA, USA
Full list of author information is available at the end of the article
proteins, and molecules, and how these interactions con-
tribute to events of biological consequence. The com-
plexities of analyzing genomic data have led to a rise in
the use of pathways for pathway analysis, a class of sta-
tistical methods that aggregate single gene effects over
the genes described in pathway modules. These pathway
analysis techniques (such as gene set enrichment analysis
(GSEA) [1] or network-based pathway analysis methods
[2]) allow variations in gene expression to be interpreted
at a functional level. Due to the large variety of pathways
available from different databases, pathway analysis often
leverages pathways from multiple databases. For exam-
ple, MSigDB, which is often used as a source of gene sets
for GSEA, combines pathways from the Kyoto Encyclope-
dia of Genes and Genomes (KEGG), the National Cancer
Institutes Pathway Interactions Database (NCI-PID), and
Reactome [3].
© The Author(s). 2019 Open Access This article is distributed under the terms of the Creative Commons Attribution 4.0
International License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and
reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to the
Creative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver
(http://creativecommons.org/publicdomain/zero/1.0/) applies to the data made available in this article, unless otherwise stated.
Wang et al. Journal of Biomedical Semantics           (2019) 10:11 Page 2 of 11
Combining pathways from different databases results in
redundancy in the pathway data set. The same or a similar
pathway may be represented in multiple databases. Meta-
resources such as Pathway Commons [4] and Consen-
susPathDB [5] allow for querying and access to pathways
from different databases, but lack the ability to collapse
redundant pathways between databases. Other resources
such as PathCards [6] or ReCiPa [7] use statistical meth-
ods to detect gene overlap between two pathways, merg-
ing pathways with significant overlapping entities into
superpathways to reduce membership redundancy. How-
ever, these methods fail to retain the functional bound-
aries of pathways, which are crucial for pathway analysis
result interpretation, i.e., allowing gene expression differ-
ences to be aggregated and interpreted at a functional
level.
Pathways from different databases are challenging to
integrate due to content and representational differences
between various pathway databases. Previous studies
have described the differences that exist between pairs
of pathway databases [811], and in our prior work,
we have categorically summarized ways in which path-
way representations have been found to differ between
many common pathway databases [12]. Although most
databases provide data in pathway file sharing stan-
dards such as BioPAX [13], SBML [14], or GPML [15],
these standards are insufficient for ensuring interop-
erability. Even when two databases present data using
the same standard language, the different decisions of
pathway editors at both individual and database levels can
result in variable pathway representation [12].
Ontologies have been used successfully to combine
disparate datasets in the biomedical domain [1618].
We hypothesize that an ontology of pathway classes
can be used to organize data from different pathway
databases, allowing us to merge data while maintaining
an understanding of the semantic relationships between
various pathways. The Pathway Ontology (PW), an
ontology of pathway terms, can be used as an anchoring
ontology to identify similar pathways [19]. The PW was
developed as part of the Rat Genome Database (RGD)
as a means to catalog and describe the relationships
among various biological pathways. The ontology covers
broad pathway categories such as metabolic, regulatory,
signaling, disease, and drug pathways, and allows for
the representation of both subclass and mereological
hierarchies via the subclass and part-of relationships
respectively. The PW is a suitable ontology for integrating
pathway data because it provides:
 a hierarchy of pathway classes and their relations to
one another,
 classes describing altered and disease pathways, and
 existing mappings to pathways from KEGG, NCI-PID,
and the Small Molecule Pathway Database (SMPDB).
The Gene Ontology (GO) describes biological pro-
cesses, and could be a suitable ontology for pathway data
integration based on its more developed classes and richer
annotations [20]. However, the GO lacks classes describ-
ing altered or disease pathways, which are essential for
downstream applications of pathway resources. The PW
describes both altered and disease pathways in its class
hierarchy and is therefore suitable for integrating pathway
data.
Using the PW, we can group together semantically and
functionally similar pathways by mapping them to the
appropriate PW class. All pathways mapped to a partic-
ular PW class can then be merged together to form a
normalized pathway representation of that class. This set
of normalized pathways can be used in pathway analysis
applications, and will have less redundancy compared to
naively combined pathway datasets, as well as increased
functional interpretability due to the preserved PW class
hierarchy.
To better enable pathway data integration, we must
map the content of other pathway databases to the
PW. However, manual mappings are both laborious
and time-consuming to produce. In light of limited
curatorial resources, we propose a method to inte-
grate computational prediction into the curation pipeline,
allowing a predictive model to reduce the number of man-
ual comparisons that need to be made by PW curators.
Machine learning methods have been used with suc-
cess for ontology-related tasks such as ontology learning,
ontology completion, and ontology alignment [21, 22].
Rule-based techniques have been very successful, but
supervised or semi-supervised approaches can also be
used when training data are available. We propose and
implement a supervised learning framework for inferring
mappings between pathways from pathway databases and
the PW, with a goal of reducing the hours associated with
manual curation.
In this article, we describe efforts to generate PW class
mappings for pathways from Reactome, one of the largest
and most comprehensive pathway databases [23]. Our
methods are generalizable to other pathway databases,
such as BioCyc [24] and WikiPathways [25], that are not
currently represented in the PW. We have applied our
trained model to BioCyc and WikiPathways to generate
mappings. Our contributions are two-fold; we introduce:
 A curation pipeline that integrates a predictive model
with manual curation, and an evaluation of our
prediction results, and
 Newly predicted and curated mappings between the
PW and Reactome
Wang et al. Journal of Biomedical Semantics           (2019) 10:11 Page 3 of 11
In this work, we describe the design and implemen-
tation of this curation pipeline, with emphasis on our
supervised mapping prediction model. We describe how
mappings are generated and provide an evaluation of
the results compared to a baseline bag-of-words (BOW)
model. PW curators manually review a randomly selected
subset of mapping outputs to determine the precision and
recall of each model. We also discuss new mappings and
relationships that we plan to add to the PW in future
versions, with particular emphasis on expanding the part-
of hierarchy and the inclusion of regulatory relationships
through the usage of terms from the Relation Ontology.
By integrating a machine learning predictive model into
the PW curation pipeline, we hope to reduce the burden of
manual curation on our efforts to integrate pathway data.
It is our hope that other researchers can incorporate sim-
ilar methodology into their ontology curation pipelines,
thereby reducing curatorial labor while increasing high
quality mappings between datasets and ontologies.
Methods
Our goal is to associate pathway instances from various
databases to the correct class in the Pathway Ontology.
The following describes our methods as applied to the
Reactome database. Specifically, we map each Reactome
pathway to a matching class in the PW if a matching class
exists. In cases where no matching class exists, a new
PW class is introduced to account for the pathway; the
new class is inserted where appropriate into the PW class
hierarchy.
Each class in the PW consists of its unique identi-
fier and its descriptive information: a canonical name,
aliases (synonyms), definition, and its location in the PW
subclass and part-of hierarchies. Each Reactome path-
way has similar descriptive information, along with the
pathway content itself: the entities and relationships that
describe the biochemical functions of the pathway. These
pieces of descriptive information can be used to asso-
ciate pathways with PW classes. Our goal is to build a
predictive model leveraging this information along with
training data to generate high-quality mapping recom-
mendations between Reactome and the PW. This predic-
tive model can then be inserted into the PW curation
pipeline to improve the speed and quality of curated map-
pings. For this task, we propose a supervised machine
learning algorithm that learns features and weights from
the information provided for each PW class or Reactome
pathway.
The pipeline (Fig. 1) we propose and test consists of the
following steps:
 Extract training data from the PW and the Unified
Medical Language System (UMLS)
Metathesaurus [26]
 Bootstrap additional training data by predicting high
likelihood mappings between Reactome pathways
and PW classes
 Train a neural network model using all training data
 Predict Reactome mappings to the PW using trained
model
 Review predicted mappings manually for correctness
and inclusion into the PW
We treat the predictive task as a binary classification
problem, where given a pathway and a PW class, we pre-
dict whether the two have a high likelihood of matching.
We construct two models, one which predicts matches
over the names and aliases of pathways and PW classes,
and one which predicts matches over the natural language
definitions of pathways and PW classes. The distinction is
introduced because not all pathways or PW classes have
natural language definitions, and neural network models
can be challenged by the presence of null fields in cases
where training datasets are small. A subsequent decision
module then collects the predictive model outputs for the
separate name and definition models and combines these
to form a final predicted similarity score.
Details for each step in the curation pipeline are pro-
vided in the following sections. We also provide a descrip-
tion of the candidate selector module we used for both
negative data sampling and candidate selection when run-
ning the predictive model. All results presented discuss
pathways from Reactome v65, released 2018, June 12.
Baseline bag-of-words model
A bag-of-words (BOW) model is provided as a baseline
model for comparison. This baseline is based on string
similarity, and is similar to the way curators previously
retrieved potential class matches for pathway instance
annotation. For the BOW model, each pathway and PW
class is represented as a set of word and n-gram tokens,
generated from its names, definition, and the names of its
parent and children classes. A idf -weighted Jaccard index
is computed between the token set of a Reactome pathway
(A) and the token set of a PW class (B) as:
Jweighted =
?
tA?B idf (t)?
tA?B idf (t)
(1)
For each Reactome pathway, PW classes with weighted
Jaccard indices above a threshold similarity score are
selected as output. The optimal threshold was determined
using a grid search over the training data. All results
provide comparisons between our neural network-based
predictive model against this baseline model.
Candidate selection
The candidate selector module takes in a pathway and
outputs a ranked list of PW classes that are potential
Wang et al. Journal of Biomedical Semantics           (2019) 10:11 Page 4 of 11
Fig. 1 Semi-automated curation pipeline
matches. Good matches are determined by large lexi-
cal overlap in descriptive information. We first generate
a string representation of each pathway or PW class by
appending together its names, definitions, and the names
of all its parents and children. Each pathway string or PW
class string from this corpus is then parsed to a set of
word tokens and character n-gram tokens. Each token is
weighted by its inverse document frequency (idf ) in the
entire corpus. Tokens with higher idf occur less frequently
and may be more relevant for determining matches. The
overall lexical overlap score between a pathway and a PW
class is determined by summing the idf of all overlapping
tokens between the two.
The candidate selector is used to reduce the number of
necessary comparisons when predicting PW class map-
pings. When the candidate selector is given a pathway as
input, it first selects all PW classes with any token over-
lap with the input pathway. The selector then sorts the
overall lexical overlap scores for these PW classes and
returns the top 20 as candidates. Instead of performingm
comparisons for each pathway (where m is the number of
PW classes), the candidate selector reduces the number of
comparisons to 20.
The candidate selector is also used to generate hard
negatives (see Training data section), which are nega-
tive training data where there is substantial lexical overlap
between the pathway string and PW class string. Hard
negatives are selected from the candidate list while ensur-
ing no overlap with positive training data. Hard negatives
are introduced into the training data to force greater
predictive precision.
Training data
To train a binary classifier, we require both positive and
negative training data. Priormappings of KEGG,NCI PID,
and the SMPDB to the PW can be used as positive labeled
training data. Together, 860 mappings are provided in the
PW. These mappings exist over 732 unique PW classes,
out of a total of 2627 classes; in other words, around 28%
of PW classes have existing mappings to pathways. These
mappings reference 206 unique pathways from KEGG, 76
from NCI-PID, and 557 from SMPDB.
For each PW class, negative mappings are also sam-
pled from these three pathway databases for training.
Approximately two easy and two hard negatives are
sampled for each PW class, where easy negatives are
randomly selected from the pathway database, and hard
negatives are selected using the candidate selector mod-
ule. Care was taken to ensure that no extracted negatives
overlap with any positive training examples.
To augment these existing mappings, we also extract
mappings from the UMLS Metathesaurus between Gene
Ontology (GO) biological process terms and the Medi-
cal Subject Headings (MeSH) [26]. GO biological process
classes overlap with concepts in the pathway space, and
we believe these mappings can provide reasonable distant
supervision for our classifier. From UMLS, we extract 732
mappings between MeSH and GO.
The breakdown of all extracted training data is given in
Table 1. Of these, 860 positive and 7116 negative map-
pings are extracted from the PW and 732 positive and 325
negative mappings from the UMLS Metathesaurus.
Bootstrapping
To further boost training data, we extract high proba-
bility positive matches between the PW and pathways
from Reactome. Including training examples from Reac-
tome adapts the predictive model to the specifics of the
Reactome database and we can expect an improvement in
prediction quality. A bootstrapping procedure (Fig. 2) is
used to iteratively train a predictive model and append its
highest likelihood predictions to the training data [27].We
employ a simple logistic regression model using manually
engineered lexical similarity features. The features we use
are:
 Normalized absolute value percent word token
number difference
Table 1 Training data by source
Source No. positive No. negative
PWmappings to KEGG, NCI-PID, and SMPDB 860 7116
GO/MeSH mappings 732 325
Bootstrapped PW/Reactome mappings 730 720
Total 2322 8161
Wang et al. Journal of Biomedical Semantics           (2019) 10:11 Page 5 of 11
Fig. 2 Bootstrapping procedure. The initial training data is derived from existing PWmappings and UMLS mappings between MeSH and GO. A
simple logistic regression model is trained on this data and used to bootstrap training samples from Reactome. The best matches between
Reactome pathways and PW classes are added to the training data set over 10 iterations to generate a final training data set
 Word token Jaccard index
 Character n-gram Jaccard index for n=3, 4, 5
For each bootstrapping iteration, we train a logistic
regression model over the training data. We run this
trained model over the PW and Reactome, generating a
set of predicted PW classes for each pathway in Reac-
tome. The top and bottom 0.25% of predictions are added
to the training data as respective positive and negative
training examples for the following iteration. We itera-
tively train the bootstrappingmodule 10 times, generating
730 positive and 720 negative training samples from Reac-
tome. A cursory review of the added training samples
revealed good quality matches (88% correct at iteration
10), where most of the matches could be considered low-
hanging fruit, with pathway and PW class names that
match well based on string similarity alone. Incorrect
matches have very close semantic relationships, such as
the Reactome pathway for RNA polymerase II transcrip-
tion matching to the PW class for RNA polymerase I
transcription.
Neural network
We constructed two neural network models for process-
ing pathway names and pathway definitions. We begin by
describing the pathway name model.
Each pathway name is represented using pre-trained
word embeddings. For each word token, we concate-
nate a 100-dimensional word2vec [28] vector and a
100-dimensional fasttext [29] vector, generating a 200-
dimensional word vector. Both word2vec and fasttext
embeddings are trained on Pubmed Central full-length
journal articles. Word2vec tends to capture the semantic
context of a word and fasttext its internal structure (pre-
fixes, suffixes etc), so combining the two allows us to cap-
ture information about both the meaning and appearance
of a word.
The pathway name is treated as a bag of word embed-
dings; the word-level embeddings of each word token
in the name are summed, generating a pathway name
embedding: a 200-dimensional vector. A PW class name
embedding is generated from the PW class name in a sim-
ilar fashion. These two embeddings are concatenated and
Wang et al. Journal of Biomedical Semantics           (2019) 10:11 Page 6 of 11
input into a decision network consisting of two fully con-
nected neuron layers. A sigmoid function processes the
output of this network, producing a final similarity score
between 0 and 1, which is thresholded to determine the
binary class output.
Pathway definitions consist of longer pieces of text
with many internal relationships (see Fig. 3 for exam-
ples). Instead of bag-of-embeddings, a bidirectional long-
short term memory (LSTM) network is used to capture
more semantic information [30]. The hidden layers at
both ends of the LSTM are concatenated to produce a
pathway definition embedding vector. The pathway def-
inition embedding and PW class definition embedding
vectors are then concatenated and input into a deci-
sion network of fully connected neuron layers. Simi-
larly, an output score between 0 and 1 is generated as
output using a sigmoid function. Figure 3 shows the
network architecture of the definition model; the name
model uses bag-of-embeddings networks in lieu of the
LSTMs.
The final training data are split into a training (90%) and
development (10%) set. The models are trained to min-
imize the binary cross-entropy loss with respect to the
training labels. We use the development set to optimize
model training for recall, because we are more concerned
about deriving all possible matches rather than all certain
matches.
Combining predictions
The trained neural networks are used to predict mappings
between Reactome and the PW. For each pathway in Reac-
tome, the candidate selector selects the top 20 PW classes,
generating up to 20 candidate pairs. For each candidate
pair (N ,M), where N is a pathway from Reactome and M
a class from PW,N has namesNname = {n1, n2, ..., np} and
M has names Mname = {m1,m2, ...,mq}. These names are
formed into unique name pairs by taking the Cartesian
product of Nname and Mname. Each pair of names (i, j) is
fed into the name neural network model, producing a set
of name similarity scores:
Sname = {sij | (i, j)  Nname × Mname} (2)
Each score sij is the similarity between the pathway
name i and PW class name j.
If the Reactome pathway has a definition, then the def-
inition texts of the pathway and PW class are fed into the
definition neural network model, yielding a single similar-
ity score Sdef . A final similarity score is produced by com-
bining and weighting the name and definition similarities:
Stotal = 0.75max (Sname) + 0.25Sdef (3)
The weights of max (Sname) and Sdef are selected to
favor name similarity because in many cases, there is a
lack thereof or non-specific definition in Reactome. More
optimal weights are likely to exist, but we do not explore
Fig. 3 Architecture of neural network model. The neural network computes similarity between a pathway definition and a PW class definition. A
bidirectional LSTM is used to encode the definition texts. This example shows the definition for Reactome pathway R-HSA-109606 and PW class
PW:0000104 being encoded and compared in the neural network
Wang et al. Journal of Biomedical Semantics           (2019) 10:11 Page 7 of 11
them in this work due to limited resources for evaluation.
Matching PW classes with Stotal above a threshold of 0.25
are output by the predictive model.
Evaluation of model results
For evaluation, a 5% subset of pathways from Reactome
were randomly selected, a total of 111 pathways out of
2222. For this subset, all output predictions from both
the BOW and NN model were extracted and presented
to two curators for manual review. Output predictions
were presented to curators after first grouping by Reac-
tome pathway and then sorting the PW classes within
each group by similarity score. A separate subset of 211
class recommendations produced by the NN model was
also evaluated by both curators, allowing us to determine
inter-rater agreement.
Curators were asked to perform the following task on
each selected subset: for each Reactome pathway-PW
class pair, grade the pair as y(es)/n(o)/r(elated), where
y(es) indicates an exact match, n(o) indicates an incorrect
match, and r(elated) indicates that although the pair is not
an exact match, the pathway is related to the PW class
(maps to parent, child, or sibling classes). Two metrics are
computed over the labeled results, precision per mapping
(ppm) and recall per pathway (rpp). The ppm is defined as
the ratio of pathway-PW class pairs rated y(es) or r(elated)
over all pairs rated. It is a measure of how correct the
models are for each recommendation produced. The rpp
is defined as the number of pathways for which at least one
y(es) or r(elated) PW class is recommended over the total
number of pathways. It is a measure of how successful the
algorithm is at making at least one successful recommen-
dation for each pathway. We also report the yield of both
models over all Reactome pathways. The yield indicates
the percentage of pathways receiving any recommended
PWmappings.
For each Reactome pathway, curators also selected the
correct mapping, either from among the predicted PW
class matches, or from elsewhere in the PW. These map-
pings are added to the PW for future release. In cases
where a correct mapping is not predicted by our model,
curators must determine whether a new class or relation
needs to be added to accommodate the Reactome pathway
in question.
Results
The model was used to generate PW mapping recom-
mendations for Reactome human pathways. The BOW
model yielded 4122 mapping suggestions for 2222 Reac-
tome pathways. The NN model produced 10,952 sugges-
tions for the same pathways. Table 2 shows example NN
predictions generated for the Reactome human apopto-
sis pathway, R-HSA-109581, of which there is no direct
name-matched class in the PW. The predictions show that
the predictive model is able to retrieve PW classes that
are similar to the Reactome pathway in both name and
content. The top predicted matches are those describ-
ing the apoptotic process, followed by those describing
related processes in immune response and cell death. Of
these recommended PW classes, the correct match is to
PW:0000009, the apoptotic cell death pathway, the second
ranked PW class recommended by the predictive model.
This PW class was selected by curators as the correct PW
mapping for R-HSA-109581.
Two RGD curators (GTH and MT) conducted a repro-
ducibility review of the predictions. Table 3 shows the
results of the reproducibility analysis. Review of 211 class
recommendations showed a 0.73 agreement between two
reviewers for each mapping (Cohens kappa for three
classes (y/n/r) = 0.56).
A comparison of BOW and NN models is provided
in Table 4. Curators reviewed 243 mapping recommen-
dations produced by the BOW model for 111 randomly
sampled pathways, and 660 recommendations produced
by the NN model for the same 111 pathways. The
BOW model had significantly lower yield compared to
the NN model (BOW: yield = 0.50; NN: yield = 0.80).
Although the BOW model had higher precision than
the NN model (BOW: ppm = 0.49; NN: ppm = 0.39), it
also had correspondingly lower recall (BOW: rpp = 0.42;
NN: rpp = 0.78). Overall, the NN model provided more
opportunities for selecting an appropriate mapping. Per-
haps combining the outputs of bothmodels could produce
better coverage with higher precision.
A number of pathways did not receive relevant sug-
gestions via either model. Reactome, in particular, con-
tains very specialized regulatory pathway representations
that do not currently have corresponding classes in the
PW. Some portions of the PW class hierarchy, such as
those describing the immune system and cellular signal-
ing, may require further development. For example, sev-
eral Reactome pathways dealing with interferon-mediated
immunity, such as R-HSA-1834941 (STING mediated
induction of host immune responses) or R-HSA-918233
(TRAF3-dependent IRF activation pathway) do not
have corresponding pathway classes in the PW. The PW
contains classes for type I (PW:0000895) and type II
(PW:0000896) interferon signaling pathways, and has sev-
eral subclasses describing signaling pathways related to
innate immune response (PW:0000819), but none of these
existing classes are suitable for describing the functions
represented by the example Reactome pathways. The PW
may need to add either more granular pathway classes,
or introduce properties such as regulates or related_to
to annotate the relationships described above and found
throughout pathways from Reactome.
The above methods can also be applied to other path-
way databases. As a test of generalizability, we ran the
Wang et al. Journal of Biomedical Semantics           (2019) 10:11 Page 8 of 11
Table 2 Top ranked predicted mappings for Reactome pathway R-HSA-109581, Apoptosis
PW ID PW class name Beginning of definition text
1 PW_0000104 intrinsic apoptotic pathway The apoptotic pathway involving organelles,
primarily the mitochon...
2 PW_0000009 apoptotic cell death pathway Apoptosis is a programmed cell death path-
way that is characterized by...
3 PW_0000106 extrinsic apoptotic pathway The apoptotic pathway involving the death
receptors mediated route of...
4 PW_0000718 p53 signaling pathway p53 transcription factor is a tumor suppres-
sor frequently mutated in...
5 PW_0000124 cellular detoxification pathway A pathway triggered by exogenous or
endogenous elements, compounds...
6 PW_0000823 humoral immunity pathway Humoral immunity is mediated by antibod-
ies secreted by the B cell...
7 PW_0000824 cell-mediated immunity pathway Cell-mediated immune response pathways
are carried out by T cell...
8 PW_0000499 nuclear factor kappa B signaling
pathway
NF-kB signaling plays an essential role in the
mammalian immune...
9 PW_0000680 altered extrinsic apoptotic pathway <no definition>
10 PW_0000233 tumor necrosis factor mediated sig-
naling pathway
Tumor necrosis factor (Tnf) signaling plays
pivotal roles in immunity...
trained predictive model over pathways from Human-
Cyc and WikiPathways, generating predicted mappings
to the PW. The NN model produced 1199 recommend
ations for 217 HumanCyc pathways and 1652 recommen-
dations for 351 WikiPathways pathways. These recom-
mendations have yet to be reviewed by curators, but can
provide a helpful starting point when mapping pathways
from these other databases to the PW. Early inspection
of the results suggest that similar pathways between these
databases receive mappings to similar or the same PW
classes. For example, Table 5 shows the top pathways
from Reactome, HumanCyc, and WikiPathways that the
NN model associated with PW:0000029, the fatty acid
biosynthetic pathway. Although imperfect, the recom-
mendations are largely relevant. Note that fewer pathways
from HumanCyc and WikiPathways are associated with
this PW class; this is due to both the smaller size of
the HumanCyc and WikiPathways databases, but also the
granularity of represented pathways.
Curator-selected mappings between Reactome and PW
classes can be used as an additional source of training data
Table 3 Inter-rater agreement for mapping labeling task
Rater #1
Rater #2 y(es) r(elated) n(o) Totals
y(es) 24 8 0 32
r(elated) 0 69 4 73
n(o) 0 46 60 106
Totals 24 123 64 211
for improving the predictive model. As the quantity of
high-quality training data increases, our predictive model
should improve, helping to further reduce the curatorial
burden of mapping other pathway databases to the PW.
Discussion
We have described our efforts to incorporate a predic-
tive classifier into the PW curation pipeline for generating
mappings between pathway databases and the PW. Results
demonstrate that our model is able to recommend rele-
vant PW class mappings for pathways. By automatically
inferring high-likelihoodmappings between pathways and
PW classes, we hope to reduce the burden on curators.
Our decisions maximalize annotation success based on
the curation pipeline described in Figure 1. For example,
we bias the NN model during training to maximize recall.
This is desirable because we have the luxury of manual
curatorial review as a gatekeeper to annotation. When
operating in situations without manual review, it may be
more desireable to bias the model towards maximizing
metrics such as precision or accuracy.
The mappings we generated between Reactome path-
ways and PW classes contribute to our overall goal of
Table 4 Comparison of BOW and NN model predictions
Model Precision (ppm) Recall (rpp) Yield
BOW 0.49 0.42 0.50
NN 0.39 0.78 0.80
Precision and recall are calculated from a 5% sample of Reactome pathways; yield is
calculated over all Reactome pathways
Wang et al. Journal of Biomedical Semantics           (2019) 10:11 Page 9 of 11
Table 5 Top pathways predicted to map to PW:0000029 ("fatty acid biosynthetic pathway")
HumanCyc Reactome WikiPathways
PWY-5966: fatty acid biosynthesis initiation II R-HSA-77288: mitochondrial fatty acid beta-
oxidation of unsaturated fatty acids
WP357: Fatty Acid Biosynthesis
PWY-5143: fatty acid activation R-HSA-77289: Mitochondrial Fatty Acid Beta-
Oxidation
R-HSA-390247: Beta-oxidation of very long
chain fatty acids
R-HSA-75105: Fatty acyl-CoA biosynthesis
R-HSA-500753: Pyrimidine biosynthesis
R-HSA-8978868: Fatty acid metabolism
pathway data organization and integration. By organizing
pathways from different databases under a single unify-
ing ontology, we can understand how pathway data from
different databases relate to one another. We can use the
PW class hierarchy to reduce redundancy among pathway
datasets by merging pathways under each PW class into
normalized pathways. Normalized pathways may have
better interpretability due to the class boundaries and
relationships provided by the ontology.
As described in previous publications, we face many
challenges to pathway data integration, such as 1) the
usage of different pathway organizational schemes by dif-
ferent databases, 2) incomplete or inconsistent descrip-
tion of pathway-subpathway relationships, as well as 3)
differences in identifier and semantic choices in repre-
senting pathway data among the various source databases
[6, 7, 12, 31]. Using a unifying ontology for organization
at the pathway level will ameliorate the first two of these
challenges. To address the third, we have demonstrated
methods of entity disambiguation and graph alignment
capable of aligning pathways even in the presence of iden-
tifier or semantic differences [32]. In this prior work, we
explored lexical and topological techniques for pathway
alignment. These pathway alignment techniques should
be able to handle many of the described representational
differences when merging pathways.
Limitations
The current mapping prediction algorithm uses pathway
name and definition information (and to some extent,
the names of parent and child pathways and PW classes,
through the candidate selector) to match pathways with
PW classes. The algorithm does not incorporate the path-
way content itself: the graph of entities and relationships
that describe biological function. By incorporating tex-
tual descriptions of pathways, we believe we capture most
of the important entities and relationships in a pathway.
Explicit information on pathway member entities were
left out of the current mapping algorithm due to con-
cern about increasing the size of the predictive model,
and challenges in representing this information as model
input. How to include this additional information in pre-
diction is an open research question.
Pathway databases are all different, each with its own
strengths and limitations. What works for Reactome
may not apply directly to all other pathway databases.
Although we have demonstrated the ability to apply
the predictive algorithm to HumanCyc and WikiPath-
ways, we have not yet evaluated the resulting predic-
tions. We have also not evaluated how newly gener-
ated Reactome mappings may benefit the detection of
mappings between other pathway databases and the
PW. Because these other databases emphasize different
aspects of pathway data (e.g., the BioCyc databases con-
tain more information on conserved metabolic pathways
between species), they may require alternate curatorial
choices for selecting appropriate mappings and for han-
dling pathways without matching PW classes. These deci-
sions will need to be explored in a further study of
generalizability.
We would also like to explore how our predictive algo-
rithm may apply to other ontologies and datasets. The
authors believe that the design of the bootstrapping algo-
rithm and the neural network may need significant adap-
tation to work in other biomedical domains. The current
predictive algorithm depends on the presence of existing
mappings that can be extracted and used as training data.
In cases where there is no access to pre-existing mappings
between data and ontology, a simple machine learning
model similar to that used in the bootstrapping procedure
may be more fitting.
Future work
RGD annotators are reviewing the remaining mapping
recommendations for Reactome pathways and adding
new mappings into the PW. Reviewers are also annotating
pathways based on predictions for BioCyc and WikiPath-
ways pathways. The predictive model will be retrained
incorporating the additional mappings generated by this
project. Upon completion of the overall mapping project,
Wang et al. Journal of Biomedical Semantics           (2019) 10:11 Page 10 of 11
the PW will contain mappings to six pathway databases:
the three that precede the developments described in this
paper (KEGG, NCI-PID, and SMPDB), and three new
pathway databases (BioCyc, Reactome, and WikiPath-
ways).
As alluded to earlier, some pathways from these
databases do not have direct correspondences in the Path-
way Ontology. In some cases, pathways representing pro-
cesses at fine granularity can only be mapped to more
general PW classes. These observations suggest that semi-
automated ontology annotation prediction could play a
helpful role in ontology completion or ontology develop-
ment. We are investigating the differences between poor
recommendation quality (failure of the model) and the
lack of appropriate recommendations (insufficient repre-
sentation in the ontology). In future work, we would like
to produce a model that distinguishes between these two
situations.
Conclusion
Pathway representations are critical for modeling and
understanding the physiological processes underlying
both normal and disease health states, but a lack of
understanding of the relationships between pathways of
different provenance undermine their collective usabil-
ity. Combining the data from different pathway databases
using a unifying ontology could address many of these
issues. We demonstrate in this article the design, imple-
mentation and evaluation of a computationally-assisted
pipeline for mapping Reactome pathways to classes in
the Pathway Ontology. Initial results of the classifica-
tion model show promise, highlighting a number of
pathway instance to PW class mappings that should be
assessed by curators. We are working towards improv-
ing the quality and quantity of these mapping rec-
ommendations, as manual curation continues over the
results for Reactome and other pathway databases. Fol-
lowing the completion of pathway mapping, we will
proceed by aligning pathways grouped together under
each PW class, generating normalized pathway rep-
resentations. Merging pathway instances along onto-
logical class lines will produce non-redundant yet
interpretable pathways for use in secondary statistical
analysis.
Abbreviations
BOW: Bag-of-words; GO: Gene ontology; GSEA: Gene set enrichment analysis;
idf : Inverse document frequency; KEGG: Kyoto encyclopedia of genes and
genomes; LSTM: Long-short term memory; MeSH: Medical subject headings;
NCI: National cancer institute; NN: Neural network; PID: Pathway interactions
database; PW: Pathway ontology; RGD: Rat genome database; SMPDB: Small
molecule pathway database; UMLS: Unified medical language system
Acknowledgements
The authors thank the reviewers and attendees of Bio-Ontologies 2018 for
their helpful comments and suggestions. The authors also thank the late Dr.
Victoria Petri, who conceived of and first created the Pathway Ontology,
without which this work could not occur.
Funding
This work was supported in part by the National Institutes of Health, National
Library of Medicine Biomedical and Health Informatics Training Program at the
University of Washington (T15LM007442), National Library of Medicine grant
R01 LM011969, and National Heart, Lung, and Blood Institute grant R01
HL064541. The content is solely the responsibility of the authors and does not
necessarily represent the official views of the National Institutes of Health.
Availability of data andmaterials
An implementation of the model is available at https://www.github.com/
lucylw/pathhier/. The Pathway Ontology is available on BioPortal at https://
bioportal.bioontology.org/ontologies/PW.
Authors contributions
LLW designed and implemented the predictive model. GTH and MT carried
out evaluative experiments. LLW wrote the manuscript with support from
GTH, JRS, MT, MES and JHG. JHG and MES helped supervise the project. LLW
and JHG conceived the original idea. All authors read and approved the final
manuscript.
Ethics approval and consent to participate
Not applicable.
Consent for publication
Not applicable.
Competing interests
The authors declare that they have no competing interests.
Author details
1Department of Biomedical Informatics and Medical Education, University of
Washington, 850 Republican St, 98109 Seattle, WA, USA. 2Department of
Biomedical Engineering, Medical College of Wisconsin, 8701 WWatertown
Plank Rd, 53226 Milwaukee, WI, USA.
Received: 2 October 2018 Accepted: 22 May 2019
RESEARCH Open Access
An annotation and modeling schema for
prescription regimens
John Aberdeen, Samuel Bayer, Cheryl Clark, Meredith Keybl and David Tresner-Kirsch*
Abstract
Background: We introduce TranScriptML, a semantic representation schema for prescription regimens allowing
various properties of prescriptions (e.g. dose, frequency, route) to be specified separately and applied (manually or
automatically) as annotations to patient instructions. In this paper, we describe the annotation schema, the curation
of a corpus of prescription instructions through a manual annotation effort, and initial experiments in modeling and
automated generation of TranScriptML representations.
Results: TranScriptML was developed in the process of curating a corpus of 2914 ambulatory prescriptions written
within the Partners Healthcare network, and its schema is informed by the content of that corpus. We developed
the representation schema as a novel set of semantic tags for prescription concept categories (e.g. frequency); each
tag label is defined with an accompanying attribute framework in which the meaning of tagged concepts can be
specified in a normalized fashion. We annotated a subset (1746) of this dataset using cross-validation and
reconciliation between multiple annotators, and used Conditional Random Field machine learning and various
other methods to train automated annotation models based on the manual annotations. The TranScriptML schema
implementation, manual annotation, and machine learning were all performed using the MITRE Annotation Toolkit
(MAT). We report that our annotation schema can be applied with varying levels of pairwise agreement, ranging
from low agreement levels (0.125 F for the relatively rare REFILL tag) to high agreement levels approaching 0.9 F for
some of the more frequent tags. We report similarly variable scores for modeling tag labels and spans, averaging 0.
748 F-measure with balanced precision and recall. The best of our various attribute modeling methods captured
most attributes with accuracy above 0.9.
Conclusions: We have described an annotation schema for prescription regimens, and shown that it is possible to
annotate prescription regimens at high accuracy for many tag types. We have further shown that many of these
tags and attributes can be modeled at high accuracy with various techniques. By structuring the textual
representation through annotation enriched with normalized values, the text can be compared against the
pharmacist-entered structured data, offering an opportunity to detect and correct discrepancies.
Keywords: Medication, Annotation, Prescriptions, Modeling
Background
Patient medication regimens are described in a variety of
genres of medical documents, including prescription or-
ders, intake interview medication lists, discharge sum-
maries, prescribing guidelines, and medication orders.
Often, at least some aspects of the regimen are described
in free text; in many cases, the entire regimen is speci-
fied in free text alone. Regimen information is essential
to patient care, as well as for secondary uses such as
retrospective studies and pharmacovigilance, but the free
text representation presents great challenges in accessing
the information computationally. In this introduction we
describe the availability and current state of the art of
medication information extraction tools. We then de-
scribe community evaluations, open representation sche-
mata, and corpus development efforts in the medication
regimen domain.
Medication information extraction systems
Over the last two decades, several systems have been de-
veloped to identify medication names and associated
© The Author(s). 2019 Open Access This article is distributed under the terms of the Creative Commons Attribution 4.0
International License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and
reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to
the Creative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver
(http://creativecommons.org/publicdomain/zero/1.0/) applies to the data made available in this article, unless otherwise stated.
* Correspondence: davidtk@mitre.org
The MITRE Corporation, 202 Burlington Rd, Bedford, MA 01730, USA
Aberdeen et al. Journal of Biomedical Semantics           (2019) 10:10 
https://doi.org/10.1186/s13326-019-0201-9
dosage attribute information in the free text of clinical
reports. Early rule-based systems include CLARIT [1],
MedLEE [2, 3], and MERKI [4]. MERKI is an open
source system that uses a library of regular expressions
and a lexicon of drug names to identify medication
names and dosage attributes. Authors of this system re-
port accuracies of 83.7% for dose, 88.0% for route of ad-
ministration, and 83.2% for frequency. CLARIT, a
commercial system, combines basic NLP, general and
special lexicons, and pattern matching rules to identify
medication names and dosage attributes. MedLEE, a
commercial system developed to extract various med-
ical concepts, identifies medication names but not dos-
age attributes. Additional commercial systems include
LifeCode from A-Life Medical, Inc., Natural Language
Patient Record from Dictaphone Corporation, and
FreePharma from Language and Computing NV. Al-
gorithms for these systems are not publicly available.
A 2009 assessment of the medication extraction per-
formance of commercial systems from four vendors (Lan-
guage and Computing, Coderyte, LingoLogics, and
Artificial Medical Intelligence) [5] found that they did well
identifying medication names (F-measure 0.932) but less
well identifying attributes such as strength (F = 0.853),
route (F = 0.803), and frequency (0.483), and concluded
that automated extraction could support but not replace a
manual process for clinical applications such as medica-
tion list generation.
Table 1 A comparison of concept coverage, and the identifiers for those concepts, in various information representations: MedXN/
PredMed information extraction output, SHARPn annotation schema, FHIR clinical data structures, and TranScriptML
MedXN / PredMed SHARPn FHIR TranScriptML
Dosage: amount of medication to be taken with each administration
Dosage Dosage Dose Take, Doseamount
Duration: how long patient is expected to be or has been taking the drug
Duration Duration Duration
Form: Physical form of the drug
Form Form Form
Frequency: how often the drug should be administered
Frequency Frequency Frequency, frequencyMax, period, periodMax, periodUnits Freq
Indication: the reason the drug is being taken by the patient
Reason Indication
Medication: Name of the drug
Medication Medication Medication Medication
Miscellaneous:
Modifiers Additional Instructions Instruction
PRN: Whether the drug is to be taken as needed
asNeeded PRN
Route: how the drug is administered
Route Route Route Route
Status: whether the medication is currently being taken
Status Change
Strength: the amount of active drug per unit (e.g. per tablet or per ml solution)
Strength Strength Strength
Timing: additional information relating to life events
When Timing
Aberdeen et al. Journal of Biomedical Semantics           (2019) 10:10 Page 2 of 11
The i2b2 2009 Medication Challenge shared task [6]
focused on extraction of medication-related information
from clinical text. The information to be extracted in-
cluded medication name, dosage amount, route of ad-
ministration, frequency, duration, and reason for
administration. Twenty teams participated in this chal-
lenge, and while all of the top 10 systems recognized
medication names well with F-measures above 0.75
F-measure, they performed less well on other attributes.
The attributes that proved hardest to extract were dura-
tions and reasons, for which the highest scores were
0.525 and 0.459, respectively.
Seven of the top ten performing systems were
rule-based systems [713]. Three of the top ten [1416]
were hybrid systems that combined machine learning
and rules, including the highest ranking system [14],
which used machine learning for tagging and rules for
integrating related components.
PredMed [17] and MedXN [18] are two more recent
systems which improve on the accuracy demonstrated
by the 2009 i2b2 challenge entries. PredMed is not yet
publicly available; MedXN is available as a free and
open-source UIMA-based tool. Both target the same set
of seven medication-related concepts, which are listed in
Table 1 in comparison to other information
representations.
Both PredMed and MedXN find spans referencing
these seven concept types in text. Additionally, MedXN
assigns an RxCUI id to normalize the medication name,
performs coreference between medication names and
regimen concepts, and attempts to assign an RxCUI
normalization to the full medication concept. The full
normalization produces a structured string combining
the referenced regimen concepts. However, neither sys-
tem normalizes the individual concepts (e.g. Frequency);
RESEARCH Open Access
Levels and building blockstoward a
domain granularity framework for the life
sciences
Lars Vogt
Abstract
Background: With the emergence of high-throughput technologies, Big Data and eScience, the use of online data
repositories and the establishment of new data standards that require data to be computer-parsable become
increasingly important. As a consequence, there is an increasing need for an integrated system of hierarchies of
levels of different types of material entities that helps with organizing, structuring and integrating data from
disparate sources to facilitate data exploration, data comparison and analysis. Theories of granularity provide such
integrated systems.
Results: On the basis of formal approaches to theories of granularity authored by information scientists and
ontology researchers, I discuss the shortcomings of some applications of the concept of levels and argue that the
general theory of granularity proposed by Keet circumvents these problems. I introduce the concept of building
blocks, which gives rise to a hierarchy of levels that can be formally characterized by Keets theory. This hierarchy
functions as an organizational backbone for integrating various other hierarchies that I briefly discuss, resulting in a
domain granularity framework for the life sciences. I also discuss the consequences of this granularity framework for
the structure of the top-level category of material entity in Basic Formal Ontology.
Conclusions: The domain granularity framework suggested here is meant to provide the basis on which a more
comprehensive information framework for the life sciences can be developed, which would provide the much
needed conceptual framework for representing domains that cover multiple granularity levels. This framework can
be used for intuitively structuring data in the life sciences, facilitating data exploration, and it can be employed for
reasoning over different granularity levels across different hierarchies. It would provide a methodological basis for
establishing comparability between data sets and for quantitatively measuring their degree of semantic similarity.
Keywords: Building block, Level, Hierarchy, Domain granularity framework, SEMANTICS, Ontology, Granularity,
Knowledge management
Background
Arranging a heterogeneous collection of entities into a
set of different levels (layers or strata) that are organized
in a linear hierarchy from a fundamental level at the bot-
tom to some higher level at the top is a general ordering
scheme that dates back at least as far as to ancient times
[1]. In biology, attempts to answer the question of how
molecules make up cells and cells make up organisms
have led to various proposals of compositional
hierarchies of different levels of biological organization
of living systems and their component parts [222].
The underlying levels idea is simple and elegant. It can
be flexibly used in many different contexts [23], ranging
from descriptions to explanations and the provision of
ontological inventories [24]. It is not only frequently
used in textbooks [2527], but also provides an import-
ant conceptual framework in various scientific and
philosophical debates, including debates on downward
causation, mechanistic explanation, complexity, reduc-
tion, and emergence [2832].
Various applications of the levels idea have been pro-
posed in science and philosophy [4, 29, 3343].
Correspondence: lars.m.vogt@gmail.com
Rheinische Friedrich-Wilhelms-Universität Bonn, Institut für Evolutionsbiologie
und Ökologie, An der Immenburg 1, 53121 Bonn, Germany
© The Author(s). 2019 Open Access This article is distributed under the terms of the Creative Commons Attribution 4.0
International License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and
reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to
the Creative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver
(http://creativecommons.org/publicdomain/zero/1.0/) applies to the data made available in this article, unless otherwise stated.
Vogt Journal of Biomedical Semantics            (2019) 10:4 
https://doi.org/10.1186/s13326-019-0196-2
Although distinct from each other, many of them also
relate to one another and take subtly different forms
when applied in related contexts, which often results in
conceptual problems [23]. Oppenheim and Putnams
[33] theory of reduction, for instance, attempts to ex-
plain phenomena of a higher-level science through the-
ories that refer to entities and to theories from the more
fundamental science, with the goal of achieving the unity
of science. As a consequence, however, levels of material
entities are associated with levels of broad scientific dis-
ciplines (e.g., physical, chemical) and of their corre-
sponding theories and this is a problem, because it
leaves the question unspecified, why objects of, for ex-
ample, physics, which range from sub-atomic particles
to entire planets and the universe as a whole, comprise a
single level (Bechtel and Hamilton [44]).
Many philosophers have made attempts to establish
criteria for the validity or usefulness of the levels idea,
sometimes expressed in form of necessary and sufficient
formal criteria, but no commonly accepted consensus
has been reached for any particular set of criteria [23,
32]. Instead of having to decide and stick with a specific
account of levels, Craver ([23], p.2) therefore suggests
descriptive pluralism about levels, claiming that the
world contains many distinct, legitimate applications of
the levels metaphor that are either unrelated or that
have only indirect relations with one another.
Irrespective of the lack of commonly accepted formal
criteria, the different accounts of levels suggested so far
usually all have in common that each level must repre-
sent an increase in organizational complexity, with each
entity of a higher level being directly composed of en-
tities belonging to the next lower level [45], resulting in
a linear hierarchy of levels from a bottom level to a top
level. Moreover, the idea presupposes that entities exist
for which it makes sense to understand them as being at
the same level.
The idea of levels and of hierarchies based on levels
has also been discussed in information science and
ontology research. Here, it has become increasingly im-
portant due to the continuously growing need of re-
searchers to manage large amounts of data (i.e., Big
Data) with the help of computers and software applica-
tions, resulting in a new driving force for scientific ex-
ploration, called data exploration or eScience [46]. Big
Data and eScience bring about the necessity for re-
searchers to communicate biological data via the World
Wide Web and to use databases and online repositories
to store, document, archive, and disseminate their data.
They also require data to be standardized accordingly
and to be computer-parsable. All this can be facilitated
by the use of ontologies [4752]. As a consequence,
ontology researchers have developed their own ap-
proaches to levels, which they call granularity levels, and
to different types of hierarchies based on levels, which
they call granular perspectives. Ontology researchers
provide explicit criteria for identifying and demarcating
different levels and different hierarchies. These criteria
specify what is called a granularity framework.
In the following, I develop a domain granularity frame-
work for the life sciences that ranges from the atomic
level to the level of multi-cellular organisms. The frame-
work attempts to reflect the hierarchical anatomical
organization of organisms, marking an important step
towards developing a general overarching information
framework for the life sciences. Since morphology takes
a central role in all attempts of developing a hierarchical
system of levels of biological entities, because unambigu-
ously modeling the various granularity relations across
morphological entities in a consistent way has been chal-
lenging, I focus mainly on morphology. Morphology is
also ... one of the covering disciplines that spans [al-
most] every single entity in any biological organism
([53], p. 65). It provides diagnostic knowledge and data
for many disciplines within the life sciences [54, 55].
And morphological terminology provides the basic refer-
ence system and descriptive framework for the
supra-molecular domain in the life sciences. It is central
to all efforts of biological inventorying and to biological
knowledge representation in general; and it provides a
common backbone for the integration of all kinds of dif-
ferent biological information [47, 48, 5658].
The paper is divided into two sections. In the first sec-
tion I briefly discuss a formal approach to levels and hier-
archies proposed by ontology researchers, which is based
on granular partitions. I compare the notion of a cumula-
tive organization, which most theories of granularity as-
sume for the anatomical organization of biological
entities, with the cumulative-constitutive organization and
discuss some of the conceptual problems that the latter
brings about. I take a brief look at the granularity scheme
implicit in the Basic Formal Ontology (BFO), before I
introduce the general theory of granularity proposed by
Keet [5961] that allows the integration of various differ-
ent granular perspectives (i.e., hierarchies).
In the other section I discuss BFOs characterization of
bona fide objects based on the identification of different
types of causal unity. I suggest adding two more types of
causal unity for characterizing functional and historical/
evolutionary bona fide entities. I also introduce the con-
cept of building blocks, which gives rise to a hierarchy of
levels of building blocks that specifies its own granular
perspective. This hierarchy is intended to function as an
organizational backbone for integrating various add-
itional granular perspectives that are relevant in the life
sciences, resulting in a domain granularity framework
for the life sciences. I briefly discuss the implicit conse-
quences of this approach for the structure of the
Vogt Journal of Biomedical Semantics            (2019) 10:4 Page 2 of 29
top-level category of material entity in BFO. I conclude
by discussing the suitability of the domain granularity
framework here suggested for providing the basis on
which an overarching information framework for the life
sciences [62] can be developed.
Methods
Ontologies and granularity
Information scientists and ontology researchers devel-
oped an account of levels that follows a formal approach
allowing for computer-parsability and automated reason-
ing over hierarchies of different levels of granularity,
with each hierarchy being understood as a distinct
granular perspective. Ontologies play an essential role in
this approach. Ontologies, together with other Semantic
Web technologies, also play a significant role in reliably
communicating and managing data within and between
databases and online repositories, providing hierarchies a
practical field of application with commercial significance.
An ontology consists of a set of terms with commonly
accepted definitions that are formulated in a highly for-
malized canonical syntax and standardized format, with
the goal to yield a lexical or taxonomical framework for
knowledge representation [63]. The terms are organized
into a nested hierarchy of classes and subclasses, form-
ing a tree of increasingly specialized terms that is called
a taxonomy [64]. However, when ontology researchers
need to refer to hierarchies other than taxonomies, for
example, a partonomy (i.e., a hierarchy based on
part-whole relations), they usually do that in reference
to some (external) granularity framework. Such parto-
nomies, however, are usually only expressed indirectly
through formalized descriptions specifying particular part-
hood relations between resources within the taxonomy of
an ontology. This often results in the respective ontology
containing several disconnected partonomies that provide
only locally applicable parthood-based granularity
schemes, as opposed to a single globally and universally
applicable scheme.
Whereas the number of biomedical ontologies is con-
tinuously increasing [65], they often differ considerably,
and their taxonomies as well as their implicit parto-
nomies and even some of their term definitions are often
inconsistent across each other [6668]. As a conse-
quence, if databases and online repositories differ with
respect to the ontologies they use, their contents are
likely to be incomparable, which significantly hampers
data exploration and integration. A solution to this
problem involves two distinct approaches: using formal
top-level ontologies [66, 69] such as BFO [70, 71] and ap-
plying a general formal theory of granularity for develop-
ing a domain granularity framework that can be applied
as a meta-layer across various ontologies.
Partial order, granular partition, and granularity tree
Key to the development of any formal theory of granu-
larity is the formal characterization of the relation that
holds between entities belonging to different levels of
granularity. A first step is to identify partial order rela-
tions. In mathematics and logics, a partial order is a bin-
ary relation R that is transitive (if b has relation R to c
and c has relation R to d, than b has relation R to d:
(Rbc) (Rcd)? Rbd), reflexive (b has relation R to itself:
Rbb), and antisymmetric (if b has relation R to c and c
has relation R to b, than b and c are identical: (Rbc)
(Rcb)? b = c) [72]. An example of a partial order rela-
tion is the parthood relation.
Granular partitions are based on partial order rela-
tions [7376]. Granular partitions are involved in all
kinds of listing, sorting, cataloging and mapping activ-
ities. A granular partition is a hierarchical partition that
consists of cells (here used in the general non-biological
meaning of cell) that contain subcells. It requires a spe-
cific theory of the relation between its cells and subcells:
(i) the subcell relation is a partial ordering relation; (ii) a
unique maximal cell exists that can be called the root
cell; (iii) chains of nested cells have a finite length; and
(iv) if two cells overlap, then one is a subcell of the
other, therewith excluding partial overlap [7376]. An
empirically meaningful theory of granular partition also
requires a theory of the relations between cells of the
partition and entities in reality (i.e., projective relation to
reality [7375]).
Depending on what is partitioned and the ontological
nature of the parts, one can distinguish a bona fide
granular partition from a fiat granular partition. A bona
fide granular partition partitions a bona fide object (i.e.,
an entity that is demarcated by a bona fide boundary
and thus exists independent of any human partitioning
activities) into its bona fide object parts. A fiat granular
partition partitions any material entity into its fiat entity
parts (i.e., entities that are demarcated by a fiat bound-
ary and thus exist as a consequence of human partition-
ing activities) (for a distinction of bona fide and fiat
entities see discussion below and [70, 71, 77]).
A granular partition can be represented as a tree, with
the nodes and leaves of the tree being the granular parts.
This tree is called a granularity tree [69, 76, 78]. Every fi-
nite granular partition can be represented as a rooted
tree of finite length [74, 75, 7981]. In a granularity tree,
a granularity level is a cut (sensu [82]; see Fig. 2b) in the
tree structure. Within a granularity tree, different levels
of granularity can be distinguished, with the root being a
level itself, and all immediate children of the root an-
other level, etc. The elements forming a granularity level
are pairwise disjoint, and each level is exhaustive, be-
cause for every entity b of the partition exists some
other entity c of the same partition, which belongs to
Vogt Journal of Biomedical Semantics            (2019) 10:4 Page 3 of 29
another level of granularity, and b stands in a partial or-
dering relation to c, or vice versa [76]. If the partitioning
relation is a mereological relation such as the part-whole
relation, all entities belonging to one granularity level in
a granularity tree exhaustively sum to the whole (i.e., the
root cell) that is partitioned [76].
Partitioning relations possess constrains regarding the
type of entities that they partition. The primitive
part-whole relation, for instance, exists only between in-
stances (particulars/individuals) [23, 8385] (for a trans-
lation to a class expression of parthood see [83, 86]). As
a consequence, parthood-based granular partitions can
be represented as instance granularity trees. The
class-subclass relation is also a partial ordering relation.
However, it exists only between types (classes, univer-
sals). Granular partitions based on a class-subclass rela-
tion therefore can be represented as type granularity
trees. The taxonomy of terms of an ontology represents
such a type granularity tree. (see also instance and type
granularity tree in [58, 87]).
Hierarchies are based on strict partial ordering rela-
tions, which represent irreflexive (b cannot stand in rela-
tion R to itself: ¬Rbb) partial ordering relations. As a
consequence, hierarchies represent a specific case of
granular partitions and granularity trees. The direct
proper parthood relation is a strict partial ordering rela-
tion. This complies with any formal system of minimal
mereology, including pure spatiotemporal parthood.
Biological reality: the problem with the cumulative
constitutive hierarchy
On the basis of the characterization of hierarchies men-
tioned above one can distinguish four basic types of
hierarchical systems [17, 21, 88]: (i) constitutive hier-
archies, (ii) cumulative constitutive hierarchies, (iii) ag-
gregative hierarchies, and (iv) cumulative aggregative
hierarchies (Fig. 1), of which only the former two hier-
archies are of interest in the here discussed context.
Interestingly, constitutive hierarchies are commonly
used by philosophers and ontology researchers to model
granularity, whereas biologists use cumulative constitu-
tive hierarchies.
In a constitutive hierarchy [38], all material entities of
a given level of granularity constitute the entities of the
next coarser level. For instance, aggregates of all atoms
that exist constitute all molecules that exist and aggre-
gates of all molecules constitute all cells [17]. In other
words, coarser level entities consist of physically joined
entities of the next finer level of granularity [88]. A con-
stitutive hierarchy is thus based on partonomic inclusion
resulting from an irreflexive proper part-whole relation,
with bona fide entities of different levels of granularity
being mereologically nested within one another, thus
representing a mereological granularity tree [76].
Most granularity schemes suggested in the ontology
literature so far presuppose a constitutive organization
of material entities [78, 89] (for an exception see [58]),
and many bio-ontologies, although often not accompan-
ied by an explicit representation of formally defined
levels of granularity, also follow this scheme. This is
problematic given that constitutive hierarchies not only
assume that coarser level entities always exclusively con-
sist of aggregates of entities of the next finer level, but
also that every entity belonging to one level of granular-
ity is part of some entity of the next coarser level of
granularity (Fig. 1a). Unfortunately, this is not the case
for many material entities: ions or chlorine radicals dem-
onstrate that not every atom necessarily is part of a mol-
ecule; in humans, extracellular matrix (ECM; a
macromolecular formation that is not a component of
cells, but a component of tissues and therefore also or-
gans and multi-cellular organisms) and blood plasma
demonstrate that not every molecule is part of a cell;
protozoa, protophyta, erythrocytes, coelomocytes, or
leukocytes demonstrate that not every cell necessarily is
part of an organ [87]. Obviously, not all the entities be-
longing to one level of granularity necessarily form parts
of entities of the next coarser level.
Moreover, constitutive hierarchies also assume that all
parts of any given level of granularity exhaustively sum
to their complex whole (Fig. 1a). Regarding biological
material entities this implies that the sum of all cells of a
human individual would have to yield the human indi-
vidual as a whole. The totality of cells of any given hu-
man being, however, does not sum to the body as a
whole, since this mereological sum would not include
the ECM in which the cells are embedded and which
provides the topological grid that determines the relative
position of the cells to one another. The aggregation of
cells would disintegrate without the ECM and could not
constitute the body as a bona fide whole. Moreover, since
not all atoms are part of a molecule and not all subatomic
particles are part of an atom, neither the sum of all mole-
cules, nor the sum of all atoms that exist in the universe
at a given point in time exhaustively sum to the universe
as a whole [87]. As a consequence, not all parts that share
the same granularity level necessarily exhaustively sum to
the maximal whole (contradicting [76, 78]).
Instead of employing a constitutive hierarchy, biologists
have argued that typical biological material entities such
as multi-cellular organisms are organized according to a
cumulative constitutive hierarchy [17, 21, 88] (Fig. 1b).
When comparing the characteristics of constitutive hier-
archies with those of cumulative constitutive hierarchies
one can easily see why most approaches to granularity
that are frequently used in ontologies, but also the formal
theory of granularity of Kumar et al. [78], model the
bio-medical domain on the basis of a constitutive
Vogt Journal of Biomedical Semantics            (2019) 10:4 Page 4 of 29
hierarchy. When partitioning a particular multi-cellular
organism (i.e., unpartitioned whole, Fig. 2b) into its direct
proper bona fide parts according to a constitutive hier-
archy, all the parts belonging to a cut, and thus to an in-
stance level, instantiate the same basic type of anatomical
entity (Fig. 2b, left). Therefore, each cut in the instance
granularity tree can be associated with a specific basic type
of anatomical entity. As a consequence, instead of talking
about Cut I, one could just as well talk about the organ
granularity level. Translating or mapping the topology of
an instance granularity tree to its corresponding type
granularity tree is thus straight forward and poses no con-
ceptual problemsif one applies a constitutive hierarchy
for partitioning the multi-cellular organism that is (Fig. 2c,
left). One could even derive a globally applicable, linear
compositional levels hierarchy for the life sciences. One
would only have to apply the constitutive hierarchy model
and compare the type granularity trees of several
multi-cellular organisms across various taxa.
However, when applying the cumulative constitutive
hierarchy model, the entire process becomes more com-
plex and conceptually more challenging [58, 87]. Ac-
cording to the cumulative constitutive hierarchy, the
parts of a multi-cellular organism that belong to a cut of
an instance granularity tree do not all instantiate the
same basic type of anatomical entity (Fig. 2b, right). For
instance, the parts that belong to the first cut in the ex-
ample shown in Fig. 2b instantiate organs, cells, and
molecules. As a consequence, the mereological sum of
all entities belonging to one instance granularity level
does not necessarily sum to the unpartitioned whole
(see, e.g., Cut III in Fig. 2b, right). Thus, one must con-
clude that Kumar et al.s [78] theory of granularity and
one of Reitsma and Bittners [76] criteria for
A B
C D
Fig. 1 Four different Types of Hierarchies. a A constitutive hierarchy of molecules, organelles, cells, and organs of a multi-cellular organism. It can
be represented as an encaptic hierarchy of types, with every molecule being part of some organelle, every organelle part of some cell and every
cell part of some organ. b The same set of entities as in A), organized in a cumulative constitutive hierarchy, which models the organization of
biological material entities more accurately. Here, not every molecule that is part of an organism is also necessarily part of some organelle and
not every cell necessarily part of some organ. c An aggregative hierarchy is based on mereological/meronymic inclusion that results from a
part-whole relation (e.g., ecological hierarchies [15, 17]) or it is based on taxonomic inclusion [138] that results from a subsumption relation (e.g.,
Linnean taxonomy). In case of mereological inclusion, this hierarchy represents a mereological granularity tree and higher level entities consist of
parts that are not physically connected, but only associated with each other. d In a cumulative aggregative hierarchy, as it is used in the
hierarchical organization of military stuff, individuals with higher ranks, such as sergeants, lieutenants, and captains, appear in aggregates of
higher order, so that squads consist of privates and sergeants, in the next level platoons of privates, sergeants, and lieutenants, and companies of
privates, sergeants, lieutenants, and captains. (Figure modified from [58])
Vogt Journal of Biomedical Semantics            (2019) 10:4 Page 5 of 29
mereological granularity trees are not conformant with
anatomical reality [58].
Moreover, the topology of the resulting instance
granularity tree cannot be easily translated into its
corresponding type granularity tree, because each in-
stance level comprises different types of entities (except
for the root and the finest level). A consequence of cu-
mulative constitutive hierarchies is that, when
A
B
C
Fig. 2 Instance Granularity Tree and Type Granularity Tree based on bona fide Granular Partition for Constitutive and Cumulative Constitutive
Hierarchies. a Compositional partitions of a constitutively and a cumulative-constitutively organized idealized multi-cellular organism into their
constitutive bona fide object parts. Four corresponding partitions are shown. Left: into organs (f); cells (e); organelles (c, d); and molecules (a, b).
Right: into organs with cells and extracellular molecules (i, j, g, h); cells with organelles and extracellular and cellular molecules (q, m, n, o, p, k, l);
organelles and molecules (v, w, t, u, r, s); and molecules (x, y). b The four compositional partitions from A) represented as a bona fide instance
granularity tree. Each partition constitutes a cut in the instance granularity tree (Cut IIV) and thus an instance granularity level. Left: Instances of
the same type of material entity do not belong to different cuts and thus are restricted to the same level of instance granularity. Right: Instances
of the same type of material entity, for instance molecule, belong to different cuts and therefore to different levels of the respective instance
granularity tree. The extension of the class molecule thus transcends the boundaries between instance granularity levels. c Left: The bona fide
instance granularity tree can be directly transformed into the corresponding type granularity treeno sortation of any parts across the
boundaries of granularity levels required, because the topology of the bona fide instance granularity tree is identical with the bona fide type
granularity tree. Right: The bona fide instance granularity tree cannot be directly transformed into or mapped upon the corresponding type
granularity tree. However, by following the simple and intuitive rule that a type must occupy the same granularity level as its finest grained
instance (i.e., sortation-by-type [58]) and by applying the concept of granular representation (see further below), one can transfer the instance
granularity tree into a corresponding type granularity tree. (Figure modified from [87])
Vogt Journal of Biomedical Semantics            (2019) 10:4 Page 6 of 29
partitioning a multi-cellular organism, different instances
of the same basic type of anatomical entity can belong
to different instance granularity levels. In other words,
when conceiving types of anatomical entities as classes,
the extension of a class such as bio-molecule crosses
the boundaries of different levels of instance granularity
when applying the cumulative constitutive hierarchy.
Therefore, mapping types directly to instance levels
would result in some types being associated with more
than one level.
This poses a fundamental problem, because ontologies
are dealing with types (i.e., classes) and not with individ-
uals (i.e., instances), and thus require a type-based
granularity framework. I have proposed an intuitive solu-
tion, i.e., sortation-by-type, in which a type granularity
tree is derived from an instance granularity tree by rank-
ing types according to the lowest level of granularity of
their corresponding instances [58]. Sortation-by-type
can be seen as a sort of granular sedimentation of all in-
stances of one type to the lowest level they occupy (see
large transparent arrows in Fig. 2c, right). Whereas this
approach seems to be intuitive, the downside is that in
the type granularity tree, the entities belonging to a
granularity level neither exhaustively sum to their re-
spective whole (except for the lowest level), nor do all of
them form parts of the entities belonging to the next
higher granularity level [58].
The granularity scheme implicit in the basic formal ontology
Formal top-level ontologies such as BFO [70, 71] play a
key role in establishing standards across different ontol-
ogies. BFO provides a genuine upper ontology upon
which all ontologies of the Open Biomedical Ontologies
Foundry (OBO Foundry [57, 90]) are built. Together
with the OBO Relations Ontology it is one of the guar-
antors for the interoperability of the ontologies within
OBO Foundry.
Because BFO is an upper ontology, its taxonomy is
comparably flat and does not include any distinction of
different granularity levels of material entities. However,
BFOs distinction of object, object aggregate, and fiat
object part as top-level categories of material entity
[70, 71] can be interpreted as a basic granularity scheme
applied for modeling the granularity within a given level
of object granularity. The underlying basic idea is that a
certain domain first must be partitioned into its top-level
object categories, resulting in a domain-specific bona fide
granularity tree (i.e., a granularity tree that is based on
bona fide granular partitions; see [76]), e.g., bio-macromo-
lecule < organelle < cell < organ < organism. According
to BFO, in order to comprehensively cover the domain,
each level of this bona fide granularity tree must be mod-
eled by its own level-specific domain reference ontology,
with cross-ontology relations managing the relationships
between entities of different levels. Therefore, in a next
step, the distinction of object, fiat object part, and object
aggregate indicates within each such ontology a simplified
model for fiat partitions and fiat granularity trees (see
Fig. 3). Of course, object aggregates can be parts of larger
object aggregates and fiat object parts can be further parti-
tioned to smaller fiat object parts, thereby extending the
basic scheme shown in Fig. 3 with additional levels.
This approach to modularizing granularity, however,
does not seem to be very practicable, because it implies
that instead of developing a single anatomy ontology of
a specific taxon of multi-cellular organisms, one would
Fig. 3 BFOs Basic Granularity Framework. A bona fide partition from a multi-cellular organism to a molecule represents the center of BFOs
granularity framework and reflects direct subclasses of BFOs object for the biological domain. According to BFO, each level of the corresponding
bona fide granularity tree must be modeled by its own domain reference ontology (i.e., a molecule ontology, a cell ontology, etc.). Within each
such level-specific ontology, BFOs top-level distinction of object, fiat object part, and object aggregate indicates a basic fiat partition that
orthogonally crosses the bona fide partition. The bona fide partition can therefore be understood as an integrating cross-granular backbone for
the different ontologies of a given domain together with their implicit fiat partitions
Vogt Journal of Biomedical Semantics            (2019) 10:4 Page 7 of 29
have to (i) develop several granularity-specific ontol-
ogies, ranging from an ontology for molecules, to an
ontology for organelles, for cells, for tissues, for organs
and for body parts for this specific taxon, and (ii) one
would have to develop an additional layer of axioms and
relationships to define the granularity relations between
entities across these different ontologies.
Because BFO does not provide a formal granularity
framework, applying the sub-categories of material en-
tity (i.e., object, fiat object part, and object aggregate)
can be ambiguous. As a consequence, many of the cur-
rently available biomedical ontologies within OBO Foun-
dry significantly vary regarding their underlying
granularity assumptions and their top-level class-struc-
ture for material entity (see subclasses of, e.g., material
anatomical entity of CARO, anatomical structure of
HAO, material entity of OBI, plant structure of PO,
anatomical structure of ZFA, independent continuant
of CL, cellular component of GO). One could argue that
BFO fails to provide a top-level structure for material
entity that can be applied for modeling the various do-
mains covered by OBO Foundry ontologies. This causes
problems with the comparability of biomedical ontol-
ogies and substantially limits the comparability of data
across databases and online repositories that reference
these ontologies. The life sciences in general and com-
parative morphology in particular, but also the compos-
itional biology style of biological theorizing [91], would
benefit from a consistent granularity framework that is
grounded in reality and that accounts for the
organizational complexity of anatomy. In order to allow
algorithm-based reasoning and inferencing, such a
framework requires an underlying formal theory of
granularity that explicitly states formal granularity rela-
tions and explicitly ranks levels of granularity. Unfortu-
nately, most anatomy ontologies are only based on
implicit assumptions regarding granularity.
Keets formal theory of granularity
Keet [5961] has developed a formal theory of granular-
ity that is agnostic regarding cumulative or cumulative
constitutive hierarchies and thus circumvents some of
the problems of theories of granularity that have been
proposed by others (e.g., [78]; problems discussed in
[58]). Keet [61] argues that granularity always involves
modeling something according to certain criteria, with
each model together with its criteria defining a granular
perspective. Finer levels within a perspective contain
knowledge or data that are more detailed than the next
coarser level, and coarser levels of granularity simplify or
make indistinguishable finer-grained details. A particular
granularity level, however, must be contained in one and
only one granular perspective, whereas a particular en-
tity (individual or type) may reside in more than one
level of granularity, but all levels in which it is contained
must belong to distinct granular perspectives [92].
Moreover, a granular perspective has at least two levels
of granularity and there has to be a strict total order be-
tween the entities of different levels of a given perspec-
tive. And if there is more than one granular perspective
for a subject domain, then these perspectives must have
some relation between each other. This way, several dif-
ferent perspectives of granularity, each with its granular-
ity tree and its corresponding set of granularity levels,
can coexist within the same granularity framework. For
instance, a granular perspective of relative location that
is based on fiat granular partitions, alongside with a
granular perspective of structural composition that is
based on bona fide partitions, a perspective of biological
processes that is based on temporal parthood relations
(i.e., processes partitioned into their sub-processes), a
perspective of functional units that is based on func-
tional parthood relations (i.e., functional units parti-
tioned into their functional sub-units), and a granular
perspective based on developmental relations [58].
The idea that a domain can be modeled by different
granular perspectives is not new [69, 88, 91, 93, 94], but
Keet [61] provides the first formal theory of granularity
that incorporates different granular perspectives within a
single domain granularity framework. Therefore, Keets
theory can be understood as an attempt to accept de-
scriptive pluralism about the idea of levels [23]. How-
ever, it also represents an attempt to integrate the
resulting set of diverse hierarchies within an integrated
and strictly formalized framework, her general formal
theory of granularity.
A granular perspective can be specified by the combin-
ation of a granulation criterion (what to granulate) and a
specific type of granularity (how to granulate) (for a de-
tailed discussion see [61]). When applied to a correspond-
ing object, a granular perspective partitions the object
resulting in a specific type of granularity tree. Each per-
spective has exactly one granulation criterion and exactly
one type of granulation. This combination determines the
uniqueness of each granular perspective. All granular per-
spectives contained in a domain are thus disjoint. Keet
[61] presumes that a domain of reality can be granulated
according to different types of granularity (mechanisms of
granulation), requiring the existence of a certain type of
granulation relation that must be specific to each particu-
lar granular perspective. The entities (individuals or types)
granulated by a type of granularity are disjoint.
Various different types of granulation relations can be
applied, which can be classified into (i) scale-dependent
(e.g., resolution, size) and (ii) non-scale-dependent types
of granularity (e.g., mereological parthood: structural
parthood, functional parthood, spatial parthood, involve-
ment; meronymic parthood: membership, constitution,
Vogt Journal of Biomedical Semantics            (2019) 10:4 Page 8 of 29
sub-quality relations, participation) [61, 95]. Within a
given perspective, the granulation relation relates entities
of adjacent granularity levels with one another. If a
granular perspective has more than two levels of granu-
larity, the granulation relation must be transitive. If a
granulation relation is intransitive, then the respective
perspective has only 2 levels.
The granulation criterion delimits the kind or category
of properties according to which the domain is parti-
tioned, the levels identified, and the subject domain
granulated (i.e., data, information, or knowledge). It spe-
cifies an aspect that all entities in a granular level must
have in common, whereas the contents of a level can be
either entity individuals (i.e., instances) or types (i.e., uni-
versals, classes), but not both. It comprises either (i) at
least two properties, none of which is a quality property
(for non-scale-dependent types of granularity) or (ii) at
least one property that is not a quality property together
with exactly one quality property that has a measurable
region (for scale-dependent types of granularity) [61].
Keets [61] formal theory of granularity thus provides
the respective formal definitions, axioms, and theorems
that allow the formal representation of granular parti-
tions based on parthood relations (i.e., mereology) as
well as on taxonomic inclusion (i.e., class-subsumption
hierarchies based on set theory) and other types of
granulation relations [60]. It even accommodates both
quantitative (i.e., arbitrary scale) and qualitative (i.e.,
non-scale-dependent) aspects of granularity.
Keets theory of granularity also provides a well suited
framework for analyzing and identifying some of the
problems of some of the granularity schemes that have
been proposed earlier, taking Eldredges somatic hier-
archy [9] as an examplethis criticism applies to many
of the published levels schemes, even including Kumar
et al.s [78] scheme: The somatic hierarchy comprises an
atom, molecule, and cell level together with an organ-
elle, organ, and individual organism level of granularity.
An obvious problem of this hierarchy is that its under-
lying granulation criterion has been conflated between
levels, because spatio-structural entities have been mixed
with functional entities. As a consequence, the under-
lying granulation relation varies depending on the level
between spatio-structural parthood and functional part-
hood. Moreover, the tissue level seems to involve a
scale-dependent granularity type, because it concerns
resolutiona tissue is the representation of a cell aggre-
gate at a coarser level of resolution, in which the
finer-grained details of the cell aggregate that enable the
individuation of individual cells are simplified or made
indistinguishable. This mixing of criteria and types of
granularity results in inconsistent granulation: a
mono-cellular organism is an entity that belongs to both
the cell and the individual organism level of the same
perspective, but according to Keet [61] an entity can
only reside in more than one level if these levels belongs
to different granularity perspectives.
Results
Developing a domain granularity framework for the life
sciences
The increase in formalism coupled with the increase in
generality compared to other theories of granularity re-
sults in more flexibility and therefore a broader applic-
ability of Keets theory. Her theory allows for detailed
and sophisticated modeling of a domain by assigning
specific types or individuals of entities to specific types
of granular perspectives (i.e., hierarchies) that are inter-
connected and integrated in a common domain granu-
larity framework. This framework can be used (i) as
template for the organization of top-level categories of
different domain ontologies and (ii) to provide an inde-
pendent overarching information framework that func-
tions like an additional organizational layer, i.e., a
meta-layer, to which terms/resources of different ontol-
ogies can be mapped. This meta-layer would provide a
consistent and integrated system of well integrated
granular perspectives that allows for modeling not only
parthood-based hierarchies, but all kinds of other rele-
vant hierarchies, for instance, hierarchies based on de-
velopmental or evolutionary relations. It can be formally
added onto an existent knowledge base to facilitate the
construction of a realism-based and more detailed model
of the biological domain (see also [58]).
In order to be broadly applicable throughout many
existing bio-medical ontologies, such a domain granularity
framework for the life sciences would have to be devel-
oped in reference to BFO and its implicit granularity
scheme using a compositional bona fide object granular
perspective that granulates bona fide object entities ac-
cording to a direct proper parthood granulation relation
(see Fig. 3). All additional granular perspectives can be dir-
ectly or indirectly related to this compositional perspec-
tive, which functions as an organizational backbone for
the entire framework, because each additional perspective
possesses some level that shares entities with some level
of this compositional perspective. The development of
such a domain granularity framework, however, may re-
sult in new demands that BFO (or some intermediate do-
main reference ontology) must meet, which could result
in the necessity to adapt or extend BFO accordingly.
Integrating BFO and frames of reference in a domain
granularity framework
Frames of reference and BFOs object category of material
entity
Smith et al. [71] (see also [70]) characterize BFOs bona
fide object category and thus natural units that exist
Vogt Journal of Biomedical Semantics            (2019) 10:4 Page 9 of 29
independent of human partitioning activities as causally
relatively isolated [96, 97] entities that are both struc-
tured through and maximal relative to a certain type of
causal unity. They distinguish three types of causal unity:
1) Causal unity via internal physical forces, which uni-
fies an entity through physical forces (e.g., fundamental
forces of strong and weak interaction, covalent bonds,
ionic bonds, metallic bonding) that are strong enough as
to maintain the structural integrity of the entity against
the strength of attractive or destructive forces from its
ordinary neighborhood. Whereas Smith et al. [71] men-
tion only examples of physical forces that apply to the
atomic and molecular scale (atoms, molecules, portions
of solid matter such as grains of sand and lumps of
iron), I would explicitly include all kinds of physical con-
nections between material component parts, independ-
ent of their scale, including cell-cell connections, but
also screws, glues, and bolts. Ultimately, they all go back
to the physical forces discussed in Smith et al. [71].
2) Causal unity via physical covering unifies an entity
through a common physical covering, for instance, a
membrane. This covering may have holes, but must be
completely connected (in the sense that a continuous path
can be traced between any two points on the surface and
that path has no gaps and does not leave the surface) and
must still serve as a barrier for entities from inside and en-
tities from outside that are above a certain size threshold.
Examples: organelles, cells, tissues, organs.
3) Causal unity via engineered assembly of components
unifies an entity through screws, glues and other fas-
teners. Often, the parts are reciprocally engineered to fit
together (e.g., dovetail joints, nuts and bolts). Examples:
cars, ballpoint pens, houses, shoes, power grids.
These three types of causal unity are ontologically not
independent from one another, because the latter two
existentially depend and thus supervene on causal unity
via internal physical forces [98]. Moreover, they do not
cover all cases of causal unity relevant in the life sciences
(BFO does not claim completeness regarding the list of
cases of causal unity; see [70, 71]), but are confined to a
synchronic approach to causal unity that is associated
with a spatio-structural frame of reference (see below).
Functional units and historical/evolutionary units are
not covered, although they are bona fide entities in their
own right that exist independent of any human parti-
tioning activities [77]. In this context it is important to
note that functional and historical/evolutionary units are
not associated with a spatio-structural frame of reference
and are thus not necessarily also spatio-structural units.
Moreover historical/evolutionary units are not confined
to a diachronic instead of a synchronic causal unity. Dia-
chronic causal unity identifies natural units based on
shared historical/evolutionary origin (for a detailed dis-
cussion see [77]). Therefore, I suggest two additional
types of causal unity that are suited to cover the missing
cases:
Causal unity via bearing a specific function unifies an
entity through the function that the entity bears, with its
functional component parts bearing sub-functions [98].
This type of causal unity is more general than causal
unity via engineered assembly of components and thus
includes it.
Causal unity via common historical/evolutionary origin
unifies an entity through the common historical/evolu-
tionary origin of the entitys component parts. A histor-
ical/evolutionary unit is demarcated so that all of its
component parts share the same historical/evolutionary
origin, with no material entity not belonging to it shar-
ing the same origin [98]. As a consequence, historical/
evolutionary units can be spatio-structurally scattered
entities such as twins living in different cities or apples
from the same tree sold in different supermarkets.
Moreover, because a given material entity can depend
on several different types of causal unity at the same
time, of which not all are relevant in every context, each
type of causal unity is connected to a specific basic
frame of reference [98]. Both causal unity via internal
physical forces and causal unity via physical covering, at
least as conceived by Smith et al. [71] (see also [70]), are
associated with a spatio-structural frame of reference. A
motivation for applying a spatio-structural frame of ref-
erence lies in inventorying what is given in a particular
point in time by focusing on the spatio-structural prop-
erties of a given entity (spatio-structural perspective
[77]). Causal unity via bearing a specific function, on the
other hand, is associated with a functional frame of refer-
ence, which may be applied for making reliable predic-
tions of what can happen in the future by focusing on
dispositional/functional aspects of reality (predictive per-
spective [77]). And causal unity via common historical/
evolutionary origin is associated with a historical/evolu-
tionary frame of reference, which may be applied for
making reliable retrodictions of what has happened in
the past by focusing on using a set of known types of re-
peatable processes to reconstruct the sequence of events
that may have lead to the currently observable situation
(retrodictive (diachronic) perspective [77]).
Because BFOs general granularity scheme associates
to each top-level category of object a corresponding
fiat object part and object aggregate category (e.g.,
molecule with fiat molecule part and molecule aggre-
gate) and because we can distinguish different
spatio-structural categories of object (e.g., atom, mol-
ecule, organelle), we can differentiate additional
spatio-structural sub-frames of reference, one for each
spatio-structural top-level category of object that we
can distinguish (e.g., atomic frame, molecular frame, or-
ganelle frame). Each such frame of reference includes
Vogt Journal of Biomedical Semantics            (2019) 10:4 Page 10 of 29
not only the entities of the respective object category,
but all entities of corresponding fiat object part and ob-
ject aggregate categories. One of the reasons for distin-
guishing different spatio-structural frames of reference lies
in enabling the identification of what is comparable in a
particular point in time by focusing on entities belonging
to a particular top-level object category and its corre-
sponding fiat object part and object aggregates entities. As
a consequence, the number of spatio-structural frames of
reference directly depends on the number of top-level
spatio-structural object categories we can distinguish.
The basic Organization of a Domain Granularity
Framework for the life sciences
As a consequence of the relevance of the different cases
of causal unity for the life sciences, a domain granularity
framework for the life sciences would have to cover
three basic categories of granular perspectives: granular
perspectives relating to (i) spatio-structural, (ii) to func-
tional, and (iii) to historical/evolutionary material en-
tities. In analogy to BFOs general granularity scheme
discussed above, each such basic category will include
one or more corresponding bona fide granular perspec-
tives, with each granularity level of a bona fide perspec-
tive having associated fiat object part and object
aggregate fiat perspectives. As a consequence, the num-
ber of granular perspectives for each such category de-
pends on the number of granularity levels of its
corresponding bona fide perspectives, with each bona fide
level requiring some additional associated fiat perspectives.
However, since each of the three basic categories of
perspectives corresponds with one of the three basic
frames of reference relevant to the life sciences, any
given material entity always belongs to at least three dif-
ferent granular perspectivesone for each basic frame
of reference (i.e., spatio-structural, functional, historical/
evolutionary). Moreover, when considering that at least
the basic spatio-structural frame of reference actually
consists of a set of several distinct spatio-structural
frames of reference, one for each identified spatio-struc-
tural top-level object category, any given material entity
actually belongs to more than three granular perspec-
tives. In other words, an entity belonging to some level
of functional granular perspective will always also belong
to some level of historical/evolutionary granular per-
spective and some level of each of the different
spatio-structural granular perspectives, and vice versa.
And because all the different granular perspectives of
one category overlap in the sense that no granular per-
spective exists that does not overlap directly or indirectly
with the bona fide perspective of this category, the per-
spectives of the three categories overlap each other as
well, thus integrating all the different perspectives of the
domain granularity framework. As a consequence,
assuming that only one bona fide perspective exists for
each basic frame of reference, the bona fide perspectives
function as the organizational backbone of the entire
framework. Ideally, these bona fide perspectives would
directly overlap with each other, which would substan-
tially increase the overall integration of the framework.
1st step: Identifying the organizational backbone granular
perspective for the life sciences based on building blocks
Building block systems: An evolutionary systems-theoretical
perspective
Are hierarchies artifactual and thus mind-dependent
constructs? If we use the levels idea merely because it
takes a central role in our representations of reality, why
should we bother to ask nature which hierarchy is most
realistic? Whereas these questions are legitimate, evi-
dence exists that suggests that evolution (including cos-
mic evolution [99]) leads to modularization. If evolution
has the tendency to aggregate material entities to larger
compositions with a significant increase in complexity,
robustness, and stability, resulting in a modularization of
matter, then hierarchy is a necessary consequence of
evolution. If building block systems evolve, which become
parts of larger building block systems, then a hierarchical
composition of building block systems must result that
has lower-level building block systems as its parts. The
resulting compositional hierarchy of building block sys-
tems is the product of natural processes and thus exists
independent of any human partitioning activities.
The idea that evolution has the tendency to evolve
such building block systems is not new. Simon [29] ar-
gued for the evolution of complex forms from simple
ones through purely random processes, with the direc-
tion towards complex forms being provided by their sta-
bility (survival of the fittesti.e., of the stable, [29], p.
471). Simon argued that [t]he time required for the evo-
lution of a complex form from simple elements depends
critically on the numbers and distribution of potential
intermediate stable forms ([29], p. 471). Hierarchy
would thus emerge almost inevitably through evolution-
ary processes for the simple reason that hierarchical
structures are stable [29].
Our understanding of how morphological structures
evolve and how they develop during morphogenesis has
substantially improved since Simon proposed the idea of
building block systems and it seems to support his idea.
Especially with the newly emerged field of evo-devo and
the discovery of hox genes, we start to understand how
regulatory gene networks function like modular struc-
tures [100102] that can recombine with other modules
in the course of evolution to form new networks [103],
and how they strongly affect development of morpho-
logical structures, their evolutionary stability, and their
evolvability [104107]. Some gene regulatory networks
Vogt Journal of Biomedical Semantics            (2019) 10:4 Page 11 of 29
have been identified that have the role of individualizing
parts of the body during development, and it seems to
be the case that these Character Identity Networks
(ChINs, [105]) are more conserved than are other as-
pects of character development and thus represent
prime candidates for building block systems.
Building blocks as Spatio-structural bona fide objects
Taking the idea of building block systems as a starting
point, I provide a specific characterization of building
block as a Lego-brick-like entity that evolves, diversifies,
and provides realitys inventory of basic categories of
material entities. The concept of building blocks then
provides the basis for a specific account of levels.
According to this account, various types of building
blocks emerged during evolution, starting when there
were only elementary particles present, to a universe that
has gradually evolved with the emergence of more and
more new types of building blocks [18, 29, 108112].
This evolutionary systems-theoretical account of levels
based on building blocks seems to provide a promising
framework for developing a globally and universally ap-
plicable hierarchy of levels of material composition. The
concept of building blocks is insofar relevant to the de-
velopment of a domain granularity framework for the
life sciences, as I argue that it gives rise to a compos-
itional granular perspective of building blocks that
represents the abovementioned ideal bona fide spatio-
structural granular perspective that functions as
organizational backbone for the granularity framework.
I characterize a building block as follows:
 A building block possesses a physical covering that is
comparable to what Jagers op Akkerhuis and Van
Straalen [18] have referred to as an interface. The
physical covering not only demarcates the building
block from its environment, making it a spatio-
structurally bona fide entity, but also functions as a
physical barrier that protects a specific inside milieu
from the outside milieu that surrounds the building
block, establishing a micro-ecosystem within the
building block that follows different functional vec-
tors than the outside macro-ecosystem. The physical
covering relates also to Smith et al.s [71] account of
causal unity via physical covering (see above). It is,
however, on the one hand more general, because it
treats also electron shells as a physical covering (see
below), and on the other hand more specific, be-
cause it includes also functional aspects of the phys-
ical covering. Moreover, contrary to the
mathematical account of boundary followed by
Smith et al. [71, 113116], the physical covering of a
building block is itself a three-dimensional material
entity and is therefore rather a boundary region [98].
This is an important aspect, as it provides building
blocks with what Wimsatt called robustness (Things
are robust if they are accessible (detectable, measur-
able, derivable, definable, producible, or the like) in a
variety of independent ways, [117], p. 210f; see also
[118]). The physical covering not only determines the
boundary region of a building block, but is itself a
bona fide functional unit that not only provides the
surface of the boundary of the building block, but also
bears the dispositions with which the building block
interacts and communicates with its environment.
 A building block is not only a spatio-structurally
bona fide entity, but also a bona fide functional unit
that possesses its own regulatory machinery with
feedback mechanisms, so that to a certain degree it
is self-organized and self-maintained. Building blocks
represent localized islands of order that have a stable
internal organization and maintain their integrity
during typical interactions. A building block usually
lives/exists longer than its constituent parts and its
behavior is predictable for the situations typically
found in its environment.
 New types of building blocks come into being as a
result of (cosmic) evolution.
 A building block is able to interact with other
building blocks to form aggregates and more
complex building blocks (Simons assemblies [29]).
Building blocks of a coarser level are composed of
building blocks of finer level(s). As a consequence, a
building block of a coarser level is necessarily
existentially dependent on a building block of some
finer level, resulting in a hierarchy of irreducible
levels. Building blocks of coarser levels can only
evolve after finer level building blocks have evolved.
Building blocks thus provide nature with its universal
inventory of matter, just like lego-bricks with which in-
creasingly complex structures can be built. The evolution
of a new type of building block that constitutes a new and
coarser level always corresponds with a substantial in-
crease in material diversity and adds a new dimension to
the spatio-structural space for evolution to explore. Build-
ing blocks are spatio-structurally, functionally, develop-
mentally and evolutionarily both integrated and stable,
but at the same time increase natures overall evolvability.
Non-biological building blocks
According to the characterization above, the electron
shell is a unit of physical covering of a building block (cf.
[18]). There are two types of material entities that are
covered by electron shells: atoms and molecules. In an
atom, a cloud of electron waves surrounds the nucleus.
It physically covers the atom and also determines the
interaction of the atom with the entities of its
Vogt Journal of Biomedical Semantics            (2019) 10:4 Page 12 of 29
environment. Electromagnetically, one can clearly iden-
tify a stable inside milieu that is protected from an out-
side milieu via the electron shell.
Electron shells from several atoms can bind to form a
molecule. In a molecule, several atoms share a common
electron shell, forming the building blocks of the next
coarser level of granularity. This also applies to lumps of
metal, in which several atomic nuclei share a common
electron shell. In metals, however, the sharing of elec-
trons is not localized between two atoms (i.e., covalent
bond), but instead free electrons are shared among a lat-
tice of positively charged ions (i.e., metallic bonding).
Therefore, causal unity via physical covering in the here
proposed concept of building blocks would include
atoms, lumps of metal and molecules as bona fide ob-
jects in the sense of Smith et al. [71] (for the sake of sim-
plicity, from here on I include metals in molecules and
also treat ionic compounds as molecules; in other words,
I include all compositions of atoms in molecules that are
based on intramolecular forces).
Molecules can further combine to form bona fide ob-
jects based on intermolecular forces such as a portion of
water that consists of several water molecules that be-
come aggregated due to hydrogen bonds. These objects,
however, do not constitute building blocks themselves,
because they lack a common physical covering. Instead,
they are bona fide aggregates of molecule building blocks.
Biological building blocks delimited by a plasma membrane
Biological building blocks are building blocks that are
biological material entities that can be found universally
across a wide range of taxonomic groups. Their proto-
typical forms have evolved during biological evolution
and have been very successful in combining and recom-
bining finer level building blocks to built building blocks
of the next coarser level. Because biological building
blocks continue to evolve, a variety of different forms
exist, all of which, however, share some common charac-
teristics so that they can be referred to as instances of
the same set of prototypical building block categories.
As a consequence, biological building blocks can consid-
erably vary in size, in particular across different taxa.
Correlating biological building block levels with scale
levels across different taxa is therefore often impossible.
In order to identify a biological building block, we
must identify, which types of biological physical
coverings meet the criteria discussed above for physical
covering of a building block. The biological plasma
membrane qualifies as such a physical covering. Various
biological material entities are surrounded and naturally
demarcated by a biological plasma membrane, with its
most important component being amphipathic mole-
cules. Amphipathic molecules such as phospholipids
possess both a hydrophobic and a hydrophilic region.
According to the fluid mosaic model, the membrane is a
fluid structure that is arranged in a mosaic-like fashion
with different kinds of proteins embedded in or attached
to a phospholipid bilayer [27]. This supramolecular
structure is thus an aggregate of molecules that is pri-
marily held together by hydrophobic interactions, which
are significantly weaker than covalent bonds, but never-
theless strong enough to maintain its structural integrity.
Therefore, following Smith et al.s [71] definition of bona
fide objects, each bio-membrane is a bona fide object
that is a molecule aggregate that is causally unified via
internal physical forces, i.e., hydrophobic interactions.
A specific degree of fluidity is essential for the proper
functioning of the membrane as a semi-permeable barrier
and for its embedded enzymatic proteins, many of which
require being able to move within the membrane for their
activity [27]. Whereas the phospholipids provide the
spatio-structural skeleton of the membrane, its various
types of proteins determine most of its functions, ranging
from selective transport across the membrane, to various
enzymatic activities, signal transduction, cell-cell recogni-
tion, intercellular joining such as gap junctions or tight
junctions, and attachment to the cytoskeleton and the
ECM. Each type of plasma membrane can be character-
ized by its set of membrane proteins.
There are two types of biological material entities that
are covered by plasma membranes: cells (prokaryotic as
well as eukaryotic cells) and organelles, the latter of which
are membrane-enclosed structures within eukaryotic cells,
including nucleus, endoplasmatic reticulum, lysosome,
mitochondrion, peroxisome, cisternae of the Golgi appar-
atus, central vacuole, chloroplast, and all vesicles and vac-
uoles. In the here suggested strict sense of organelle as a
membrane-enclosed material entity within eukaryotic
cells, the Golgi apparatus itself is not an organelle, but an
aggregate of organelles, because its cisternae are physically
disconnected organelles themselves.
Cells and organelles are thus biological building blocks
and therefore spatio-structural as well as functional bona
fide entities. When only considering the topology of the
membranes, one must, however, distinguish a building
block single-membrane-enclosed entity that comprises all
organelles and prokaryotic cells, from a building block
membrane-within-membrane entity that comprises
eukaryotic cells, which are membrane-enclosed entities
that have membrane-enclosed entities as their parts.
Several eukaryotic cells can fuse to form a syncytium,
which is a multinucleated cell (e.g., skeletal muscles and
cardiac muscle in humans and the syncytiotrophoblast in
vertebrates, which is the epithelial covering of a placenta),
or they can conduct multiple nuclear divisions without ac-
companying cytokinesis to form coenocytes. In both cases
several nuclei share the same cell membrane, thus, form-
ing mutliplets of eukaryotic cells. However, although
Vogt Journal of Biomedical Semantics            (2019) 10:4 Page 13 of 29
topologically substantially different to eukaryotic cells with
a single nucleus, syncytia and coenocytes are nevertheless
membrane-within-membrane entities.
Prokaryotic cells as well as eukaryotic cells can be-
come aggregated such as can be seen in bacterial col-
onies or in epithelia of multi-cellular animals, forming
bona fide objects in the sense of Smith et al. [71] based
on causal unity via internal physical forces. These ob-
jects, however, do not constitute building blocks them-
selves, because they lack a common physical covering.
Instead, they are bona fide aggregates of molecule and
cell building blocks.
Biological building blocks delimited by an epithelium
An epithelium is another type of biological physical cov-
ering that qualifies as a covering of a building block. An
epithelium is composed of polarized cells that form a
tightly packed continuous single-layered sheet of cells.
Every epithelium has an apical surface and a lower basal
surface, the latter of which is attached to a basal lamina
that is a layer of ECM secreted by the epithelial cells.
The basal lamina acts as a filter for any molecules
attempting to pass into the space covered by the epithe-
lium. Many epithelial cells possess microvilli at their ap-
ical side, increasing the surface area of this side of the
epithelium, which is important for functions of secre-
tion, absorption, and sensory functions. The apical side
can also possess a motile cilium for pushing substances
along the apical surface of the epithelium. Tight junc-
tions in case of vertebrates and septate junctions in case
of invertebrates connect the plasma membranes of adja-
cent epithelial cells through specific proteins in the
membranes, forming a continuous semi-permeable seal
around the epithelial cells that prevents fluids from
moving through the intercellular spaces of the epithelial
cells and thus across the epithelium. According to Smith
et al.s [71] definition of bona fide objects, each epithe-
lium as such is thus a cell aggregate that forms a bona
fide object that is causally unified via internal physical
forces, i.e., tight junctions or septate junctions respect-
ively. The epithelium functions as a diffusion barrier.
The epithelium lining the blood vessels of Tetrapoda,
for example, functions as a hemato-encephalic barrier
that prevents some substances in the blood (e.g., some
toxins and pathogens) to come in contact with brain tis-
sue. This protects a specific inside milieu within the
brain from its outside milieu. Epithelia can have various
additional functions, ranging from selective absorption
of water and nutrients, protection, elimination of waste
products, secretion of enzymes and hormones, transcel-
lular transport, to sensory functions. All animal glands,
for instance, are made of epithelial cells.
There are two types of anatomical entities that are
covered by epithelia: organisms with an epidermis, and
epithelially-delimited compartments, the latter of which
are epithelium-enclosed structures within multi-cellular
animals, including, for instance, the circulatory system
in humans, lungs in vertebrates, and the intestine in ani-
mals. Therefore, epithelially-delimited compartment and
epithelially-delimited multi-cellular organism are both
biological building blocks, the latter of which are
epithelium-within-epithelium entities.
Epithelially-delimited compartments can aggregate
such as the digestive system in humans, which consists
of the gastrointestinal tract together with all accessory
organs of digestion (tongue, salivary glands, pancreas,
liver, and gallbladder). Although one can argue that such
an aggregate forms a functional bona fide unit, it does
not constitute a building block, because it lacks a com-
mon physical covering. Instead, it is an aggregate of mol-
ecules, cells and epithelially-delimited compartment
building blocks (see discussion below).
Results I: Spatio-structural granular perspectives
Compositional building block (CBB) granular perspective
On the basis of the abovementioned characterization of
building blocks one can identify the following prototyp-
ical building blocks: atom < molecule (including metals
and ionic compounds) < single-membrane-enclosed en-
tity (i.e., most organelles and all prokaryotic cells)
< membrane-within-membrane entity (i.e., eukaryotic
cell) < epithelially-delimited compartment (i.e., some,
but not all of the entities that are commonly referred to
as organs) < epithelially-delimited multi-cellular organ-
ism (i.e., organisms with an epidermis).
Comparable to the hierarchy proposed by Jagers op
Akkerhuis and Van Straalen [18], the resulting hierarchy
of levels of building blocks ranks complexity solely in a
strict layer-by-layer fashionit is a robust hierarchy that
does not allow for bypasses, such as the sequence sand
< stone < planet allows bypassing the stone level by
constructing a planet from sand alone [18]. Levels in an
aggregate hierarchy on the other hand allow such
bypassing (see also distinction of aggregates and levels of
organization in [35]). The hierarchy of levels of building
blocks provides what Craver [23] would call monolithic
levels that reach across all material domains of reality
and that are globally and universally applicable. Because
the concept of a building block is based on an evolution-
ary interpretation, it explicitly predicts the diversification
of newly evolved building blocks of a given level, with
each higher level exhibiting the possibility of an expo-
nentially larger number of different types of entities as-
sociated with a building block to be evolvedthe
number of possible types of molecules is exponentially
larger than the number of possible types of atoms. When
considering that actual material entities can be com-
posed of a multiplicity of different possible combinations
Vogt Journal of Biomedical Semantics            (2019) 10:4 Page 14 of 29
(i.e., aggregates) of those building blocks, comparable to
constructions made from lego-bricks, the diversity of
possible types of material entities increases even more
with each newly evolved building block.
On the basis of this concept of building blocks and the
implicit hierarchy of building blocks, a granular perspec-
tive of levels of building blocks can be characterized using
Keets general formal theory of granularity [61]. The sub-
ject domain in all granularity perspectives discussed in the
following is restricted to cumulative-constitutively orga-
nized material entities. The bona fide partition of a given
building block entity into its building block components
represents a qualitative compositional partition (as op-
posed to a qualitative regional partition or a quantitative
resolution-based partition). This compositional building
block (CBB) granular perspective is based on a direct
proper parthood relation between instances of different
top-level categories of building blocks (see discussion
below), and thus has the granulation criterion (Fig. 4):
According to Keets formal theory of granularity, this
perspective has a granulation of the non-scale dependent
single-relation-type granularity type (nrG [61]; also
called non-scale dependent primitive granularity type,
npG [60]). It is based on the direct proper parthood rela-
tion as its granulation relation. Entities residing in adja-
cent CBB granularity levels are thus related through the
direct proper parthood relation. In order to constitute a
CBB granular perspective, instances of at least two dif-
ferent categories of building block must exist, of which
instances of one category are direct proper parts of in-
stances of the other. In other words, the levels of the
CBB granular perspective are demarcated from one an-
other according to the properties of the top-level cat-
egories of building block and they are ordered from
finest to coarsest granularity level according to the direct
proper parthood relation. The number of levels within
the CBB granular perspective directly depends on the
number of top level categories of building blocks identi-
fied (Fig. 4).
According to the underlying cumulative constitutive
organization, for all instances of building block holds
(compositional object granularity perspective [58]):
1. An instance of a building block is not necessarily a
proper part of an instance of some building block of
the adjacent coarser CBB granularity level.
2. Every instance of a building block, except for those
belonging to the finest CBB granularity level, has at
least two instances of building blocks of finer levels
as its proper parts.
3. The instance of the building block that is granulated
is the maximum entity that belongs to the coarsest
CBB granularity level, and every other instance of a
building block belonging to this granulation is a
proper part of this maximum entity. However,
because this maximum entity is cumulative-
constitutively organized, its direct proper parts not
necessarily all belong to the second coarsest CBB
granularity level.
Because each entity belonging to a specific CBB granu-
larity level represents a BFO object, we can distinguish
six different spatio-structural frames of reference, which
can be ordered according to the associate CBB granu-
larity levels from finer to coarser spatio-structural
frames of reference: an atom, a molecule, an organelle/
prokaryotic cell, a eukaryotic cell, an epithelially-delim-
ited compartment and an epithelially-delimited
multi-cellular organism frame of reference. Each such
spatio-structural frame of reference has its own set of
granular perspectives. As a consequence, whereas any
given material entity can belong to six different
spatio-structural granular perspectives, it can belong to
maximally one CBB granularity level.
Fig. 4 Compositional Building Block (CBB) Granular Perspective. The different building blocks are granulated according to the direct proper
parthood granulation relation (the large dark arrows). The granulation is of the non-scale dependent single-relation-type granularity type (nrG
[61]), and uses the combination of the granulation relation together with the common properties of all categories of the building block type as
its granulation criterion. Due to the cumulative constitutive organization, finer-level building block entities can be considered to be parts
associated with coarser-level building block entities, for instance, ECM being an associated part of a eukaryotic cell
building block directProperPartOf building block;
building block hasDirectProperPart building block.
Vogt Journal of Biomedical Semantics            (2019) 10:4 Page 15 of 29
Moreover, because a building block is defined as a
bona fide spatio-structural entity as well as a bona fide
functional unit, the CBB granular perspective comes
close to the ideal organizational backbone for the devel-
opment of a domain granularity framework for the life
sciences. Conceptually, it therefore takes in a central
position within this framework.
Compositional building block cluster (CBB-C) granular
perspectives
As already mentioned above, building blocks can aggre-
gate to form bona fide entities that are not building
blocks themselves. Each spatio-structural frame of refer-
ence (i.e., atomic, molecular, single-membrane-enclosed,
membrane-within-membrane, etc.) accommodates two
distinct categories of bona fide entities. The eukaryotic
frame of reference, for instance, includes eukaryotic cell
as well as bona fide cluster of eukaryotic cells. Whereas
the former is a building block and thus belongs to the
respective granularity level of the CBB granular perspec-
tive, the latter is not, because only the former is based
on the more restrictive causal unity via physical covering
as criterion for their bona fideness. The bona fideness of
bona fide cluster of eukaryotic cells, in contrast, is only
based on the more general causal unity via internal
physical forces. However, because they represent aggre-
gates of building blocks that can be partitioned into their
component object parts that belong to the same
spatio-structural frame of reference, one can
characterize the corresponding qualitative compositional
partitions as compositional building block cluster
(CBB-C) granular perspectives (see Fig. 5). Each CBB
granularity level has its own corresponding CBB-C
granular perspective. This CBB-C granular perspective is
based on a direct proper parthood relation between in-
stances of building blocks of a given spatio-structural
frame of reference and their corresponding bona fide
clusters, and thus has the building-block-level-specific
granulation criterion (Fig. 5):
X = a specific spatio-structural frame of reference.
Like the CBB granular perspective, the CBB-C per-
spective has a granulation of the non-scale dependent
single-relation-type granularity type (nrG [61]) and is
based on the direct proper parthood relation as its
Fig. 5 Set of Granular Perspectives within a given spatio-structural Frame of Reference. The figure shows all qualitative granular perspectives that the
domain granularity framework for the life sciences distinguishes for any given spatio-structural frame of reference and thus any corresponding CBB
granularity level (here, the set of perspectives for the eukaryotic cell level as an example). The large dark arrows indicate the granulation relation and
the white boxes contain the granulated entity types. a = Region-Based Fiat Building Block Part Granularity Perspective; b = Region-Based Fiat Building
Block Cluster Granularity Perspective; c = Region-Based Group of Building Block Level Objects Granularity Perspective; d = Region-Based Group of Fiat
Building Block Level Entities Granularity Perspective (see also Table 1)
building block X directProperPartOf bona fide cluster of
[building block]s X;
bona fide cluster
of [building block]s X
hasDirectProperPart building block X;
Vogt Journal of Biomedical Semantics            (2019) 10:4 Page 16 of 29
granulation relation. Because the domain and range of
the granulation relation differ according to the granula-
tion criterion, the granulation relation is not transitive
and thus each of the CBB-C perspectives includes only
two distinct granularity levels.
Region-based granular perspectives
Besides the two types of compositional granular perspec-
tives, each spatio-structural frame of reference has its
own set of seven different associated region-based
granular perspectives (for an overview, see Fig. 5). The
different perspectives, together with their specific granu-
lation criterion, granulation type, and granulation rela-
tion are listed in Table 1. They differ only with respect
to their granulation type, but they all share the same
non-scale dependent single-relation-type granularity
type (nrG [61]) and are all based on the proper parthood
relation as their granulation relation.
These seven general types of region-based granular
perspectives result in a set of 49 different specific
region-based granular perspectives within the domain
granularity framework for the life sciences. This set is
sufficient to model all possible region-based partition re-
lations between any given pair of spatio-structural en-
tities for a given spatio-structural frame of reference.
Function-based and history/evolution-based granular
perspectives
In analogy to the distinction between the CBB and the
region-based granular perspectives for spatio-structural
entities, one can also distinguish between a compos-
itional functional unit (CFU) granular perspective (which
corresponds with the mechanism-based approach to
Table 1 List of Region-Based Granularity Perspectives for each given spatio-structural frame of reference (compare with Fig. 5); nrG
= non-scale dependent single-relation granularity type, sgrG = scale-dependent grain size with respect to resolution [61]
Level-Specific Granularity
Perspective
Granulation Criterion Granularity Type Granulation Relation # Levels
Region-Based Building Block
Cluster Granularity Perspective
fiat [building block] part
fiat [building block] part
group of fiat [building
block] level entities
fiat [building block]cluster
properPartOf
properPartOf
hasProperPart
hasProperPart
group of fiat
[building block]
level entities OR
fiat [building block]
cluster;
fiat [building block]
part OR
fiat [building block]
part
nrG proper parthood 2
Region-Based Building Block
Part Granularity Perspective
fiat [building block] part
[building block]
properPartOf
hasProperPart
[building block];
fiat [building block]
part
nrG proper parthood 2
Region-Based Fiat Building
Block Aggregate Granularity
Perspective
[building block]
[building block]
fiat [building block]
cluster
scattered fiat
[building block] entity
properPartOf
properPartOf
hasProperPart
hasProperPart
fiat [building block]
cluster OR
scattered fiat
[building block] entity;
[building block] OR
[building block]
nrG proper parthood 2
Region-Based Fiat Building
Block Part Granularity
Perspective
fiat [building block] part
fiat [building block] part
properPartOf
hasProperPart
fiat [building block]
part;
fiat [building block]
part
nrG proper parthood ?
Region-Based Fiat Building
Block Cluster Granularity
Perspective
fiat [building block]
cluster
fiat [building block]
cluster
properPartOf
hasProperPart
fiat [building block]
cluster;
fiat [building block]
cluster
nrG proper parthood ?
Region-Based Group of
Building Block Level Objects
Granularity Perspective
group of [building block]
level objects
group of [building block]
level objects
properPartOf
hasProperPart
group of
[building block]
level objects;
group of
[building block]
level objects
nrG proper parthood many
Region-Based Group of Fiat
Building Block Level Entities
Granularity Perspective
group of fiat [building block]
level entities
group of fiat [building block]
level entities
properPartOf
hasProperPart
group of fiat
[building block]
level entities;
group of fiat
[building block]
level entities
nrG proper parthood ?
Vogt Journal of Biomedical Semantics            (2019) 10:4 Page 17 of 29
levels [119123]) and various region-based functional en-
tity granular perspectives, as well as between a compos-
itional historical/evolutionary unit (CH/EU) granular
perspective and various region-based historical/evolution-
ary entity granular perspectives respectively.
The partition of a given functional unit or historical/
evolutionary unit into components that themselves are
functional units or historical/evolutionary units represents
a qualitative compositional partition. The functional com-
positional partition is based on a direct proper functional
parthood relation (which can be derived from the direct
proper parthood relation by restricting its domain and
range to instances of functional unit) between instances
of different sub-categories of functional unit (see next
chapter), which thus represents the granulation relation of
the CFU granular perspective. Its granulation criterion is:
The historical/evolutionary compositional partition, on
the other hand, is based on a direct proper historical/evolu-
tionary (DirPropHistEvol) parthood relation (which can be
derived from the direct proper parthood relation by restrict-
ing its domain and range to instances of historical/evolu-
tionary unit) between instances of different sub-categories
of historical/evolutionary unit (see next chapter), which
thus represents the granulation relation of the CH/EU
granular perspective. Its granulation criterion is:
According to Keets formal theory of granularity, both
perspectives have a granulation of the non-scale dependent
single-relation-type granularity type (nrG [61]). Contrary
to the CBB granular perspective, however, an underlying
hierarchy of levels of functional or historical/evolutionary
building blocks that defines the number of possible levels
of a CFU or CH/EU granular perspective, like the CBB
granular perspective does for spatio-structural entities, is
missing. Neither the CFU nor the CH/EU granular per-
spective can be based on a hierarchy of monolithic levels
of functional or historical/evolutionary units that are glo-
bally and universally applicable and reach across all do-
mains of the life sciencesto stay within the metaphor: we
do not know realitys inventory of functional and histor-
ical/evolutionary lego-bricks. Instead, representatives of
different species, even different particular biological mater-
ial entities, can substantially differ in the number and
structure of their CFU and CH/EU granular perspectives.
Because we do not distinguish between different
sub-types of functional and historical/evolutionary causal
unity, like we do with causal unity via internal physical
forces and via physical covering for spatio-structural en-
tities, there is no analog for the CBB-C granular perspec-
tive for functional and historical/evolutionary entities.
However, one can differentiate various region-based func-
tional and region-based historical/evolutionary granular
perspectives in analogy to the various region-based granu-
lar perspectives for spatio-structural entities, which I do
not discuss here for lack of space.
2nd step: Dealing with specific problems resulting from
the cumulative constitutive Organization of Reality
Extending and rearranging BFOs top-level category of
material entity to accommodate different frames of reference
The frame-dependence of the relevance of different
types of causal unity and the resulting differentiation of
three basic categories of granular perspectives and their
corresponding basic frames of reference (i.e., spatio-
structural, functional, historical/evolutionary), together
with the differentiation of spatio-structural frames of ref-
erence in dependence on the number of granularity
levels identified for the CBB granular perspective (i.e.,
atomic, molecular, etc.), reflect a basic distinction of
sub-categories of material entity. I therefore suggest the
following top-level classes for BFOs material entity (see
Fig. 6). The classes functional entity, historical/evolu-
tionary entity, and spatio-structural entity distinguish
foundational types of material entity based on their
underlying type of causal unity, which is causal unity via
bearing a specific function, causal unity via common his-
torical/evolutionary origin, and causal unity via internal
physical forces, respectively. And because causal unity via
physical covering supervenes on causal unity via internal
physical forces, the latter covers the former [98]. Because
of the frame-dependence of the relevance of these differ-
ent types of causal unity, these three classes are not dis-
joint. As a consequence, some given material entity may
instantiate functional entity, historical/evolutionary entity,
and spatio-structural entity at the same time.
On the basis of the identification of different
spatio-structural frames of reference, I can now suggest the
following top-level classes for spatio-structural entity:
atom level entity, molecule level entity, organelle/prokary-
otic cell level entity, eukaryotic cell level entity, epithelial-
ly-delimited compartment level entity, epithelially-
delimited multi-cellular organism level entity (see Fig. 6).
Each of these categories corresponds with one of the
spatio-structural frames of reference. Due to the
frame-dependence, these six classes of spatio-structural
entity are also not disjoint, because some given
spatio-structural entity may be a molecule, but at the same
time also a fiat organelle part and a fiat eukaryotic cell part.
functional unit directProperFunctionalPartOf functional unit;
functional unit hasDirectProperFunctionalPart functional unit.
hist/evol unit DirPropHistEvolPartOf hist/evol unit;
hist/evol unit hasDirPropHistEvolPart hist/evol unit.
Vogt Journal of Biomedical Semantics            (2019) 10:4 Page 18 of 29
On the basis of (i) the identification of different
spatio-structural frames of reference, (ii) the implications
of a cumulative constitutive organization of biological
material entities, and (iii) because bona fideness is
granularity- and thus frame-dependent [77, 98], I treat
all bona fide and fiat entities from a given spatio-struc-
tural frame of reference in coarser frames of reference as
fiat entities. As a consequence, portion of matter entity
is introduced as another top level class of
spatio-structural entity in addition to the set of
building-block-level-specific classes. It refers to the rep-
resentation of entities from a finer spatio-structural
frame of reference level at coarser frame-levels (see next
chapter and Figs. 6 and 8).
Regarding the functional and historical/evolutionary
entities, one can only distinguish bona fide and fiat en-
tities with respect to their corresponding frames of refer-
ence. Therefore, functional entity has the top-level
classes functional unit, which comprises all bona fide
functional entities, and fiat functional unit part, which
comprises all fiat functional entities respectively.
Accordingly, one can distinguish historical/evolutionary
unit from fiat historical/evolutionary unit part. Because
for functional and historical/evolutionary entities no
backbone granularity scheme exists that is comparable
to the building block levels hierarchy and the associated
CBB granular perspective discussed above, no additional
differentiation into further subclasses is suggested. One
could, of course, differentiate functional entities based
on the type of functions they bear and thus the type of
corresponding processes (i.e., functionings), into func-
tional units of locomotion, physiology, ecology, develop-
ment, and of reproduction and propagation, and
historical/evolutionary entities into historical units of de-
velopment, heredity, and of evolution and developmen-
tal, genealogical and evolutionary lineages [77].
Because each spatio-structural frame of reference in-
cludes not only the corresponding building block and its
bona fide aggregates, but also their corresponding fiat
building block parts and fiat building block aggregates,
each direct subclass of spatio-structural entity includes
all corresponding fiat and bona fide entities. In other
words, I interpret BFOs categories object, object aggre-
gate, fiat object part as being applicable to each
spatio-structural frame of reference. Therefore, I con-
sider the distinction between fiat and bona fide material
entities to be foundational for each spatio-structural
frame of reference. Taking the eukaryotic cell level en-
tity (i.e., membrane-within-membrane frame of refer-
ence) as an example, this approach results in the basic
distinction of eukaryotic cell level object and fiat
eukaryotic cell level entity (see Fig. 7).
The eukaryotic cell level object corresponds with
BFOs object category. Depending on which type of
Fig. 6 Top-Level Subclasses of material entity and spatio-structural entity. The labeled grey boxes represent classes. The class spatio-structural
entity is characterized in reference to causal unity via internal physical forces, functional entity in reference to causal unity via bearing a specific
function, and historical/evolutionary entity in reference to causal unity via common historical/evolutionary origin. As a consequence of the
perspective-dependence of bona fideness, these three classes are not disjoint. The functional and historical/evolutionary entities are further
differentiated according to disjoint categories of bona fide units and fiat unit parts. Spatio-structural entities are further differentiated in
correspondence with the granularity levels of the compositional building block granular perspective (see discussion in text), ranging from atom level
entity to epithelially-delimited multi-cellular organism level entity, but include not only the respective bona fide entities of that level, but also their
corresponding object aggregate and fiat object part entities. Because bona fideness is not only perspective-dependent, but also granularity-
dependent, each building block level has its own spatio-structural frame of reference and thus its own perspective. Due to the cumulative-constitutive
organization of biological entities, entities from finer spatio-structural frames of reference (e.g., molecules) must be represented in coarser frames of
reference (e.g., eukaryotic cell) as fiat portions of matter. These representations are covered through the portion of matter entity class (see also Fig. 8)
Vogt Journal of Biomedical Semantics            (2019) 10:4 Page 19 of 29
causal unity is relevant for the given object entity, I dis-
tinguish two types of objects for each spatio-structural
frame of reference and thus two subclasses for each dir-
ect subclass of spatio-structural entity. On the one
hand the entities that belong to the corresponding CBB
granularity level, which are objects that are based on the
more specific causal unity via physical covering. In the
case of eukaryotic cell level object this would be
eukaryotic cell (see Fig. 7), or molecule in the case of
molecule level object. On the other hand, because build-
ing blocks can aggregate to form bona fide clusters based
on the more general causal unity via internal physical
forces, another object category is required to deal with
these types of objects. Thus, eukaryotic cell level object
would not only have eukaryotic cell as its direct subclass,
but also bona fide cluster of eukaryotic cells, for example,
those cells that together build an epithelium (which pro-
vides the physical covering of the building block entities of
the next coarser spatio-structural frame of reference). Or,
in case of molecule level object, bona fide cluster of mol-
ecules can form a bio-membrane or a chitin cuticula, both
of which are bona fide objects that are based on causal
unity via internal physical forces (as opposed to the build-
ing block itself, which is additionally based on causal unity
via physical covering).
These building block level objects are contrasted with
fiat building block level entities, which cover BFOs fiat
object part and object aggregate and comprise all mater-
ial entities that possess spatio-structurally no causal unity
(neither via internal physical forces nor via physical cover-
ingnote that this fiatness depends on the granularity
level of the building block entity, which provides the rele-
vant spatio-structural frame of reference in this context).
Fiat building block entities can be further differenti-
ated based on whether they are spatio-structurally
self-connected, giving rise to two distinct subclasses. In
case of fiat eukaryotic cell level entity this results in the
distinction of self-connected fiat eukaryotic cell entity
and scattered fiat eukaryotic cell entity (Fig. 7).
Self-connected fiat entities can be further differentiated
into fiat building block parts and thus the building block
level specific correlate to BFOs fiat object part, and fiat
building block clusters. For the eukaryotic cell level, the
former would translate into fiat eukaryotic cell part and
the latter into fiat eukaryotic cell cluster, respectively. A
scattered fiat entity, on the other hand, can be further
differentiated based on the type of its scattered compo-
nent parts. If all scattered component parts are building
block level objects that correspond to the relevant
spatio-structural frame of reference, the scattered entity
is a group of building block level objects (e.g., group of
eukaryotic cell level objects). However, if at least one of
its component parts is a fiat building block level entity,
the scattered entity is a group of building block level
Fig. 7 Top-Level Subclasses of eukaryotic cell level entity. Eukaryotic cell level entities are differentiated into a bona fide eukaryotic cell level
object and a fiat eukaryotic cell level entity class, which are disjoint. The former is differentiated based on its underlying type of causal unity into
eukaryotic cell, which is based on physical covering, and bona fide cluster of eukaryotic cells, which is based only on internal physical forces
and not on physical covering. The fiat eukaryotic cell level entities are differentiated based on their self-connectedness into the disjoint subclasses
self-connected fiat eukaryotic cell entity and scattered fiat eukaryotic cell entity. See text for more details
Vogt Journal of Biomedical Semantics            (2019) 10:4 Page 20 of 29
entities (e.g., group of fiat eukaryotic cell level entities)
(see Fig. 7). For a distinction of (i) groups based on
metric proximity as the relation between its parts versus
(ii) clusters based on topological adherence as the rela-
tion between its parts see Vogt et al. [87, 124].
Consequence from the cumulative constitutive organization
of biological material entities and the frame-dependence of
their representation
The abovementioned direct subclasses of spatio-struc-
tural entity must accommodate all types of material en-
tities found in cumulative-constitutively organized
biological material entities. Therefore, its sub-classes al-
ways refer to the building block entity of the correspond-
ing spatio-structural frame of reference, independent of
whether finer-level entities are also involved. In other
words, eukaryotic cell or fiat eukaryotic cell part com-
prise all types of eukaryotic cell or eukaryotic cell part en-
tities, with and without associated portions of connected
ECM, and epithelially-delimited compartment comprises
all types of epithelially-delimited compartments, with and
without associated portions of connected molecular mat-
ter and portions of connected tissue (see also Figs. 4 and
5). Therefore, when we talk about a eukaryotic cell cluster,
this can refer to a cluster of cells with surrounding ECM,
but it could also refer to a cluster of cells without sur-
rounding ECM. This is a rather pragmatic choice, as
the alternative would require distinguishing various
categories to cover each possible combination of dif-
ferent levels of building block entities that can be
found in a cumulative constitutive organization, which
would result in a tremendous increase in top-level
classes [87, 124]. This would neither be convenient
and intuitive to use, nor really necessary.
Because biological material entities are usually
cumulative-constitutively organized (see discussion
above), entities of finer building block levels can exist
outside of building blocks of coarser levels, for instance,
molecules outside of eukaryotic cells. Unfortunately,
these finer level entities cannot be covered with the cat-
egories of the coarser levels, since they are neither bona
fide objects nor fiat object parts entities of this object
levela molecule that exists outside of eukaryotic cells
does neither represent a eukaryotic cell level object nor
a fiat eukaryotic cell level entity. In other words, the ad-
equate classes for referring to these entities belong to a
different and finer spatio-structural frame of reference.
However, respective entities still must be represented in
the frame of reference of the coarser level (see sorta-
tion-by-type and type granularity trees problematic dis-
cussed in chapter Biological Reality: The Problem with
the Cumulative Constitutive Hierarchy, see Fig. 2). As
already mentioned above, I therefore introduce the class
portion of matter entity. For instance, eukaryotic cell
clusters and single eukaryotic cells, as well as molecule
clusters and single molecules, can exist outside of
epithelially-delimited compartments (see also Fig. 2).
However, none of the subclasses of epithelially-delimited
compartment level entity can accommodate these mater-
ial entities. They therefore must be covered by the classes
portion of molecule entity and portion of eukaryotic cell
entity respectively, which are frame-of-reference-specific
subclasses of portion of matter entity (see Figs. 6 and 8).
A portion of matter is a non-countable entity (c.f.
masses [125]; amount of matter [126]; portion of un-
structured stuff [127]; see also body substance [64]; and
portion of body substance [56]). In order to count the
number of component parts of a portion of matter, one
would have to change the spatio-structural frame of ref-
erence from the current frame to a frame of a finer level
that corresponds with the component parts of that por-
tion. Thus, a cluster of molecules, for instance, the chitin
cuticula that forms the exoskeleton in insects, which is a
bona fide cluster of chitin molecules and thus instanti-
ates molecule level object at the molecular frame of ref-
erence, is represented as a self-connected (fiat) portion
of molecular matter at all coarser spatio-structural
frames of reference. The individual molecules that build
the cluster cannot be individually differentiated anymore
at reference levels coarser than the molecular level, be-
cause their bona fideness disintegrates at these coarser
levels [87], which is why all portions of matter are
treated as fiat entities. If a portion of matter consists of
a mixture of building block entities of different
spatio-structural frames of reference such as a portion of
connective tissue that is a group of cells embedded in a
cluster of collagen molecules, the coarsest building block
entity is used for classifying it, which in this case would
be a portion of connective tissue. Portions of tissue al-
ways refer to cell aggregates. Most cells in multi-cellular
organisms are surrounded by a complex cluster of mole-
cules, i.e., the ECM.
Because entities belonging to a finer spatio-structural
frame of reference are always represented as non-count-
able fiat portions of matter in coarser spatio-structural
frames of reference, one can only distinguish between
self-connected and scattered portions. In case of portion
of eukaryotic cell entity, one can thus distinguish self--
connected portion of eukaryotic cell tissue from scat-
tered portions of eukaryotic cell tissue respectively (see
Fig. 8).
Cross-granular multiple instantiation
Due to its granular nature, any given biological material
entity always instantiates several different material entity
categories at the same time, one for each spatio-struc-
tural frame of reference [87]. For example, every in-
stance of eukaryotic cell instantiates at finer frames of
Vogt Journal of Biomedical Semantics            (2019) 10:4 Page 21 of 29
reference also bona fide cluster of molecules and bona
fide cluster of atoms, because a eukaryotic cell is a bona
fide composition of clustered molecules and at the same
time also a bona fide composition of clustered atoms. At
coarser frames of reference it also instantiates
frame-specific classes. Which class is instantiated at
those coarser frames, however, depends on the particular
eukaryotic cell. If it exists outside of any epithelially-
delimited compartment, it is not covered by any
level-specific subcategory of epithelially-delimited com-
partment entity and therefore instantiates some category
of portion of eukaryotic cell entity (see discussion in
previous chapter). If it is part of an epithelially-delimited
compartment it instantiates fiat epithelially-delimited
compartment part.
One could, of course, define a class eukaryotic cell, a
class maximal cellular molecule cluster, and a class
maximal cellular atom cluster and all these three classes
would have the same extension, although they belong to
different frames of reference; and according to the
principle of extensionality of class logic, these classes
would be identical from a logics point of view. However,
from an epistemic point of view, due to the frame- and
granularity-dependence of bona fideness, these classes
cannot be strictly synonymized [87]. Therefore, when
dealing with biological material entities we necessarily
have to deal with multiple cross-granular instantiations
[87] of subcategories of material entity, all of which do
not stand in a subsumption relation to one another.
Their requirement is a necessary consequence of the fact
that every building block level has its own associated
spatio-structural frame of reference.
Results II: Additional granular perspectives
Granular representation and resolution-based
representation (RBR) granular perspectives
A consequence of the abovementioned situation of mul-
tiple cross-granular instantiation is that each particular
biological material entity necessarily instantiates multiple
subclasses of material entity. This can be modeled
through providing a URI for each representation. In
order to indicate that these URIs refer to the same con-
crete thing in reality, the resources must be adequately
related to one another. Therefore, a specific strict partial
ordering relation, i.e., granular representation relation, is
introduced, which can be differentiated into has coarser
granular representation and its inverse relation, has finer
granular representation. It has spatio-structural entity
as its range and its domain. This relation gives rise to a
granular partition, a scale-based resolution granular par-
tition. Scale-based, because the CBB granularity perspec-
tive can be interpreted to provide a scale that is based
on the ordering of CBB granularity levels from the finest
to the coarsest level. Resolution, because each individual
resource refers to the same concrete material entity, but
represents it in its level-specific resolution. This
scale-based resolution granular partition also covers the
non-countable portion of matter entity granular repre-
sentations of a given particular material entity that can
instantiate identical subclasses of portion of matter
Fig. 8 Top-Level Subclasses of portion of matter entity. The entities of each building block level, except for the coarsest level of epithelially-delimited
multi-cellular organisms, can be represented as a respective portion of matter entity in coarser spatio-structural frames of reference. Therefore, portion
of matter entity is differentiated into building block level specific subclasses. Further differentiations are shown for the classes portion of molecule
entity and portion of eukaryotic cell entity, which are based on whether the entity is a self-connected portion of matter, for instance, a portion of
ECM or a portion of connective tissue, or a group of scattered portions, for instance, the group of portions of muscle tissues in a human being
Vogt Journal of Biomedical Semantics            (2019) 10:4 Page 22 of 29
entity across several spatio-structural frames of refer-
ence (see Fig. 2c).
As a consequence, the entities that belong to the same
scale-based resolution granular partition are only different
granular representations of the same particular material
entity, with each granular representation directly linked to
a specific spatio-structural frame of reference [87].
On the basis of this granular representation relation,
and in addition to the various qualitative granular per-
spectives discussed so far, one can differentiate several
quantitative scale-based granular perspectives (cf. [58]).
This is required to formally model the specific relation be-
tween resources that refer to different granular represen-
tations of the same particular material entity in various
finer and coarser spatio-structural frames of reference.
All resolution-based representation (RBR) granular
perspectives are based on the combination of the CBB
granular perspective and a strict partial ordering granu-
lar representation relation between instances of different
subclasses of spatio-structural entity that belong to dif-
ferent spatio-structural frames of reference. The possibil-
ities for distinguishing different types of RBR granular
perspectives is extensive and results from the different
range and domain combinations for the granulation rela-
tion, with each unique combination resulting in a unique
granulation criterion. Here, however, I will only discuss
the most general and inclusive type of RBR granular per-
spective that has the granulation criterion (Fig. 9):
X = a specific spatio-structural frame of reference; X +
1 = the next coarser spatio-structural frame of reference
adjacent to X.
This perspective has a granulation of the scale
dependent grain-size-according-to-resolution granularity
type (sgrG [61]). It is based on the granular representa-
tion relation as its granulation relation. Because this
RBR granular perspective directly depends on the CBB
granular perspective, the number of its granularity levels
corresponds with the number of CBB granularity levels.
Resolution-based Countability representation (RBCR)
granular perspectives
The RBR granular perspective does not differentiate
whether a representation is of the countable building
block level entity kind (e.g., atom level entity, molecule
level entity) or the non-countable portion of matter en-
tity kind, as it allows all kinds of spatio-structural en-
tities to be granulated. In order to identify changes from
countable to non-countable representations of a given
real entity across different spatio-structural frames of
reference, two complementary resolution-based count-
ability representation (RBCR) granular perspectives are
suggested. For this reason the following two granular
countability representation relations are introduced: (i)
has coarser non-countable granular representation
(co_n-c_GranRep), with some building block level entity
(e.g., eukaryotic cell level entity) as its domain and por-
tion of matter entity as its range, together with its in-
verse relation has finer countable granular
representation (fi_c_GranRep), and (ii) has coarser
countable granular representation (co_c_GranRep), with
portion of matter entity as its domain and some build-
ing block level entity as its range, together with its in-
verse relation has finer non-countable granular
representation (fi_n-c_GranRep). On the basis of these
two relations two complementary RBCR granular per-
spectives can be distinguished: (i) countable to
non-countable RBCR granular perspective, and (ii) non--
countable to countable RBCR granular perspective. The
countable to non-countable perspective has the granula-
tion criterion (Fig. 9):
The non-countable to countable perspective has the
granulation criterion:
X = a specific spatio-structural frame of reference; X +
1 = the next coarser spatio-structural frame of reference
adjacent to X.
These two complementary perspectives have both a
granulation of the scale dependent grain-size-according-
to-resolution granularity type (sgrG [61]). Each is based
on its respective granular countability representation re-
lation as its granulation relation. Because the domain
and range of their respective granulation relation differ,
the granulation relation is not transitive and thus both
RBCR granular perspectives comprise only two distinct
granularity levels.
Function-based representation (F-BR) and historical/evolution-
based representation (H/E-BR) granular perspectives
The functional frame of reference requires its own
granular representation due to cross-granular multiple
instantiation (analogue to cross-granular multiple
spatio-structural
entity X
hasCoarserGranRep spatio-structural entity X + 1;
spatio-structural
entity X + 1
hasFinerGranRep spatio-structural entity X;
spatio-structural entity X co_n-c_GranRep portion of matter entity X + 1;
portion of
matter entity X + 1
fi_c_GranRep spatio-structural entity X;
portion of matter entity X co_c_GranRep spatio-structural entity X + 1;
spatio-structural entity X + 1 fi_n-c_GranRep portion of matter entity X.
Vogt Journal of Biomedical Semantics            (2019) 10:4 Page 23 of 29
instantiation as a consequence of multiple spatio-struc-
tural frames of reference). This function-related granular
representation is required because some instances of
spatio-structural entity are at the same time also in-
stances of functional unit. The filter apparatus of a ter-
minal cell of a protonephridium, for instance, instantiates
fiat eukaryotic cell part, because the filter apparatus con-
sists of the cells cilium, a filter and a set of microvilli, but
not the other parts of the terminal cell. The filter appar-
atus, however, also instantiates functional unit, because it
functions as a filter during excretion.
The historical/evolutionary frame of reference also re-
quires its own granular representation due to cross-granular
multiple instantiation. Every anatomical entity that is a
homologue and that thus instantiates historical/evolution-
ary unit also instantiates spatio-structural entity.
Fig. 9 Resolution-Based Representation (RBR) and Resolution-Based Countability Representation (RBCR) Granularity Perspective. The different levels
of the RBR granular perspective are granulated according to the has coarser granular representation relation (the white broad arrows). The
granulation is of the scale dependent grain-size-according-to-resolution granularity type (sgrG [61]). The two levels of each of the two RBCR
granular perspectives, on the other hand, are granulated according to the has coarser non-countable granular representation relation and the has
finer countable granular representation relation, respectively (dotted gray arrows). Their granulation is of the scale dependent grain-size-according-
to-resolution granularity type (sgrG [61]). All three perspectives use the combination of the granulation relation together with the scale provided
through the set of different spatio-structural frames of reference that are sequentially ordered through the associated CBB granular perspective
(i.e., the building block levels hierarchy). As a consequence, the RBR granular perspective comprises six granularity levels, whereas the two RBCR
granular perspectives each comprise only two granularity levels, because their granulation relation is not transitive (its domain and range differ)
Vogt Journal of Biomedical Semantics            (2019) 10:4 Page 24 of 29
For this reason the following two granular representa-
tion relations are introduced: (i) has functional granular
representation (FuncGranRep), with spatio-structural
entity as its domain and functional entity as its range
and its inverse relation functional has spatio-structural
granular representation (FuncSp-StrGranRep), and (ii)
has historical/evolutionary granular representation
(Hist/EvGranRep), with spatio-structural entity as its
domain and historical/evolutionary entity as its range
and its inverse relation historical/evolutionary has
spatio-structural granular representation (Hist/EvSp-Str-
GranRep). On the basis of these two relations two
granular perspectives can be distinguished: (i) a func-
tion-based representation (F-BR) granular perspective
and (ii) a historical/evolution-based representation (H/
E-BR) granular perspective. The F-BR granular perspec-
tive has the granulation criterion:
The H/E-BR granular perspective has the granulation
criterion:
These two perspectives have both a granulation of the
scale-dependent grain-size-according-to-resolution granu-
larity type (sgrG [61]). Resolution is here used in the sense
of depending on a specific frame of reference that func-
tions like a lens for filtering out all aspects irrelevant to
the given frame of reference. Each is based on its respect-
ive granular representation relation as its granulation rela-
tion. Because in both perspectives the domain and
range of the respective granulation relations differ, the
granulation relations are not transitive. Consequently,
both granular perspectives comprise only two distinct
granularity levels.
Discussion
The here proposed approach for the development of a
domain granularity framework for the life sciences com-
prises a core set of granular perspectives that can be uti-
lized for efficiently managing large semantic graphs that
contain data about material entities that range from
atoms to multi-cellular organisms and beyond. The
granularity framework provides a meta-layer that (i) de-
fines the relations between entities that belong to differ-
ent granularity levels of the same granular perspective
and between entities across different granular
perspectives; (ii) integrates various frames of reference
within a single framework, all of which are essential for
the life sciences, ranging from purely spatio-structural
frames of reference, to functional, developmental, eco-
logical, and evolutionary frames of reference; (iii) im-
proves searching and navigating through large complex
graphs by using one or a combination of several granular
perspectives as filters and for efficiently utilizing the
hierarchical structure inherent in the semantic graphs;
and (iv) facilitates reasoning and inferencing by provid-
ing additional hierarchical structures that can be used
for measuring semantic similarities between different se-
mantic graphs and between resources within a graph.
This domain granularity framework complies with
Cravers [23] claim of descriptive pluralism about the
levels idea. It comprises various hierarchies of different
levels. The compositional building block (CBB) granular
perspective (Fig. 4) takes in a key position in the frame-
work, because it provides the backbone hierarchy that
facilitates the integration of all the other granular per-
spectives. The CBB granular perspective resembles a
purely compositional account of the levels idea, without
making the mistake to mix entities relevant in different
frames of reference (see problems discussed further above
regarding Eldredges somatic hierarchy [9]). Furthermore,
with its focus on physical covering and evolving building
blocks, the CBB granular perspective is also influenced by
the evolutionary systems-theoretical accounts of the levels
idea, thereby integrating purely spatio-structural consider-
ations with functional and evolutionary aspects. The set of
region-based granular perspectives, on the other hand, do
not have a pre-defined structure in terms of a fix number
of granularity levels, but must be determined on a local
case-by-case approach, thereby reflecting one of the criti-
cism regarding the single compositional hierarchy of the
compositional account of the levels idea (for the compos-
itional account of levels see [4, 29, 33, 117, 128, 129]; for
critique of this approach see [44, 130133]).
The set of functional parthood-based granular per-
spectives resemble the mechanism-based account of the
levels idea [119123]. The lack of a globally applicable
general granular perspective comparable to the CBB
granular perspective for functional parthood thereby re-
flects that functional parthood-based granularity levels
depend on a given mechanism (i.e., a function, and
therefore also a causal process) and thus are local,
case-specific, and cannot result in a universal scheme
that is globally applicable [120]. And finally, the different
spatio-structural frames of reference, with their diverse
sets of parthood-based granular perspectives, together
with the granular perspectives mediating between these
and other frames of reference, reflect many aspects that
Wimsatt [4, 35, 117, 134] discussed in his prototypical
account of levels of organization.
spatio-structural entity FuncGranRep functional entity;
functional entity FuncSp-StrGranRep spatio-structural entity.
spatio-structural entity Hist/EvGranRep historical/evolutionary entity;
historical/evolutionary
entity
Hist/EvSp-StrGranRep spatio-structural entity.
Vogt Journal of Biomedical Semantics            (2019) 10:4 Page 25 of 29
Although this domain granularity framework for the
life sciences comprises all these different accounts of the
levels idea, it nevertheless is characterized and defined
in a formally coherent framework that integrates all
these diverse granular perspectives. There might be con-
ceptually and computationally simpler and more elegant
solutions to the theoretical, conceptual, and computa-
tional challenge of modeling the granularity of
cumulative-constitutively organized (biological) material
entities, but these solutions model the hierarchies found
in reality incorrectly. It seems that if we want to do just-
ice to the complex nature of reality, our models must be
complex as well.
Conclusion
A domain granularity framework based on Keets theory
of granularity would not only provide a much needed
conceptual framework for representing domains that
cover multiple granularity levels such as anatomy/
morphology or the life sciences in general, but also a
structure that can be utilized for providing users a more
intuitive experience when navigating and exploring data
represented as semantic graphs in knowledge bases and
content management systems of the life sciences. The
framework could, for instance, be used for querying a
given semantic graph in order to retrieve any partition
expressed in the graph that corresponds with the granu-
lar perspective that the user is interested in. The frame-
work can contain various such perspectives, each of
which can be applied on a given semantic graph or
knowledge base to the effect of filtering out all informa-
tion irrelevant to this particular perspective, thereby sub-
stantially facilitating a desperately needed system that
supports browsing and navigating through increasingly
complex semantic graphs (i.e., datasets).
If the hierarchical order of the various granular per-
spectives contained in a domain granularity framework
reflects reality, the framework would provide a hierarch-
ical structure that could be meaningfully employed for
reasoning over different granularity levels and even dif-
ferent granular perspectives, thereby providing a meth-
odological basis for effectively establishing comparability
between different semantic graphs, which can be used
for automatic assessment and measurement of semantic
similarity between different semantic graphs. Being able
to quantitatively measure degrees of similarity between
semantic graphs would provide new means for analyzing
all kinds of data from the life sciences (e.g., [135137].
Abbreviations
BFO: Basic Formal Ontology; CBB: Compositional Building Block; CBB-
C: Compositional Building Block Cluster; CFU: Compositional Functional Unit;
CH/EU: Compositional Historical/Evolutionary Unit; ChIN: Character Identity
Network; co_c_GranRep: Has-Coarser-Countable-Granular-Representation
relation; co_n-c_GranRep: Has-Coarser-Non-Countable-Granular-
Representation relation; DirPropHistEvolPartOf: Direct-Proper-Historical/
Evolutionary-Part-Of relation; ECM: Extracellular matrix; evo-devo: Evolutionary
developmental biology; F-BR: Function-Based Representation;
fi_c_GranRep: Has-Finer-Countable-Granular-Representation relation; fi_n-
c_GranRep: Has-Finer-Non-Countable-Granular-Representation relation;
FuncGranRep: Has-Functional-Granular-Representation relation; FuncSp-
StrGranRep: Functional-Has-Spatio-Structural-Granular-Representation relation;
H/E-BR: Historical/Evolution-Based Representation; hasCoarserGranRep: Has-
Coarser-Granular-Representation relation; hasDirPropHistEvolPart: Has-Direct-
Proper-Historical/Evolutionary-Part relation; hasFinerGranRep: Has-Finer-
Granular-Representation relation; Hist/EvGranRep: Has-Historical/Evolutionary-
Granular-Representation relation; Hist/EvSP-StrGranRep: Historical/
Evolutionary-Has-Spatio-Structural-Granular-Representation relation;
npG: Non-scale dependent primitive granularity type; nrG: Non-scale
dependent single-relation-type granularity type; OBO Foundry: Open
Biomedical Ontologies Foundry; RBCR: Resolution-Based Countability
Representation; RBR: Resolution-Based Representation; sgrG: Scale dependent
grain-size-according-to-resolution granularity type; URI: Uniform Resource
Identifier
Acknowledgements
I thank Thomas Bartolomaeus, Peter Grobe, Björn Quast, Ludger Jansen, and
Barry Smith for commenting on an earlier draft of this MS. It goes without
saying, however, that I am solely responsible for all the arguments and
statements in this paper. I am also grateful to the taxpayers of Germany.
This work was supported by grant VO 1244/8-1 from the German Research
Foundation DFG. I am also grateful to the taxpayers of Germany.
Funding
This work was supported by grant VO 1244/81 from the German Research
Foundation DFG. I am also grateful to the taxpayers of Germany.
Availability of data and materials
Not applicable.
Authors contributions
LV: developed the particular building blocks approach, the different
granularity perspectives and their relations with one another, and drafted the
manuscript. The author read and approved the final manuscript.
Ethics approval and consent to participate
Not applicable.
Consent for publication
Not applicable.
Competing interests
The author declares that he has no competing interests.
Publishers Note
Springer Nature remains neutral with regard to jurisdictional claims in
published maps and institutional affiliations.
Received: 24 September 2018 Accepted: 14 January 2019
Chiu et al. Journal of Biomedical Semantics            (2019) 10:2 
https://doi.org/10.1186/s13326-018-0193-x
DATABASE Open Access
A neural classification method for
supporting the creation of BioVerbNet
Billy Chiu1* , Olga Majewska1, Sampo Pyysalo1, Laura Wey2, Ulla Stenius3, Anna Korhonen1
and Martha Palmer4
Abstract
Background: VerbNet, an extensive computational verb lexicon for English, has proved useful for supporting a
wide range of Natural Language Processing tasks requiring information about the behaviour and meaning of verbs.
Biomedical text processing and mining could benefit from a similar resource. We take the first step towards the
development of BioVerbNet: A VerbNet specifically aimed at describing verbs in the area of biomedicine. Because
VerbNet-style classification is extremely time consuming, we start from a small manual classification of biomedical
verbs and apply a state-of-the-art neural representation model, specifically developed for class-based optimization, to
expand the classification with new verbs, using all the PubMed abstracts and the full articles in the PubMed Central
Open Access subset as data.
Results: Direct evaluation of the resulting classification against BioSimVerb (verb similarity judgement data in
biomedicine) shows promising results when representation learning is performed using verb class-based contexts.
Human validation by linguists and biologists reveals that the automatically expanded classification is highly accurate.
Including novel, valid member verbs and classes, our method can be used to facilitate cost-effective development of
BioVerbNet.
Conclusion: This work constitutes the first effort on applying a state-of-the-art architecture for neural representation
learning to biomedical verb classification. While we discuss future optimization of the method, our promising results
suggest that the automatic classification released with this article can be used to readily support application tasks in
biomedicine.
Keywords: Verb lexicon, Representation learning
Background
Natural Language Processing (NLP) and text mining of
biomedical literature are critically important for the man-
agement of rapidly growing literature in biomedical sci-
ences. Core bio-NLP technologies such as syntactic and
semantic parsing, event identification, relation extrac-
tion, and entailment detection can all benefit from rich
computational lexicons containing information about the
behaviour and meaning of words in biomedical texts.
While relatively well-developed resources are available for
nouns in biomedicine (e.g. UMLS Metathesaurus, [1]),
*Correspondence: hwc25@cam.ac.uk
Billy Chiu and Olga Majewska contributed equally to this work.
1Language Technology Laboratory, MML, University of Cambridge, 9 West
Road, CB39DB Cambridge, UK
Full list of author information is available at the end of the article
verb-related resources are still lacking in both depth and
coverage [26].
One particularly useful verb resource for general
domain NLP is VerbNet [7]. Providing detailed syn-
tactic and semantic information for English verbs, this
broad-coverage resource has proved useful in supporting
a wide variety of NLP tasks and applications, including
word sense disambiguation [8], semantic role labelling [9],
semantic parsing [10], information extraction [11] and
text mining applications [12, 13], among others.
Our ultimate aim is to create BioVerbNet  the
first VerbNet for supporting NLP and text mining in
biomedicine. However, because manual VerbNet-style
classification is a highly expensive and time-consuming
task, we first investigate a data-driven approach to the cre-
ation of this resource. Previous works have shown that
while an unsupervised verb clustering approach based
© The Author(s). 2019 Open Access This article is distributed under the terms of the Creative Commons Attribution 4.0
International License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and
reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to the
Creative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver
(http://creativecommons.org/publicdomain/zero/1.0/) applies to the data made available in this article, unless otherwise stated.
Chiu et al. Journal of Biomedical Semantics            (2019) 10:2 Page 2 of 12
on conventional NLP has the advantage of discover-
ing novel verb classes from corpus data with minimal
prior knowledge, such automatically acquired classes nec-
essarily contain quite a lot of noise [14]. Conversely,
when training data is available, supervised verb clas-
sification can yield higher precision. Korhonen et al.
(2006) manually developed a VerbNet-style gold stan-
dard for evaluation of automatic verb classification in
biomedicine [15] (detailed in Automatic verb classifica-
tion section). We take this resource as a starting point
in supervised classification aimed at finding novel mem-
ber verbs and classes in data, with the idea that human
evaluators can validate the output and use the correct
classifications as a starting point for the development of
BioVerbNet.
Most existing methods for automatic verb classifica-
tion rely heavily on feature engineering, which is time-
consuming and requires expert knowledge [16]. Hence, we
automate the process of feature learning by using a neu-
ral learning approach, followed by the application of the
Nearest Centroid Classifier to assign verbs into classes.
We encode word features into a low-dimensional space
using neural networks [1719]. Neural word represen-
tations (embeddings) serve now as invaluable features
in a broad range of NLP tasks, including named entity
recognition [2022] and text classification [23, 24]. Neural
representation models such as the skip-gram model with
negative sampling (SGNS) are highly efficient in captur-
ing syntactic and semantic properties of words in corpora
and are therefore intuitively useful also for VerbNet-style
classification [25].
Our methodology consists of two steps: First, we apply
the recent method by Vulic´ et al. [26] to identify best con-
texts for learning biomedical verb representations. The
method, based on the skip-gram model with negative
sampling (SGNS), has produced successful results in the
general domain but has not previously been applied to
specialised domains such as biomedicine. It involves first
creating a context configuration space based on depen-
dency relations between words, followed by applying an
adapted beam search algorithm to search this space for the
class-specific contexts, and finally using these contexts to
create class-specific representations.
In this work, we apply the method to a large biomedical
corpus: the PubMed Central Open Access subset [27] and
all the PubMed abstracts, consisting of about 10 billions
tokens and 27 million word types in total. We evaluate
the trained representations against a gold standard aimed
at capturing verb similarity in biomedicine (BioSimVerb,
[6]). Our results show that when the model is optimized
with context configuration for verbs, it outperforms the
baseline model (a standard SGNS without verb-specific
contexts) significantly, yielding a 5 point improvement in
Spearmans rank correlation (referred to as ? henceforth).
In the second step, the optimized representation is used
to provide word features for building a verb classifica-
tion. This is obtained by expanding the small manually
developed VerbNet-style classification of 192 biomedi-
cal verbs by Korhonen et al. [15] (details in Automatic
verb classification section) with 957 new candidate verbs.
The candidate verbs are chosen from BioSimVerb (details
in Verb classification section), based on their frequent
occurrence in biomedical journals across 120 subdomains
of biomedicine (as categorized by Broad Subject Terms
[28]). This ensures the wide coverage of verb classifica-
tion ideal for the development of BioVerbNet. We use the
Nearest Centroid Classifier to connect the new candidates
to an appropriate class in the resource of Korhonen et al.
[15]. The resulting classification provides 1149 verbs
assigned to the 50 classes in the original resource. It lists,
for each verb, the most frequent dependency contexts
that reflect their syntactic behaviour along with example
sentences.
Qualitative evaluation of the automatically expanded
classes by linguists and biologists reveals that the method
is highly accurate: the vast majority of the novel mem-
bers verbs and classes are legitimate. The method can
therefore be used to greatly facilitate the development
of BioVerbNet by hypothesizing novel classifications for
expert validation. We discuss further optimization of the
method for real-life computational lexicography, but our
promising results suggest that the automatic classification
released with this article can be used to readily support
NLP application tasks in biomedicine.
Apart from proposing an automatic approach to the
creation of BioVerbNet, our study provides an investi-
gation of how different types of dependency-based con-
texts influence the learning of verb representations in
biomedicine. The optimal context configuration proved to
be highly domain-specific. Our results and insights can
facilitate researchers to develop useful methods for train-
ing class-specific representations for biomedical NLP. The
resources are publicly available to the research commu-
nity under an Open Data license at: https://github.com/
cambridgeltl/bio-verbnet.
Related work
Computational verb lexicons
VerbNet [7] is the most extensive verb lexicon currently
available in the general domain. It consists of verbs
grouped into classes based on their shared syntactic and
semantic properties, such as syntactic frames, semantic
roles of arguments, etc. For example, the members (e.g.
delete and discharge) in the verb class Remove have similar
frames and meaning, and can be used to describe sim-
ilar events. VerbNet classes have supported many NLP
tasks, such as word sense disambiguation [8], information
extraction [11] and text mining applications [12, 13]. The
Chiu et al. Journal of Biomedical Semantics            (2019) 10:2 Page 3 of 12
current version of VerbNet (v3.3) consists of 9344 verbs
organised in 329 main classes [29]. Although it has a wide
coverage for general domain NLP applications, it is not
designed for specialized domains, such as biomedicine,
where verbs tend to have a very different meaning and
behaviour than in general English [2, 3]. Hence, there is
a need to develop domain-specific resources to support
biomedical NLP.
Some large lexical resources, such as UMLS Metathe-
saurus [1], can be found in the biomedical domain. How-
ever, most of them focus on nouns and do not provide a
good coverage of other important word classes like verbs.
The lexicons which cover biomedical verbs are usually
smaller in scale and limited to certain sub-domains in
biomedicine. For example, the UMLS SPECIALIST lex-
icon [30], which is created manually by lexicographers,
mainly contains medical and health-related vocabularies.
On the other hand, the BioLexicon [31]  a corpus-driven
lexicon which contains syntactic and semantic frame
information for verbs  is extracted from the Escherichia
Coli (E.Coli) domain, which limits its usefulness to appli-
cations that deal with other sub-domains of biomedicine.
Automatic verb classification
Verb classification links together syntactic and semantic
properties of groups of verbs by means of lexical classes.
Such grouping can reduce the parameters used for repre-
senting verbs individually. While it is time-consuming to
manually classify a large number of verbs, previous stud-
ies have shown that it is possible to automatically acquire
verb classes from both general [3235] and biomedical
texts [15, 36, 37]. For example, Li and Brew (2008) classify
1,300 verbs into 48 Levin classes using Bayesian Multi-
nomial Regression for classification [38]. A range of verb
features have been explored in their works, including
the dependency relations between the arguments and the
prepositions. On the other hand, Sun (2013) uses rich fea-
tures based on the predicate-argument structure (e.g. verb
RESEARCH Open Access
Development of a cardiac-centered frailty
ontology
Kristina Doing-Harris1* , Bruce E. Bray2,3, Anne Thackeray4, Rashmee U. Shah2, Yijun Shao5, Yan Cheng5,
Qing Zeng-Treitler5, Jennifer H. Garvin3,6 and Charlene Weir3,6
Abstract
Background: A Cardiac-centered Frailty Ontology can be an important foundation for using NLP to assess patient
frailty. Frailty is an important consideration when making patient treatment decisions, particularly in older adults,
those with a cardiac diagnosis, or when major surgery is a consideration. Clinicians often report patients frailty in
progress notes and other documentation. Frailty is recorded in many different ways in patient records and many
different validated frailty-measuring instruments are available, with little consistency across instruments. We
specifically explored concepts relevant to decisions regarding cardiac interventions. We based our work on text
found in a large corpus of clinical notes from the Department of Veterans Affairs (VA) national Electronic Health
Record (EHR) database.
Results: The full ontology has 156 concepts, with 246 terms. It includes 86 concepts we expect to find in clinical
documents, with 12 qualifier values. The remaining 58 concepts represent hierarchical groups (e.g., physical function
findings). Our top-level class is clinical finding, which has children clinical history finding, instrument finding, and
physical examination finding, reflecting the OGMS definition of clinical finding. Instrument finding is any score found
for the existing frailty instruments. Within our ontology, we used SNOMED-CT concepts where possible. Some of
the 86 concepts we expect to find in clinical documents are associated with the properties like ability interpretation.
The concept ability to walk can either be able, assisted or unable. Each concept-property level pairing gets a
different frailty score. Each scored concept received three scores: a frailty score, a relevance to cardiac decisions
score, and a likelihood of resolving after the recommended intervention score. The ontology includes the
relationship between scores from ten frailty instruments and frailty as assessed using ontology concepts. It also
included rules for mapping ontology elements to instrument items for three common frailty assessment
instruments. Ontology elements are used in two clinical NLP systems.
Conclusions: We developed and validated a Cardiac-centered Frailty Ontology, which is a machine-interoperable
description of frailty that reflects all the areas that clinicians consider when deciding which cardiac intervention will
best serve the patient as well as frailty indications generally relevant to medical decisions. The ontology owl file is
available on Bioportal at http://bioportal.bioontology.org/ontologies/CCFO.
Keywords: Ontology, Frailty, Surgery, Cardiology, SNOMED-CT
* Correspondence: kdoingharris@gmail.com
1Nuance Communications, Burlington, MA, USA
Full list of author information is available at the end of the article
© The Author(s). 2019 Open Access This article is distributed under the terms of the Creative Commons Attribution 4.0
International License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and
reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to
the Creative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver
(http://creativecommons.org/publicdomain/zero/1.0/) applies to the data made available in this article, unless otherwise stated.
Doing-Harris et al. Journal of Biomedical Semantics            (2019) 10:3 
https://doi.org/10.1186/s13326-019-0195-3
Background
Frailty and cardiac decision making
Frailty is an important patient attribute for treatment de-
cisions in general [14] because assessing frailty severity
predicts response to treatment and patient outcomes
across many conditions [2, 510]. In the modern era of
interventional cardiac care, patient frailty is increasingly
important to decisions regarding major cardiac surgery
and interventional procedures [1, 9, 11]. With the grow-
ing numbers of elderly and diabetic patients [6, 12],
these decisions are common [13]. Older, frail patients
with aortic valve stenosis can now be referred for
coronary artery bypass graft surgery (CABG), a trans-
catheter valve replacement (TAVR), or medical manage-
ment [1416]. While TAVR is minimally invasive with
shorter length of stay, frail patients may not necessarily
benefit due to non-cardiac illnesses that limit quality of
life or increase risk of procedural complications [11, 17],
including increased length of stay, infection rates, and
re-hospitalization. In 2015, the National Institute on
Aging cited frailty assessment as a key priority in the
perioperative approach to cardiac surgery [13].
Assessing frailty is done by intuitive estimates or ap-
praisals, counting comorbid conditions, and the use of
formal assessment instruments [2, 18, 19]. Frailty can in-
clude physical disability, deficits in mood, sensorium,
and cognition, along with patient experience of pain or
incontinence [3, 6].
The purpose of this paper is to describe the devel-
opment of an ontology of frailty, paying special atten-
tion to how it relates to cardiac care decisions. Our
ontology is designed to access the aspects of frailty
that distinguish it from a simple count of comorbid
conditions. We describe a necessary and sufficient
view of patient frailty indicators apart from comorbid
conditions. This ontology has been designed to allow
computerized extraction of frailty information from
the narrative documents patient records. Because
frailty is a topic that is interpreted in many ways and
measured with several instruments [5, 1820], we
built our ontology using as many term identification
techniques as possible, gathering terms using existent
instruments, physician interviews, and automated
chart reviews. We aimed to allow cross walking be-
tween the measurement instruments. The hierarchical
structure was adapted from SNOMED-CT [21] but
expanded and informed by the nuances in clinical
decision-making. We tested a draft version of our
ontology by creating instrument-scoring rules, by
using it to improve automated detection of frailty in-
dicators in a Natural Language Processing (NLP) sys-
tem, and by using it as an input feature to a system
trained to predict patient mortality after a major car-
diovascular procedure (MCVP) [22].
Frailty and NLP
Given that frailty information is so important, extract-
ing it from clinical records is vital for patient care
and research. The three methods of extracting infor-
mation from clinical records are structured data, hu-
man chart review, or automated NLP systems. There
are 3 reasons why an NLP approach is likely to be
the most successful: 1) physicians do not consistently
use frailty instruments, 2) there is no key, which rec-
onciles scores across instruments, 3) they do not all
use the same definition of frailty.
Clinicians collect frailty information, but not in a
systematic fashion nor by consistently using frailty in-
struments [20]. They document narrative descriptions
of frailty information that they find relevant to the
specific clinical situation. It is possible that since cli-
nicians believe they can rapidly use their clinical judg-
ment to assess a patients frailty when they see them
[18], they do not feel the need to systematically use
specific frailty instruments. Their narrative notations
are considered sufficient. However, large-scale retro-
spective studies of patient outcomes require chart re-
view, and if frailty is largely documented in narrative,
then structured text cannot be used and the effort of
wading through text in a chart causes a time bottle-
neck for human reviewers.
The inconsistent use of frailty instruments would not
matter for chart review based on structured information
if there were a method for reconciling scores from dif-
ferent instruments. The method would create equiva-
lences between the instruments. These equivalences
would take as many factors into account as possible.
Creating score equivalence metrics would be a task that
humans would find challenging.
If clinicians all used a similar definition of frailty,
humans chart review or NLP systems without ontology
components would be able to locate their descriptions
easily, but they do not. Clinicians ideas about which
patients are frail are influenced by both the culture
within their organizational department, the decision at
hand, and the wider society. For example, departmental
culture may involve specific frailty tests (e.g., 6-min
walk distance) and social culture may mean that frailty
indicators have different thresholds (e.g., low body mass
index (BMI) in Japan vs. the US [23].) Frailty indicators
are also specific to each patient. A patients level of mo-
bility is highly dependent on prior exercise activities,
desire for exercise, and the patients personal prefer-
ences. The number of frailty instruments that have
been developed evidences the variability in the concep-
tion of frailty, and therefore the complexity of the rela-
tionship between frailty and decision-making. Buta, et
al. [20] identified 67 frailty instruments of which nine
were cited more than 200 times.
Doing-Harris et al. Journal of Biomedical Semantics            (2019) 10:3 Page 2 of 16
Since current charting practices make human chart
review or using structured data untenable, one could
force a structured data solution by picking a single in-
strument and screen all patients. Picking a single in-
strument and screening everyone is hampered by the
low specificity of current instruments [4, 20] and by
lack of instrument adoption. In addition, frailty assess-
ment varies substantially over time. Assessing all indi-
viduals over time would be necessary to understand the
trajectory and implications of frailty [4], which would
mean that the structured data solution would only be-
come helpful after a significant time-interval. Systemat-
ically conducting frailty assessments at all encounters
would fail to highlight decision-specific frailty issues, it
would add a substantial burden to the clinician, and
cost to the healthcare system.
Ontology building
Ontologies may be used in NLP projects to bridge struc-
tured data fields. Some structured data fields from clin-
ical records across institutions or even within the same
institution use different words to denote the same infor-
mation (e.g., patient name vs. lastname, firstname)
[2426]. Ontologies are also used for named entity rec-
ognition and decision modeling [2729]. For example,
named entity recognition can locate all mentions of dis-
orders that patients may have as well as relevant patient
demographics. Decision modeling uses either the named
entities found or other inputs to access ontological ele-
ments, which contribute to creating rules or other
models of decisions. Our ontology of patient frailty is
designed to fulfill both purposes.
We employed the standard methodology for building
ontologies including reconciling clinical text, medical lit-
erature, and existing ontologies [26, 3032]. We chose
to develop our ontology by adhering as closely as pos-
sible to realist principles. Realist principles lead to stable
ontologies [33], which can be reasoned with while avoid-
ing illogical inferences [34].
We conceptualized clinical records as textual record-
ings of the authors ideas about the patient. An existing
ontological concept that corresponds to the authors
ideas about the patient is clinical finding from the
Ontology of General Medical Science (OGMS), which is
defined as A representation that is either the output of
a clinical history taking or a physical examination or an
image finding, or some combination thereof. [35] In
contrast, the definition of a clinical finding used in
SNOMED-CT is observations, judgments or assess-
ments about patients. The definition specifies that it is
designed to convey the actual state of the body and
is inclusive of concepts with a semantic tag disorder
(http://browser.ihtsdotools.org/). By referring directly to
the patients body and not the clinicians findings, one is
ignoring consideration of human error, cognitive biases,
and other aspects that may influence patient-clinician
and clinician-EHR interactions [36, 37]. However,
SNOMED-CTs definition of clinical finding also in-
cludes concepts with the semantic tag finding, which 
are not separate from the observing of them, which
brings them closer to the OGMS definition. We re-
stricted ourselves to findings.
Integration with prior work
Two prior studies have successfully mined frailty infor-
mation from rehabilitation and nursing home notes.
One generated International Classification of Function-
ing, Disability and Health (ICF) codes and the other
extracted Barthel index scores [38, 39]. Their work
indicates that it is possible to locate and extract
frailty-relevant terms. We expanded their work by in-
creasing the number of frailty-related terms identified.
The UMLS Metathesaurus [40] contains a complex
structure of frailty-related concepts. It is evident that
SNOMED CT contributes concepts from many, if not all,
of the available frailty instruments. However, the UMLS
Metathesaurus is not realist due to long-standing require-
ments of backward compatibility [33, 41, 42]. We wanted
our ontology to be interoperable with as many other
ontologies as possible. We did not want to create some-
thing that entirely ignored the UMLS Metathesaurus.
Recent papers have discussed realist approaches, specific-
ally with respect to SNOMED-CT [33, 41, 43, 44]. Com-
patibility with SNOMED-CT can be used as a bridge to
the UMLS Metathesaurus. Therefore, we incorporated
SNOMED-CT concepts into the Cardiac-centered Frailty
Ontology as often as possible, but did not limit ourselves
to SNOMED-CT.
Objective
In this study we created a machine-interoperable de-
scription of frailty that reflects all the areas that clini-
cians consider when deciding which cardiac intervention
will best serve the patient as well as general indications
of frailty found in patient records.
Results
In this section we describe each of the four phases of
ontology development (Identify other ontologies and of-
ficial clinical tools, group terms into high-level classes,
define attributes of classes, analyze and validate), which
led to the final ontological structure.
Phase 1  Collect terms by identifying other ontologies
and official clinical tools
The research team met regularly to iteratively identify
terms from a variety of sources. We reviewed 14 frailty
instruments described in the methods section (below).
Doing-Harris et al. Journal of Biomedical Semantics            (2019) 10:3 Page 3 of 16
The terms from these instruments were mapped onto
the UMLS meta-thesaurus. If there was a SNOMED-CT
term we used it.
In addition, we interviewed 12 clinicians (cardiologists,
geriatricians, and cardiac surgeons) where we provided 7
hypothetical patient vignettes. Clinicians were asked to
discuss patient frailty in relation to a decision between
CABG, TAVR, and medical management. Each hypothet-
ical patient had a different mix of frailty indicators. The
full study will be described in a separate paper. The
terms found in the interviews included muscle weakness,
oxygen need, gait velocity, 6-min walk distance, volun-
teers, lower extremity strength, robust, functional status,
functionality, deconditioned, acute vs. chronic findings
and BMI. We identified terms at the level of concept
granularity relevant to cardiac decision-making. For ex-
ample, terms relating to housework (e.g., dusting,
washing dishes, and vacuuming) were grouped into a
single concept ability to perform domestic activities be-
cause whether a patient is dusting or vacuuming is not
relevant to their cardiac health.
In order to filter the terms into unique groups to aid
the next step of creating hierarchies, the total set of
terms underwent an initial sorting by the research team
to identify explicit synonyms and concepts. The terms
were found to correspond to the general categories of
toileting, mental health, social functioning, working, ex-
ercise, walking, eating, general health, bathing, dressing
& grooming, transfers, and modifiers (i.e., body locations
and qualifiers). Using these groupings, we had an initial
set of 108 unique concepts.
For those 108 concepts, we identified 198 unique
concept-related terms. Terms within concepts were fur-
ther expanded by SNOMED-CT synonyms and aug-
mented by the teams previous experience with clinical
documents. After the term expansion, nearly all of the
concepts had either 1 or 2 terms, while one concept had
12 terms. The concept with the most terms was Lack of
energy finding, with lack of energy, tired, fatigue,
lack energy, tiredness, sleepiness, drowsiness, ex-
haustion, exhaust, wear out, drain, and weary.
Our clinician interviews made it clear that clinicians
rely heavily on the Society of Thoracic Surgeons (STS)
score in assessing patients likelihood of surviving sur-
gery. We examined the STS calculation and found it was
more sensitive to comorbid conditions than indications
of frailty. The clinicians also indicated that comorbid
conditions are often included in assessments of patient
frailty. Since we were interested in creating an ontology
of frailty apart from comorbid conditions, we only in-
cluded the concept comorbid conditions count, not spe-
cific conditions the patient might have.
A second term expansion was done using automated
chart review. Terms found included stagger as indicative
of the concept impairment of balance finding, prosthet-
ics, shoes, gripping strength, fatigue, weakness,
SOB, short of breath, dyspnea, muscle strength,
motor strength, decreased strength, assist, para-
lyzed, handicap, unassisted, dresses, bathes, and
stand. Some terms were removed because they com-
monly occurred with a meaning alternate to the one we
were after. These terms included dressing, supine,
working, eating, strength, incontinence.
After all terms had been gathered we had 246 terms
associated with the 108 concepts.
Phase 2  Group terms into high-level concepts
The identified frailty concepts were arranged in hier-
archical relationship by mapping them to SNOMED-CT
equivalents using SNOMED-CT concepts within the cat-
egory clinical finding, with semantic type finding. The
goal for this process was to restrict the SNOMED-CT
mappings to as small a selection as possible, while main-
taining correspondence, which means our ontology is
somewhat compatible with SNOMED-CT.
Figure 1 shows the top concepts in our Cardiac-centered
Frailty Ontology. In order to create an ontology that is
interoperable with SNOMED-CT, it is important that
where concepts in the two ontologies share a name and an
id number they are used to represent precisely the same
portion of reality. Therefore, if we did not match the exact
use described by SNOMED-CT, we explain why and do
not use the SCTID.
As discussed in the introduction, we did not use clin-
ical finding in the same way as SNOMED-CT, we re-
stricted ourselves to the subset with semantic tag
finding. Therefore, we did not use the SNOMED-CT ID
number for the concept clinical finding. Our concept
Clinical finding (CCFOID:1) has children clinical history
finding (CCFOID:11), instrument finding (CCFOID:12),
and physical examination finding (CCFOID:13), reflecting
the OGMS definition of clinical finding. Instrument find-
ing is any score found for the existing frailty instruments
already mentioned. We included classes not mapped to
SNOMED-CT for demographics (CCFOID:14) and quali-
fier values for the properties of our concepts in our top
level.
In the Cardiac-centered Frailty Ontology we included
demographics in clinical findings because we are refer-
ring to demographic information collected by the
clinician at a clinical visit, not to the demographic infor-
mation that inheres in the patient and may change be-
tween visits.
Clinical history finding
The obvious choice for findings arising from the pa-
tients clinical history taking is clinical history and obser-
vation finding (finding) (SCTID: 250171008). It turns
Doing-Harris et al. Journal of Biomedical Semantics            (2019) 10:3 Page 4 of 16
out that all of the children listed in the SNOMED-CT
browser (http://browser.ihtsdotools.org) have semantic
type finding, which is what we were after. Like clinical
finding, we do not want to include all the children of
clinical history and observation finding, which means we
are not referring to the same portion of reality. Syn-
onymous terms and the SNOMED-CT term identifica-
tion number (SCTID) are not necessary because we are
not looking for the concept to be represented in clinical
documents. For these reasons, we shorten the name to
clinical history finding and exclude the SCTID.
The same problem arises when we try to find a
SNOMED-CT equivalent of physical function finding
(CCFOID:112). The topic modeling, our interviews
with clinicians, and existing instruments all indicate
that the patients physical abilities are a necessary
category. The closest SNOMED-CT equivalent is
functional finding (finding) (SCTID: 118228005),
which has among its children concepts we need, for
example finding of activity of daily living (finding)
(SCTID: 118233009, CCFOID:1124). However, it in-
cludes findings unrelated to physical abilities like does
comply with treatment (SCTID: 386673006). There-
fore, we do not use functional finding and leave phys-
ical function finding, with no SCTID.
SNOMED-CT is so exhaustive that there can be
hierarchical structure that is beyond our needs. Social
and personal history finding (SCTID: 365448001,
CCFOID:115) has two intervening problem parents
finding by method and history finding, which lead to
clinical finding and not clinical history and observation
finding. There is no indication in the documentation
Fig. 1 Top three layers of concepts in the Cardiac-centered Frailty Ontology
Doing-Harris et al. Journal of Biomedical Semantics            (2019) 10:3 Page 5 of 16
about how history finding differs from clinical history
and observation finding. The children of Social and
personal history finding and psychological finding
(SCTID: 116367006, CCFOID:113) that we are inter-
ested in also have intervening concepts. It may be bet-
ter practice to just use the SCTIDs for the lowest
levels. Those will be the only ones used in the NLP.
Alteration in comfort finding (SCTID: 130979001,
CCFOID:111) has the intervening parent problem
sensory nervous system finding (finding) (SCTID:
106147001) and neurological finding (finding) (SCTID:
102957003), which go to clinical finding (finding). The
courses qualifier value (CCFOID:43) concept we include
corresponds to the SNOMED clinical finding attribute
clinical course. We also include a concept for seen by a
professional allied to medicine finding because the snip-
pet annotations indicated that being seen by physical
therapy, occupational therapy or other allied professions
indicated patient frailty.
Physical examination finding
We included in Physical Examination Finding
(CCFOID:13) concepts that fall in the SNOMED-CT
hierarchy under general findings of observation of patient
(finding) (SCTID: 118222006). In SNOMED-CT general
finding of observation of the patient is a child of clinical
history and observation finding. Since we did not include
observation in our concepts, we included this separate
concept for physically observing the patient. We took a
very restricted subset of the children of general findings of
observation of patient (finding), hence the name change
and absence of SCTID. The children we included are
physical deconditioning finding (SCTID: 31031000119102,
CCFOID:134), dyspnea on exertion finding (SCTID:
60845006, CCFOID:131), muscle weakness of limb finding
(SCTID: 713514005, CCFOID:133), weight finding
(SCTID: 107647005, CCFOID:135), and general well-being
finding (SCTID: 365275006, CCFOID:132).
Physical deconditioning has no children. We included
all of the children of muscle weakness of limb because
they separate upper and lower limbs, which our inter-
views indicated is an important distinction. Weight find-
ing has many irrelevant children including finding of
color zone for Broselow Luten pediatric weight estimation
(finding). We did not include these children.
For dyspnea on exertion finding, and General
well-being finding, we kept the SCTID because we could
map all of the children, although this is not currently
part of the ontology. For the children not currently ex-
plicitly listed, we would need to determine whether they
were indicative of high or low frailty. We added the con-
cept comorbid condition count finding (CCFOID:131),
which we discussed earlier, as a child of general
well-being finding.
The full ontology has 156 concepts, with 246 terms.
The ontology owl file is available on Bioportal at http://
bioportal.bioontology.org/ontologies/CCFO. We con-
sider CCFO a view into SNOMED-CT. We define
view in accordance with the Ontology Views Project be-
ing done by the Structural Informatics Group at Washing-
ton University (http://sig.biostr.washington.edu/projects/
ontviews/). In this definition a view is a new ontology that
includes some portion of the viewed ontology. CCFO con-
tains portions of SNOMED-CT. It is therefore a view of
SNOMED-CT. As a view, it falls under SNOMED-CTs
existing licensure (https://www.snomed.org/snomed-ct/
get-snomed).
Table 1 shows the number of concepts by their num-
ber of terms. The table lists the number of terms associ-
ated with each of the 86 concepts we expect to find in
clinical documents. The remaining 58 concepts, not in
the table, represent hierarchical groups (e.g., physical
function findings) and 12 qualifier values. Two concepts
from demographics (CCFOID:14) have no terms (patient
age finding, CCFOID:141 and indeterminate sex finding,
CCFOID:1422). Lack of energy finding (CCFOID:132222)
still has the highest number of terms.
Table 2 lists some important concepts and their asso-
ciated terms. The term list is included as Additional file
1. Since terms are not synonyms for the concepts in the
ontology, they are not included in the ontology itself.
Terms are text that we consider indicative of the au-
thors thoughts about the concept. Concepts themselves
are portions of reality, not pieces of text.
Phase 3  Define object properties for concepts
Concept properties were determined by rating scales
used in the instruments. Activities have a frequency
property that is found in the SNOMED-CT frequency
qualifier value (SCTID: 272123002, CCFOID:44) re-
stricted to high frequency qualifier value (SCTID:
27732004, CCFOID:441) and mid-frequency (SCTID:
255218000, CCFOID:442). Frequency values contrast
with a value of absent finding qualifier value (SCTID:
272519000, CCFOID:42). Possible values are restricted
based on the likelihood of finding specific text qualifiers.
Abilities have an ability interpretation property that is
found in ability interpretation qualifier value (SCTID:
371148001, CCFOID:41). These values are also restricted
to able qualifier value (SCTID: 371150009, CCFOID:412),
able with difficulty qualifier value (SCTID: 371157007,
Table 1 Breakdown of the number of terms per concept in the
Cardiac-centered Frailty Ontology. These counts are for the 86
concepts that we expect to find in clinical documents
# terms 1 2 3 4 5 6 7 8 > 8
# concepts 24 29 7 8 6 5 0 3 4
Doing-Harris et al. Journal of Biomedical Semantics            (2019) 10:3 Page 6 of 16
CCFOID:411) and unable qualifier value (SCTID:
371151008, CCFOID:413). Finally, all clinical findings
have a course property from courses qualifier value
(SCTID: 288524001, CCFOID:43), including chronic
qualifier value (SCTID: 90734009, CCFOID:431), clinical
course with short duration qualifier value (SCTID:
424572001, CCFOID:432), and sudden onset qualifier
value (SCTID: 385315009, CCFOID:433).
More properties of the concepts were determined
by scores of relevance to cardiac decisions and their
likelihood of resolving after the recommended inter-
vention. Three investigators and three interview par-
ticipants scored 81 of the 84 concepts that we
expected to find in clinical documents. Three con-
cepts were added after scoring was complete (ability
to drive a car finding CCFOID:11241, quadriceps
weakness finding CCFOID:1334, and calf weakness
finding CCFOID:1331).
For the 81 concepts that were scored, ability concepts
were qualified with the able qualifier values (able/inde-
pendent, with difficulty/assisted, and unable/dependent)
each concept-value pair was given a separate score. Ac-
tivity and mental state concepts were qualified with fre-
quency qualifier values (high frequency, mid-frequency,
absent) and scored seperately. Rockwood categories as
described in the Dalhousie University Clinical Frailty
Score [45] were averaged across the eight raters. Ratings
of low, medium, or high for relevance to frailty and
fix-ability where set to the majority rating for the six
raters, who had clinical experience.
Only three concepts were given low relevance to frailty
ratings by all six raters calm finding (CCFOID:113331),
happy finding (CCFOID:113332), and nervous finding
(CCFOID:113333) concepts from the mental state find-
ing (CCFOID:11333) concept. Fifty-two concepts were
rated as highly relevant by all six raters, nine by at least
three raters. Thirteen concepts had relevancy ratings of
medium by all six raters, four by at least three raters.
Table 3 shows the findings for nine concepts central to
the assessment of frailty. Ability to participate in leisure
activities finding (CCFOID:112412) is included in Table 3
to demonstrate a cardiac intervention-specific concept.
Table 2 List of concepts central to assessing frailty and their
associated terms. Terms are not synonymous with the concept
or the concept name. They indicate author may have been
thinking about the concept. Bolded terms were not found in
the topic modeling paper. Underlined terms were added by the
annotation task
Concept Terms (not synonyms)
ability to run finding Difficulty running; able to run; unable
to run; run
ability to stand finding Difficulty standing up; unable to stand up;
able to stand up; stand up
able to mobilize finding ambulate independently; steady gait;
unsteady gait
bed-ridden finding bed-ridden; supine; stretcher
Paralysis finding paralysis; paralyzed
wheelchair bound finding wheelchair; scooter; w/c; wheel chair
able to perform dressing
activity finding
dresses; Able to dress; independent with
dressing; Needs help with dressing;
Dependent for dressing; unable to dress;
Difficulty dressing; shoes; ties shoes;
able to perform personal
grooming activity finding
Able to wash own hair; Unable to wash
own hair; Difficulty washing own hair;
clean appearance; personal grooming;
neatly dressed; well-groomed;
well-groomed without assistance;
good personal hygiene
Table 3 Scores for nine concepts central to the assessment of frailty. Rockwood scores are on a scale of 1 - very fit to 9  terminally
ill. They are averaged across raters. Will fix refers to clinical findings that the cardiac intervention will alleviate. Relevance is how
important the concept is to decisions about cardiac interventions. L  low, m  medium, h  high
Concept Rockwood Will Fix Relevance
Able With Difficulty Unable
ability to run finding 1 3.33 4 M H
ability to stand finding 2.67 5.11 7.44 TIED L+ H
able to mobilize finding steady gait
3
unsteady gait 6 M H
bed-ridden finding Only level
8
L H
Paralysis finding Paraplegic
6
Quadriplegic
8
L TIED M+
wheelchair bound finding Only level
6
M H
able to perform dressing activity finding 3 4 7 L H
able to perform personal grooming activity finding 1 4 7 L H
ability to participate in leisure activities finding 2 3 5.5 H H
Doing-Harris et al. Journal of Biomedical Semantics            (2019) 10:3 Page 7 of 16
We determined which concepts are specific to cardiac
intervention decisions by using the difference between rat-
ings for will fix and relevance (in Table 3). Will fix refers
to findings the cardiac intervention will alleviate; while
relevance refers to findings that our reviewers indicated
were relevant to frailty. We considered concepts that are
highly relevant to frailty and are either highly likely to be
alleviated by cardiac intervention or are associated with
eventual recovery, to be especially important. For instance,
bed-ridden is seen as generally relevant and not specific-
ally relevant to cardiology. Enjoys light exercise finding
(CCFOID:11231), ability to participate in leisure activities
finding (CCFOID:112412), dyspnea on exertion finding
(CCFOID:131), and fit and well finding (CCFOID:1323)
are all rated as specifically relevant to cardiology as well as
being generally relevant. Thirty-two concepts are rated as
moderately specific to cardiology and 45 were given low
cardiology-specific ratings.
In this section, we also looked at the mapping instru-
ment scores found in the clinical document set to frailty
scores from Rockwood categories as described in the
Dalhousie University Clinical Frailty Score [45]. Table 4
lists the instruments and their scoring criteria.
Phase 4 - analyze and validate
We created implementation rules to map ontology ele-
ments to instrument questions for three common instru-
ments. The rules for these three instruments (Barthel
index, Katz ADLs, and SF-36) are listed in Table 5. Note
that the mappings are not one-to-one. Some of the in-
strument questions were mapped to equivalent concepts.
For example, both Barthel index and Katz ADLs uses
the parent concepts ability to perform personal care ac-
tivities (SCTID: 284774007) to include feeding self,
dressing, grooming, toileting, and washing oneself, and
ability to transfer location (SCTID: 714882001). By cre-
ating implementation rules, we were able to demonstrate
that the Cardiac-centered Frailty Ontology covered the
topics used in the instruments.
In addition, we conducted preliminary NLP analysis
using the ontology. We wanted to determine if narrative
text that included frailty terms also included enough in-
formation to determine whether the patient had
frailty-related functional deficits. Frailty terms from the
Cardiac-centered Frailty Ontology and from a prior
study [46] were used. We extracted 2460 clinical record
snippets centered at the frailty keyword terms. Three
Table 4 Instrument scores found in clinical document set and the scoring criteria, which allow the NLP system to use the scores to
determine indication of frailty
Instrument Name Scoring Criteria
Activities of Daily Living (ADL) Screen 18 patient independent
6 patient very independent
Functional Independence Measure (FIM) 7-complete independence;
6-modified independence;
5-Supervision or step-up;
4-Minimal Contact Assistance;
3-Moderate Assistance;
2-Maximal Assistance;
1-Total Assistance
Katz index ADL Score of 6 = High, Patient is independent.
Score of 0 = Low, patient is very dependent.
Barthel index ADL: 70100 = Independent;
Less than 70 = Needs significant
physical/supervisory assistance.
Instrumental activities of daily living (IADL) 2 = without assistance,
1 = with assistance,
0 = unable
Instrumental activities of daily living (IADL)
scale (Lawton) / IADL Screen
The total score may range from 0 to 8.
A lower score indicates a higher level of dependence.
Functional Activity Questionnaire (FAQ) Score of 5 or more indicates significant impairment
in instrumental activities of daily living.
Morse fall scale / Annual Fall Scale / MRT > = 45: high fall risk
2544: moderate risk
024: low risk
Tinetti assessment measures Maximum possible balance score: 16 points.
Maximum possible gait score: 12 points.
Maximum total score: 28 points. -Scores below
19 indicate high risk for falls.
Scores in the 1924 range indicate
some risk for falls.
Braden scale Pressure Ulcer Risk:
total score < =9 very high risk
total score 1012 high risk
total score 1314 moderate risk
total score 1518 mild risk
total score 1923 no risk
Doing-Harris et al. Journal of Biomedical Semantics            (2019) 10:3 Page 8 of 16
Table 5 Examples of Frailty Instruments implemented with the Cardiac-centered Frailty Ontology
Frailty Insrument: Barthell Index
Incontinence finding (CCFOID:11271) of either kind = 0
Continence finding (CCFOID:11271) or absent qualified incontinence finding of both kinds = 2
Able to perform personal care activities finding (CCFOID:11244) for each of its children:
unqualified or able = 2
with difficulty = 1
unable = 0
Ability to transfer location finding (CCFOID:1122)(any one) = 2
Absent (CCFOID:42) qualified = 0
Able (CCFOID:412) qualified able to mobilize finding (CCFOID:112121) or no aid for walking finding (CCFOID:112472) = 3
Able with difficulty (CCFOID:411) qualified able to mobilize finding or walking aid use finding (any kind) = 2
wheelchair bound finding (CCFOID: 1121223) = 1
unable (CCFOID:413) qualified able to mobilize finding or bed-ridden finding (CCFOID:1121221) = 0
Able qualified able to walk upstairs finding (CCFOID:1124713) or able to walk downstairs finding (CCFOID:1124711) = 2
Unable qualified able to walk upstairs finding = 0
Barthell Index Scoring
Add up the score: 20 = no disability 0 = complete disability
Frailty Instrument: Katz  ADLs
Count the number of:
Each of the able qualified ability to perform personal care activities finding (bathing, dressing, toileting, feeding)(CCFOID:11244) = 1
Unable qualified = 0
Any able qualified ability to transfer location finding (CCFOID:1122) = 1
Unable qualified = 0
Both unqualified continence finding or absent qualified incontinence finding of either kind = 1
Unqualified Incontinence finding of either kind = 0
Katz - ADLs Scoring
Add up the score: 6 = high functioning 0 = low functioning
Frailty Instrument: SF-36
Average the following for General Health score:
Questions 1, 33, 34, 35, 36
First assessment covers 5 questions, 1 score.
unqualified or high frequency (CCFOID:441) qualified fit and well finding = 100
mid-frequency (CCFOID:442) qualified fit and well finding = 75
absent qualified generally unwell finding (CCFOID:1324) = 50
mid-frequency qualified generally unwell finding = 25
unqualified or high frequency qualified generally unwell finding = 0
Question 2
unqualified or high frequency qualified fit and well finding with sudden onset (CCFOID:433) qualification = 100
mid-frequency qualified fit and well finding with sudden onset qualification = 75
absent qualified generally unwell finding = 50
generally unwell finding:
mid-frequency qualified = 25
unqualified or high frequency = 0
Average the following for Pain score
Question 21
absent qualified alteration in comfort: pain finding (CCFOID:1111) = 100
mid-frequency qualified alteration in comfort: pain finding = 50
high frequency qualified alteration in comfort: pain finding = 0
Question 22
absent qualified alteration in comfort: pain finding, with able qualified able to carry out daily routine finding (CCFOID:11245) = 100
mid-frequency qualified alteration in comfort: pain finding, with able qualified able to carry out daily routine finding = 75
high-frequency qualified alteration in comfort: pain finding, with able qualified able to carry out daily routine finding = 50
mid-frequency qualified alteration in comfort: pain finding, with difficulty qualified able to carry out daily routine finding = 25
high-frequency qualified alteration in comfort: pain finding, with unable or with difficulty qualified able to carry out daily routine finding = 0
Average the following for Physical Functioning score:
Question 3
high frequency qualified enjoys vigorous exercise finding (CCFOID:11233) or able qualified ability to run finding (CCFOID:11213) = 100
mid-frequency qualified enjoys vigorous exercise finding = 50
gets no exercise finding or unable qualified ability to run finding or absent qualified enjoys vigorous exercise finding = 0
Question 4
high frequency qualified enjoys moderate exercise finding (CCFOID:11232) = 100
mid-frequency qualified enjoys moderate exercise finding = 50
gets no exercise finding or unable qualified ability to run finding or absent qualified enjoys moderate exercise finding = 0
Question 5
able qualified ability to perform general purpose physical activity finding (CCFOID:11243) or able qualified ability to perform shopping activities finding
(CCFOID:112413) = 100
Doing-Harris et al. Journal of Biomedical Semantics            (2019) 10:3 Page 9 of 16
clinicians and two informatics researchers reviewed the
snippets. They categorized them as: a) Yes Deficit, or b)
other. We trained a classifier on the snippets using a
support vector machine (SVM). The average SVM per-
formance, using 10-fold cross validation, achieved an ac-
curacy score of 80.5%. Since frail patients typically have
Table 5 Examples of Frailty Instruments implemented with the Cardiac-centered Frailty Ontology (Continued)
with difficulty qualified ability to perform general purpose physical activity finding or with difficulty qualified ability to perform shopping activities finding =
50
unable qualified ability to perform general purpose physical activity finding or unable qualified ability to perform shopping activities finding = 0
Question 6 & 7
This covers 2 question (scores twice) able qualified able to walk upstairs finding = 200
with difficulty qualified able to walk upstairs finding = 100
unable qualified able to walk upstairs finding = 0
Question 8
able qualified able to kneel finding (CCFOID:11211) = 100
with difficulty qualified able to kneel finding = 50
unable qualified able to kneel finding = 0
Questions 911
This covers 3 question (scores three times) able qualified able to walk finding (CCFOID:112471) = 300
with difficulty qualified able to walk finding = 200
unable qualified able to walk finding = 0
Question 12
able qualified ability to perform personal care activities finding = 100
with difficulty qualified ability to perform personal care activities finding = 50
unable qualified ability to perform personal care activities finding = 0
Average the following for Role Limitations due to Physical Health score:
Question 1315
This covers 3 question (scores three times) absent qualified occupational maladjustment finding (CCFOID:1154) = 300
mid-frequency qualified occupational maladjustment finding = 150
high-frequency qualified occupational maladjustment finding = 0
Question 16
able qualified able to carry out daily routine finding = 100
with difficulty qualified able to carry out daily routine finding = 50
unable qualified able to carry out daily routine finding = 0
Average the following for Role Limitations due to Emotional Problems score
Question 1719
This covers 3 question (scores three times) absent qualified occupational maladjustment finding and any psychological finding (CCFOID:113) = 300
mid-frequency qualified occupational maladjustment finding and any psychological finding = 150
high-frequency qualified occupational maladjustment finding and any psychological finding = 0
Average the following for Energy/Fatigue score
Questions 23, 27, 29, 31 (1 score)
able qualified able to sustain energy level finding (CCFOID:132221) or absent qualified lack of energy finding or absent qualified fatigue = 100
with difficulty qualified able to sustain energy level finding or mid-frequency qualified lack of energy finding or mid-frequency qualified fatigue = 50
unable qualified able to sustain energy level finding or high frequency qualified lack of energy finding or high frequency qualified fatigue = 0
Average the following for Emotional Well-Being score
Questions 24, 26
This covers 2 question (scores twice) high frequency qualified calm finding or absent qualified nervous finding or absent qualified anxiety diagnosis
(CCFOID:21) = 200
mid-frequency qualified calm finding = 150
mid-frequency qualified nervous finding = 100
absent qualified calm finding = 50
high frequency qualified nervous finding or anxiety diagnosis = 0
Questions 25, 28, 30
This covers 3 question (scores three times) high frequency qualified happy finding or absent qualified sad finding (CCFOID:113334) or absent qualified
depression diagnosis (CCFOID:22) = 300
mid-frequency qualified happy finding = 225
mid-frequency qualified sad finding = 150
absent qualified happy finding = 75
high frequency qualified sad finding or depression diagnosis = 0
Average the following for Social Functioning score
Question 32
able qualified ability to perform community living activities finding (CCFOID:11241) = 100
with difficulty qualified ability to perform community living activities finding = 50
unable qualified ability to perform community living activities finding = 0
Question 20
absent qualified impaired social interaction finding (CCFOID:11531) = 100
mid-frequency qualified impaired social interaction finding = 50
high frequency qualified impaired social interaction finding = 0
SF-36 Scoring
Scores are from 0 to 100 for each section, higher score = less frail/better health
Doing-Harris et al. Journal of Biomedical Semantics            (2019) 10:3 Page 10 of 16
multiple frailty descriptions, the accuracy was deemed to
adequately indicate that the terms in our ontology could
be used to focus a learning system on frailty-relevant
clinical text.
Finally, in [22] we tested whether the ontology could
be used to help train a system to predict mortality for
heart failure patients who underwent a major cardiovas-
cular procedure (MCVP). We collected 2-years of clin-
ical history data for a cohort of 20,000 heart failure
patients leading to the MCVP. Frailty terms were identi-
fied in the text and classified as asserted or negated (i.e.,
yes deficit or other) using NLP. The ontology was
used to map identified terms to their concepts. This
study used an early draft of the ontology that had only 7
higher-level concepts: therapy, medical findings, exercise,
mobility, living activity, self-care and social function.
These concepts became clinical findings; seen by profes-
sional allied to medicine, physical examination finding,
activity exercise pattern, ability to move, activity of daily
living, eating, feeding drinking ability, and social and
personal history finding, respectively. We aggregated the
frailty concepts by group and selected maximum frailty
score from among the concepts in each group.
A deep neural network (DNN), pictured in Fig. 2, was
trained on a visual representation of the data features,
which were hospitalizations, ICD9 codes for diagnoses,
medications, and the frailty score. In ten-fold cross val-
idation, the area under the curve (AUC) for mortality
prediction was 78.3% (95% CI 77.1 to 79.5%) on the test
data for the DNN model. We view this as additional val-
idation for the ontology.
Discussion
We developed and validated the Cardiac-centered Frailty
Ontology. We created our own hierarchy to allow re-
moval of unnecessary layers, unnecessary concepts, and
maintain realist design principles as much as possible.
We used SNOMED-CT concepts for all of the lowest
level concepts. We incorporated 14 existing instruments
in our initial development. We added five more for scor-
ing and rule sets, when analysis of a 400-document clin-
ical document set showed these instruments were in
common use [20]. We adapted the standard ontology
development model [32] by using clinician interviews to
identify important concepts, without the necessity of for-
cing clinician agreement.
Our ontology development techniques differed from
the standard techniques in two ways. We used
vignette-guided interviews in lieu of a subject matter
expert meeting to gain consensus and used validated
frailty assessment instruments in lieu of the frailty lit-
erature. Interviews allowed us to determine concepts to
assess patient frailty based on specific clinical decisions.
That our participants came from different institutions
helped minimized institution-related medical-cultural
bias in frailty assessment. By including concepts that
any one group might have excluded, we retain the
chance that our NLP system will find all relevant
Fig. 2 Deep neural network described in Zeng-Treitler, et al., 2018 [22]
Doing-Harris et al. Journal of Biomedical Semantics            (2019) 10:3 Page 11 of 16
concepts. Since the research group determined the con-
cepts to include, we needed to be sure that we were not
injecting our own opinions. Based on the amount of
previous work in the area and existing SNOMED-CT
concepts we included, we felt that our choices were not
influenced by our opinions. We had our participants
separately rate concepts for frailty severity, chance of
cardiac intervention alleviating the problem, and rele-
vance to frailty. By returning to the participants, we
made explicit the extent and nature of their disagree-
ments. We can then use this information going
forward.
To address the concepts of frailty related cardiac inter-
ventions specifically; we included the concepts found in
our interviews that we had not found from other
sources. Quadriceps weakness finding is particularly
relevant to cardiac intervention decisions because
post-surgical patients cannot use their arms to help
themselves stand. Surgical incisions require the upper
body not be used. Therefore, if the patient cannot stand
using their quadriceps alone, their post-surgical mobility
is impaired, which impedes healing. Our participant rat-
ings show that only a few concepts are specifically rele-
vant to cardiac decisions, while around half are generally
relevant, but not specifically relevant to cardiology. All
four of the cardiac-specific concepts were also consid-
ered highly relevant to general assessments of frailty. As-
sessment of the utility of these cardiac-specific concepts
in predicting patient outcomes was piloted as part of
two studies to predict patient mortality [22, 47].
The Cardiac-centered Frailty Ontology reflects general
frailty assessment as implemented in the frailty instruments
used in its development [2, 4858]. It includes participant
ratings and our separate analysis of the interview data to
create a picture of clinical decision-making with respect to
cardiac interventions. Based on our orientation toward
surgery-related decision-making [811, 1317], we have
excluded some of the specificity required to make
non-surgery-related frailty decisions. We grouped all types
of lack of energy findings together even though difference
between tiredness and weariness may be important in
other contexts. Once we have the NLP system functioning,
it will be important to assess differences in outcome predic-
tion using STS scores, with and without Cardiac-centered
Frailty Ontology concepts.
We used a realist ontology development process [59] be-
cause it appeals to our understanding of the world, it helps
ensure that the ontology is stable, and it avoids illogical
inferences. By separating concept name and term list, we
allow for language evolution, because the way terms are
used changes over time. However, the portions of reality de-
noted by the concept and the concept name do not change.
Concepts refer to Representations in the minds of cli-
nicians. These representations are far richer than the
terms used to indicate their presence in the mind of an
author. Representations are multi-modal. They include
memories and imaginings, relevance to goals, and other
information value attributes.
We are looking for clinical findings, which are conclu-
sions drawn by clinicians and recorded in narrative form
[60]. Restricting ourselves to findings also minimizes
problems with illogical inferences. Take for example the
concept enjoys light exercise finding, the truth of this as
a conclusion drawn by a clinician is unchanged by
whether or not the patient enjoys the process of exer-
cising or whether or not the patient actually exercises.
That it is an activity exercise pattern finding also re-
mains a valid inference.
Our main focus was the findings noted in narrative
text documented during clinical care, i.e., clinical his-
tory findings. We recognize that comorbid conditions
are relevant to frailty assessment, but there are exist-
ent tools for identifying comorbid conditions. Clinical
history findings represent the frailty-specific informa-
tion we are interested in automatically extracting
from clinical documents. We included a very re-
stricted subset of findings from physical examination.
We tested the comprehensiveness of our coverage by
creating scoring rules for the frailty assessment in-
struments. If concepts were missing, we would not be
able to create appropriate rules. We assessed the rele-
vance of each concept by asking participants to rate
them as high, medium, or low in relevance to asses-
sing frailty with respect to cardiac intervention deci-
sions. A preponderance of low relevance ratings
would indicate a problem. We found only three.
Three quarters of the concepts were rated as highly
relevant. Taken together these results indicate that we
have covered the necessary and sufficient concepts re-
lated to frailty assessment.
One of the best qualities of both SNOMED-CT [21]
and the UMLS Metathesaurus [40] is their exhaustive
coverage of the medical domain. One would be hard
pressed to find a medical concept that was not contained
within them. This exhaustiveness creates problems when
we try to use them in NLP applications. Simple matching
to either vocabulary results in too many false positives.
The Cardiac-centered Frailty Ontology creates a compre-
hensive picture of frailty, while limiting the concepts from
SNOMED-CT to only those directly relevant. We used
concepts, with semantic type finding, found by human re-
view of frailty assessment instruments, physician inter-
views, and chart review.
Limitations
The main limitation of this work is the influence
imparted on the ontology by our own ideas and biases.
This limitation is shared by all ontologies. Our personal
Doing-Harris et al. Journal of Biomedical Semantics            (2019) 10:3 Page 12 of 16
bias was minimized by the inclusion of the current ac-
cepted validated instruments on frailty. Each instrument
reflects both expert consensus on the relevant concepts
and empirical evidence of validity.
As is the case with all ontology development for NLP,
ontologies precede NLP systems. The clinical outcome
prediction NLP system used in our validation was not
designed to model clinician decision-making. Without
having a decision-making NLP system, it is difficult to
assess whether the Cardiac-centered Frailty Ontology
will facilitate all of the outcome predictions that we
envision.
Conclusions
We developed and validated a Cardiac-centered Frailty
Ontology. The ontology is a machine-interoperable de-
scription of frailty that reflects all the areas that clini-
cians consider when deciding which cardiac intervention
will best serve the patient. It was designed to share as
many elements as possible with SNOMED-CT to allow
interoperability. It could not be simply a subset of
SNOMED-CT because there was no appropriate subset
for us to choose.
Methods
We used the ontology development process described
in Noy, et al. [32]. This process consisted of four
phases. Phase 1 used existing ontologies and official
clinical tools to identify individual terms. The clinical
tools we used were validated frailty instruments and
automated chart review. We expanded this to term
based on physician interviews. In Phase 2 we grouped
terms into high-level concepts. We did this by exam-
ining concepts and hierarchies found in the existing
SNOMED-CT ontology, while keeping the structure
compact and realist. In Phase 3 we defined object
properties for concepts. Our methodology included
mapping concept attributes from scoring collected for
the identified concepts and properties indicated by in-
strument questions. Instruments have an associated
property, which indicates a mapping between instru-
ment scores and our ontologys concept frailty scores.
For Phase 4, analysis and validation, we created im-
plementation rules for using the Cardiac-centered
Frailty Ontology to reconcile scores on three common
frailty instruments. Ontology structure was developed
in Protégé [61], while term mappings were kept and
shared in a Google sheet.
Phase 1  Aggregate terms form other ontologies and
validated clinical tools
To extract frailty concepts from existing instruments,
five members of the research team reviewed the specific
items from 14 instruments chosen by the number of
times they were cited and expert recommendation [20]:
(1) Physical Frailty Phenotype (PFP, also called CHS
frailty phenotype) [2]; (2) SF-36 [48]; (3) FIM [49]; (5)
Clinical Frailty Scale [50]; (6) Brief Frailty Instrument
[62]; (6) the Barthell Index [51]; (7) Health Assessment
Questionnaire (HAQ) [52]; (8) PSMS [53]; (9) Katz ADL
[54]; (10) Duke Activity Index [55]; (11) RDRS [56]; (12)
FACIT [57]; (13) NYHA [58]; (14) Deficit Accumulation
Index (DAI, also called Frailty Index) [63]. Each person
reviewed each individual item from each instrument.
Terms from the World Health Organizations Inter-
national Classification of Functioning, Disability and
Health (ICF) were also included in the analysis because
the instruments varied in their levels of abstraction, their
scopes, and uniqueness.
At this step we added an ontology entry for comorbid
condition count. Comorbid conditions are an important
indicator of frailty. However, they are not the focus of
our investigations. We focused on frailty-specific indica-
tors in order to identify core frailty concepts in clinical
documents.
The concept list was expanded by the findings of the
interviews of cardiologist and cardiac surgeons described
above.
Finally, we included terms extracted from manual note
review by members of the research team with clinical
experience. These reviews were in preparation for NLP
topic modeling by Shao, et al., (2016). They reviewed
clinical notes and social media posts [64].
Phase 2 - group terms into high-level concepts
We organized constructs in hierarchical relationship
based on: 1) the results of topic modeling, 2) the
basic organization of the frailty instruments, and 3)
by mapping them to SNOMED-CT equivalents. We
used SNOMED-CT concepts within the category clin-
ical finding, with semantic type finding. The goal for
this process was to restrict the SNOMED-CT map-
pings to as small a selection as possible, while main-
taining correspondence with groupings from topic
modeling and instruments, which means our ontology
is somewhat compatible with SNOMED-CT.
Phase 3  Define object properties for concepts
Object properties were determined in two ways,
through the scales used to answer instrument ques-
tions and by scoring terms and concepts based on
key decisions when making cardiac surgery decisions.
For instrument findings, we defined properties, which
related instrument scores to the Rockwood global as-
sessment of frailty (described below) [45].
Rockwood categories are described in the Dalhousie
University Clinical Frailty score, which has 9 categories
Doing-Harris et al. Journal of Biomedical Semantics            (2019) 10:3 Page 13 of 16
[45]. The categories are (1) very fit, (2) well, (3) man-
aging well, (4) vulnerable, (5) mildly frail, (6) moderately
frail, (7) severely frail, (8) very severely frail, and (9) ter-
minally ill [50]. Concepts in the ontology vary in how
they map onto these severity categories. Some concepts
have three levels of severity of impairment (able,
assisted, and unable). The concept ability to walk, for
example, has these three levels, where each level indi-
cates a different Rockwood category. The scales provided
for question answering in the frailty instruments indi-
cated concept severity levels. These scales took the form
of able to unable and all the time to never.
To establish the relationship of the concepts to
these aspects of frailty three members of the team
(BB, CW, KDH) and 3 participant cardiologists scored
the concepts on three key decisions identified in the
interviews: 1) Rockwood category (described below)
as an indicator of ability to survive surgery, 2) rele-
vance to cardiac decision-making as a reflection of
the patients ability to recover from surgery, and 3)
the likelihood that the cardiac intervention will fix
the problem.
Another outcome of our physician interviews was
that clinicians consider indications of frailty within
the context of cardiac decisions by assessing whether
they are likely to be a result of the patients cardiac
condition and whether they are specifically relevant to
cardiac decisions. The medically trained members of
this group also characterized the constructs as low,
medium, high for both their likelihood to be fixed by
cardiac intervention and their relationship to cardiac
decision-making.
For instrument scores, we created score rating for 10
commonly cited instruments that were not included in
the initial concept-finding step. The initial mapping was
created by author YC and verified by the remaining
authors.
Phase 4  Analyze and validate
For this phase, we created rules to implement three frailty
assessment instruments using the Cardiac-centered Frailty
Ontology. We mapped instrument questions and re-
sponses to Cardiac-centered Frailty Ontology concepts
and properties.
We also tested the utility of the ontology in two differ-
ent automated NLP systems. One system was designed
to classify clinical note snippets as indicative or frailty or
not. The other was designed to predict patient mortality
after MCVP.
Additional file
Additional file 1: Frailty ontology concept list. (XLSX 37 kb)
Abbreviations
ADLs: Activities of daily living; BMI: Body mass index; CABG: Coronary artery
bypass graft; CCFOID: Cardiac-centered frailty ontology identification
number; DNN: Deep neural network; EHR: Electronic Health Record;
FAQ: Functional activity questionnaire; FIM: Functional independence
measure; IADL: Instrumental activities of daily living; MCVP: Major
cardiovascular procedure; MRT: Morse fall scale; NLP: Natural Language
Processing; OGMS: Ontology of General Medical Science; SCTID: SNOMED-CT
identification number; SF-36: MOS 36-item short form health survey;
STS: Society of Thoracic Surgeons; SVM: Support vector machine;
TAVR: Transcatheter valve replacement; UMLS: Unified Medical Language
System; VA: Veterans affairs
Funding
This work is funded by the NIH grant R56 AG052536-01A1 and grants from
the US Department of Veterans Affairs, Office of Research and Development,
Health Services Research and Development including CHIR HIR 08374, HIR
08204, CRE 12315 and the CREATE: A VHA NLP Software Ecosystem for
Collaborative Development and Integration. Dr. Rashmee Shah, National Insti-
tutes of Health (K08 HL136850).
Availability of data and materials
The datasets used and/or analyzed during the current study are available
from the corresponding author on reasonable request. The ontology owl file
is available on Bioportal at http://bioportal.bioontology.org/ontologies/CCFO.
Authors contributions
KDH oversaw the group generating terms from assessment instruments and
constructed the final ontology; CW and BEB provided oversight and ideas on
all aspects of the project, and edits to the manuscript; BEB and RUS provided
cardiology expertise, ideas, and edits. AT and JHG provided ideas and edits;
YS, YC, and QZT provided terms gathered from two previous studies, ideas
and integration with NLP. YC provided initial instrument score to frailty score
mappings. All authors read and approved the final manuscript.
Ethics approval and consent to participate
This work is approved under University of Utah IRB_00096877 (Use Frailty
Status to Predict Postoperative Outcomes in Elderly Patient) consent to
participate was verbal (use of forms was waived).
Consent for publication
Not applicable
Competing interests
The authors declare that they have no competing interests.
Publishers Note
Springer Nature remains neutral with regard to jurisdictional claims in
published maps and institutional affiliations.
Author details
1Nuance Communications, Burlington, MA, USA. 2Division of Cardiovascular
Medicine, University of Utah, Salt Lake City, UT, USA. 3Department of
Biomedical Informatics, University of Utah, Salt Lake City, UT, USA. 4Physical
Therapy and Athletic Training Department, University of Utah, Salt Lake City,
UT, USA. 5Medical Informatics Center, George Washington University,
Washington DC, USA. 6VA Healthcare System, Salt Lake City, UT, USA.
Received: 2 July 2018 Accepted: 1 January 2019
RESEARCH Open Access
KLOSURE: Closing in on openended
patient questionnaires with text mining
Irena Spasi?1*, David Owen1, Andrew Smith2 and Kate Button3
From UK Healthcare Text Analysis Conference (HealTAC 2018)
Manchester, UK. 18-19 April 2018
Abstract
Background: Knee injury and Osteoarthritis Outcome Score (KOOS) is an instrument used to quantify patients
perceptions about their knee condition and associated problems. It is administered as a 42-item closed-ended
questionnaire in which patients are asked to self-assess five outcomes: pain, other symptoms, activities of daily
living, sport and recreation activities, and quality of life. We developed KLOG as a 10-item open-ended version of
the KOOS questionnaire in an attempt to obtain deeper insight into patients opinions including their unmet needs.
However, the openended nature of the questionnaire incurs analytical overhead associated with the interpretation
of responses. The goal of this study was to automate such analysis. We implemented KLOSURE as a system for
mining freetext responses to the KLOG questionnaire. It consists of two subsystems, one concerned with feature
extraction and the other one concerned with classification of feature vectors. Feature extraction is performed by a
set of four modules whose main functionalities are linguistic pre-processing, sentiment analysis, named entity
recognition and lexicon lookup respectively. Outputs produced by each module are combined into feature vectors.
The structure of feature vectors will vary across the KLOG questions. Finally, Weka, a machine learning workbench,
was used for classification of feature vectors.
Results: The precision of the system varied between 62.8 and 95.3%, whereas the recall varied from 58.3 to 87.6%
across the 10 questions. The overall performance in terms of Fmeasure varied between 59.0 and 91.3% with an
average of 74.4% and a standard deviation of 8.8.
Conclusions: We demonstrated the feasibility of mining open-ended patient questionnaires. By automatically mapping
free text answers onto a Likert scale, we can effectively measure the progress of rehabilitation over time. In comparison to
traditional closed-ended questionnaires, our approach offers much richer information that can be utilised to support
clinical decision making. In conclusion, we demonstrated how text mining can be used to combine the benefits of
qualitative and quantitative analysis of patient experiences.
Keywords: Text mining, Natural language processing, Text classification, Named entity recognition, Sentiment analysis,
Patient reported outcome measure, Open-ended questionnaire
© The Author(s). 2019 Open Access This article is distributed under the terms of the Creative Commons Attribution 4.0
International License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and
reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to
the Creative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver
(http://creativecommons.org/publicdomain/zero/1.0/) applies to the data made available in this article, unless otherwise stated.
* Correspondence: SpasicI@cardiff.ac.uk
1School of Computer Science & Informatics, Cardiff University, Cardiff, UK
Full list of author information is available at the end of the article
Spasi? et al. Journal of Biomedical Semantics 2019, 10(Suppl 1):24
https://doi.org/10.1186/s13326-019-0215-3
Background
Musculoskeletal pain is recognised globally as negatively
impacting healthy aging and accounts for 21.3% of total
years lived with disability [1]. It is associated with frailty,
loss of function and independence during everyday activ-
ities and reduced overall physical and mental wellbeing
[2]. The knee is one of the most commonly affected joints
reportedly affecting 30% of people with joint pain [3].
Knee osteoarthritis is one of the most common conditions
and affects 18% of people over the age of 45 in England
[4]. With an aging population, this number is set to in-
crease, placing greater burden on health resources [4],
adding to waiting lists and causing delays in receiving ap-
propriate care [5]. Therefore, self-management treatment
approaches, which equip patients with the skills to man-
age their health condition, are essential. When away from
the secondary care setting, patient reported outcome mea-
sures (PROMs) can be used to monitor their health status
remotely.
PROMs are standardised, validated questionnaires
completed by patients in an attempt to measure their
own perceptions of their health conditions. Patient re-
sponses are converted into a numerical score, which can
be used to monitor patient progress over time and plan
treatment accordingly. The Knee injuries and Osteoarth-
ritis Outcome Score (KOOS) [6] is one of the most
widely used PROMs for assessing patients opinions
about their knee condition. It is administered as a 42-
item closed-ended questionnaire in which patients are
asked to assess five outcomes: pain, other symptoms, ac-
tivities of daily living, sport and recreation activities, and
quality of life. The resulting scores on a scale of 0100
can help both patients and clinicians to monitor the pro-
gress of knee rehabilitation. However, KOOS does not
capture details surrounding particular patient circum-
stances [7]. By forcing the respondents to choose from
ready-made options, closed-ended questions restrict
freedom and spontaneity of responses and as such they
are unlikely to tap into the full range of positive and
negative expressions of patients [8]. Alternatively, modi-
fying KOOS into an open-ended questionnaire has got a
great potential to inform clinicians about patients opin-
ions including their unmet needs, but this incurs analyt-
ical overhead associated with the interpretation of
responses.
Unfortunately, patient experience questionnaires re-
main largely quantitative in nature [9] despite the find-
ings that they tend to overestimate patient satisfaction
[10] and that qualitative analysis tends to uncover more
actionable information [11]. This can be explained partly
by the lack of knowledge on how best to collect and
present patients responses to the stakeholders [10].
From a practical point of view, the cost of qualitative
analysis in terms of time and labour play a major factor
in its prevalence or the scale of such studies. Poorer stat-
istical significance has often been used as an excuse to
dismiss valuable information that can be provided by
qualitative research [12]. In light of these issues, text
mining (TM), which aims to discover patterns, relation-
ships and trends within text documents, has found a
great many biomedical applications [13]. In particular, it
is increasingly used to analyse patient experiences, i.e.
their thoughts, feelings and behaviours, expressed in
their own words [14]. Therefore, TM may support
scalability of qualitative analyses of open-ended
questionnaires.
To date, most TM approaches used to support the
analyses of open-ended questionnaires focused on aggre-
gating all responses across a surveyed population, e.g.
consumers [15], students [16, 17], patients [18], etc.
Early techniques used to process open-ended question-
naires included rule-based text classification approaches
[15]. The proliferation of user-generated data on the
Web encouraged the use of data mining, e.g. clustering
[16] and association rule mining [19]. The rising popu-
larity of supervised machine learning approaches paved
the way to classifying individual responses. In terms of
the overall aim and techniques applied, the work on
screening patients for posttraumatic stress disorder is
the closest to our own [20]. They used an open-ended
questionnaire to elicit self-narratives from participants
who experienced a traumatic event. They used super-
vised machine learning to implement a binary classifier
with an aim to automatically diagnose a participant,
based on their overall response, as having or not having
posttraumatic stress disorder. Our approach goes a step
further by classifying a response to each open-ended
question separately against multiple classes.
Methods
The aim of this study was to automate measurement of
health outcomes from patients freetext responses to
openended questions. Addressing this aim required us
to: (1) develop an openended questionnaire, (2) collect
responses to the questionnaire, (3) analyse the responses
manually to establish the ground truth, (4) develop text
mining methods to analyse the responses automatically,
and (5) evaluate the performance of the text mining
methods. The following sections describe these steps in
more detail.
Open-ended questionnaire
Questionnaire development
We developed an openended questionnaire to capture
patients opinions about all aspects relevant to assessing
the management of their knee condition while minimising
the number and complexity of questions. We designed
KLOG (contracted from knee log) as an openended
Spasi? et al. Journal of Biomedical Semantics 2019, 10(Suppl 1):24 Page 2 of 11
version of the KOOS questionnaire [6]. Like KOOS,
KLOG was designed to elicit responses that can be used
to assess five outcomes: pain, other symptoms, activities of
daily living, sport and recreation, and quality of life. The
openended nature of the questionnaire enabled us to re-
duce the number of questions from 42 in KOOS to only
10 in KLOG. For example, KOOS contains 9 closed
ended questions related to pain: (P1) How often do you
experience knee pain? What amount of knee pain have
you experienced the last week during the following activ-
ities? (P2) twisting/pivoting on your knee, (P3) straighten-
ing knee fully, (P4) bending knee fully, (P5) walking on flat
surface, (P6) going up or down stairs, (P7) at night while
in bed, (P8) sitting or lying, (P9) standing upright. KLOG
compresses them into a single openended question:
Can you describe any knee pain you have experienced
over the past week? To illustrate a greater coverage of the
open-ended question, we provide a sample of answers:
1. <P1>Constant</P1> pain whether in < P8>sitting</
P8> or < P9>standing</P9>.
2. <P1>Occasional</P1> sharp pain as well as ache,
especially < NA>walking downhill</NA> or on <
NA>uneven ground</NA>.
3. No pain when < P8>sitting</P8>, some pain when <
P6>walking upstairs</P6> and < NA>walking long
distances</NA>.
4. <P1>Occasional</P1> sharp pain especially when <
P6>going up steps</P6>.
5. Some general pain when < NA>exercising</NA> and
quite painful in the joint for < P1>the last 2 days</
P1>.
6. I have severe aching and bad pain when I < NA>get
up from sitting</NA> and < P5>general walking</
P5>.
7. <P1>Occasionally</P1> the knee joint aches together
with momentary sudden stabbing pain in various
parts of the knee. Also, pain if I am < P8>sat</P8>
with the knee < P4>bent</P4> such as < P8>sat</P8>
in an office chair.
8. <NA>Exercise</NA> induced occasional medial
and lateral knee joint discomfort knee. Plus some <
P7>nocturnal</P7> discomfort.
We used XML tags to relate freetext answers to the
corresponding questions in KOOS as shown in the
above answers. We can see that when answering a more
generic openended KLOG question, patients do pro-
vide information related to the corresponding closed
ended questions in KOOS, but they also provide a much
richer account of circumstances surrounding their ex-
RESEARCH Open Access
Identification of conclusive association
entities in biomedical articles
Rey-Long Liu
Abstract
Background: Conclusive association entities (CAEs) in a biomedical article a are those biomedical entities (e.g.,
genes, diseases, and chemicals) that are specifically involved in the associations concluded in a. Identification of
CAEs among candidate entities in the title and the abstract of an article is essential for curation and exploration of
conclusive findings in biomedical literature. However, the identification is challenging, as it is difficult to conduct
semantic analysis to determine whether an entity is a specific target on which the reported findings are conclusive
enough.
Results: We investigate how five types of statistical indicators can contribute to prioritizing the candidate entities
so that CAEs can be ranked on the top for exploratory analysis. The indicators work on titles and abstracts of
articles. They are evaluated by the CAEs designated by biomedical experts to curate entity associations concluded
in articles. The indicators have significantly different performance in ranking the CAEs identified by the biomedical
experts. Some indicators do not perform well in CAE identification, even though they were used in many techniques for
article retrieval and keyword extraction. Learning-based fusion of certain indicators can further improve performance.
Most of the articles have at least one of their CAEs successfully ranked at top-2 positions. The CAEs can be visualized to
support exploratory analysis of conclusive results on the CAEs.
Conclusion: With proper fusion of the statistical indicators, CAEs in biomedical articles can be identified for exploratory
analysis. The results are essential for the indexing of biomedical articles to support validation of highly related conclusive
findings in biomedical literature.
Keywords: Conclusive association entity, Statistical indicator, Visualization, Exploratory analysis
Introduction
Conclusive association entities (CAEs) in a biomedical
article a are those biomedical entities (e.g., genes, dis-
eases, and chemicals) that are specifically involved in the
associations concluded in a. Consider the article in
Table 1 as an example (ID in the search engine PubMed
is 6,492,995). The article is curated by CTD (Compara-
tive Toxicogenomics Database), which maintains a data-
base of associations between chemicals, genes, and
diseases [1]. An association is curated only if CTD scien-
tists verify that conclusive evidences are reported to sup-
port the association. The article mentions seven entities
in the set of entities considered by CTD. With this art-
icle, several associations are curated: the gene prolactin
interacts with two chemicals 2-bromolisuride and
lisuride; while the disease hyperprolactinaemia has a
marker association with two chemicals 2-bromolisuride
and reserpine, as well as a therapeutic association with
the chemical lisuride. These chemicals as well as the
gene and the disease can thus be CAEs of the article.
Other entities in the article are non-CAEs: Dopamine is
not a specific target on which the conclusions are made,
while transdihydrolisuride is an entity on which the re-
ported findings may not be conclusive enough (as its ef-
fects may change in different conditions).
As CAEs are the entities on which conclusions of an art-
icle are made, identification of CAEs is essential for the
analysis of highly related conclusive findings in biomedical
literature. Biomedical scientists are often concerned with
conclusive findings on specific entities. For example, CTD,
GHR (Genetic Home Reference), and OMIM (Online
Mendelian Inheritance in Human) recruit many experts to
frequently update their entity association databases by
Correspondence: rlliutcu@mail.tcu.edu.tw
Department of Medical Informatics, Tzu Chi University, Hualien, Taiwan,
Republic of China
© The Author(s). 2019 Open Access This article is distributed under the terms of the Creative Commons Attribution 4.0
International License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and
reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to
the Creative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver
(http://creativecommons.org/publicdomain/zero/1.0/) applies to the data made available in this article, unless otherwise stated.
Liu Journal of Biomedical Semantics            (2019) 10:1 
https://doi.org/10.1186/s13326-018-0194-9
carefully searching for those articles whose main findings
support the associations [24].
However, among the candidate entities in the title and
the abstract of an article, identification of CAEs is chal-
lenging. For the article in Table 1, it is difficult to iden-
tify the specific targets and then estimate how conclusive
the findings on the targets are (recall that Dopamine
and transdihydrolisuride are not specific entities on
which the reported findings are conclusive enough). For
another example, consider the article in Table 2. This
article mentions eight entities, and with this article,
CTD curates two associations: the disease Parkinsons
disease has a marker association with two chemicals
MPTP and Trichloroethylene. The disease and the two
chemicals are thus CAEs, and the other five entities are
non-CAEs. These CAEs are discussed in different ways,
and both CAEs and non-CAEs may appear at any parts
of the article, including the title of the article. For ex-
ample, Parkinsonism appears at the title of the article,
but it is not a CAE (based on the curation done by CTD
scientists). Parkinsonism refers to a group of neuro-
logical disorders that cause movement problems, but
this article focuses on Parkinsons disease specifically,
because it investigates a neurodegeneration issue con-
cerning Parkinsons disease, which is a neurodegenera-
tive brain disorder that causes the loss of motor control.
One possible way to tackle the challenges of identify-
ing CAEs is to build complete domain-specific know-
ledge, as well as intelligent and scalable discourse
understanding techniques that can determine whether
an entity is a specific target on which the reported find-
ings are conclusive enough. However, it is both difficult
and costly to build such domain-specific knowledge and
intelligent techniques, and no previous studies built
them to identify CAEs in biomedical articles.
Problem definition and contribution
In this paper, we investigate the development of those
techniques that, given candidate entities in the title
and the abstract of a biomedical article a, identify
CAEs in a for exploratory analysis. More specifically,
we investigate how five types of statistical indicators
can contribute to prioritizing the candidate entities so
that CAEs can be ranked on the top, without relying
Table 1 An article curated by CTD scientists. Five entities are identified as CAEs (see the boxed entities), which are the ones on
which conclusive associations in the article are presented. Two entities are non-CAEs (see the shaded entities): Dopamine is not a
specific target in the article, while transdihydrolisuride is an entity on which the findings may not be conclusive enough (see the
underlined part).
Liu Journal of Biomedical Semantics            (2019) 10:1 Page 2 of 20
on any domain knowledge and discourse analysis.
These indicators include:
(1) Frequency-based indicator: The indicator is
concerned with the frequencies of candidate entities
in article a. It is motivated by a hypothesis that
CAEs in an article tend to appear frequently in the
article. For example, in the examples discussed
above, some CAEs have higher frequencies in the
articles (e.g., 2-bromolisuride in Table 1 and
trichloroethylene in Table 2).
(2) Rareness-based indicator: The indicator is
concerned with how rarely the candidate entities (in
article a) appear in a collection of articles. An entity
that appears in few articles is said to appear rarely.
This indicator is motivated by a hypothesis that
specific (general) entities tend to be rare (frequent)
entity in articles. As noted above, specific entities in
an article are likely to be CAEs in the article,
making this indicator potentially helpful for CAE
identification.
(3) Co-occurrence-based indicator: The indicator is
concerned with how often a candidate entity
co-occurs with other entities in an article. It is
motivated by a hypothesis that an entity that
co-occurs with many other entities in an article
may be related to these entities, and hence is likely
to be a CAE in the article.
(4) Concentration-based indicator: The indicator is
concerned with how candidate entities (in article a)
concentrate in a collection of articles. An entity that
appears frequently in individual articles has a high
concentration in these articles. This indicator is
motivated by a hypothesis that an entity with a high
Table 2 Another article curated by CTD. Three entities are identified as CAEs (see the boxed entities). More entities are not
identified as CAEs (see the shaded entities), even though some of them appear at several places in the article, including the title.
Liu Journal of Biomedical Semantics            (2019) 10:1 Page 3 of 20
concentration in articles may be a target of these
articles, and hence it is likely to be a CAE of
another article as well.
(5) Locality-based indicator: The indicator is concerned
with the positions of candidate entities in article a.
It is motivated by a hypothesis that CAEs of an
article may tend to be mentioned at certain parts
that may be related to the goals and conclusions of
the article. Such parts may include the title (e.g.,
prolactin in Table 1 and trichloroethylene in
Table 2), the beginning part (e.g., 2-Br-LIS in
Table 1 and Parkinsons disease in Table 2), and the
ending part (e.g., 2-Br-LIS in Table 1 and MPTP in
Table 2) of the article.
Obviously, these indicators cannot always succeed in
distinguishing CAEs from non-CAEs, because CAEs in
an article may be discussed in different ways in different
parts of the article. We thus have two research
questions:
(Q1) How does each indicator perform in identifying
CAEs?
(Q2) Can these indicators be fused to improve CAE
identification?
We investigate these questions by those articles that
biomedical experts believe to be targeted at specific as-
sociations among genes, diseases, and chemicals. Investi-
gation of these questions can provide fundamental
guidelines for the development of systems to index bio-
medical articles to support validation of highly related
conclusive findings in biomedical literature.
Related work
Our goal in this paper is to investigate how the five types
of statistical indicators can be used to prioritize entities
in titles and abstracts of articles so that CAEs, which are
specific entities involved in the entity associations con-
cluded in the articles, can be ranked on the top for ex-
ploratory analysis. To our knowledge, no previous
studies focused on the same goal, and hence we discuss
several types of related studies to clarify the contribu-
tions of the paper.
Extraction of biomedical entity associations
CAEs are those entities that are involved in specific as-
sociations concluded in an article, and hence CAE iden-
tification is related to the task of extracting associations
from the article. However, an association that happens
to be mentioned in an article is not necessarily the con-
clusive finding of the article, due to two reasons: (1) the
association may have been published, and it is men-
tioned in the article simply because it is related to the
background of the article (rather than the main finding
concluded in the article), and (2) the associated entities
may not be the specific targets on which the reported
findings are conclusive enough (e.g., the non-CAEs in the
last sentence of the article shown in Table 2). Therefore,
entities in an association extracted from an article are
not necessarily CAEs of the article. We aim at prioritiz-
ing candidate entities so that CAEs in the articles can be
ranked on the top.
Moreover, from a technical viewpoint, the statistical in-
dicators investigated in this paper may provide different
kinds of information to improve association extraction
techniques, which often extracted associations by prede-
fining a set of rules (e.g., [59]) and lexical-syntactic pat-
terns (e.g., [7, 8, 10, 11]). As performance of association
extraction was limited, various approaches were devel-
oped, such as integrating the rules and the patterns (e.g.,
[79, 12, 13]) and designing domain-specific rules and
patterns (e.g., for protein-protein interaction [14], protein
phosphorylation [15], and drug-drug interactions [16]).
These previous techniques strived to design and tune the
rule/pattern sets to consider the lexical, syntactic, seman-
tic, anaphoric, and discourse aspects of understanding
those sentences that might indicate associations. Instead
of striving to understand these sentences, the indicators
investigated in this paper rank CAEs based on statistical
analysis on how candidate entities individually appear in
the whole set of articles. Those entities that are ranked on
the top in an article are likely to be entities of the associa-
tions reported in the article. These indicators may thus
provide different types of information to further improve
association extraction, without relying on a complete and
scalable set of rules and patterns.
Indexing of biomedical articles
CAEs are different from those MeSH (Medical Subject
Heading) terms employed by PubMed to index articles.
For example, for the article in Table 1, PubMed employs
over ten MeSH terms as indexes, however many of them
are not in the above set of CAEs (e.g., Animals and
Ergolines) and some of the above CAEs are not
employed as indexes (e.g., Hyperprolactinaemia and
2-bromolisuride). Index terms for an article are not ne-
cessarily those CAEs that biomedical experts employ to
curate specific associations concluded in the article.
Identification of CAEs in an article is thus different from
indexing (labeling or classification) of the article with
MeSH terms, which was a goal of many previous studies
(e.g., techniques reported in the BioASQ workshop [17]
and the Medical Text Indexer tool [18]).
Ranking of entities
We model CAE identification as an entity ranking task,
which aims at prioritizing candidate entities so that
Liu Journal of Biomedical Semantics            (2019) 10:1 Page 4 of 20
CAEs in an article can be ranked on the top. Many pre-
vious studies focused on entity ranking as well. However
they have various goals different from ours in the paper.
Entity ranking was ever defined as a task to find a
ranked list of entities that are of a specified type and
have a certain relationship with a given entity [19, 20]. It
was thus concerned with how a system ranked entities
in response to a query, which consisted of three ele-
ments: an input entity, the type of the target entity, and
a description of the relation. For example, to find man-
ufacturers of vehicles used by UPS, the input entity
may be UPS, the type of the target entity may be
manufacturer, and the relation description may be
manufacturers of vehicles used by UPS [20]. Many
techniques were developed (e.g., [21]), and several vari-
ants of the problem scenarios were investigated, such as
consdiering a chronologically ordered list of relevant
documents [22] and providing support sentences for the
entities retrieved [23]. When compared with these previ-
ous studies, we have a different goal: finding CAEs in a
given article (rather than for a query). To identify the
CAEs, no query is entered as input.
Another scenario of entity ranking was concerned with
the ranking of entities in a given set D of documents,
based on several factors such as the probability of the
topics discussed in D as well as the correlation between
the topics and the entities [24]. Therefore, its goal was
to identify popular topic entities in D, while we have a
different goal: finding those entities on which conclusive
findings are reported (rather than popular topic entities)
in an article (rather than a document collection).
Many previous studies aimed at ranking (extracting)
entities (keywords) in an article as well, however their
goals were different from ours as well. In the biomedical
domain, the MetaMap indexing tool (MMI) was a com-
ponent of Medical Text Indexer to index (label) articles
with MeSH terms [18]. MMI only worked on MeSH
terms in an article [25]. It employed the depth of each
term in the MeSH tree as a critical factor to rank MeSH
terms [25]. Therefore, effective techniques need to be
developed to deal with those entities not in MeSH but in
other ontologies (e.g., OMIM and the Entrez-Gene data-
base, which are considered by curators of CTD [26]).
We investigate potential contributions of five types of
statistical indicators to identifying CAEs from various
ontologies.
Another interesting feature of our goal is to identify
CAEs in titles and abstracts of articles, which are more
commonly available than full texts of the articles. Many
previous studies worked on full texts of biomedical arti-
cles to identify important entities or keywords [27, 28].
For example, BioCreative defined entity ranking as a task
of identifying important genes in a full-text article [27].
Important genes were those genes whose experimental
settings contributed to main assertions of the article,
and hence were essential for biomedical information
curation [27]. Participants of BioCreative employed vari-
ous strategies to rank genes, however many of the strat-
egies cannot work well when only titles and abstracts are
available (e.g., preferring those genes in the abstract, fig-
ure legends, table captions, or certain sections of the art-
icle [27]). As titles and abstracts are more commonly
available than full texts, the techniques developed in the
paper can be applicable to more articles. In the title and
the abstract of an article, several entities may be related
to experimental assertions of the article, but they are not
necessarily CAEs, based on the curation done by CTD
experts. Only specific entities on which conclusive find-
ings are reported were selected as CAEs (recall that
Lisuride was a CAE but Dopamine was not in Table 1;
Parkinsons disease was a CAE but Parkinsonism was
not in Table 2).
We are thus concerned with the potential contribu-
tions of the five types of statistical indicators to ranking
entities in titles and abstracts of articles. Some types of
the indicators were considered by previous keyword
rankers (extractors) as well. For example, a frequency--
based indicator was employed to select keywords [25].
Integration of frequency-based and rareness-based indi-
cators was one of the best techniques to extract key-
words in articles [29, 30]. A locality-based indicator was
employed by preferring those terms appearing in the
title of a biomedical article [25]. A co-occurrence-based
indicator was employed by keyword extractors in the
biomedical domain [28], as well as other domains such
as news [30, 31], computer science [32], and artificial
intelligence [29].
When compared with these keyword rankers, we in-
vestigate how more types of indicators (and their fusion)
perform in identifying those CAEs that are involved in
the entity associations concluded in biomedical articles.
Interestingly, we find that the indicators do not neces-
sarily perform well in identifying the CAEs, and
learning-based fusion of the indicators can further im-
prove performance (ref. Results).
Retrieval of articles for specific entities
Retrieval of relevant articles for a query term (entity) is
often based on the estimation of the relatedness between
the term and each article. A CAE identifier requires such
a relatedness estimation component as well. However,
when compared with article retrievers, instead of retriev-
ing articles for a query entity, a CAE identifier con-
versely finds entities that are related to the conclusive
findings of a given article. Therefore, although article re-
trievers do not aim at CAE identification, some of their
term-article relatedness components may have potential
contributions to CAE identification.
Liu Journal of Biomedical Semantics            (2019) 10:1 Page 5 of 20
The frequency-based and the rareness-based indicators
were routinely considered by biomedical article re-
trievers. Among the previous article retrievers that con-
sidered the two indicators, BM25 [33] was one of the
best techniques in finding biomedical articles [34]. A
concentration-based indicator was considered by an art-
icle retriever ES, which was tested in [35] and found to
be one of the best biomedical articles retrievers [36].
Locality-based indicators were employed by many article
retrievers, which preferred those articles in which the
entities of interest appeared at certain parts of the arti-
cles, including the titles, the first sentences, and the last
sentences of the articles [26, 37, 38]. Similar locality in-
formation was employed to retrieve articles about spe-
cific gene-disease associations [39] and estimate
inter-article similarity [40]. The locality-based informa-
tion was also used to extract text passages (e.g., sen-
tences) about gene functions [41] and evidence-based
medicine [42].
Note that the previous article retrievers also employed
several indicators that are helpful for article retrieval but
not CAE identification. We thus do not investigate them
in this paper. For example, PubMed considered the
query length as an indicator to improve article retrieval
[38]. This indicator is query-specific without providing
helpful information to CAE identification in which no
input query is assumed. Similarly, we do not investi-
gate article-specific indicators, such as the article
length, as well as the field length (e.g., the lengths of
the title and the abstract), publication type, and publi-
cation year, which were considered by PubMed [38].
They are not helpful for CAE identification, which
aims at finding CAEs in a given article, rather than
ranking multiple articles with different article-specific
characteristics.
It is thus interesting to identify those indicators that
have potential contributions to CAE identification, and
investigate how they really perform in CAE identifica-
tion. We identify the five types of indicators based on
the observation of how CAEs may appear in biomedical
articles. These indicators are investigated both individu-
ally and collectively, and case studies are conducted to
further investigate their practical contributions to cur-
ation of biomedical databases.
Methods
The steps to conduct the research include (1) selection
of the potential indicators for CAE identification, (2) fu-
sion of the indicators, and (3) performance evaluation.
Potential indicators
Table 3 defines the five types of indicators investigated
in the paper. The first indicator is TF (term frequency),
which is a frequency-based indicator. It counts the num-
ber of times an entity appears in an article. As CAEs in
an article may appear frequently in the article, one may
expect that an entity with a high TF is likely to be a
CAE of the article. The second indicator is IDF (inverse
document frequency), which is a rareness-based indica-
tor. An entity that appears in fewer articles will have a
larger IDF, which may also indicate that the entity is
more specific. As CAEs in an article a tend to be specific
ones, we expect that an entity with a higher IDF is likely
to be a CAE in a.
The third indicator is CoOcc, which is a
co-occurrence-based indicator. Following [28], it is de-
fined in Eq. 1. For an entity e in an article a, CoOcc is
the sum of the probabilities of e co-occurs with other
entities in sentences in a. One may expect that an entity
Table 3 Definitions of individual indicators
Type Indicator Definition
(1) Frequency-based TF TF(e, a) = Number of times e appears in a
(2) Rareness-based IDF IDFðeÞ ¼ Log2 jAjþ1
½i
DFðeÞþ1½ii
(3) Co-occurrence-based CoOcc
CoOccðe; aÞ ¼
X
x?a;x?e
jSe?xðaÞj½iii
jSeðaÞj½iv
(4) Concentration-based AvgTF AvgTFðeÞ ¼ cðe;CÞ½vDFðeÞ
(5) Locality-based TITLE
TITLEðe; aÞ ¼ 1; if e appears in title of a;
0; otherwise:

AbstractX
AbstractXðe; aÞ ¼
1; if e appears in the first X or Last X
sentences in abstract of a;
0; otherwise:
8<
:
[i] |A| = Number of articles in the collection of articles C;
[ii]DF(e) = Number of articles (in C) mentioning e;
[iii]Se?x(a) = Set of sentences (in a) that e and x co-occur;
[iv]Se(a) = Set of sentences (in a) mentioning e;
[v]c(e,C) = Number of times e appears in articles in C
Liu Journal of Biomedical Semantics            (2019) 10:1 Page 6 of 20
with a larger CoOcc in an article a may be related to
more entities in a, and hence is likely to be a CAE in a.
The fourth indicator is AvgTF, which is a
concentration-based indicator. For an entity e, AvgTF is
the micro average frequency of e appearing in a collec-
tion of articles. An entity with a larger AvgTF in a collec-
tion of articles may be a target of these articles, and
hence it is likely to be a CAE of articles as well.
The fifth and the sixth indicators are TITLE and
AbstractX, which are locality-based indicators. For an
entity e in an article a, TITLE is concerned with whether
e appears in the title of a, while AbstractX is concerned
with whether e appears in the first X or last X sentences
in the abstract of a. As the title, the first sentences, and
the last sentences of an article are often treated as crit-
ical parts for retrieval of biomedical articles [26, 37, 38],
one may expect that an entity with larger TITLE and
AbstractX is likely to be a CAE of a.
Fusion of the indicators
Proper fusion of the above indicators may improve CAE
identification. We thus investigate two kinds of fusion
strategies: learning-based strategies and typical strat-
egies. For the learning-based strategies, we employ Ran-
kingSVM [43], which is one of the best techniques
routinely used to integrate multiple indicators by SVM
(Support Vector Machine) to achieve better ranking
(e.g., [36, 44]). We employ SVMrank [45] to implement
RankingSVM. All the indicators are integrated by Ran-
kingSVM. Different combinations of the indicators are
also tested to identify the best ways to fuse the
indicators.
For the typical fusion strategies, Table 4 summarizes
several indicators that are defined based on
state-of-the-art keyword extractors and article retrievers.
The first type of typical strategies fused the
frequency-based (TF) and rareness-based (IDF) indica-
tors. TFIDF and BM25e are two indicators of this type.
TFIDF is the product of TF and IDF. It was found to be
one of the best techniques to extract keywords in articles
[29, 30]. BM25e is defined based on BM25, which was
found to be one of the best techniques to retrieve
biomedical articles [34]. It employs Eq. 1 to estimate the
similarity between and entity e and an article a, where k1
and b are two parameters, |a| is the number of terms in
article a (i.e., length of a), and avgal is the average
length of a collection of articles.
BM25e e; að Þ ¼ TF e; að Þ k1 þ 1ð Þ
TF e; að Þ þ k1 1?bþ b aj javgal
  IDF eð Þ
ð1Þ
The second type of typical strategies fused frequency-
based, rareness-based, and concentration-based indica-
tors. ESe is an indicator of this type. It is defined based
on ES, which was one of the best techniques to retrieve
biomedical articles as well [36]. ESe employs Eq. 2 to es-
timate the similarity between and entity e and an article
a, where, where DF(e) is the number of articles contain-
ing e (i.e., document frequency of e); C is a collection of
articles; N is the total number of articles in C; c(e,C) is
the number of times e appears in C. Therefore, ESe im-
plements a concentration-based indicator by the ratio of
c(e,C) to DF(e), which measures how e concentrates in
articles by computing the micro average TF of e in the
articles.
ESe e; að Þ ¼ TF e; að Þ
TF e; að Þ þ 0:45 
ffiffiffiffiffiffiffiffiffiffiffi
aj j
avgdl
s

ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi
c e;Cð Þ
DF eð Þ
 3
 N
DF eð Þ
s
ð2Þ
The third type of typical strategies fused
frequency-based and locality-based indicators. CCSEe
and eGRABe are two indicators of this type. CCSEe is
defined based on a locality-based biomedical article re-
triever CCSE (core content similarity estimation [40]).
The CCSEe score of an entity e in an article a is the sum
of three factors concerning how e is related to the goal,
background, and conclusion of a. The factors are defined
Table 4 Typical strategies to fuse the indicators
Liu Journal of Biomedical Semantics            (2019) 10:1 Page 7 of 20
as linear weights that are derived based on the positions
of e in a (for detailed definitions for the linear weights,
the reader is referred to [40]). For example, e is related
to the goal of a if it occurs in the title of a; e is related
to the background of a if it occurs in the beginning part
of the abstract of a; and e is related to the conclusion of
a if it occurs in the ending part of the abstract of a.
Similarly, eGRABe considers locality information as well.
It is defined based on a gene article retriever eGRAB
(extractor of gene-relevant abstracts [37]). The eGRABe
score of an entity e in an article a is increased by 1 if (1)
e appears in a at least three times; (2) e appears in the
title of a; or (3) e appears in first X or last X sentences
in the abstract of a. We set X to 1 ~ 3, and hence have
three respective versions: eGRABe-1, eGRABe-2,
eGRABe-3. Note that, in addition to the locality-based
information of an entity, both CCSEe and eGRABe have
incorporated frequency-based information as well, be-
cause an entity with multiple occurrences in different
parts of an article will get amplified scores.
Performance evaluation
The data
Experimental data is collected from CTD (available at
http://ctdbase.org/), which recruits biomedical experts
to maintain a database of biomedical articles with main
research focuses on associations between chemicals,
genes, and diseases [1, 26]. CTD recruited and trained a
number of biomedical experts to curate the associations
with a controlled vocabulary. An experiment showed
that the experts achieved a high degree of agreement in
selecting articles to curate (77% agreement among all
curators, and 85% average agreement between every two
curators), with good accuracy in curating associations in
the articles (average precision and recall were 0.91 and
0.71 respectively) [26]. Associations curated by CTD ex-
perts are also reviewed for quality control before they
are released [26].
We thus evaluate how CAEs curated by the experts
are identified by systems. We randomly sample 300 en-
tities from three kinds of association files in CTD:
<chemical, gene>, <chemical disease>, and < gene, dis-
ease>. For each entity e all associations involving e are
collected. These associations can serve as the basis to
comprehensively collect test articles. For each of the as-
sociations, we collect all articles that CTD experts se-
lected to curate the association. For each article a, we
collect all associations that CTD experts curated with a.
Entities involved in these associations can thus be the
CAEs in a (i.e., the gold standard for a). We totally have
60,507 articles with their CAEs appearing in their titles
or abstracts (see Additional file 1). These articles
amount to about 50% of all articles in CTD.
As we are evaluating how systems perform in identify-
ing CAEs among a given set of candidate entities in an
article, candidate entities in each article should be iden-
tified. For our evaluation purpose, the candidate entities
need to be identified based on the vocabulary of CTD,
because CTD experts have employed this vocabulary to
curate CAEs in the articles. Other potential entities not
in the vocabulary are beyond the scope of consideration,
because whether they are CAEs in the articles is not
verified by domain experts.
More specifically, this vocabulary comprehensively in-
cludes about 2.5 million (2,535,754) terms for the names,
symbols, and synonyms of entities of three types: genes,
diseases, and chemicals. They are selected and modified
from multiple sources, such as MeSH (for chemicals and
diseases), the Entrez-Gene database (for genes, devel-
oped by National Center for Biotechnology Information),
and OMIM (for diseases) [26]. The vocabulary is thus
customized for the curation purpose of CTD (e.g., en-
tities for species-specific entities are added, while some
entities not considered by CTD are removed [4648]).
Candidate entities in each article are mapped to their
IDs by a dictionary-based normalization approach,
which was employed by many previous studies as well
(e.g., [6, 49, 50]). To further fit the approach to our
evaluation purpose, given an article a, all terms that are
CAEs of a are first mapped to their corresponding entity
IDs, as the existence of the entities in a has been con-
firmed by CTD experts. Other terms are then identified
by checking whether official symbols or names of en-
tities in the vocabulary appear in a; and if no, synonyms
of entities are checked. Moreover, authors of articles
often employ their own abbreviations (or symbols) to
represent an entity. For example, the article in Table 1
contains several author-defined abbreviations
expressed in parentheses, such as DA (for dopamine),
LIS (for lisuride), and TDHL (for transdihydrolisuride).
We thus map these abbreviations to their corresponding
entity IDs as well.
As noted above (ref. Fusion of the indicators), we also
investigate several learning-based strategies to fuse indi-
vidual indicators, and hence we require training data to
train the fusion systems. We thus evenly split the 60,507
articles into five parts on which 5-fold cross validation is
conducted. In each experiment fold, a part of the data is
used for testing while the other four parts are used for
training, and the cross-validation process is repeated five
times, with each of the five parts being used exactly once
as testing data.
Evaluation criteria
As the systems aim at prioritizing candidate entities in
an article so that CAEs of the article can be ranked on
the top, we employ three evaluation criteria to measure
Liu Journal of Biomedical Semantics            (2019) 10:1 Page 8 of 20
how CAEs are ranked high. The first criterion is mean
average precision (MAP), which is defined in Eq. 3,
where |A| is the number of test articles in the experi-
ment (i.e., |A| = 60,507), ki is number of entities that are
believed (by CTD experts) to be CAEs of the ith article,
and Seeni(j) is the number of entities whose ranks are
higher than or equal to that of the jth CAE for the ith art-
icle. Therefore, AP(i) is actually the average precision
(AP) for the ith article. It is the average of the precision
when each CAE is seen in the ranked list. Given an art-
icle, if a system can rank higher those CAEs in the art-
icle, AP for the article will be higher. MAP is simply the
average of the AP values for all test articles.
MAP ¼
XjAj
i¼1
AP ið Þ
j A j ; AP ið Þ ¼
Xki
j¼1
j
Seeni jð Þ
ki
ð3Þ
The second criterion is average precision at top-X
(Average P@X, see Eq. 4), which is the average of the
P@X values for all test articles. P@X is the precision
when top-X entities are shown to the readers (see Eq. 5).
Therefore, when X is set to a small value, P@X measures
how a system ranks CAEs very high. In the experiments,
we set X to 1, 3, and 5.
Average P@X ¼
XjAj
i¼1
P@X ið Þ
j A j ð4Þ
P@X ið Þ
¼ Number of top?Xentities thatare CAEs in the i
th article
X
ð5Þ
The third evaluation criterion is %P@X > 0, which is
the percentage of the test articles that have at least one
CAE ranked at top-X positions (X = 1, 2 and 3). It can
be a good measure to indicate whether a system can suc-
cessfully identify CAEs for a large portion of the test ar-
ticles. This measure is of practical significance, because
a CAE identification system can provide practical sup-
port to biomedical researchers only if it can successfully
identify CAEs for most articles.
Results
We separately present the experimental results, which
aim at answering the two research questions (Q1 and
Q2) respectively. Case studies are also conducted to
show how the identified CAEs can be visualized to sup-
port exploratory analysis for curating biomedical
databases.
Q1: How does each indicator perform in identifying CAEs?
Figure 1 shows the performance of each individual indi-
cator in CAE identification. To verify whether the per-
formance differences between two indicators are
statistically significant, we conduct paired t-test with
99% as the confidence level. The results show that the
concentration-based indicator (i.e., AvgTF) performs sig-
nificantly better than all the other indicators.
Fig. 1 Performance of individual indicators: The concentration-based indicator (i.e., AvgTF) performs significantly better than all the other
indicators ( denotes that the indicator performs significantly better than others)
Liu Journal of Biomedical Semantics            (2019) 10:1 Page 9 of 20
We further analyze each indicator by investigating
how CAEs and non-CAEs distribute with the informa-
tion provided by each indicator. For an indicator c, Eq. 6
is used to compute the probability of CAEs whose values
(estimated by c) fall in a specific interval. Similarly, Eq. 7
is defined for the probability of non-CAEs. Therefore,
given an indicator c, these probabilities aim at measuring
the prevalence rate of CAEs and non-CAEs in each
interval. Moreover, we are also concerned with the prob-
ability gain of finding CAEs (ProbGain) in each interval
(see Eq. 8). It is the difference between the probability of
finding CAEs in an interval and the overall probability
of finding CAEs. Therefore, a positive (negative) Prob-
Gain in an interval indicates that it is generally more
(less) likely to find CAEs in the interval.
Pi CAEð Þ ¼ Number of CAEs that fall in interval iTotal number of CAEs in all articles
ð6Þ
Pi NonCAEð Þ ¼ Number of non?CAEs that fall in interval iTotal number of non?CAEs in all articles
ð7Þ
ProbGaini ¼ Number of CAEs in interval iNumber of entities in interval i
?
Number of CAEs in all articles
Total number of entities in all articles
ð8Þ
Figure 2 shows how CAEs and non-CAEs distribute
with the information provided by CoOcc. The two
dashed lines respectively show the prevalence probabil-
ities of CAEs and non-CAEs. They indicate that CAEs
and non-CAEs mainly fall in the area where 0 <CoOcc ?
10. However in this area, ProbGain oscillates around
zero with small absolute values. Therefore, most CAEs
and non-CAEs have similar CoOcc values, making
CoOcc less capable of distinguishing CAEs from
non-CAEs. Given that co-occurrence-based information
was found to be one of the best information to extract
keywords [29, 30], the result show that it is not necessar-
ily quite helpful for identifying CAEs in biomedical
articles.
Figure 3 shows how CAEs and non-CAEs distribute
with the information provided by the locality-based indi-
cators (i.e., AbstractX and TITLE). Positions of entities
Fig. 2 Analysis of the co-occurrence-based indicator (CoOcc): Both CAEs and non-CAEs mainly fall in the area where 0 < CoOcc? 10 (see the two
dashed lines), however in this area, probability gain of finding CAEs (ProbGain) oscillates around zero with small absolute values (see the solid
line), and hence most CAEs and non-CAEs have similar CoOcc values. This is the reason why CoOcc is less capable of distinguishing CAEs
from non-CAEs
Liu Journal of Biomedical Semantics            (2019) 10:1 Page 10 of 20
can be measured in terms of words or sentences. An ab-
stract is divided into 20 parts, and in each part we com-
pute the prevalence probabilities of CAEs and
non-CAEs, as well as ProbGain. The results show that,
when considering the abstracts of the articles, both
CAEs and non-CAEs have somewhat uniform distribu-
tions at different positions, and they have very similar
distributions (and hence ProbGain in the abstract parts
oscillates around zero with small absolute values).
Therefore, although the first sentences and the last sen-
tences of abstracts were used to retrieve biomedical arti-
cles [26, 37, 40], they are not necessarily quite helpful
for CAE identification. On the other hand, TITLE works
better, as CAEs are more likely to appear in titles than
non-CAEs. However, TITLE has weaknesses as well, be-
cause most CAEs do not appear in titles (as shown in
the leftmost part of Fig. 3, only 11.4% of CAEs appear in
titles).
Figure 4 shows how CAEs and non-CAEs distribute
with the information provided by the rareness-based in-
dicators (i.e., IDF). The IDF spectrum is divided into 20
parts. IDF values of non-CAEs fall in the whole
spectrum, however nearly no CAEs have IDF values fall-
ing in the lower 30% part. ProbGain of IDF thus
oscillates more dramatically than those of the
co-occurrence-based and locality-based indicators noted
above, making IDF more helpful for CAE identification,
especially for those entities with lower IDF values.
a
b
Fig. 3 Analysis of the locality-based indicators (AbstractX and TITLE): Positions of entities can be measured in terms of words or sentences, as
shown in (a) and (b) respectively. When compared with non-CAEs, CAEs are more likely to appear in titles of articles, as shown in the left-most
parts of (a) and (b). On the other hand, when considering the abstracts of the articles, both CAEs and non-CAEs have somewhat uniform
distributions at different positions, and moreover they have very similar distributions (see the two overlapping dashed lines). Therefore, TITLE
works better than AbstractX in distinguishing CAEs from non-CAEs (see the solid line). However, TITLE has weaknesses as well, because most CAEs
do not appear in the titles of articles (only 11.4% of CAEs appear in the titles)
Liu Journal of Biomedical Semantics            (2019) 10:1 Page 11 of 20
However, many entities have IDF values fall in the mid-
dle parts of the spectrum (i.e., between 35 and 65%). For
these entities, IDF may not work well.
Figure 5 shows how CAEs and non-CAEs distribute
with the information provided by the frequency-based
indicator (TF). Most entities have TF values less than 6.
Most non-CAEs have TF = 1, and ProbGain of finding
CAEs becomes large when TF ? 4 (see the solid line). TF
thus performs well in identifying CAEs whose TF = 1 or
TF ? 4. However, many entities have TF values falling be-
tween 2 and 3, and for these entities TF has difficulty in
distinguishing them (absolute value of ProbGain is small
for TF = 2 or 3). Therefore, although it is reasonable to
retrieve articles for an entity by preferring those articles
in which the entity appears at least three times [37], this
strategy may not be suitable for identifying CAEs.
Figure 6 shows how CAEs and non-CAEs distribute
with the information provided by the concentration--
based indicator (AvgTF). The AvgTF spectrum is divided
into 20 parts, and most CAEs have AvgTF values falling
between 10 to 40% of the maximum AvgTF, while most
non-CAEs have AvgTF values falling below 10% of the
maximum AvgTF. Therefore, when compared with other
indicators, AvgTF has ProbGain that oscillates more dra-
matically, making it more capable of distinguishing
CAEs from non-CAEs.
Table 5 summarizes the potential and the limitation of
each indicator in CAE identification. In conclusion,
these indicators have significantly different performance
in CAE identification. AvgTF has significantly better per-
formance than all other indicators. Concentration of an
entity in a collection of articles is thus a good way to
distinguish CAEs from non-CAEs. CoOcc and AbstractX
are less capable of distinguishing CAEs from non-CAEs,
although they have been used in many article retrievers
and keyword extractors. Other indicators may have their
own weaknesses as well, especially when identifying
CAEs with different statistical characteristics.
Q2: Can these indicators be fused to improve CAE
identification?
It is thus interesting to fuse the indicators to further im-
prove performance. A poorer indicator may still contrib-
ute, especially if it can provide helpful information that
is not provided by other indicators. Figure 7 shows the
performance of the typical fusion strategies. As noted
above (ref. Fusion of the indicators), all the fusion strat-
egies consider TF, however they have significantly differ-
ent performance.
CCSEe and eGRABe, which considers both TF and
locality-based information, perform even worse than TF.
They have lower MAP than TF (CCSEe: 0.6329;
Fig. 4 Analysis of the rareness-based indicator (IDF): IDF values of non-CAEs fall in the whole IDF spectrum, while nearly no CAEs have low IDF
values (see the two dashed lines). IDF may thus be a useful indicator for CAE identification, especially for those entities with lower IDF values (i.e.,
the lower 30% of the IDF spectrum, see the solid line for probability gain of finding CAEs). However, many entities have IDF values fall in the
middle parts of the spectrum (i.e., between 35 and 65%). For these entities, IDF may not work well (see the solid line for ProbGain)
Liu Journal of Biomedical Semantics            (2019) 10:1 Page 12 of 20
eGRABe-3: 0.6500; but TF: 0.6633, ref. Fig. 1). As noted
above (ref. Fusion of the indicators), CCSEe and
eGRABe are respectively based on two article retrievers
CCSE [40] and eGRAB [37]. They consider TF and
TITLE, which are helpful indicators in certain cases (ref.
Fig. 3, and ref. Fig. 5). However, TF has weaknesses as
well because many CAEs and non-CAEs have TF values
falling between 2 and 3 (as noted in the discussion for
Fig. 5). CCSEe and eGRABe cannot properly tackle this
weakness, even though they also consider the positions
of entities in the abstract, which are less helpful for CAE
identification (ref. the poor performance of AbstractX,
noted in the discussion for Fig. 3).
BM25e and TFIDF, which fuse TF and the
rareness-based indicator IDF, can successfully improve
TF. TFIDF performs better than BM25e, which fuses TF
and IDF in a more complicated way (ref. Equation 1).
TFIDF performs significantly better than others in Aver-
age P@1 and P@2, but not Average P@3 and MAP. On
the other hand, ESe fuses TF, IDF, and the
concentration-based indicator (AvgTF). It performs sig-
nificantly better than others in Average P@3 and MAP.
However, it does not further improve Average P@1 of
AvgTF (ESe: 0.6809 vs. AvgTF: 0.6979, ref. Figure 7 and
Fig. 1). Therefore, both TFIDF and ESe have their
weaknesses in CAE identification as well, although they
are respectively defined based on the best keyword ex-
tractors and article retrievers (ref. Fusion of the
indicators).
It is thus interesting to investigate other ways to
fuse the indicators properly. Figure 8 shows the con-
tribution of learning-based fusion by SVM. All the six
indicators defined in Table 3 are fused (for the
AbstractX indicator, we employ Abstract2, as it is the
best setting for AbstractX, ref. Figure 1). Contribution
of an indicator to the fused system can be investi-
gated by removing it from the fused system. The re-
sults show that removal of a better indicator tends to
deteriorate performance more seriously. ALL-Ab-
stract2, which fuses all indicators except for Ab-
stract2, performs better than all others, including
ALL, which fuses all the six indicators. Further Re-
moving CoOcc from ALL-Abstract2 gets poorer per-
formance. The performance differences between
ALL-Abstract2 and others are statistically significant,
except for ALL-CoOcc on Average P@1. Therefore, it
may not be necessary to fuse all the six indicators.
Without the locality information provided by Ab-
stract2, collaboration of the other five indicators has
been good in distinguishing CAEs from non-CAEs.
Fig. 5 Analysis of the frequency-based indicator (TF): Most entities have TF less than 6 (see the two dashed lines). Most non-CAEs have a TF value
equal to 1, and probability gain of finding CAEs (ProbGain) becomes large when TF ? 4 (see the solid line). TF thus performs well in identifying
CAEs whose TF= 1 or TF? 4. However, many entities have TF values falling between 2 and 3, and for these entities TF has difficulty in distinguishing
CAEs from non-CAEs
Liu Journal of Biomedical Semantics            (2019) 10:1 Page 13 of 20
Moreover, as noted above, the two best typical fusion
strategies TFIDF and ESe have weaknesses. ALL-Ab-
stract2 tackles the weaknesses by learning-based fusion
of five indicators. It performs significantly better than all
the typical fusion strategies. There are 9.6% improve-
ment in Average P@1 (0.7934 vs. 0.7239 by TFIDF);
10.9% improvement in Average P@2 (0.6989 vs. 0.6302
by TFIDF); 8.5% improvement in Average P@3 (0.6153
vs. 0.5669 by ESe); and 8.3% improvement in MAP
(0.7824 vs. 0.7226 by ESe).
Figure 9 investigates how CAEs are ranked at top posi-
tions for a large percentage of articles (i.e., %P@X > 0,
ref. Evaluation criteria). For 92.46% of the articles,
ALL-Abstract2 ranks at least one of their CAEs at top-2
positions. The percentage achieved by randomly ranking
the entities is only 42.33%. TFIDF and ESe, which have
better MAP noted above, do not necessarily perform
better than the best individual indicator AvgTF in
%P@X > 0, especially when X is 2 and 3. ALL-Abstract2
performs better than them as well. The results are of
Fig. 6 Analysis of the concentration-based indicator (AvgTF): Most CAEs have AvgTF values falling between 10 to 40% of the maximum, while
most non-CAEs have AvgTF values falling below 10% of the maximum (see the two dashed lines). Therefore, probability gain of finding CAEs
(ProbGain) oscillates more dramatically with larger absolute values (see the solid line), and hence AvgTF performs better than all the other
indicators in CAE identification
Table 5 Summary of the performance of each indicator
Indicator Potential in CAE identification Limitation in CAE identification
TF TF works well for those entities whose TF = 1 or TF? 4, as non-CAEs
tend to have TF = 1, and few of them have TF ? 4.
Many CAEs and non-CAEs have TF values falling between 2 and 3.
IDF IDF values of non-CAEs fall in the IDF spectrum, while nearly no
CAEs have IDF values falling in the lower 30% part, making IDF help-
ful to filter out non-CAEs with lower IDF values.
Many CAEs and non-CAEs have IDF values fall in the middle parts of
the spectrum (i.e., between 35 and 65%).
CoOcc None. CAEs and non-CAEs tend to have similar CoOcc values.
AvgTF CAEs tend to have AvgTF > 10% of the maximum AvgTF, while non-
CAEs tend to have AvgTF? 10% of the maximum.
None.
TITLE When compared with non-CAEs, CAEs are more likely to appear in
titles of articles.
Most CAEs do not appear in the titles of articles.
AbstractX None. CAEs and non-CAEs have somewhat uniform and similar distribu-
tions at different positions in the abstract.
Liu Journal of Biomedical Semantics            (2019) 10:1 Page 14 of 20
practical significance to stable identification of CAEs for
most articles.
In conclusion, proper fusion of the indicators is not a
trivial task. Typical fusion strategies do not necessarily
have better CAE identification performance than
individual indicators, even though these fusion strategies
were employed by state-of-the-art article retrievers and
keyword extractors. Learning-based fusion by SVM is a
good way to fuse the indicators. However, it is not ne-
cessary to fuse all the indicators. Without the locality
Fig. 7 Fusion of indicators by typical strategies: All the typical strategies have considered the frequency-based indicator (TF). However, CCSEe and
eGRABe, which fuse TF and locality-based indicators, even deteriorates performance (TF has been able to achieve a higher MAP of 0.6633, ref. Fig. 1).
BM25e and TFIDF, which fuse TF and the rareness-based indicator IDF, can further improve performance. TFIDF performs significantly better than
others in Average P@1 and P@2 ( denotes that the indicator performs significantly better than others). ESe fuses TF, IDF, and the concentration-based
indicator (AvgTF). It performs significantly better than others in Average P@3 and MAP
Fig. 8 Fusion of indicators by SVM: All the six indicators are fused (see ALL), and removal of an indicator X from ALL is denoted as ALL-X. We find
that removal of a better indicator tends to deteriorate performance more seriously. ALL-Abstract2 performs significantly better than ALL ( denotes
that the indicator performs significantly better than others), indicating that it would be good to integrate all indicators except for Abstract2. It
performs significantly better than others except for ALL-CoOcc on Average P@1 (denoted by ?). It also performs significantly better than typical
fusion strategies (ref. Fig. 7)
Liu Journal of Biomedical Semantics            (2019) 10:1 Page 15 of 20
information collected from the abstracts of the articles,
collaboration of the other indicators has been able to
achieve significantly better performance, with most arti-
cles (over 92%) having at least one of CAEs successfully
ranked at top-2 positions.
Case studies
To further investigate potential contributions of the
identified CAEs, we conduct case studies to show how
the identified CAEs can be visualized to support cur-
ation of biomedical databases in practice. Visualization
of the CAEs identified from a collection of articles aims
at supporting the exploratory analysis of the CAEs. We
are motivated by a typical need of biomedical re-
searchers: analysis of a specific research finding is often
based on validation of the evidence recently published in
multiple articles with focuses on the finding. For ex-
ample, to curate a gene-disease association, GHR experts
need to check multiple articles focusing on the associ-
ation so that conflicting or unclarified information can
be excluded [51]. Therefore, the identified CAEs should
be visualized to support the exploration of how fre-
quently and recently the CAEs are published in articles,
as well as how two entities are CAEs in the same arti-
cles, which indicates that the two entities may be highly
related to each other.
More specifically, for each article, top-2 entities identi-
fied by ALL-Abstract2 are treated as CAEs of the article.
For each entity e, we compute two items: (1) frequency:
number of articles having e as a CAE, and (2) recency:
average publication year of these articles. A frequency-re-
cency map can thus be constructed to visualize the CAEs
(see Fig. 10a). With the map, researchers can have a glo-
bal view to navigate on the space of how frequently and
recently the CAEs are published in the articles. Consider
three CAEs that are published relatively frequently and
recently: cocaine (ID in CTD: D003042), resveratrol (ID
in CTD: C059514), and SIRT1 (sirtuin 1, ID in CTD:
23411). They are CAEs of 1838, 772, and 135 articles, re-
spectively. To investigate whether the results are helpful
for biomedical curators, for each CAE, Eq. 9 is used to
measure Jaccard similarity between the sets of articles
that are recommended by the system and CTD experts
respectively.
JaccardSimilarity A1;A2ð Þ ¼ j A1?A2 jj A1?A2 j ð9Þ
Jaccard similarities for cocaine, resveratrol, and SIRT1
are 0.8796, 0.875, and 0.8252, respectively. The map can
thus serve as a helpful guide to the space of how fre-
quently and recently the CAEs are published in the
articles.
Moreover, given the map, two kinds of navigation can
be supported: focused view of an entity and zoom-in view
of multiple entities. The focused view is triggered for a
specific entity. As a case study, consider a focused view
of cocaine (ID in CTD: D003042), which is a CAE with
the largest frequency in Fig. 10a. This view focuses on
Fig. 9 Percentage of articles with CAEs ranked at top positions (i.e., %P@X > 0): For 92.46% of the articles, ALL-Abstract2 ranks at least one of their
CAEs at top-2 positions. The percentage achieved by randomly ranking the entities (i.e., the Random baseline) is only 42.33%. ALL-Abstract2 also
performs better than the best indicators noted in Figs. 1 and 7 (i.e., AvgTF, TFIDF, and ESe). It can thus be used to stably identify CAEs for most
articles in practice
Liu Journal of Biomedical Semantics            (2019) 10:1 Page 16 of 20
those articles with cocaine as a CAE (see Fig. 10b). It
provides a new frequency-recency map to show those
entities that are CAEs of those articles with cocaine as a
CAE. Therefore, with the focused-view map, researchers
can navigate through the information space of how co-
caine is related to other entities, as well as those articles
that report conclusive findings of both cocaine and the
related entities. For example, in Fig. 10b, seizures (ID in
CTD: D012640) is an entity with the largest frequency
(63 articles), indicating that many articles may have both
cocaine and seizures as CAEs, and hence the association
between cocaine and seizures deserves investigation. Ac-
tually CTD experts used almost all of these articles (61
out of the 63 articles) to curate this association. The fo-
cused view can thus support the curation task.
The zoom-in view is triggered by selecting a zone in
Fig. 10a. There are four zones derived by setting the
thresholds for the frequency and the recency. In Fig. 10a,
the frequency threshold is set to 100 articles, and the re-
cency threshold to the year of 2012. The four zones aim
at supporting different kinds of exploratory analysis. Fig-
ure 10c provides a zoom-in view on zone IV, which sup-
ports the navigation of those entities that are being
studied in fewer articles more recently. Navigation on this
zone can thus facilitate the validation of emerging
studies on these entities. As case studies, consider three
a
b
c
Zoom-in view 
of multiple 
entities 
Focused view of 
a specific entity
Fig. 10 Visualization of the CAEs identified for online exploration: (a) A frequency-recency map for the CAEs identified from a collection of articles;
(b) Focused view of a specific entity of interest (e.g., cocaine, which is a CAE of a large number of articles); (c) Zoom-in view of multiple entities
(e.g., Zone IV, which contains those entities being studied recently)
Liu Journal of Biomedical Semantics            (2019) 10:1 Page 17 of 20
CAEs of multiple articles published most recently. Each
of them is CAEs of two articles published in 2015: schi-
zandrol B (entity ID: C033585, article IDs: 25319358,
25,753,323), ETV6 (ETS variant 6, entity ID: 2120, article
IDs: 25581430, 25,807,284), and polyhexamethylenegua-
nidine (entity ID: C060540, article IDs: 25716161,
24,769,016). We find that CTD experts have employed
all these articles to curate these CAEs. The zoom-in view
can thus be helpful for the curation task as well.
Discussion
Application and suggestion
Identification of CAEs can be a new service provided by
biomedical search engines (e.g., PubMed), which rou-
tinely collect and preprocess articles for subsequent re-
trieval. For each collected article, the preprocessing
process of the search engines can be enhanced by com-
puting the individual and fused indicators for CAE iden-
tification. With the CAEs identified for each article, the
search engines can facilitate timely and comprehensive
dissemination of conclusive findings in biomedical litera-
ture. The new service can also be a good tool for bio-
medical researchers, curators (e.g., CTD, OMIM, and
GHR), and text mining systems that cross-validate con-
clusive findings on certain entities in multiple articles.
Visualization of CAEs by a frequency-recency map can
be a new service provided by biomedical search engines
as well. With the new service, researchers can explore
the space of CAEs in a collection of articles retrieved for
a specific query. The visualization strategy can also be
adopted by biomedical databases curated by experts,
such as those entity databases that are being maintained
by CTD and GHR. By setting a certain condition (e.g.,
frequency, recency, and entities of interest), researchers
can navigate on the space of highly related entities and
articles for exploratory analysis.
Another interesting application is the extraction of key
sentences in biomedical articles. Those sentences that
mention CAEs of an article may be the key sentences
that describe the main findings of the article. Extraction
of the key sentences is thus helpful for the identification
and mining of the main findings reported in biomedical
literature (e.g., mining associations among entities),
which are main goals of many biomedical information
extraction and mining systems.
Limitation and future research
As noted above (ref. The data), for our evaluation pur-
pose, candidate entities in articles are identified based
on the vocabulary of CTD, which contains millions of
terms for the names, symbols, and synonyms of genes,
diseases, and chemicals. The experimental setting pro-
vides reliable evidence for performance evaluation, be-
cause CTD has employed the vocabulary to curate CAEs
in the articles. Other entities not in the vocabulary are
not verified by the domain experts of CTD, and hence
their effects are not investigated in the paper.
As the CAE identification techniques investigated in
this paper work on a given set of candidate entities, they
can collaborate with different techniques that map en-
tities in articles to their normalized names or IDs. Previ-
ous entity mapping techniques were often developed for
specific applications with different performance in differ-
ent cases. For example, entity recognition techniques
were developed for specific domains or types of entities,
such as chemicals [52], genes [53], and diseases [54].
Mapping the entities into suitable IDs is an important
research topic as well (e.g., mapping of genes [55]) for
which tools were implemented (e.g., MetaMap, available
at https://metamap.nlm.nih.gov/) and techniques were
developed with different performance in different cases
[56]. By collaborating with those entity mapping tech-
niques that are tuned for specific applications, CAE
identification may be improved for the applications.
CAE identification may also be improved by collecting
more information from multiple articles, based on three
observations: (1) given two entities e1 and e2 that are
CAEs in an article, there may be an association <e1, e2 >
between them, (2) associations between CAEs may be
used to infer possible associations (e.g., given <e1, e2 >
and < e2, e3>, an inferred association may be <e1, e3>),
and (3) if two candidate entities in an article a are in-
volved in an inferred association (e.g., e1 and e3 are can-
didate entities in a, and < e1, e3 > is an inferred
association), they are likely to be CAEs of a. Therefore,
CAE identification for an article may be improved by
CAE-based association mining on a collection of articles.
The CAE identification techniques investigated in this
paper can be used to identify CAE associations (based
on the 1st observation). Novel techniques may be devel-
oped to infer possible associations and refine CAE iden-
tification for each article (based on the 2nd and 3rd
observations, respectively).
The CAE visualization strategy noted above (ref. Case
studies) can be extended as well. An interesting exten-
sion is network-based navigation of conclusive findings
on a set of entities of interest. Given a set Ei of entities
of interest, the system identifies a set Eh of entities that
are highly related to the entities in Ei. Two entities are
highly related if they are CAEs of the same article (i.e.,
the article reports conclusive findings on them). The sys-
tem then visualizes Ei and Eh with an association net-
work in which a node is an entity, and an edge between
two nodes indicates that they are highly related. The
users can click on any edge between two entities to
check the distribution of those articles that have the two
entities as CAEs. With the CAE network, biomedical re-
searchers can have global and detailed views on a set of
Liu Journal of Biomedical Semantics            (2019) 10:1 Page 18 of 20
entities among which associations are reported as con-
clusive findings in literature.
Conclusion
CAEs in a biomedical article a are specific entities on
which conclusive associations are reported in a. They
are different from keywords (e.g., MeSH terms)
employed to index (classify or label) a. This paper is the
first study to investigate how five types of statistical indi-
cators can contribute to prioritizing candidate entities in
the title and the abstract of an article so that CAEs can
be ranked on the top for exploratory analysis.
The results show that these indicators have signifi-
cantly different performance. Some indicators do not
perform well in CAE identification, even though they
were used in many article retrievers and keyword extrac-
tors. Learning-based fusion of certain indicators can suc-
cessfully rank CAEs in most articles at top-2 positions.
As it can work on titles and abstracts of articles, which
are more commonly available than full texts of the arti-
cles, it can be applicable to much more articles. By visu-
alizing the identified CAEs with frequency-recency
maps, biomedical researchers can navigate to check how
frequently and recently the CAEs are published in arti-
cles, as well as how two entities are CAEs in the same
articles (i.e., they may be highly related to each other).
The results are of both technical and practical signifi-
cance to the indexing of biomedical articles to support
validation of highly related conclusive findings in bio-
medical literature. They can also be used to enhance
biomedical search engines, curated databases, and text
mining systems, which often serve as essential compo-
nents of many biomedical information processing
systems.
Additional file
Additional file 1: Biomedical articles that are employed as the
experimental data. There are 60,507 articles, which amount to about 50% of
the articles in CTD. Each article has a PubMed ID, followed by its CAEs
(represented by their IDs in CTD and separated by |). CAEs of an article a are
the specific entities involved in the associations that CTD experts
curated based on the conclusive findings of a. (TXT 4849 kb)
Abbreviations
%P@X > 0: Percentage of articles having at least one CFE ranked at top-X po-
sitions; Average P@X: Average precision at top-X; CAE: Conclusive association
entity; IDF: Inverse document frequency; MAP: Mean average precision;
ProbGain: Probability gain; SVM: Support vector machine; TF: Term frequency
Acknowledgements
The author is grateful to Zhe-Ting Guo for collecting and preprocessing the
experimental data.
Funding
This research was supported by Ministry of Science and Technology, Taiwan,
under the grants MOST 1052221-E-320-004 and MOST 1072221-E-320-004.
Availability of data and materials
The dataset supporting the conclusions of this article is included in
Additional file 1, which contains the list of articles tested in the experiment.
Each article has a PubMed ID, followed by a tab character as well as a list of
conclusive association entities in the article recognized by CTD.
Authors contributions
RL designs the research, conducts the experiments, analyze the experimental
results, as well as drafts the manuscript. The author read and approved the
final manuscript.
Ethics approval and consent to participate
Not applicable.
Consent for publication
Not applicable.
Competing interests
The authors declare that they have no competing interests.
Publishers Note
Springer Nature remains neutral with regard to jurisdictional claims in
published maps and institutional affiliations.
Received: 17 August 2018 Accepted: 20 December 2018
Kafkas and Hoehndorf Journal of Biomedical Semantics           (2019) 10:15 
https://doi.org/10.1186/s13326-019-0208-2
RESEARCH Open Access
Ontology based mining of
pathogendisease associations from
literature
S¸enay Kafkas1,2* and Robert Hoehndorf1,2
Abstract
Background: Infectious diseases claim millions of lives especially in the developing countries each year.
Identification of causative pathogens accurately and rapidly plays a key role in the success of treatment. To support
infectious disease research and mechanisms of infection, there is a need for an open resource on pathogendisease
associations that can be utilized in computational studies. A large number of pathogendisease associations is
available from the literature in unstructured form and we need automated methods to extract the data.
Results: We developed a text mining system designed for extracting pathogendisease relations from literature. Our
approach utilizes background knowledge from an ontology and statistical methods for extracting associations
between pathogens and diseases. In total, we extracted a total of 3420 pathogendisease associations from literature.
We integrated our literature-derived associations into a database which links pathogens to their phenotypes for
supporting infectious disease research.
Conclusions: To the best of our knowledge, we present the first study focusing on extracting pathogendisease
associations from publications. We believe the text mined data can be utilized as a valuable resource for infectious
disease research. All the data is publicly available from https://github.com/bio-ontology-research-group/padimi and
through a public SPARQL endpoint from http://patho.phenomebrowser.net/.
Keywords: Text mining, Relationship extraction, Pathogendisease association, Pathogen, Infectious disease
Background
Each year, millions of people die due to infectious diseases.
The World Health Organisation (WHO)[1] reported that
11? million deaths were due to HIV/AIDS in 2015 alone.
Infectious diseases cause devastating results not only on
global public health but also on the countries economies.
Developing countries, especially the ones in Africa, are the
most affected by infectious diseases.
Several scientific resources have been developed to
support infectious disease research. A large number of
these resources focus on hostpathogen interactions [2, 3]
as well as particular mechanisms of drug resistance [4].
*Correspondence: senay.kafkas@kaust.edu.sa
1Computational Bioscience Research Center, King Abdullah University of
Science and Technology, 23955-6900 Thuwal, Saudi Arabia
2Computer, Electrical and Mathematical Sciences and Engineering Division,
King Abdullah University of Science and Technology, 23955-6900 Thuwal,
Saudi Arabia
Additionally, there are several resources that broadly char-
acterize different aspects of diseases [5]. However, rela-
tively little structured information is available about the
relationships between pathogens and disease, information
that is also needed to support infectious disease research.
For example, pathogendisease relations (and the result-
ing relations between pathogens and phenotypes elicited
in their hosts) provide complementary information to
molecular approaches to discover hostpathogen interac-
tions [6]. More generally, however, while there is often
a direct correspondence between an infectious disease
and a type of pathogen, the relation between disease and
the pathogen causing it needs to be available in a struc-
tured format to allow automatic processing and linking
of phenotypes (i.e., disease) to the molecular mecha-
nisms (i.e., the pathogens and their molecular interac-
tions). Such information is further useful as some diseases
© The Author(s). 2019 Open Access This article is distributed under the terms of the Creative Commons Attribution 4.0
International License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and
reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to the
Creative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver
(http://creativecommons.org/publicdomain/zero/1.0/) applies to the data made available in this article, unless otherwise stated.
Kafkas and Hoehndorf Journal of Biomedical Semantics           (2019) 10:15 Page 2 of 5
can be caused by multiple types of pathogens, and the
same pathogen may cause different types of diseases (e.g.,
depending on the anatomical site of infection).
Currently, pathogendisease associations are mainly
covered in structured format by proprietary databases
such as the Kyoto Encyclopedia of Genes and Genomes
(KEGG) [7]; KEGGs DISEASE database contains a
detailed classification of infectious diseases and links
them to the taxon or the taxa that are known to cause
the disease. For example, KEGG links the disease Tuber-
culosis (H00342) to two taxa:Mycobacterium tuberculosis
and Mycobacterium canettii. Pathogendisease associa-
tions are also described in the biomedical literature and
public resources such as Wikipedia [8], or in the Human
Disease Ontology [5] in natural language form. Auto-
mated methods are needed to extract these associations
from natural language.
Here, we further developed and evaluated a text
mining system for extracting pathogendisease asso-
ciations from literature [9]. While most of the exist-
ing text mining studies related to infectious disease
focus on extracting hostpathogen interactions from text
[10, 11] and archiving this data [2, 3], to the best
of our knowledge, we present the first text mining
system which focuses on extracting pathogendisease
associations. Our literature-extracted associations are
available for download from https://github.com/bio-
ontology-research-group/padimi and are included in
PathoPhenoDB [12] and accessible through a public
SPARQL endpoint at http://patho.phenomebrowser.net/.
Materials &methods
Ontologies and resources used
We used the latest archived version of the Open
Access full text articles subset of PubMed Central
(http://europepmc.org/ftp/archive/v.2017.12/, containing
approximately 1.8 million articles) from the Europe PMC
database [13]. We used the NCBI Taxonomy [14] (down-
loaded on 22-08-2017) and the Human Disease Ontol-
ogy (DO) [5] (February 2018 release) to provide the
vocabulary to identify pathogen and infectious disease
mentions in text. We selected these two comprehen-
sive OBO ontologies due to the fact that our method
utilizes ontology structure to propagate information in
relation extraction as well as interoperablity reasons. Fur-
thermore, in a relevant study [15], we link pathogens
to disease phenotypes in support of infectious disease
research by utilizing the mappings from DO to phe-
notpes. We generated two dictionaries from the labels
and synonyms in the two ontologies and refined them
before applying text mining. In the refinement pro-
cess, we filtered out terms which have less than three
characters and terms that are ambiguous with common
English words (e.g., Arabia as a pathogen name). We
extracted the taxon labels and synonyms belonging to
all fungi, viruses, bacteria, worms, insects, and proto-
zoa from the NCBI Taxonomy to form our pathogen
dictionary. The final pathogen and disease dictionar-
ies cover a total of 1,519,235 labels and synonyms
belonging to 1,250,373 distinct pathogen taxa and 1380
labels and synonyms belonging to 438 distinct infectious
diseases.
Pathogen and disease class recognition
A class is an entity in an ontology that characterizes a
category of things with particular characteristics. Classes
usually have a set of terms attached as labels or synonyms
[16]. We used the Whatizit text mining workflow [17] to
annotate pathogen and disease classes in text with the two
dictionaries for diseases and pathogens. Because disease
name abbreviations can be ambiguous with some other
names (e.g., ALS is an abbreviation both for Amyotrophic
Lateral Sclerosis and Advanced Life Support), we used
a disease abbreviation filter for screening out the non-
disease abbreviations that could be introduced during the
annotation process [18]. Briefly, this filter operates based
on rules utilizing heuristic information. First, it identifies
abbreviations and their long forms in text by using regu-
lar expressions. Second, it utilizes several rules to decide
whether to keep the abbreviation annotated as a disease
name or filter out. The rules cover keeping the abbrevia-
tion either if any of its long forms from DO exists in the
document or its long form contains a keyword such as
disease, disorder, syndrome, defect, etct?hat describes
a disease name.
PathogenDisease association extraction
Our association extraction method is based on identifica-
tion of pathogendisease co-occurrences at the sentence
level and applying a filter based on co-occurrence statis-
tics (total number of co-occurrences of a given pair is cal-
culated by considering the total number of co-occurrences
across all sentences in all documents) and an extended
version of Normalized Point-wise Mutual Information
(NPMI) [19] association strength measurement to reduce
noise possibly introduced by the high recall, low preci-
sion co-occurrence method. We selected the associations
(between pathogen and disease classes) having an NMPI
value above 0.2 and co-occurring at least 10 times in the
literature.
We extended NPMI, which is a measure of collocation
between two terms, to a measure of collocation between
two classes. Hence, we reformulated the NPMI measure
for our application. First, we identify, for every class,
the set of labels and synonyms associated with the class
(Labels(C) denotes the set of labels and synonyms of C).
We then define Terms(C) as the set of all terms that can be
used to refer to C: Terms(C) := {x|x ? Labels(S)?S  C}.
Kafkas and Hoehndorf Journal of Biomedical Semantics           (2019) 10:15 Page 3 of 5
We calculate the NPMI between classes C and D as
npmi(C,D) = log
nC,D·ntot
nC ·nD
? log nC,Dntot
(1)
where ntot is the total number of sentences in our cor-
pus in which at least one pathogen and one disease name
co-occur (i.e., 4,427,138), nC,D is the number of sentences
in which both a term from Terms(C) and a term from
Terms(D) co-occur, nC is the number of sentences in
which a term fromTerms(C) occurs, and nD is the number
of sentences in which a term from Terms(D) occurs.
Results
Statistics on extracted pathogenDisease associations
We extracted a total of 3420 distinct pathogendisease
pairs belonging to 316 1357 distinct diseases and
pathogens respectively from over 1.8 million Open Access
full text articles. To identify the associations, we used
a combination of lexical, statistical, and ontology-based
rules. We used lexical matches to identify whether the
label or synonym of a pathogen or disease is mentioned
in a document; we used a statistical measure, the nor-
malized point-wise mutual information, to determine
whether pathogen and disease mentions co-occur sig-
nificantly often in literature; and we used ontologies as
background knowledge to expand sets of terms based on
ontology-base inheritance.
Performance evaluation
To evaluate the text mined pathogendisease associa-
tions, we used several manually curated resources includ-
ing the KEGG [7] database, DO [5], and a list of pathogen
disease associations in Wikipedia [8] as reference, and
we compare our results to the information contained in
them. We could identify 744 pathogendisease associa-
tions (between 455 distinct pathogens and 331 distinct
diseases) in KEGG, 353 pathogendisease associations
in Wikipedia (between 250 distinct pathogens and 245
distinct diseases) and 94 pathogendisease associations
in DO (between 90 distinct pathogens and 41 distinct
diseases) for which we could map the pathogen and dis-
ease identifiers from NCBI Taxonomy and DO to their
identifiers/names in KEGG, DO and Wikipedia. Figure 1
shows the overlapping and distinctly identified pathogen
disease associations from these resources and literature.
The recall of our method is 29.4% (219) for KEGG,
50.7% (179) for Wikipedia, 45.7% (43) for DO. There are
525 pairs in KEGG, 174 pairs in Wikipedia and 51 pairs in
DO which we could not cover by text mining. The main
reason we cannot identify an association is due to limita-
tions in our named entity and normalization procedure as
well as its non-existence in the literature.
In addition to the information contained in existing
databases, we extracted many more associations from lit-
erature (3121 in total). To determine the accuracy of these
associations, first we randomly selected 50 pathogen
disease pairs and all of the evidence sentences linked to
them. We applied our threshold values based on NPMI
Fig. 1 Overlapping pathogendisease associations between literature and other resources
Kafkas and Hoehndorf Journal of Biomedical Semantics           (2019) 10:15 Page 4 of 5
and number of co-occurrences to distinguish between
positive and negative associations; we then manually ana-
lyzed the evidence sentences linked to these associations
(each association are extracted from one or more sen-
tences) to classify each positive association as either False
Positive or True Positive and each negative association
either as True Negative or False Negative (manual evalua-
tion data is freely available [20]).
In our manual evaluation, we achieve a precision of 64%,
a recall of 89% and an F-score of 74%. The false pos-
itives were mainly due to ambiguous abbreviations and
pathogen names. For example, Katanga which is a geo-
graphical place name was annotated as a pathogen name
(NCBITaxon:966285) by our method.
Some false negatives were due to rejections by the sys-
tem based on the threshold settings. For example, Bar-
tonellosis (DOID:11102) and Bartonella ancashensis
(NCBITaxon:1318743) which is also covered by KEGG
co-occurred only two times (in two different articles,
PMCID:4102455 and PMCID:5382735) in our corpus
and therefore the association between them was rejected
as we limited our analysis to pathogendisease pairs that
co-occurred ten or more times. Other false negatives were
due to missing pathogen or disease labels in our dictionar-
ies. For example, our system could not identify a KEGG
covered association between necrotizing ulcerative gin-
givitis (DOID:13924) and Fusobacterium nucleatum
(NCBITaxon:851) since we included only the infections
disease branch of DO in our disease dictionary while
necrotizing ulcerative gingivitis is not a sub-class of
infectious disease in DO.
Discussion
By using ontologies as background knowledge to expand
our sets of terms and labels, it is possible to identify
pathogendisease associations even if the labels and syn-
onyms directly associated with the pathogen or disease
are not directly found to co-occur in text. For exam-
ple, we extracted a total of 44 distinct pathogendisease
associations relevant to dengue disease (DOID:11205).
Twelve our of 44 associations are the direct associ-
ations of dengue disease (i.e., a label or synonym of
the disease is explicitly mentioned in text) while the
remaining 32 are indirect associations obtained from
associations with labels and synonyms of the sub-
classes asymptomatic dengue (DOID:0050143), dengue
hemorrhagic fever (DOID:12206), and dengue shock
syndrome (DOID:0050125). In total, we found 812
pathogendisease associations which do not directly co-
occur in literature but are inferred through the ontology.
The performance of our system depends on two
parameters: the NPMI value and the number of co-
occurrences used as a threshold. In the future, we may
use these two values to automatically determine optimal
threshold based on a more comprehensive evaluation set
of pathogendisease associations which needs to be cre-
ated and could also be useful for developing machine
learning based methods. While our initial text mining
approach performs at a promising level (F-score 74%),
there is still some room for improvements. As we found
the pathogen names to be ambiguous with other domain
specific names, we plan to further improve the abbrevia-
tion and name filters we apply. For improving the recall
of our system, it may be possible to expand our dictio-
naries with other resources covering disease and pathogen
names such as the Experimental Factor Ontology (EFO)
[21] and the Unified Medical Language System (UMLS)
[22] for diseases, and the Encyclopedia of Life [23] for
pathogens.
Conclusion
Here, we present a text mining method for extracting
pathogendisease associations from the biomedical liter-
ature. Our method performed at a promising level with
some room for improvements. In future, we plan to
improve our text mining method by developing and inte-
grating a pathogen abbreviation filter and expanding the
coverage of our pathogen and disease dictionaries. In the
scope of infectious disease research, we have included our
results in a database of pathogens and the phenotypes they
elicit in humans. We believe that our results can further
support infectious disease research.
Acknowledgement
Authors would like to thank Mrs. Marwa Abdellatif for her help to make the
data available from the SPARQL end-point.
Consent of publication
Not applicable.
Abbreviations
DO: Human disease ontology; EFO: Experimental factor ontology; KEGG: Kyoto
encyclopedia of genes and genomes; NPMI: Normalized point-wise mutual
information; UMLS: Unified medical language system; WHO: World health
organisation
Authors contributions
RH and S¸K conceived of the study; S¸K performed all experiments. S¸K and RH
analyzed the results. S¸K drafted the manuscript, R.H. revised the manuscript. All
authors have read and approved the final version of the manuscript.
Funding
This work has been supported by funding from King Abdullah University of
Science and Technology (KAUST) Office of Sponsored Research (OSR) under
Award No. URF/1/3454-01-01 and FCC/1/1976-08-01.
Availability of data andmaterials
All the data is available from https://github.com/bio-ontology-research-
group/padimi and (http://patho.phenomebrowser.net/) through a public
SPARQL endpoint.
Ethics approval and consent to participate
Not applicable.
Competing interests
The authors declare that they have no competing interests.
Kafkas and Hoehndorf Journal of Biomedical Semantics           (2019) 10:15 Page 5 of 5
Received: 3 October 2018 Accepted: 2 September 2019
Tissot and Dobson Journal of Biomedical Semantics 2019, 10(Suppl 1):17
https://doi.org/10.1186/s13326-019-0216-2
RESEARCH Open Access
Combining string and phonetic
similarity matching to identify misspelt
names of drugs in medical records written in
Portuguese
Hegler Tissot1* and Richard Dobson1,2,3
From UK Healthcare Text Analysis Conference (HealTAC 2018)
Manchester, UK. 1819 April 2018
Abstract
Background: There is an increasing amount of unstructured medical data that can be analysed for different
purposes. However, information extraction from free text data may be particularly inefficient in the presence of
spelling errors. Existing approaches use string similarity methods to search for valid words within a text, coupled with
a supporting dictionary. However, they are not rich enough to encode both typing and phonetic misspellings.
Results: Experimental results showed a joint string and language-dependent phonetic similarity is more accurate
than traditional string distance metrics when identifying misspelt names of drugs in a set of medical records written in
Portuguese.
Conclusion: We present a hybrid approach to efficiently perform similarity match that overcomes the loss of
information inherit from using either exact match search or string based similarity search methods.
Keywords: Phonetic similarity, Similarity search, Misspelt names of drugs
Background
There is a large amount of unstructured data being pro-
duced by different kinds of information systems, in a
variety of formats, due to the advancement of commu-
nication and information technologies [1, 2]. Within the
clinical domain, Electronic Health Record (EHR) sys-
tems are becoming widely adopted, from which infor-
mation describing the patients health conditions is often
presented and stored in the form of free text notes [3].
Existing text-mining methods aim to extract detailed
structured information from clinical narratives, such as
drug prescriptions, their variability, and adverse drug
reactions [4, 5]. However, free-text is susceptible to typ-
ing and phonetic misspellings. Spelling errors of generic
drug names can occur in up to one out of six entries
*Correspondence: h.tissot@ucl.ac.uk
1Institute of Health Informatics, University College London, London, UK
Full list of author information is available at the end of the article
in electronic drug information systems. Such errors are
likely to be responsible for up to 12% of adverse drug
events, mainly caused by errors during transcription of
prescriptions, illegible prescriptions, or drug name confu-
sion [6]. Due to such frequency and the relevance of drug
information in clinical tasks, spelling correction becomes
crucial to support health care professionals with spelling
error-tolerant engine systems.
Similarity comparison algorithms can be used to iden-
tify and extract concepts from free text [7] when text is
loaded with misspellings. String similarity metrics (e.g.
Edit Distance [8] and Jaro-Winkler Distance [9]) can mea-
sure similarity between two strings. These functions can
be used to compare the elements from the input data
source against an existing dictionary in order to identify
a possible valid word matching a misspelling. However,
existing string similarity algorithms may be inefficient to
analyse text loaded with spelling errors because they may
© The Author(s). 2019 Open Access This article is distributed under the terms of the Creative Commons Attribution 4.0
International License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and
reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to the
Creative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver
(http://creativecommons.org/publicdomain/zero/1.0/) applies to the data made available in this article, unless otherwise stated.
Tissot and Dobson Journal of Biomedical Semantics 2019, 10(Suppl 1):17 Page 2 of 7
not necessarily handle specific aspects, such as phonetic
errors [10]. In these cases, it is necessary to use phonetic
similarity metrics.
In order to overcome the possible loss of information
by using exact match search methods to find mentions of
drugs within patient records, we propose a hybrid solution
coupling string and phonetic similarity metrics to identify
misspelt names of drugs. This approach was used to pro-
duce a dictionary of misspelt variations. A Trie-based
fast similarity search algorithm was then able to iden-
tify a broader range of potential candidates as misspelt
variations for each drug name.
Use-case
Since July 2013 the Brazilian government tries to address
the shortage of doctors, especially in the inner cities and
the outskirts of large cities in Brazil, through the hir-
ing of doctors from other countries. With the addition of
doctors with distinct language background in the public
health system (especially from South and Central America
where people originally speak Spanish), a larger number of
spelling errors have been found in electronic record sys-
tems. Such errors occur mainly due to the similarity of the
Portuguese language with other Latin languages (such as
Spanish and Italian) [11].
InfoSaude (InfoHealth) [12] is an information system
created to manage and track medical records, such as
exams, vaccinations, and drug prescriptions. The system
is used to meet the needs of 75 public health centres
in the city of Florianopolis/Brazil. It integrates different
information structures used by the Brazilian Ministry of
Health, such as the Outpatient Information System (CIS)
and the International Code of Diseases (ICD). The system
also generates information for Ambulatory Care Indi-
vidual Report (RAAI), summarizing data on the type of
care, pregnancies, procedures performed on the patient,
applied vaccines and drug prescriptions.Whilst maintain-
ing a series of structured information, the system also con-
tains textual fields that are filled by health professionals
during patient care.
Although InfoSaude has structured information about
drug prescriptions, a deeper analysis on drug usage, abuse,
or checking whether patients are correctly and effectively
making use of the prescribed drugs, relies on the observa-
tions registered by the clinicians using free text. However,
the textual content of the medical records does not go
through any kind of review. Thus, it is common to find a
number of spelling and phonetic errors that could harm
any further analysis. An information extraction system
is expected to overcome this problem in order to avoid
information loss.
Approximate stringmatch
The existing similarity match methods range from using
basic string similarity distance metrics, which measure
inverse similarity between two text strings by providing
an algorithm-specific numerical indication of distance, to
the use of more sophisticated methods coupled with the
phonetic representation of words in a given language.
Edit Distance (ED) (or Levenshtein Distance) [8] is
the most widely known string metric. ED operates
between two input strings  ED(w1,w2)  and returns the
minimum number of operations (single-character edits)
required to transform string w1 into w2. Other exam-
ples and variations of string similarity metrics include
Jaro-Winkler Distance [9], Hamming Distance [13], and
StringSim [14]. However, string distance measures tend to
ignore the relative likelihood errors.
Phonetic representations encode words based on the
sound of each letter to translate a string into a canonical
form. Soundex [15] is an example of a phonetic match-
ing scheme initially designed for English that uses codes
based on the sound of each letter to translate a string into
a canonical form of at most four characters, preserving
the first letter. In addition, phonetic similarity metrics are
able to assign a high score even though comparing dissim-
ilar pairs of strings that produce similar sounds [14, 16].
As the result, phonetically similar entries will have the
same (or similar) keys and they can be indexed for efficient
search using some hashing method. However, phonetics
is language-dependent [17, 18] and solutions for this sort
of problems must be specially designed for each specific
language.
In addition, fast similarity search approaches have been
proposed in order to match free text against large dic-
tionaries or databases, being supported by either indexed
database structures [14, 19, 20] or Trie-based (prefix
index) approximate matching [2123]. In an initial exper-
iment, Fuzzy Keyword Search [22] has proved to be
efficient by combining Trie-based search with string sim-
ilarity functions. However, processing time grows expo-
nentially as long as the Edit Distance threshold increases,
becoming inefficient for ED > 2, which we were able to
confirm by comparing the processing time (in millisec-
onds) spent to perform 1000 searches over a dictionary of
80,000 entries, varying ED amongst 0 (16 ms), 1 (218 ms)
and 2 (3267 ms).
Method
As part of a NLP pipeline that aims to identify different
aspects of drug usage by patients, one of the atomic steps
within this pipeline is the identification of drug names
in free text. In this section we describe how string and
phonetic similarity metrics can be combined to improve
accuracy on identifying misspelt names of drugs within
a set of records written in Portuguese. Our approach has
two main steps. First, we combine string (StringSim) and
language-dependent phonetic (PhoneticMapSimPT ) sim-
ilarity metrics proposed in [18] in a hybrid similarity
Tissot and Dobson Journal of Biomedical Semantics 2019, 10(Suppl 1):17 Page 3 of 7
search solution in order to produce a base dictionary
of misspelt variations. These metrics were originally
designed for the Brazilian Portuguese language. Finally,
this dictionary is used as input for a fast Trie-based
similarity search algorithm that finds potential candidates
to be annotated as drug names in text.
We started using list of 5535 drug names available in
the InfoSaude system, and searching the most cited drugs
in a experimental dataset of clinical notes provided by
the InfoSaude team (de-identified data with no ethical
approval required) from 4748 distinct patients (multiple
documents per patient). An exact match search produced
a list of 516 drug names, from which the 20 most cited
drugs in the text were initially selected (Table 1).
In this first step, we aim to produce a base dictionary
of misspelt drug name variations by combining string and
phonetic thresholds in order to maximise the accuracy on
identifying true positive misspelt words. Such thresholds
are used to determine whether a candidate misspelt word
correspond to a drug name. Inappropriate low threshold
valuesmay return toomany false candidates favouring low
precision by including words with low similarity values
that do not correspond to a drug name. In contrast, high
threshold values may exclude possible valid misspelt drug
names from the final matching, favouring low recall. The
Table 1 Occurrence (#) of the 20 most cited drug names in a set
of 4748 medical records written in Portuguese
Drug name Number of occurrences
Fluoxetina 18624
Paracetamol 8697
Diazepam 8474
Amitriptilina 8463
Omeprazol 7825
Dipirona 7320
Glicose 5721
Captopril 5383
Insulina 5290
Nimesulida 4228
Clorpromazina 4226
Enalapril 4144
Imipramina 4135
Sinvastatina 3862
Carbamazepina 3853
Amoxicilina 3716
Ibuprofeno 3714
Metformina 3467
Risperidona 3464
Atenolol 3224
method used to find the most suitable string and phonetic
similarity thresholds is described below:
 We selected a list of candidate words (similar words)
for each drug, by finding all words that have at least 3
matching consonantal phonemes in each pair of true
positive and candidate drug name or the Edit
Distance metric ? 3.
 The returned list of similar words corresponding to a
given drug name d was manually analysed. We
applied a filter in order to consider candidates words
w where StringSim(d,w) ? 0.6 (this threshold can be
considered relatively low and resulted approximately
50% of false positive candidates). The final result is a
list of 1791 distinct candidate words for the set of
drug names listed in Table 1  an average of 90
similar candidate words per drug.
 The candidate words were manually annotated to
identify whether each word corresponds to a valid
drug name, resulting 938 positive matches and 853
negative matches. We also automatically annotated
each positive and negative match with the
corresponding string and phonetic similarity
measures (StringSim and PhoneticMapSimPT).
 We used the annotated set of candidates to perform a
grid search over the combined string and phonetic
similarity values in order to find the best similarity
threshold values that favour precision and recall. The
list of 20 drugs was split into two groups (10 drugs
each) used as training and validation sets. The grid
search algorithm is presented in the form of a
pseudo-code in Fig. 1.
The pseudo-code performs an exhaustive search for the
best pair of phonetic and string similarity thresholds. The
input comprises two manually annotated lists (trainSet
and validSet)  containing names of drugs and candidate
similar words with the corresponding positive or negative
match flag  and a list with 7730 pairs of possible string
and phonetic threshold values. 660 pairs of similarity
values contain StringSim = 0, i.e. a possible solution con-
sidering only the phonetic similarity metric as a threshold.
Finally, for each possible pair of threshold values, the algo-
rithm calculates Precision, Recall, and F1 for each set of
10 drugs (trainSet  lines 2-7  and validSet  lines 8-13).
The final thresholds are updated each time both F1train
and F1valid simultaneously achieve better values  lines
14-19. After executing the described pseudo-code on the
data extracted from the medical record set, we observed
a hybrid solution considering both phonetic and simi-
larity thresholds achieved better accuracy on identifying
misspelt names of drugs. The hybrid solution combines
a smaller phonetic threshold to perform a fast similar-
ity search that result more similar words, coupled with a
Tissot and Dobson Journal of Biomedical Semantics 2019, 10(Suppl 1):17 Page 4 of 7
Fig. 1 A pseudo-code to find similarity thresholds
string similarity threshold that works as a complementary
filter. Table 2 depicts the final resulting threshold values.
Results
The final threshold values were used to find positive mis-
spelt names for a broader list of drugs. A total of 1442
misspelt words corresponding to 409 different drug names
were identified. Table 3 shows the drug names (except
those occurring in the training and validation sets) in
Table 2 Best threshold values found by the grid search method
Parameter Value
Training Set Number of true positives 417
Number of false positives 31
Number of false negatives 25
Precision 0.931
Recall 0.943
F1-score 0.937
Validation Set Number of true positives 477
Number of false positives 39
Number of false negatives 19
Precision 0.924
Recall 0.961
F1-score 0.942
Thresholds Phonetic similarity 0.844
String similarity 0.831
which the greatest number of misspelt forms were found,
as well as the corresponding accuracy (precision, recall,
F1) on identifying the misspelt variations for each drug.
We also compare the accuracy of our approach against the
widely used Edit Distance metric.
Information Extraction and NLP systems are tradition-
ally evaluated through precision, recall, and F1-score rel-
evance measures. Precision is equivalent to the amount
of retrieved instances that are relevant, while recall is
equivalent to the amount of relevant instances that are
retrieved. The terms true positives (TP) and true negatives
(TN) represent the correct result and the correct absence
of results respectively, while the terms false positives (FP)
and false negatives (FN) correspond to the unexpected
result and the missing result respectively. These terms are
used to define precision and recall according to Eqs. 1
and 2. In other words, the greater is precision the lesser is
the proportion of false positive results, whilst the greater
is recall the lesser is the proportion of false negative
results. Finally, the F1-score result can be interpreted as
the weighted average (or harmonic mean) between preci-
sion and recall [24], reaching its best value at 1 and worst
score at 0 (Eq. 3).
Precision = TPTP + FP (1)
Recall = TPTP + FN (2)
Tissot and Dobson Journal of Biomedical Semantics 2019, 10(Suppl 1):17 Page 5 of 7
Table 3 Drugs with the highest number of misspelt variations
Drug name Number of similar words
Inexact Phonetic Match F1-Score when using only string match
Precision Recall F1 ED ? 1 ED ? 2 ED ? 3 ED ? 4
Propanolol 52 0.960 0.979 0.967 0.310 0.819 0.945 0.955
Glibenclamida 49 1.000 1.000 1.000 0.829 0.956 0.955 0.961
Anlodipino 49 0.913 0.976 0.944 0.612 0.938 0.952 0.942
Medroxiprogesterona 47 1.000 0.914 0.955 0.763 0.881 0.955 0.927
Metoclopramida 46 1.000 0.977 0.989 0.750 0.977 0.965 0.964
Loratadina 46 0.837 0.947 0.889 0.774 0.973 0.963 0.955
Dexametasona 45 1.000 0.800 0.889 0.615 0.915 0.954 0.952
Furosemida 43 0.963 1.000 0.981 0.844 1.000 0.976 0.961
Prednisona 42 1.000 0.878 0.935 0.730 0.952 0.976 0.956
Hidroclorotiazida 41 1.000 0.975 0.987 0.776 0.962 0.952 0.940
Diclofenaco 41 0.923 0.947 0.935 0.812 0.914 0.950 0.912
Ciprofloxacino 37 1.000 0.918 0.958 0.520 0.878 0.935 0.922
Espironolactona 36 1.000 1.000 1.000 0.714 0.941 0.948 0.962
Salbutamol 36 1.000 0.972 0.986 0.819 0.956 0.976 0.943
Clonazepam 34 1.000 1.000 1.000 0.692 0.969 0.961 0.939
Beclometasona 33 1.000 0.967 0.984 0.777 0.935 0.961 0.921
Dexclorfeniramina 31 1.000 0.903 0.949 0.708 0.872 0.960 0.959
Metronidazol 30 0.965 0.965 0.965 0.816 0.964 0.942 0.926
Prednisolona 30 0.965 0.965 0.965 0.739 0.925 0.976 0.966
Isossorbida 29 0.963 1.000 0.981 0.761 0.960 0.957 0.936
Average F1-score 0.963 0.718 0.934 0.958 0.945
The best F1 score is highlighted for each drug
F1 = 2 × Precision × RecallPrecision + Recall (3)
Some drugs reach recall lower than 0.9 (e.g. Dexameta-
sona and Prednisona) and Loratadina has a precision
around 0.83, which is lower than most others. Although
not being conclusive and still needs further investiga-
tion, we found in an initial analysis the observed differ-
ences among the scores refer to some prefixes (e.g. cap,
clo, para, ox) and suffixes (e.g. mina, lina, pina,
tina) that are used to compound names of distinct drugs,
increasing the value of the similarity scores for negative
matches, thus leading to false positives. Some words in
Portuguese can also be compound by the verbal derivative
form of a noun, such as insulinizar as a verb referring
to the substance Insulina. All these factors combined
increase the probability of a drug name being similar to a
more diverse set of distinct words or other drugs in this
specific language.
A hybrid solution showed to be efficient on dealing
with both phonetic and spelling errors, and combining
both string and phonetic similarity thresholds favoured
precision and recall when looking for misspelt drug
names. However, this approach suffers in terms of per-
formance in a large corpus. Thus, we used the result-
ing dictionary of true positive misspelt names of drugs
as input for an adapted version of the Trie-based fast
search approach algorithm proposed in [22]. This com-
bined approach showed to be efficient (in terms of per-
formance) on finding dictionary-based variations with
max(ED(word1;word2)) = 1. As a result, hundreds of
potential misspelt variations for drug names were identi-
fied after processing a new set of medical records com-
prising approximately 5 million documents. To illustrate
the potential use of such combined method, 231 positive
misspelt variations for Fluoxetina (Fluoxetine) and 501
positive misspelt variations for Paracetamol have been
already positively identified. Table 4 shows that some of
this variations for the drug Fluoxetina can have high
values for the Edit Distance metric.
Conclusions and future work
In this paper, we presented a hybrid similarity approach
that efficiently performs a joint string and language-
dependent phonetic similarity search over a set of med-
ical records written in Portuguese. Experimental results
showed this method is potentially accurate and able to
Tissot and Dobson Journal of Biomedical Semantics 2019, 10(Suppl 1):17 Page 6 of 7
Table 4 Examples of misspelt variations for Fluoxetina
(Fluoxetine) and the corresponding Edit Distance (ED) values
Misspelt variation ED
dfluoxetina 1
flluoxetina 1
floxetina 1
fluoexetina 1
fluoixetina 1
fluopxetina 1
fluoxertina 1
fluoxetiina 1
fluoxetijna 1
fluoxetin 1
fluoxetinas 1
fluoxetna 1
fluoxetona 1
fluoxettina 1
fluoxetuina 1
fluoxewtina 1
fluoxtina 1
fluozxetina 1
fluuoxetina 1
fluuoxetina 1
fluxetina 1
fluyoxetina 1
flhuoxetin 2
flluoxetin 2
flouxetina 2
fluoxeitna 2
fluoxetian 2
fluxoetina 2
fluxotina 2
fluloextina 3
fluoxetinaate 3
fluoxetinapor 3
flxtina 3
fluoxetinapara 4
infloexetina 4
identify misspelt names of drugs, overcoming the loss of
information inherit from using either exact match search
methods or string based similarity search. We coupled
the proposed approach with a Trie-based fast similarity
search algorithm that is able to use small Edit Distance
threshold (? 1) over the produced dictionary of mis-
spelt names in order to find a broader number of misspelt
variations within an affordable processing time in a large
corpus.
Some of the directions in which this work can be
extended include: a) adapting the phonetic matching pro-
cess originally designed to the Portuguese language to be
used over large corpora in different languages, such as
English; b) integrating our method in a framework for
Medical Records Information Extraction applications to
address the problem of generically dealing with spelling
errors in the information extraction process beyond
names of drugs, including other types of clinical variables,
such as symptoms and diagnoses; c) exploring the use of
machine learning methods to optimally and dynamically
tune the threshold parameters and disambiguating mis-
spelt candidates in cases when they are similar to more
than one medication; d) comparing the proposed solution
with other approximate string match approaches.
Abbreviations
CIS: Outpatient Information System; ED: Edit Distance (or Levenshtein
Distance); EHR: Electronic Health Record; HealTAC: Healthcare Text Analytics
Conference; ICD: International Code of Diseases; NIHR: National Institute for
Health Research; RAAI: Ambulatory Care Individual Report
Acknowledgments
We would like to thank the InfoSaude team for the permission to use the
patient EHR data.
An initial version of this paper has been presented at the Healthcare Text
Analytics Conference 2018 (HealTAC), in April 2018 (http://healtex.org/
healtac-2018/).
About this supplement
This article has been published as part of the Journal of Biomedical Semantics
Volume 10 Supplement 1, 2019: HealTAC-2018: Unlocking Evidence Contained in
Healthcare Free-text. The full contents of the supplement are available online at
https://jbiomedsem.biomedcentral.com/articles/supplements/volume-10-
supplement-1.
Authors contributions
HT designed the joint string and language-dependent phonetic similarity
approach used in the work, performed the experiments and analysd the final
results. RD reviewed the analysis and final results. All authors have read and
approved the final manuscript.
Funding
This study was funded Health Data Research UK (grant No. LOND1), which is
funded by the UK Medical Research Council, Engineering and Physical
Sciences Research Council, Economic and Social Research Council,
Department of Health and Social Care (England), Chief Scientist Office of the
Scottish Government Health and Social Care Directorates, Health and Social
Care Research and Development Division (Welsh Government), Public Health
Agency (Northern Ireland), British Heart Foundation and Wellcome Trust. ADS
is supported by a postdoctoral fellowship from THIS Institute. Publication costs
are funded by UCL open access block grant.
Availability of data andmaterials
The dataset is available at http://github.com/HeglerTissot/mnd, including the
complete set of drug names and words used in our model, as well as the pre
calculated values for the string and phonetic similarity matching metrics for
each pair (drug,word).
Ethics approval and consent to participate
Not applicable.
Consent for publication
Not applicable.
Competing interests
The authors declare that they have no competing interests.
Tissot and Dobson Journal of Biomedical Semantics 2019, 10(Suppl 1):17 Page 7 of 7
Author details
1Institute of Health Informatics, University College London, London, UK.
2Health Data Research UK London, University College London, London, UK.
3Department of Biostatistics and Health Informatics, Institute of Psychiatry,
Psychology and Neuroscience, Kings College London, London, UK.
Published: 12 November 2019
RESEARCH Open Access
Automated SNOMED CT concept and
attribute relationship detection through a
web-based implementation of cTAKES
Martijn G. Kersloot1* , Francis Lau2, Ameen Abu-Hanna1, Derk L. Arts1 and Ronald Cornet1
Abstract
Background: Information in Electronic Health Records is largely stored as unstructured free text. Natural language
processing (NLP), or Medical Language Processing (MLP) in medicine, aims at extracting structured information
from free text, and is less expensive and time-consuming than manual extraction. However, most algorithms in MLP
are institution-specific or address only one clinical need, and thus cannot be broadly applied. In addition, most MLP
systems do not detect concepts in misspelled text and cannot detect attribute relationships between concepts. The
objective of this study was to develop and evaluate an MLP application that includes generic algorithms for the
detection of (misspelled) concepts and of attribute relationships between them.
Methods: An implementation of the MLP system cTAKES, called DIRECT, was developed with generic SNOMED CT
concept filter, concept relationship detection, and attribute relationship detection algorithms and a custom
dictionary. Four implementations of cTAKES were evaluated by comparing 98 manually annotated oncology charts
with the output of DIRECT. The F1-score was determined for named-entity recognition and attribute relationship
detection for the concepts lung cancer, non-small cell lung cancer, and recurrence. The performance of the four
implementations was compared with a two-tailed permutation test.
Results: DIRECT detected lung cancer and non-small cell lung cancer concepts with F1-scores between 0.828 and
0.947 and between 0.862 and 0.933, respectively. The concept recurrence was detected with a significantly higher
F1-score of 0.921, compared to the other implementations, and the relationship between recurrence and lung
cancer with an F1-score of 0.857. The precision of the detection of lung cancer, non-small cell lung cancer, and
recurrence concepts were 1.000, 0.966, and 0.879, compared to precisions of 0.943, 0.967, and 0.000 in the original
implementation, respectively.
Conclusion: DIRECT can detect oncology concepts and attribute relationships with high precision and can detect
recurrence with significant increase in F1-score, compared to the original implementation of cTAKES, due to the
usage of a custom dictionary and a generic concept relationship detection algorithm. These concepts and
relationships can be used to encode clinical narratives, and can thus substantially reduce manual chart abstraction
efforts, saving time for clinicians and researchers.
Keywords: Chart abstraction, Natural language processing, Electronic health records, Algorithms, SNOMED CT
© The Author(s). 2019 Open Access This article is distributed under the terms of the Creative Commons Attribution 4.0
International License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and
reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to
the Creative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver
(http://creativecommons.org/publicdomain/zero/1.0/) applies to the data made available in this article, unless otherwise stated.
* Correspondence: m.g.kersloot@amsterdamumc.nl
1Department of Medical Informatics, Amsterdam Public Health Research
Institute, Amsterdam UMC, University of Amsterdam, Meibergdreef 9, 1105AZ
Amsterdam, The Netherlands
Full list of author information is available at the end of the article
Kersloot et al. Journal of Biomedical Semantics           (2019) 10:14 
https://doi.org/10.1186/s13326-019-0207-3
Background
Much of the data present in Electronic Health Records
(EHRs) are stored as unstructured free text [1] as clini-
cians often resort to making free-text notes, despite
available coding options [2]. The use of free text
should be taken into account when EHR data are
reused for other purposes [3], since data reuse for re-
search and development of clinical decision support
tools can improve healthcare [4]. However, using free-
text notes for searching, summarizing, statistical
analysis, and as input for decision support systems is
challenging [5].
One of the tasks of natural language processing
(NLP) methods, named-entity recognition, aims to ex-
tract structured information from free text that is less
expensive and time-consuming than extracting it
manually [6]. NLP in the medical field, medical lan-
guage processing (MLP), is more challenging than NLP
in various other fields since clinical texts have different
grammar, contain ambiguous abbreviations (i.e., the
same set of letters has multiple meanings), and contain
more misspellings [1, 7]. Recent studies show that
MLP can successfully be used for several purposes in-
cluding deriving comorbidities from the EHR [8], de-
tecting adverse events [9], and finding eligible patients
for clinical trials by attaching clinical concepts to pa-
tient charts (encoding) [10]. Furthermore, MLP has
been proven successful in extracting diagnoses from
free-text notes from the EHR, thereby reducing manual
chart abstraction efforts. It can, for example, be used
to automatically detect the recurrence of breast cancer
in patient charts, reducing the number of manually
reviewed charts by 90% [11]. Other research shows
that MLP can identify uncodified diabetes cases, lead-
ing to a more complete ascertainment of diagnoses
and, thus, better information provision and targeted
care for patients [12].
MLP systems include multiple algorithms to process
free text and extract information from it. Clinical Text
Analysis and Knowledge Extraction System (cTAKES) is
an open-source MLP system from The Apache Software
Foundation [13]. It is based on the Unstructured Infor-
mation Management Architecture (UIMA) framework
and the OpenNLP toolkit [13]. cTAKES provides linguis-
tic and semantic annotations for unstructured free text
[13] using SNOMED CT [14] and RxNorm [15] diction-
aries. cTAKES is designed to be modular and extensible
at the information model and method levels, ensuring
that it is suitable for a variety of use cases [16].
MLP algorithms have been implemented in various
systems. A recent systematic review has shown that
most implementations of MLP algorithms are institu-
tion-specific, address only one clinical need, might be
overfitted, and thus not scalable [17]. In addition, most
MLP systems do not detect concepts in misspelled text,
e.g. Smll cell lng cancer, only detect unqualified rela-
tionships (e.g. Non-small cell lung cancer relates in a
way to Recurrent, Fig. 1.1) between concepts or their
instances, and cannot detect attribute relationships, e.g.
Non-small cell lung cancer with Recurrent as Clinical
course (Fig. 1.2). Attribute relationships make the type
of relationship between concepts or their instances ex-
plicit (e.g. Clinical Course in Fig. 1.2).
Since most MLP systems do not offer these algo-
rithms, this study aimed to develop a cTAKES imple-
mentation that includes generic algorithms for the
detection of concepts from properly spelled and mis-
spelled descriptions and attribute relationships between
these concepts. The implementation is evaluated by en-
coding free-text oncology charts to detect charts that
describe recurrent non-small cell lung cancer, and use
these outcomes to calculate the F1-score.
Material and methods
cTAKES
cTAKES enables encoding through several algorithms,
which are included in several pipelines. We used cTAKES
AggregatePlaintextFastUMLSProcessor pipeline (e.g. the
Fig. 1 A representation of a unqualified relationship between Non-small cell lung cancer and Recurrent (1) and an attribute relationship of
Non-small cell lung cancer with Recurrent as Clinical course (2). The attribute relationship is modelled as a SNOMED CT concept definition
diagram of recurrent non-small cell lung cancer (a new post-coordinated expression). Purple blocks represent defined concepts, blue blocks
represent primitive SNOMED CT concepts and yellow blocks represent attributes. Attribute groups are represented using a white circle, and
conjunctions are represented using a black dot
Kersloot et al. Journal of Biomedical Semantics           (2019) 10:14 Page 2 of 13
output of one algorithm becomes the input to the next
[18]), as shown in Fig. 2, for the pre-processing and
processing of free-text clinical narratives, since it uses
the Unified Medical Language System (UMLS) [19] as
its dictionary. In this project, we focus on the
SNOMED CT concepts that are included in the UMLS,
as the hierarchical and relational structure of SNOMED
CT allows us to determine and define relationships be-
tween medical concepts.
Development of an MLP tool
Our project involved the development of a cTAKES
implementation named Disease Information and Rela-
tionship ExtraCtion Tool (DIRECT). cTAKES provides
a generic way of concept matching (through dictionary
look-up), and detection of syntactic relationships and
RESEARCH Open Access
Natural language processing for disease
phenotyping in UK primary care records
for research: a pilot study in myocardial
infarction and death
Anoop D. Shah1,2,3,4*, Emily Bailey4, Tim Williams5, Spiros Denaxas1,2,3, Richard Dobson1,2,3,6 and
Harry Hemingway1,2,3
From UK Healthcare Text Analysis Conference (HealTAC 2018)
Manchester, UK. 18-19 April 2018
Abstract
Background: Free text in electronic health records (EHR) may contain additional phenotypic information beyond
structured (coded) information. For major health events  heart attack and death  there is a lack of studies evaluating
the extent to which free text in the primary care record might add information. Our objectives were to describe the
contribution of free text in primary care to the recording of information about myocardial infarction (MI), including
subtype, left ventricular function, laboratory results and symptoms; and recording of cause of death. We used the
CALIBER EHR research platform which contains primary care data from the Clinical Practice Research Datalink (CPRD)
linked to hospital admission data, the MINAP registry of acute coronary syndromes and the death registry. In CALIBER
we randomly selected 2000 patients with MI and 1800 deaths. We implemented a rule-based natural language engine,
the Freetext Matching Algorithm, on site at CPRD to analyse free text in the primary care record without raw
data being released to researchers. We analysed text recorded within 90 days before or 90 days after the MI,
and on or after the date of death.
Results: We extracted 10,927 diagnoses, 3658 test results, 3313 statements of negation, and 850 suspected
diagnoses from the myocardial infarction patients. Inclusion of free text increased the recorded proportion of
patients with chest pain in the week prior to MI from 19 to 27%, and differentiated between MI subtypes in
a quarter more patients than structured data alone. Cause of death was incompletely recorded in primary care; in 36%
the cause was in coded data and in 21% it was in free text. Only 47% of patients had exactly the same cause of death
in primary care and the death registry, but this did not differ between coded and free text causes of death.
Conclusions: Among patients who suffer MI or die, unstructured free text in primary care records contains much
information that is potentially useful for research such as symptoms, investigation results and specific diagnoses.
Access to large scale unstructured data in electronic health records (millions of patients) might yield important
insights.
Keywords: Free text, Myocardial infarction, Primary care, Chest pain, Natural language processing
© The Author(s). 2019 Open Access This article is distributed under the terms of the Creative Commons Attribution 4.0
International License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and
reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to
the Creative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver
(http://creativecommons.org/publicdomain/zero/1.0/) applies to the data made available in this article, unless otherwise stated.
* Correspondence: anoop@doctors.org.uk
1Health Data Research UK London, University College London, 222 Euston
Road, London NW1 2DA, UK
2Institute of Health Informatics, University College London, 222 Euston Road,
London NW1 2DA, UK
Full list of author information is available at the end of the article
Shah et al. Journal of Biomedical Semantics 2019, 10(Suppl 1):20
https://doi.org/10.1186/s13326-019-0214-4
Background
Electronic health records (EHR) are increasingly used for
clinical research, but much of the information they
contain is stored in an unstructured way [1, 2]. Research
projects using EHR databases conventionally use only
the structured information, but could potentially miss
important information if it is not coded correctly (Fig. 1).
There has been increasing interest in using natural lan-
guage processing (NLP) to extract additional information
from the free text for research, such as in the eMERGE
hospital network in the US [3]. However, there have been
few studies using NLP on primary care data, which is
crucial for understanding early manifestations of disease
(before a patient is admitted to hospital or attends a
secondary care clinic). This may enable the development
of early diagnosis and treatment strategies.
For example, a previous study using structured infor-
mation in primary care data found more than a 5-fold
increase in the frequency of chest pain consultations in
the two months prior to a myocardial infarction (MI)
[4]. If some consultations for chest pain are not recorded
using appropriate codes, as suggested in US studies [5],
the prevalence of chest pain prior to MI may be under-
estimated. Accurate information on such symptoms is
essential to inform public health endeavours aimed at
preventing MI, but has not previously been studied on a
large scale in the UK.
We used primary care data from the Clinical Practice
Research Datalink (CPRD), a population-based source of
longitudinal clinical information. Although early studies
using CPRD manually reviewed small samples of text to
validate coded diagnoses [6], there has been little re-
search on the potential contribution of free text beyond
the coded information in UK primary care, and previous
studies have been limited to a few hundred texts [710].
At the time of this study, free text from CPRD primary
care was stored at the Department of Health, and could
be released to researchers after manual anonymisation
Fig. 1 Illustration of patients experience, information entered in the structured part of the primary care record (Read codes), and additional
information that might be available in free text. In this hypothetical example, the subtype of myocardial infarction and preceding symptoms are
present only in the free text
Shah et al. Journal of Biomedical Semantics 2019, 10(Suppl 1):20 Page 2 of 10
by CPRD staff. This was time-consuming and costly,
feasible for only small samples of text for validation
studies. However, free text is no longer collected or made
available by CPRD because of confidentiality concerns, so
it is essential to know what is missing from the structured
data.
To address these challenges, we developed and vali-
dated a natural language processing system, the Freetext
Matching Algorithm (FMA) [7]. This is an entity linking
program which maps sequences of words to Read codes,
using manually defined synonyms and patterns to recog-
nise the context of words in the text. As well as diagnoses,
it can extract symptoms, dates and laboratory test results.
The output of the algorithm is structured, containing only
codes and numeric values. In this paper we describe a
pilot project to use FMA to analyse primary care free text
at source, without needing manual anonymisation, thus
analysing larger samples of text than has previously been
possible.
Our specific aims were to describe the contribution of
free text to the recording of information about MI in
CPRD primary care data, including MI subtype, left
ventricular function, laboratory results, symptoms, and
whether the MI record related to a new or historic
event. We also used FMA to investigate cause of death
recording in general practice, comparing the results to
the cause of death recorded in the death registry.
Methods
Study data source
We used linked electronic health records from four
data sources in England (the CALIBER resource [11]),
which contains primary care data from CPRD linked to
administrative hospital records (Hospital Episode Sta-
tistics, HES) and death registrations from the Office for
National Statistics (ONS). The CALIBER programme
involved additional linkage with the Myocardial Ischaemia
National Audit Project (MINAP), facilitated by CPRD, and
contained data from 244 practices in England. We previ-
ously carried out a study of the completeness and diagnos-
tic validity of MI records in CALIBER [12], which included
21,482 patients with a first MI recorded in either MINAP,
HES, ONS or CPRD primary care in 20032009. For this
pilot project we chose a random subset of 2000 patients
from this study. This sample size would yield enough free
text to demonstrate the value of this approach as it would
be too large to anonymise manually, but it would be
feasible to extract and analyse as a pilot project. We also
studied 1800 patients who died of any cause between 2001
and 2009 and had a death registry record in linked ONS
data (200 patients per year).
For the MI population, we analysed free text in the
primary care record associated with clinical, test or re-
ferral events up to 90 days before or after the MI, and
for the death population, we analysed free text in pri-
mary care associated with clinical or referral events on
or after the date of death.
Natural language processing
The Freetext Matching Algorithm (FMA) is a natural
language processing system designed to extract Read
codes and other structured data from UK general prac-
tice records. It was developed using small samples of
pre-anonymised text from CPRD and is available under
an open source license (GPL Version 3).
FMA has been described previously [7]; briefly it is a
rule-based annotation and information extraction engine.
The text is first cleaned of semi-structured computer-
generated phrases (defined in a manual lookup), then
converted to lower case and split into individual words.
The program identifies dates, numbers and words, and
maps individual words to lookup tables of medical words
(any word contained within any Read term) and non-
medical words (from an English lexicon). If a word does
not match any entry in the dictionaries, it is assumed to
be misspelt, and the program attempts spelling correction
with a single letter insertion or substitution algorithm.
Attributes such as negation are identified by sequential
application of regular expression rules, and the program
then attempts to match sequences of up to five words to
Read terms. If the text phrase does not match a Read term
exactly, parts of the phrase are substituted by alternative
words and phrases using the synonym table. A custom
scoring function rates the quality of each potential match,
and returns the Read term with the closest match above a
minimum threshold. The output of the algorithm is a se-
quence of Read terms or quantitative data with attributes.
We tested the FMA on pre-anonymised samples of
free text from patients with coronary artery disease, and
added terms to the lookup tables to enable it to detect
subtype of myocardial infarction and left ventricular
function. We collaborated with CPRD to arrange for
their staff to run the program on free text for the study
population. CPRD staff verified that the output con-
tained only coded or numeric data before releasing it to
researchers. We used FMA in preference to other open
source NLP tools because it was small (a single 200 KB
executable and 8.5MB lookup tables) and required no
installation or special software, so it was easy for CPRD
staff to run. It also had the advantage of being custo-
mised for text in primary care records, returning results
in a similar format to existing structured CPRD data.
Information extracted from free text
We summarised the frequencies of Read codes extracted
by FMA with different data types within 90 days of
myocardial infarction. We calculated the frequencies of
recording in Read codes and free text for symptoms and
Shah et al. Journal of Biomedical Semantics 2019, 10(Suppl 1):20 Page 3 of 10
investigation results of particular interest, such as chest
pain, shortness of breath, pulse rate, angiogram results
and left ventricular function.
Classifying the type of myocardial infarction
For patients who had a MINAP record in CALIBER, i.e.
those who arrived at hospital alive and whose data were
submitted to the national acute coronary syndrome
registry, we investigated the accuracy of structured and
unstructured information in the primary care record.
We classified the type of myocardial infarction according
to the closest STEMI or NSTEMI Read code or free text
record after the date of MI within 30 days. We calculated
the sensitivity and specificity of Read codes and free text
for identifying the type of MI.
Validity of myocardial infarction records
Two clinicians manually reviewed the CALIBER record
(CPRD structured primary care record, linked data from
HES, and information extracted by FMA), for patients
with MI recorded in primary care but not HES or
MINAP. They adjudicated whether or not the MI Read
code in CPRD represented a true current MI, resolving
any disagreements by discussion to reach a consensus.
For patients with MI recorded in HES, MINAP or ONS
within 30 days of the primary care record, we assumed
that the MI was genuine and did not review their record
manually.
We tested a machine learning algorithm (Random For-
est [13]) on the task of discriminating between correct
and incorrect MI records, using the manual adjudication
or presence of a HES or MINAP record as the gold
standard for a true MI. Predictor variables for this task
included the likelihood of the exact Read code to be as-
sociated with a HES or MINAP record for MI in other
patients (Supplementary Table 7 in Herrett et al. [12]),
specific details about the MI record (the consultation
type, whether it was entered on the date it occurred,
whether there was a coronary register entry on the same
date, whether it was recorded as a new or continuing
episode), whether there was a Read code for hospital
admission within 7 days, and whether there was a Read
code for chest pain or shortness of breath within 7 days.
We also generated binary variables for the presence of
the most common 100 Read codes entered on the same
date, or dated within 30 days of the MI date, or Read
codes extracted by FMA within 30 days of the MI date.
We generated composite variables grouping Read codes
by their first 1, 2 or 3 characters, in case groups of Read
codes were better predictors than sparse variables en-
coding the presence of individual Read codes.
We used Random Forest with 100 trees, trying all vari-
ables at every split (to avoid bias due to a large proportion
of sparse or non-informative variables). We calculated the
accuracy of models generated from 200 bootstrap samples
of the data, using the patients not selected as the test set
for each model.
Cause of death
We manually reviewed structured death certificate infor-
mation, Read codes and diagnoses extracted by FMA
from CPRD primary care data to assign the most likely
underlying cause of death for the sample of 1800
patients. We converted the causes of death to ICD-10
using the Read to ICD-10 mapping table, and allocated
the underlying cause of death by manual review of the
extracted coded diagnoses and application of the ICD-10
selection rules [14], blinded to the cause of death
recorded in the death registry (we did not have access to
review the raw free text diagnoses). We calculated the
proportion of deaths with cause recorded in different
ways, giving priority to the more specific information
(e.g. a free text diagnosis with death certificate category
was given priority over a Read coded diagnosis without
category). We compared the causes of death thus
extracted with the gold standard cause in the death
registry. We assessed the similarity of the underlying
ICD-10 code and concordance for three common diag-
nosis groups: coronary heart disease, cerebrovascular
disease and cancers.
Statistical analysis
All statistical analysis was carried out using R Version
3.4 [15], using the packages CALIBERdatamanage and
CALIBERcodelists (published on R-Forge [16]) to assist
with data management.
Results
FMA analysed 31,913 text entries in CPRD containing
705,523 words in 40 min on a Windows 2008 Server.
Information extracted from free text for myocardial
infarction patients
We included 2000 MI patients in this study, with me-
dian age 75 years (interquartile range 63, 83), of whom
781 (39%) were female. FMA extracted 21,369 Read
codes with the attribute medical history or current or
previous condition, of which 10,957 were diagnoses
(defined as Read codes in the diagnosis chapter, rather
than administration, procedures, test results etc.), and
1117 suspected conditions, of which 850 were diagnoses.
FMA also extracted 3658 test results, 3313 statements of
negation and 968 entries referring to hospital admission
(Fig. 2). The most common negated conditions were
chest pain (377 entries), breathlessness or dyspnoea
(300), unspecified pain (208) and oedema (121). The
most common Read coded diagnosis in the free text was
acute myocardial infarction (8.1%) (Table 1).
Shah et al. Journal of Biomedical Semantics 2019, 10(Suppl 1):20 Page 4 of 10
Among patients with MI not recorded in CPRD struc-
tured data, 108 (18.9%) had MI recorded in free text
within 30 days. The proportion of patients with record-
ing of symptoms and investigations associated with MI
increased when free text was included. For example, the
prevalence of chest pain within 7 days prior to MI would
be underestimated by a third if free text were ignored
(18.9% instead of 27.2%) (Table 2).
Classifying the type of myocardial infarction
Among the 608 patients with a MINAP record giving
detailed information about the MI, 149 (25%) had a Read
code stating the type of MI and 46 (8%) had this infor-
mation available only in the free text. Inclusion of free
text information increased the sensitivity for detection of
MI subtypes, with a slight reduction in sensitivity and
positive predictive value (Table 3). Concordance of
derived MI subtypes with the MINAP gold standard was
lower for free text (78.3%; 95% CI 63.6%, 89.1%) than
Read codes (91.9, 95% CI 86.4%, 95.8%).
Validity of myocardial infarction records
Our manual review of coded and free text data con-
cluded that the majority of patients with MI recorded
only in CPRD primary care data (210/267) had a genuine
recent MI. In some cases, free text contributed directly
to our decision; for example, one patient had an MI code
on the same date as a mental health diagnosis, but the
free text stated that the MI was one year ago. We
assessed whether information in the free text could
improve the performance of machine learning models
for identifying a true MI. Using the Random Forest
model on the entire sample of 2000 patients, the per-
centage correct (mean and 95% bootstrap confidence
interval) without using free text was 95.9% (95% CI
94.3%, 97.4%) and using free text was 95.6% (95% CI
93.9%, 97.3%); i.e. no significant difference.
Cause of death
Cause of death was incompletely recorded in CPRD
primary care data, with only a slight improvement over
time. Free text contributed 37% of the causes recorded
in primary care (381/1022) (Table 4). Only 46.7% of pa-
tients (95% CI 43.6%, 49.8%) had the same exact ICD-10
code for the underlying cause in primary care and the
death registry, but in 72.5% (95% CI 69.7%, 75.2%) the
cause was from the same ICD-10 chapter. CPRD pri-
mary care data had high specificity but moderate sensi-
tivity for identifying coronary, cerebrovascular or cancer
deaths, but no difference in accuracy between structured
and free text records (Table 5).
Discussion
We analysed a larger quantity of unstructured free text
in a UK primary care database than any previous study.
We were able to do so by using natural language proces-
sing software to extract information without requiring
manual review or anonymisation of the free text record.
Free text notes in primary care records commonly contain
brief expressions, non-grammatical phrases, spelling
mistakes and irregular punctuation, posing a particular
challenge to NLP tools [17]. There have been attempts to
better phenotype myocardial infarctions using NLP on
hospital discharge summaries [18], but none using
primary care data. Overall there have been very few NLP
studies on free text in UK primary care [710]; this is the
largest to date. Under CPRD policy at the time of the
study, free text required manual anonymisation by CPRD
staff before being released to researchers, and anonymis-
ing the 705,523 words analysed in this project would have
cost over £35,000. We previously carried out a validation
study of myocardial infarction (MI) in the CALIBER
linked EHR resource. We found that agreement between
the data sources in CALIBER was poor [12]. MI records in
primary care data typically did not differentiate between
subtypes of MI (STEMI, ST segment elevation MI, or
NSTEMI, non ST segment elevation MI), despite the
clinical importance of this distinction.
Summary of main findings
We found that free text contained a large amount of in-
formation on symptoms, test results (e.g. left ventricular
Fig. 2 Data items extracted from primary care free text for 2000 patients within 90 days before or after myocardial infarction
Shah et al. Journal of Biomedical Semantics 2019, 10(Suppl 1):20 Page 5 of 10
function), clinical measurements, diagnoses, admissions
and administration (e.g. sickness certificates), much of
which was not present in the structured data, and could
potentially be useful for clinical research studies. Free
text contained a large number of records of suspected
conditions, for which the clinical system does not pro-
vide a facility for structured recording. Symptoms related
to myocardial infarction such as chest pain and shortness
of breath were recorded in the free text rather than as Read
codes in about a third of patients, because the information
was scanned as an image and not converted to text.
We attempted to use free text to help determine if a
MI record in CPRD with no linked MI record in another
data source was a true current MI, rather than an incor-
rectly dated historic event. Based on manual review of
the FMA-annotated CPRD record, we concluded that
the vast majority were true current MI, which limited
our ability to quantify the contribution of the free text
for such determination. The small number of incorrect
MI records made this a difficult machine learning task,
as it is known that imbalance in datasets for machine
learning can lead to a biased classifier. Potential methods
of improving performance on such tasks may be to alter
the training balance [19], or develop bias-aware prob-
abilistic classifiers [20].
Cause of death was incompletely recorded, even with
the addition of free text, and in a significant proportion
of cases the cause of death in the death registry and in
primary care were different. This may be because the
general practitioner did not receive definitive cause of
death information from post mortems or coroner re-
ports; cause of death information was more complete
and accurate for cancer deaths, where there is less ambi-
guity. Linked registry data seems to be the only complete
and accurate source of cause of death data.
Limitations
Research studies incorporating NLP must include valid-
ation of variables derived using NLP, which is usually
done by manual review of a random subset of the
records. The main limitation of our study was that we
were unable to manually validate the extracted data
items against the original raw text, because CPRD with-
drew access to free text for researchers part-way through
the study (and no longer collects free text). We refer to
a previous validation of the Freetext Matching Algo-
rithm demonstrating over 90% precision [7], which is
adequate for this project demonstrating the broad utility
of free text in primary care, but studies with clinical im-
plications would require the NLP error rate for specific
variables to be propagated into the uncertainty of the
final estimates. For some measures we were able to com-
pare information extracted from text with linked registry
datasets (MINAP and the death registry).
Table 1 Most common Read codes extracted from free text for
2000 patients within 90 days of MI in CALIBER (top five codes in
each category)
Number of records
(%)
Read
code
Read term
Current or previous condition (diagnosis Read codes)
887 (8.1%) G30z.00 Acute myocardial infarction NOS
443 (4.1%) R065.00 [D] Chest pain
304 (2.8%) C10..00 Diabetes mellitus
272 (2.5%) G307100 Acute non-ST segment elevation myocar-
dial infarction
256 (2.3%) G33..00 Angina pectoris
Current or previous condition (non ? diagnosis Read codes)
991 (9.5%) 8H3Z.00 Other hospital admission NOS
913 (8.8%) 8H00 Referral for further care
795 (7.6%) 1M00 Pain
469 (4.5%) 173..00 Breathlessness
445 (4.3%) 8HA..11 Discharged from follow up
Quantitative test result
577 (15.8%) 42Z7.00 Red blood cell distribution width
142 (3.9%) 42M..00 Lymphocyte count
141 (3.9%) 42N..00 Monocyte count
139 (3.8%) 42K..00 Eosinophil count
138 (3.8%) 42J..00 Neutrophil count
Absence of condition (diagnosis Read codes)
121 (7.8%) R023.00 [D] Oedema
105 (6.8%) G33..00 Angina pectoris
90 (5.8%) R065.00 [D] Chest pain
57 (3.7%) A....00 Infectious and parasitic diseases
38 (2.5%) R006200 [D] Fever NOS
Absence of condition (non-diagnosis Read codes)
281 (15.6%) 182..00 Chest pain
274 (15.2%) 173..00 Breathlessness
208 (11.5%) 1M00 Pain
89 (4.9%) 2I18.12 O/E - tenderness
48 (2.7%) 199..00 Vomiting
Suspected condition (diagnosis Read codes)
70 (8.2%) G30z.00 Acute myocardial infarction NOS
48 (5.6%) K190.00 Urinary tract infection, site not specified
40 (4.7%) A.00 Infectious and parasitic diseases
32 (3.8%) G33..00 Angina pectoris
23 (2.7%) G581.13 Impaired left ventricular function
Suspected condition (non-diagnosis Read codes)
44 (16.5%) 8H00 Referral for further care
18 (6.7%) 8H3Z.00 Other hospital admission NOS
16 (6.0%) 1M00 Pain
9 (3.4%) 173..00 Breathlessness
7 (2.6%) 2C2..11 O/E - anaemic
Shah et al. Journal of Biomedical Semantics 2019, 10(Suppl 1):20 Page 6 of 10
Another limitation is that we used only one natural
language processing algorithm; other open source anno-
tators have been released since the development of the
FMA. Examples include cTakes [21] (Mayo Clinic),
MetaMap [22] (US National Library of Medicine), Hitex
[23] (Harvard Medical School) and Bio-Yodie, developed
as part of the KConnect Horizon 2020 project [24]. For
this project we used our in-house FMA algorithm be-
cause of its small size and simplicity. We limited the
sample size in order to be able to solve any unexpected
problems, and to facilitate CPRDs process of assuring
that the output contained only numerical data, with no
unintended leak of text.
Another limitation was the use of only a single annota-
tor for the cause of death classification. The ICD-10
rules for selecting the underlying cause of death are
complex; in this study this task was performed by a
clinician with experience in classifying the cause of death
for over 2000 patients in a previous study [7]. It would
have required considerable resource to train another an-
notator to the same level. Given that agreement between
the primary care record and death registry was poor
even with a well-trained annotator, it was unlikely that
additional annotation would alter the conclusion that
the primary care record is an unreliable source of cause
of death information.
Clinical implications
Although there has been much research activity around
natural language processing of clinical text, few advances
have made it to the clinic [25]. A fundamental problem
is that information extracted from text cannot be relied
upon to be completely accurate because of the nuances
of human language; an error rate of 5% may be accom-
modated in research but is not an acceptable risk when
planning treatment for an individual patient. A potential
Table 2 Information available in CPRD primary care data (coded data and free text) for a random sample of 2000 patients with
myocardial infarction in the linked CALIBER dataset
Data element Structured data only Structured or free text % increase by
using free text
Within 90 days before or after MI:
Pulse rate 323 (16.2%) 634 (31.7%) 96%
Blood pressure 1557 (77.9%) 1609 (80.5%) 3%
Left ventricular function result 115 (5.8%) 309 (15.5%) 169%
Coronary angiogram results 26 (1.3%) 198 (9.9%) 662%
Irregular pulse 2 (0.1%) 6 (0.3%) 200%
Atrial fibrillation or flutter 121 (6.0%) 153 (7.6%) 26%
Chest pain ?7 days before MI 378 (18.9%) 543 (27.2%) 44%
Chest pain ?90 days before MI 455 (22.8%) 642 (32.1%) 41%
Shortness of breath ?7 days before MI 62 (3.1%) 102 (5.1%) 65%
Shortness of breath ?90 days before MI 125 (6.3%) 196 (9.8%) 57%
Table 3 Type of MI as recorded in CPRD primary care data, for patients with a gold standard MI subtype record in MINAP
Subtype of MI
Primary care source of type of MI STEMI (N = 315) NSTEMI (N = 293)
Structured (Read codes)
(number of patients)
STEMI 41 6
NSTEMI 6 96
Free text
(number of patients)
STEMI 13 5
NSTEMI 5 23
Patients with no information on type of MI in primary care 250 163
Accuracy of MI classification using structured data Sensitivity, % 13.0 (9.5, 17.2) 32.8 (27.4, 38.5)
Specificity, % 98.0 (95.6, 99.2) 98.1 (95.9, 99.3)
Positive predictive value, % 87.2 (74.3, 95.2) 94.1 (87.6, 97.8)
Accuracy of MI classification using structured and free text data Sensitivity, % 17.1 (13.1, 21.8) 40.6 (34.9, 46.5)
Specificity, % 96.2 (93.4, 98.1) 96.5 (93.8, 98.2)
Positive predictive value, % 83.1 (71.7, 91.2) 91.5 (85.4, 95.7)
Shah et al. Journal of Biomedical Semantics 2019, 10(Suppl 1):20 Page 7 of 10
solution is to embed real-time natural language process-
ing within clinical systems, to generate structured data
whilst giving clinicians the freedom to express their
thoughts in a natural way. The NHS Common User
Interface guidelines [26] contains recommendations for
such technology, but current systems have not yet
implemented it in practice.
Research implications
NLP has been applied to primary care records in other
countries for research studies attempting early diagnosis
of multiple sclerosis [27], classification of childhood
respiratory illnesses [28, 29] and identification of heart
failure symptoms [30]. However, NLP of primary care
notes can be challenging  the language is terse, often
ungrammatical and abbreviated [17]. The sublanguage of
primary care clinical notes has not been studied at scale,
nor are we aware of international comparisons in this
area, which would be helpful for generalising NLP
methodology worldwide.
One of the difficulties in healthcare text analytic re-
search is the governance and access restrictions on the
use of free text. In the UK, CPRD no longer provides
access to primary care free text, following the Informa-
tion Commissioners Office instructions (https://ico.org.
uk/), leaving The Health Improvement Network as the
only UK primary care research database containing free
text. CPRD can facilitate GP questionnaires to validate
or enhance a small sample of records (at additional
cost), but large-scale research using CPRD will be based
entirely on the coded data. In the long term, incentives
such as the Quality and Outcomes Framework [31] may
help to improve data completeness for specific data
items that are clinically important.
However, in some secondary care NHS Trusts, clinical
text is available for research under secure governance
arrangements. The South London and Maudsley NHS
Trust has been using the Cogstack architecture [32] to
analyse clinical text for mental health research for a
number of years [33]. At Kings College Hospital, a simi-
lar system is in use for audit and quality improvement,
and is undergoing ethical review for use for research.
The value of primary care free text as demonstrated in
our study and others [8, 9] makes the case for
investment in systems to enable natural language
processing on primary care free text at source, with
appropriate governance to maximise the clinical benefits
Table 4 Proportion of deaths with a cause recorded in CPRD primary care data (N = 600 for each 3-year band)
How cause of death is recorded in primary care Years 20012003 Years 20042006 Years 20072009 Accuracy (95% CI)
Transcribed death certificate entry (e.g. 1a Heart failure, 1b Acute myocardial infarction)
Read codes 46 (7.7%) 103 (17.2%) 112 (18.7%) 59% (52%, 65%)
Free text 32 (5.3%) 41 (6.8%) 47 (7.8%) 53% (44%, 63%)
Explicit cause of death (e.g. Cause of death: myocardial infarction)
Read codes 26 (4.3%) 47 (7.8%) 36 (6.0%) 30% (22%, 40%)
Free text 16 (2.7%) 17 (2.8%) 16 (2.7%) 55% (40%, 69%)
Cause of death implied by diagnosis dated on or after date of death
Read codes 140 (23.3%) 79 (13.2%) 52 (8.7%) 44% (37%, 51%)
Free text 69 (11.5%) 67 (11.2%) 76 (12.7%) 40% (34%, 46%)
No cause of death in CPRD 271 (45.2%) 246 (41.0%) 261 (43.5%) 
Table 5 Accuracy of underlying cause of death in CPRD primary
care data compared to the death registry gold standard, for the
1022 individuals with cause of death recorded in both sources.
For coronary deaths not recorded as coronary in CPRD, the
most common causes in CPRD were I469 Cardiac arrest, I500
Congestive heart failure and I501 Left ventricular failure. For
stroke deaths not recorded as stroke in CPRD, the most
common causes in CPRD were J180 Bronchopneumonia,
unspecified, J189 Pneumonia, unspecified and F03X
Unspecified dementia
Source of cause of death record in CPRD Free text Coded
Number of deaths 381 641
Same underlying cause 184 (48.3%) 293 (45.7%)
Same 2-character ICD-10 code for under-
lying cause
222 (58.3%) 371 (57.9%)
Same ICD-10 chapter for underlying cause 278 (73.0%) 463 (72.2%)
Coronary deaths (ICD-10 I20I25, N = 163):
Sensitivity, % 65.3 (50.4,
78.3)
68.4 (59.1,
76.8)
Specificity, % 97.9 (95.7,
99.1)
98.3 (96.8,
99.2)
Cerebrovascular deaths (ICD-10 F01, I60I69, N = 101):
Sensitivity, % 66.7 (51.6,
79.6)
58.5 (44.1,
71.9)
Specificity, % 98.5 (96.5,
99.5)
97.8 (96.2,
98.8)
Cancer deaths (ICD-10 C00C97, N = 268):
Sensitivity, % 93.0 (86.1,
97.1)
80.4 (73.5,
86.1)
Specificity, % 95.7 (92.7,
97.8)
98.5 (97.0,
99.4)
Shah et al. Journal of Biomedical Semantics 2019, 10(Suppl 1):20 Page 8 of 10
of such research whilst protecting the confidentiality of
patient data.
Conclusion
Unstructured free text in primary care records contains
much information that is potentially useful for research
and is not recorded in the structured data, such as
symptoms, investigation results and specific diagnoses.
Natural language processing to convert this information
into a structured form can enrich primary care data at
scale for research, and potentially yield population-based
insights into early presentations of disease.
Abbreviations
CALIBER: Clinical Research using Linked Bespoke datasets and Electronic
Records; CPRD: Clinical Practice Research Datalink; EHR: electronic health
record; FMA: Freetext Matching Algorithm; GP: general practitioner;
HES: Hospital Episode Statistics; ICD: International Classification of Diseases;
MI: myocardial infarction; MINAP: Myocardial Ischaemia National Audit
Project; NHS: National Health Service; NLP: natural language processing;
NSTEMI: non ST elevation myocardial infarction; ONS: Office for National
Statistics; STEMI: ST elevation myocardial infarction; UK: United Kingdom
Acknowledgements
We acknowledge the help of Nick Wilson and other CPRD staff in data
extraction and running the FMA software. An initial version of this paper has
been presented at the Healthcare Text Analytics Conference 2018 (HealTAC),
in Manchester, UK in April 2018.
About this supplement
This article has been published as part of the Journal of Biomedical
Semantics Volume 10 Supplement 1, 2019: HealTAC-2018: Unclocking
Evidence Contained in Healthcare Free-text. The full contents of the
supplement are available onlline at https://jbiomedsem.biomedcentral.com/
articles/supplements/volume-10-supplement-1.
Authors contribution
ADS wrote the Freetext Matching Algorithm software, analysed the data and
drafted the paper. EB and ADS manually adjudicated the myocardial
infarction records. TW arranged for the Freetext Matching Algorithm to run
at CPRD. TW and HH supervised the study. All authors contributed to, read
and approved the final manuscript.
Funding
The CALIBER project was funded by the Wellcome Trust (086091/Z/08/Z) and
the National Institute of Health Research (NIHR) (RP-PG-0407-10314). This
study was supported by the Farr Institute of Health Informatics Research,
funded by the Medical Research Council (K006584/1) in partnership with
other funders. ADS was supported by a Wellcome Trust Clinical Research
Training Fellowship (0938/30/Z/10/Z) and is currently supported by the NIHR
University College London Hospitals Biomedical Research Centre and a post-
doctoral fellowship from THIS Institute. Publication costs are funded by THIS
Institute. HH is a National Institute for Health Research (NIHR) Senior Investi-
gator. His work is supported by: 1. Health Data Research UK, which is funded
by the UK Medical Research Council, Engineering and Physical Sciences Re-
search Council, Economic and Social Research Council, Department of Health
and Social Care (England), Chief Scientist Office of the Scottish Government
Health and Social Care Directorates, Health and Social Care Research and De-
velopment Division (Welsh Government), Public Health Agency (Northern
Ireland), British Heart Foundation and Wellcome Trust (grant no. LOND1). 2.
The BigData@Heart Consortium, funded by the Innovative Medicines
Initiative-2 Joint Undertaking under grant agreement No. 116074. This Joint
Undertaking receives support from the European Unions Horizon 2020 re-
search and innovation programme and EFPIA; it is chaired by DE Grobbee
and SD Anker, partnering with 20 academic and industry partners and ESC.
3. The National Institute for Health Research University College London Hos-
pitals Biomedical Research Centre.
Availability of data and materials
The data that support the findings of this study are available from CPRD, but
restrictions apply to the availability of these data, which were used under
license for the current study, and so are not publicly available. This project
uses the CALIBER dataset, which is de-identified (pseudonymised) but is suffi-
ciently detailed to be considered sensitive data with a potential risk of pa-
tient re-identification if combined with other data sources, and the terms of
the data sharing agreement do not permit it to be shared. Access to the
database for research can be obtained by submitting an application to the
CPRD Independent Scientific Advisory Committee.
All the software used in this project is available as open source software. The
Freetext Matching Algorithm is available on Github: https://github.com/
anoopshah/freetext-matching-algorithm and the lookups are on https://
github.com/anoopshah/freetext-matching-algorithm-lookups. Operating
system: Windows, or Linux with wine and Visual Basic 6 runtime.
Programming language: Visual Basic 6. License: GNU General Public License
v3.0.
Ethics approval and consent to participate
The CALIBER programme has been approved by a NHS Research Ethics
Committee (09/H0810/16). This study was approved by the CPRD
Independent Scientific Advisory Committee (protocol 12_117). Individual
patient consent is not required for observational CPRD studies, but patients
have the opportunity to opt out of contributing to the database.
Consent for publication
Not applicable.
Competing interests
The authors declare that they have no competing interests.
Author details
1Health Data Research UK London, University College London, 222 Euston
Road, London NW1 2DA, UK. 2Institute of Health Informatics, University
College London, 222 Euston Road, London NW1 2DA, UK. 3The National
Institute for Health Research University College London Hospitals Biomedical
Research Centre, University College London, 222 Euston Road, London NW1
2DA, UK. 4University College London Hospitals NHS Foundation Trust, 235
Euston Road, London NW1 2BU, UK. 5Clinical Practice Research Datalink,
Medicines and Healthcare products Regulatory Agency, 10 South Colonnade,
London E14 4PU, UK. 6Department of Biostatistics and Health Informatics,
Kings College London, De Crespigny Park, Denmark Hill, London SE5 8AF,
UK.
Published: 12 November 2019
RESEARCH Open Access
OHMI: the ontology of host-microbiome
interactions
Yongqun He1* , Haihe Wang1,2, Jie Zheng3, Daniel P. Beiting4, Anna Maria Masci5, Hong Yu1,6, Kaiyong Liu7,
Jianmin Wu8, Jeffrey L. Curtis1,9, Barry Smith10, Alexander V. Alekseyenko11 and Jihad S. Obeid11
Abstract
Background: Host-microbiome interactions (HMIs) are critical for the modulation of biological processes and are
associated with several diseases. Extensive HMI studies have generated large amounts of data. We propose that the
logical representation of the knowledge derived from these data and the standardized representation of
experimental variables and processes can foster integration of data and reproducibility of experiments and thereby
further HMI knowledge discovery.
Methods: Through a multi-institutional collaboration, a community-based Ontology of Host-Microbiome
Interactions (OHMI) was developed following the Open Biological/Biomedical Ontologies (OBO) Foundry principles.
As an OBO library ontology, OHMI leverages established ontologies to create logically structured representations of
(1) microbiomes, microbial taxonomy, host species, host anatomical entities, and HMIs under different conditions
and (2) associated study protocols and types of data analysis and experimental results.
Results: Aligned with the Basic Formal Ontology, OHMI comprises over 1000 terms, including terms imported from
more than 10 existing ontologies together with some 500 OHMI-specific terms. A specific OHMI design pattern was
generated to represent typical host-microbiome interaction studies. As one major OHMI use case, drawing on data
from over 50 peer-reviewed publications, we identified over 100 bacteria and fungi from the gut, oral cavity, skin,
and airway that are associated with six rheumatic diseases including rheumatoid arthritis. Our ontological study
identified new high-level microbiota taxonomical structures. Two microbiome-related competency questions were
also designed and addressed. We were also able to use OHMI to represent statistically significant results identified
from a large existing microbiome database data analysis.
Conclusion: OHMI represents entities and relations in the domain of HMIs. It supports shared knowledge
representation, data and metadata standardization and integration, and can be used in formulation of advanced
queries for purposes of data analysis.
Keywords: Microbiome, Host-microbiome interaction, Ontology, Ontology of host-microbiome interactions, OHMI,
Metadata, OBO Foundry, Rheumatic disease, Rheumatoid arthritis
Background
A microbiome is defined as a community of microbes
(for example, bacteria) found in a particular habitat (for
example, a human host) [13]. Microbiomes exist in and
on human and other hosts, where they are crucial for ac-
tive immunologic and physiological system development
[1, 46]. Research in host-microbiome interaction
(HMI) has accelerated significantly in the past decade, as
evidenced by the rise in the number of microbiome-
related publications indexed in PubMed (from 604 to
over 11,500 in the ten years since 2018). This growing
body of HMI studies and associated data pose signifi-
cant challenges. For example, it can be difficult for in-
vestigators to achieve reproducible results across
laboratories, and even more challenging to integrate data
systematically across studies. To facilitate advanced data
integration and knowledge discovery, several funding
sources now require that data generated from funded re-
search be structured to conform to the FAIR (Findable,
© The Author(s). 2019 Open Access This article is distributed under the terms of the Creative Commons Attribution 4.0
International License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and
reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to
the Creative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver
(http://creativecommons.org/publicdomain/zero/1.0/) applies to the data made available in this article, unless otherwise stated.
* Correspondence: yongqunh@med.umich.edu
1University of Michigan Medical School, Ann Arbor, MI 48109, USA
Full list of author information is available at the end of the article
He et al. Journal of Biomedical Semantics           (2019) 10:25 
https://doi.org/10.1186/s13326-019-0217-1
Accessible, Interoperable, and Reusable) data principles
[7]. To support data FAIRness and experimental repro-
ducibility in HMI research, a strategy is needed to
standardize the representation of the entities involved in
HMI, including host and microbial organisms, microbial
locations, and environments. As in other research areas,
so also here: the lack of a comprehensive standardized
representation of these entities prevents integration and
systems-level analysis of the HMI data produced by dif-
ferent studies, laboratories and institutions.
An ontology is a human- and computer-interpretable
representation of the types, properties, and interrelation-
ships that exist in a particular domain [8]. Ontologies
allow semantically-based reasoning by computer sys-
tems, and enable people and machines to make mutually
supportive logical inferences. In biomedical research, on-
tologies have served for some 20 years as powerful tools
for data classification, representation of standards, con-
struction of knowledge bases, and enhanced search and
analysis. Several microbiology-related ontologies exist,
including the NCBI organismal classification (NCBI-
Taxon) [9], the Uberon multi-species anatomy ontology
(UBERON) [10] and the Environment Ontology (ENVO)
[11]. These ontologies permit standardized representa-
tion of, respectively, host and microbial organisms, ana-
tomic locations of microbes inside hosts, and
microbiome environments. The Ontology for Microbial
Phenotypes (OMP) standardizes phenotypic information
relating to microbes [12]. The Ontology of Prokaryotic
Phenotypic and Metabolic Characters (MicrO) covers
the attributes of prokaryotes, the processes in which they
participate, and the material entities (such as cell com-
ponents, microbiological culture media and medium in-
gredients) with which they are associated in these
processes [13]. Many of the terms in OMP and MicrO
were themselves imported from existing OBO ontol-
ogies, including the Phenotypic Quality Ontology
(PATO) [14], the Gene Ontology (GO) [15], Chemical
Entities of Biological Interest (ChEBI) [16], the Protein
Ontology (PR) [17], and the Ontology for Biomedical In-
vestigations (OBI) [18].
The above-mentioned ontologies provide components
for the systematic representation of certain aspects of
HMIs, but they do not cover, for example, HMIs  the
interactions between hosts and microbiomes  them-
selves. They also do not cover the associations between
HMIs and specific diseases (such as rheumatoid arth-
ritis), or HMI investigation metadata. We have created
the Ontology of Host-Microbiome Interactions
(OHMI), therefore, not merely in order to incorporate
terms in these specific areas, which are important foci
of current microbiome research, but also to provide a
single framework for systematic representation of all
entities relevant to HMI.
Methods
OHMI ontology development
OHMI follows the Open Biological/Biomedical Ontologies
(OBO) Foundry (http://www.obofoundry.org/) principles.
For example, OHMI satisfies the openness and collabor-
ation principles [19], in that it is based on an open discus-
sion involving representatives from multiple disciplines
engaged in microbiome research in which not only the
scope of the ontology was identified but also the develop-
ment strategy, design patterns, and initial use cases. The
OHMI GitHub website (https://github.com/OHMI-ontol-
ogy/OHMI) documents the successive versions of the
ontology presented at the 23rd International Scientific
Symposium on Biometrics (BioStat 2017), the Sixth An-
nual Workshop of the Clinical and Translational Science
Ontology Group, and the Microbe 2018 meeting of the
American Society of Microbiology (ASM).
OHMI uses the eXtensible Ontology development
(XOD) methods [20], meaning that it reuses terms from
existing ontologies and aligns all terms within a single se-
mantic framework as defined by the Basic Formal Ontol-
ogy (BFO) [21]. The Ontofox tool was used for extraction
and reuse of terms from existing ontologies [22]. The
Ontorat tool was used for generating new terms based on
consensus ontology design patterns [23]. OHMI was for-
matted in the Web Ontology Language (OWL2), and the
Protégé OWL Editor (version 5.0) [24] was used for man-
ual editing. The HermiT reasoner (http://hermit-reasoner.
com/) tool was employed to detect inconsistencies or con-
flicts arising during development.
Host-microbiome interaction minimal information
collection and ontological representation
All HMI-related data elements were first compiled in a
spreadsheet from the literature, public resources, and
use cases, then discussed by the community, and trans-
formed into terms and relational expressions for inclu-
sion in the ontology. Following the OBO Foundry
principle of reuse, wherever a term was already defined
in one or more existing ontologies (identified using
Ontobee [25]) we imported the term into OHMI using
what we deemed to be the most biologically accurate
definition. Otherwise, we created a new term, which was
either (1) included in OHMI or (2) suggested for inclu-
sion in an appropriate higher-level OBO Foundry ontol-
ogy in order to make it available for importing into
OHMI.
OHMI use case studies and evaluation
Our major use case was the study of the association
between microbiome profiles and rheumatic diseases.
Rheumatic diseases include conditions causing chronic,
often intermittent pain affecting the joints and/or con-
nective tissues such as rheumatoid arthritis (RA),
He et al. Journal of Biomedical Semantics           (2019) 10:25 Page 2 of 14
ankylosing spondylitis (AS), and systemic lupus erythema-
tosus (SLE). In this study, we manually curated published
rheumatic disease-related HMI data from peer-reviewed
publications.
We have also defined and used two competency questions
derived from the rheumatic disease use case to evaluate the
OHMI ontology. For this purpose, we used the Simple
Protocol And Resource Description Framework (RDF)
Query Language (SPARQL) and Description Logic (DL)
languages. SPARQL is a query language that retrieves data
stored in the RDF format [26]. SPARQL queries were per-
formed using the Ontobees SPARQL endpoint (http://www.
ontobee.org/sparql) [25]. The SPARQL scripts are provided
in the OHMI GitHub (https://raw.githubusercontent.com/
OHMI-ontology/OHMI/master/docs/SPARQL%20scripts.
txt). DL queries were performed using the Protégé 5.0 (beta
15) DL Query plugin as described in the Results section.
Ontology access and license
OHMI is an open source project maintained through
https://github.com/ohmi-ontology. The source code, in-
cluding development and release versions, is available at
https://github.com/ohmi-ontology/OHMI. OHMI is re-
leased under a Creative Commons 4.0 License. It has
been accepted as an OBO library ontology (http://obo-
foundry.org/ontology/ohmi.html) and deposited in the
Ontobee ontology server [25] at http://www.ontobee.
org/ontology/OHMI, and in BioPortal [27] at https://
bioportal.bioontology.org/ontologies/OHMI. Ontobee is
the default server for dereferencing OHMI terms.
Results
OHMI ontology design and upper-level structure
Figure 1 shows selected upper-level terms and branches
of the OHMI hierarchy. Instead of coding everything
from scratch, we imported and aligned related terms
from existing reference ontologies in the OBO Library,
including BFO, NCBITaxon, ENVO, UBERON, OBI, and
the Information Artifact Ontology (IAO) [10].
The class OHMI: microbiome is defined as a subclass
of ENVO:biome. The latter is defined as follows:
biome = def. an ecosystem to which resident ecological
communities have evolved adaptations.
OHMI then defines microbiome as follows:
microbiome = def. a biome that consists of a collection
of microorganisms (i.e., microbiota) and the surround-
ing environment where the microorganisms reside and
have evolved adaptations.
OHMI further defines the term microbiota as a sub-
class of the term collection of organisms in the Popu-
lation and Community Ontology (PCO):
microbiota = def. a collection of microbial organisms
that reside in a particular environment.
Fig. 1 Selected upper level terms and hierarchy of OHMI. OHMI terms are marked by red labels. The full names of listed ontologies are provided
in the list of abbreviations at the end of this paper
He et al. Journal of Biomedical Semantics           (2019) 10:25 Page 3 of 14
To define the host class in OHMI, we first of all de-
fine the host role, which is a BFO:role borne by an entity
when one or more further entities are spatially located
in its interior. An OHMI:host is then an organism that
bears a host role in relation to some microbiome.
The basic design pattern of OHMI is illustrated in Fig. 2.
An ontology design pattern is a general pattern to solve a
recurrent modeling problem in ontology development by
providing scalable and robust representations of entities
and entity relations of a certain sort [23]. Terms from the
Relation Ontology (RO) [28] have been used to represent
OHMI assertions and to formulate corresponding defini-
tions. Specifically, a host-microbiome interaction (HMI) is
defined as follows:
host-microbiome interaction = def. an interaction that
occurs between a microbiome and its host.
with a logically equivalent class definition as follows:
host-microbiome interaction: interaction and (has partici-
pant some host) and (has participant some microbiome).
Each HMI occurs in some specific anatomic entity (for
example the gut) located in the host organism. This host
organism may in addition have a disease  a phenomenon
that is illustrated by the representation of a general HMI
pattern in patients with ankylosing spondylitis (AS) (Fig.
2). In this example, AS human-gut microbiota interaction
is a HMI in which the host is a human with AS, while
gut is the anatomic entity where the microbiota resides.
The expansion of Porphyromonas macacae in AS human
gut is an AS human-gut microbiota interaction in which
the size of the population of Porphyromonas macacae is
increased (Fig. 2).
As of September 9, 2019, OHMI contains 1238 terms, in-
cluding 1020 classes, and 128 object properties. OHMI in-
cludes 481 OHMI-specific classes and properties with the
OHMI_ prefix, which are new ontology terms not cov-
ered in any other OBO Foundry ontologies. More detailed
and updated OHMI statistics can be found at the Ontobee
statistics page at: http://www.ontobee.org/ontostat/OHMI.
Systematic collection and representation of rheumatic
disease-related HMI knowledge
As a major use case, we systematically collected and an-
notated the peer-reviewed results of studies of HMI re-
lated to rheumatic diseases. Rheumatic diseases are
characterized by inflammation of connective tissues,
most commonly the joints, but also the tendons, liga-
ments, bones, muscles, and even solid organs. Our use
case study focused on the most common rheumatic dis-
eases, including AS, enthesitis-related arthritis (ERA),
gout, psoriatic arthritis (PsA), RA, and systemic lupus er-
ythematosus (SLE), which affect approximately 1% of the
global human population. RA is a common rheumatic
Fig. 2 Illustration of OHMI ontology design pattern for representing host-microbiome interactions. The red box represents different levels of host-
microbiome interactions. A specific example is the OHMI representation of a human-microbiome interaction in which the human host has the
disease ankylosing spondylitis (AS). The human and microbiome classes are duplicated in this figure for clarity. Note that not every organism has
the host role, and the role is here assigned to a host organism only in the case of host-microbiome interactions
He et al. Journal of Biomedical Semantics           (2019) 10:25 Page 4 of 14
disease characterized by persistent synovitis, systemic in-
flammation, and autoantibodies [29]. Many studies have
found close associations between rheumatic diseases and
HMI [3033]. Specifically, the gastrointestinal microbiome
and its homeostasis are altered in patients with autoimmune
and inflammatory rheumatic diseases such as RA [33, 34].
A significant amount of research on the role of the micro-
biome in autoimmunity has focused primarily on RA [35].
To better understand the relations among rheumatic
diseases and microbiomes, we performed a meta-analysis
of such relations from relevant literature. In total, from
Alex et al. Journal of Biomedical Semantics 2019, 10(Suppl 1):23
https://doi.org/10.1186/s13326-019-0211-7
RESEARCH Open Access
Text mining brain imaging reports
Beatrice Alex1,2,3*, Claire Grover1,3, Richard Tobin1, Cathie Sudlow4, Grant Mair5 and
William Whiteley5
From UK Healthcare Text Analysis Conference (HealTAC 2018)
Manchester, UK. 1819 April 2018
Abstract
Background: With the improvements to text mining technology and the availability of large unstructured
Electronic Healthcare Records (EHR) datasets, it is now possible to extract structured information from raw text
contained within EHR at reasonably high accuracy. We describe a text mining system for classifying radiologists
reports of CT and MRI brain scans, assigning labels indicating occurrence and type of stroke, as well as other
observations. Our system, the Edinburgh Information Extraction for Radiology reports (EdIE-R) system, which we
describe here, was developed and tested on a collection of radiology reports.
The work reported in this paper is based on 1168 radiology reports from the Edinburgh Stroke Study (ESS), a
hospital-based register of stroke and transient ischaemic attack patients. We manually created annotations for this
data in parallel with developing the rule-based EdIE-R system to identify phenotype information related to stroke in
radiology reports. This process was iterative and domain expert feedback was considered at each iteration to adapt
and tune the EdIE-R text mining system which identifies entities, negation and relations between entities in each
report and determines report-level labels (phenotypes).
Results: The inter-annotator agreement (IAA) for all types of annotations is high at 96.96 for entities, 96.46 for
negation, 95.84 for relations and 94.02 for labels. The equivalent system scores on the blind test set are equally high at
95.49 for entities, 94.41 for negation, 98.27 for relations and 96.39 for labels for the first annotator and 96.86, 96.01,
96.53 and 92.61, respectively for the second annotator.
Conclusion: Automated reading of such EHR data at such high levels of accuracies opens up avenues for population
health monitoring and audit, and can provide a resource for epidemiological studies. We are in the process of
validating EdIE-R in separate larger cohorts in NHS England and Scotland. The manually annotated ESS corpus will be
available for research purposes on application.
Keywords: Text mining, Electronic healthcare records, Neuroimaging reports, Stroke classification
Background
The goal of the EdIE-R system [1] is to label each
report with an indication of what the radiologist was
able to observe in the scan image, for example, small
vessel disease, ischaemic stroke etc. Like most other sys-
tems for extracting information from electronic health-
care records, we use text mining techniques to identify the
*Correspondence: balex@ed.ac.uk
1School of Informatics, University of Edinburgh, Informatics Forum, 10
Crichton Street, Edinburgh, UK
2Edinburgh Futures Institute, School of Literatures, Languages and Cultures,
University of Edinburgh, 50 George Square, Edinburgh, UK
Full list of author information is available at the end of the article
relevant parts of the report which can then be used as a
basis for predicting the document-level labels.
Text mining systems typically apply Named Entity
Recognition (NER), Relation Extraction (RE) and nega-
tion detection. NER is used to identify words or phrases
that are entities relevant to the text mining task and
RE links entities when they are related in some rele-
vant way. Negation detection identifies contexts where the
author is stating that entities or relations do not exist. For
example, Fig. 1 shows different types of annotations: two
ischaemic stroke entities, infarcts and infarction, two tem-
poral modifiers, old and acute, and a location modifier,
thalamic. The first ischaemic stroke entity enters
© The Author(s). 2019 Open Access This article is distributed under the terms of the Creative Commons Attribution 4.0
International License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and
reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to the
Creative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver
(http://creativecommons.org/publicdomain/zero/1.0/) applies to the data made available in this article, unless otherwise stated.
Alex et al. Journal of Biomedical Semantics 2019, 10(Suppl 1):23 Page 2 of 11
Fig. 1 Example of entity, relation and negation mark-up
into two relations, one with a temporal modifier and one
with a location modifier, while the second ischaemic
stroke entity is in a relation with a temporal modifier.
These latter two entities are marked as negative (crossed
out) because they are in the scope of the negative wordNo.
Annotations such as these are output by the text mining
system and are then used as the basis for the assignment
of labels to the reports.
In order to develop NER and RE components, decisions
need to be made about which entities and which rela-
tions the system should identify. These decisions are best
made through dialogue between the domain experts, who
know what information they would ideally like to access,
and text mining experts, who can judge which pieces of
information can be identified with sufficient accuracy.
In addition, manually annotated subsets of the data are
needed to train and develop the components as well as to
evaluate their performance.
In building EdIE-R, we used the process of annotation
as a means to focus the radiologist/text miner dialogue
at the same time as developing the prototype system. We
used an agile development methodology where iterations
of system development were interleaved with annotation
iterations. After initial scoping, automatic annotations
from the system were presented to the domain experts
for correction using the BRAT annotation tool [2]. The
system and manual annotations were compared and dis-
agreements were resolved either by adjusting the man-
ual annotation or by improving the system. We iterated
over the process a number of times with both system
and manual annotation improving in each cycle. This
method has several advantages. First, it allows both teams
to work simultaneously, unlike methods where all the
annotation is done in advance of system development.
Second, discussion of the system and manual disagree-
ments allows the text miners to come to a much clearer
understanding of the meaning of the domain language
and the domain specialists to understand the limitations
of the technology. Through negotiation, several changes
to the annotation scheme were made during the iterative
process. Third, doing annotation as correction tends to
reduce insignificant differences between manual and sys-
tem annotation.
Related work
Named entity recognition is a well-established task in
NLP. The CoNLL shared-task evaluations [3] established
benchmarks for NER evaluation and prompted research
into supervised machine learning methods for NER, for
example, the Stanford NER tagger [4]. Rule-based tech-
niques are also still used for NER: see e.g. the ANNIE
NER tagger which is part of GATE [5]. Relation extraction
is often included as a subtask in text mining applications
[6] with approaches to it ranging from rule-based through
supervised to unsupervised machine learning.
Text mining technology for the biomedical domain has
been a subject of research for two decades with several
community initiatives to provide data and a forum for
shared tasks, such as BioCreative [7] and BioNLP [8].
Both of these organised shared tasks in NE and RE: see
[9, 10] for our contributions. More recently the shared
task approach has been used for electronic health records
(EHRs) by the LOUHI workshops, e.g. LOUHI17 [11] or
LOUHI18 [12]. There are many individual studies apply-
ing information extraction to EHRs, see [13] for a review
of some of these. Negation detection has been recognised
as an important step, particularly in medical text mining,
with the NegEx algorithm [14] being frequently used.
Several researchers have applied NLP and text mining
approaches to radiology reports. Pons et al. (2016) provide
a useful systematic review of NLP in radiology [15]. They
include 67 different studies which they group according
to 5 distinct purposes, namely diagnostic surveillance,
cohort building for epidemiological studies, query-based
case retrieval, quality assessment of radiologic practice,
and clinical support services. Conditions targeted by the
systems are various and include appendicitis, pneumonia,
renal cysts, pulmonary embolism, liver conditions and
Fig. 2 EdIE-R processing pipeline
Alex et al. Journal of Biomedical Semantics 2019, 10(Suppl 1):23 Page 3 of 11
general metastases, to name but a few. Across all these
application areas the NLP systems surveyed tend to have
the same broad structure where a flow diagram showing
the individual components looks much like our diagram
of the EdIE-R system shown in Fig. 2 below.
Two recent studies by Hassanpour and Langlotz (2016)
and by Cornegruta et al. (2016) describe machine
learning methods for entity recognition from radiol-
ogy reports [16, 17]. Hassanpour and Langlotz [16]
tested two existing feature-based machine learning clas-
sifiers for this task. Their annotation scheme contains
four broad types of named entities (Anatomy, Anatomy
modifier, Observation and Observation modifier) as well
as strings expressing Uncertainty. They used NegEx
to identify negation in the text as a feature feed-
ing into their models. The machine learning classifier
both result in an average F1-score of 85% for 10-fold
cross-validation on a data set containing 150 manu-
ally annotated radiology reports from three different
institutions.
Cornegruta et al. [17] describe work on analysing a
large corpus of historical chest X-ray reports. Their sys-
tem described is interestingly similar to ours in the way
the report text is annotated with named entity and nega-
tion mark-up although the entity list (Body Location,
Descriptor, Clinical Finding, Medical Device) is both
smaller and more complex in that disjoint entities are
permitted. No relation extraction is performed but nega-
tion mark-up is included. The NER method uses a bidi-
rectional LSTM (BiLSTM) neural network architecture,
which is contrasted with a baseline system which uses
string matching look-up against RadLex [18] and Medical
Subject Headings (MeSH) [19] concepts combined with
parsing, plus NegEx for negation detection. The BiLSTM
NER tagger significantly outperforms the baseline but
it is worth noting that, in general, rule-based and
machine learning approaches attain similar levels of per-
formance on NER if the rule-based system uses more
sophisticated techniques than string matching, as ours
does.
There has also been some work on summarising radi-
ology reports. Most recently, Zhang et al. [20] proposed
a state-of-the-art neural network-based approach to sum-
marisation of radiology impressions. An impression is the
Conclusion section of a radiology report summarised by
the radiologist after dictating or writing down their find-
ings presented in the image. Automating this step is an
extremely useful task that can save radiologists a lot of
effort and time. Two different radiology reports describ-
ing similar symptoms and conditions, however, are not
guaranteed to result in the same summary text. The out-
put of summarisation therefore does not lend itself well
for large-scale data analysis in the same way as classifica-
tion of symptoms and conditions does, for example, for
identifying patients with the same findings for epidemio-
logical studies.
With a specific focus on stroke, Flynn et al. (2010) [21]
developed a system for analysis of brain scan radiology
reports from Tayside, Scotland, i.e. EHR reports which
are very similar to the those in the ESS data set [22].
Their aim was to improve on the coding of the reports
which were frequently given generic stroke codes even
when a more precise code could be determined by look-
ing at the report. Their method used a keyword matching
step looking for affirmative or negative uses of key words
from a stroke lexicon. They report results which were
acceptably accurate in identifying ischaemic stroke (94.7%
positive predictive value (precision)) on a dataset of 150
reports manually classified as ischaemic stroke. Their
method performed less reliably in identifying intracere-
bral haemorrhage (76.7% positive predictive value) on a
dataset of 150 reports manually classified as intracere-
bral haemorrhage. The paper does not report sensitivity
(recall) scores as the data only contains positive examples
of either type.
To the best of our knowledge, EdIE-R is the first sys-
tem that performs named entity extraction, negated entity
detection, relation extraction and document level labelling
with the goal to classify radiology report with types of
stroke, tumours and other information. The extracted
entities (positive or negative) and relations are all used to
do the final classification (labelling) step. The information
captured in and about the reports include a compre-
hensive set of entities and labels. We provide a detailed
evaluation of EdIE-R for all the steps it is designed to
perform using standard natural language processing eval-
uation metrics, including precision, recall and F1-score.
Compared to the previous study [21] we therefore test
on an unseen test set of random radiology reports which
contain positive and negative examples of the information
EdIE-R is designed to extract and label.
Method
Annotation scheme
There are four aspects to the annotation of brain scan
reports in our data: entities, relations, negation mark-up,
and labels. These are all illustrated in Fig. 3, a screen grab
of an annotated report loaded into the BRAT tool. As
shown, each report is preceded by a list of all possible
labels but only those that have beenmarked as selected are
labels for the report. Entities, relations and negation have
been annotated within the textual body of the report.
Entities are of two types, observations or mod-
ifiers. The full set of observation entities are:
ischaemic stroke, haemorrhagic stroke,
stroke (unknown type), tumour:meningioma,
tumour:metastasis, tumour:glioma, tumour,
subdural haematoma, small vessel disease,
Alex et al. Journal of Biomedical Semantics 2019, 10(Suppl 1):23 Page 4 of 11
Fig. 3 An annotated report
atrophy, microbleed, subarachnoid ha
emorrhage and haemorrhagic transformation.
The four modifier entities, which are used to identify loca-
tion (deep vs. cortical/lobar) and recency (old vs. recent)
of an observation, are loc:deep, loc:cortical,
time:old, time:recent.
Relations link a subset of observation entities, namely
stroke and microbleed entities, with modifier entities.
Strokes may be associated with both a location and a
time, while microbleeds are associated only with loca-
tion. Some words or phrases, such as POCI (Posterior
Circulation Infarct) in Fig. 2, carry both observation and
modifier meaning and in these cases nested entities are
used. Here there is a mod-loc relation between the
loc:cortical entity and the ischaemic stroke entity
but we do not require this to be made explicit in the
annotation since the nesting implies it.
There is a close relationship between the entity
and relation names and the labels. For example,
the label Ischaemic stroke, cortical, old has
been chosen and this clearly relates to the two occur-
rences of an ischaemic stroke entity in a relation
with both a loc:cortical and a time:old modifier.
The annotators are instructed not to select labels unless
there is explicit linguistic evidence to support the choice.
Occasionally they will be able to infer labels from implicit
information but they are asked not to annotate these cases
as the aim is to model linguistically explicit information
not human expertise.
Proper identification of negation and its scope is
essential to achieving high accuracy. We model negation
in the annotation as an attribute on entities, which is
visualized in BRAT as a crossing out. Wherever the
text contains negation scoping over entities, the anno-
tators must add the negative attribute. The negative
example in Fig. 2, No acute haemorrhage, masses or
extra-axial collections, is a clear and simple case but
syntactically more complex cases occur, e.g. cases where
the negation marker is distant from the entities within
its scope. There are cases where the radiologist is unable
to positively identify or exclude an observation, as for
example in a small focus of acute infarct cannot be com-
pletely excluded. The annotators are asked to mark these
cases as negative, as only clearly positive observations
Alex et al. Journal of Biomedical Semantics 2019, 10(Suppl 1):23 Page 5 of 11
should contribute to the labels assigned to the
reports.
The EdIE-R system
EdIE-R is a rule-based text mining systemwhich we devel-
oped in tandem with manual data annotation in the form
of correction of the system output. The presentation of
the data in the BRAT tool, as illustrated in Fig. 2, is the
view that the annotators see, but this is a format that has
been derived from the data structure which the system
manipulates and outputs, which is an XML data structure.
We have developed the systems text analysis components
using the LT-XML2 programs, which are the core of our
XML rule-based text mining software [23]. Our most
recent software release, the Edinburgh Geoparser [24],
contains all of our general-purpose components, such as
the tokeniser, NER tagger and chunker, which we have
adapted to the brain scan report domain in EdIE-R.
As shown in Fig. 3, the EdIE-R system has a pipeline
architecture. Scan reports are converted from their orig-
inal format into an initial XML format and subsequent
components incrementally add annotations to the XML
structure, with each stage making computations over the
annotations of previous stages. The document zoning
step segments the reports into sections including clinical
details, the report itself and the radiologists conclusion.
It also adds metadata which includes all of the possi-
ble labels that can be assigned; by the final stage of the
pipeline an attribute on each label indicates whether that
label has been selected. An example of a report in XML
after document zoning is shown in Fig. 4. We combine
NER and label mark-up in this way so that manual anno-
tation of all levels of analysis can be done at the same
time.
Subsequent steps of the pipeline do linguistic process-
ing. The tokeniser splits textual content into paragraphs,
sentences and word tokens, with punctuation characters
also treated as tokens. The C&C POS tagger [25] labels
each word with its syntactic category. The default C&C
model has been trained on modern U.S. newspaper text
and although it performs well on most text types, it is not
wholly suitable for the medical text in our reports. For this
Fig. 4 XML format after document zoning
Alex et al. Journal of Biomedical Semantics 2019, 10(Suppl 1):23 Page 6 of 11
Fig. 5 Example lexical entries
reason, we also use a model trained on the Genia biomed-
ical corpus [26]. After running the POS tagger with each
of the models we apply a correction stage to moderate dis-
agreements between them. After POS tagging, we apply
the morpha lemmatiser [27] to analyse inflected nouns
and verbs and compute their lemma (morphological
stem). The output of POS tagging and lemmatization
is stored in attribute values on word token
elements.
The fifth step in the pipeline is the NER component,
which incorporates lexical lookup. From examples in the
development set we manually curated two lexicons, one
for observations (e.g. the atrophy entity inter-cerebral
volume loss and the ischaemic stroke entity lacunar
Fig. 6 XML representation of entities and relations in Fig. 1
Alex et al. Journal of Biomedical Semantics 2019, 10(Suppl 1):23 Page 7 of 11
Table 1 The annotated ESS data sets
Reports Of which CT Of which MRI Sentences Words
Development
dev1 18 18 0 158 1651
dev2 25 16 9 231 2671
dev3 80 78 2 888 6833
dev4 82 74 8 833 6935
dev5 82 69 13 965 8,061
dev6 77 67 10 762 6078
Total 364 322 42 3837 32,229
Test
test1 89 74 15 969 7,919
test2 92 82 10 996 8,226
test3 85 82 3 890 6697
Total 266 238 28 2855 22,842
event) and one for modifiers (e.g. the time:old enti-
ties old, previous and established), e.g. see Fig. 5. The
process of lexical lookup results in the addition of fur-
ther attributes to the word tokens of matching words and
phrases. The lexicons are applied one after the other, first
the observations lexicon and then the modifiers, so that
some words or phrases can be marked as both observa-
tion and modifier to achieve the nested entity mark-up
described above.
The next stage of processing performs a shallow syntac-
tic analysis using our chunker [28] to segment sentences
into phrases or word groups, i.e. syntactic structures
headed by nouns (noun groups), verbs (verb groups) etc.
The purpose of doing this is to create a useful data struc-
ture for dealing with nested entities and coordinations of
entities as well as to define the scope of negation mark-
ers in terms of structure rather than just word sequences.
At this stage complex negative noun groups such as No
acute haemorrhage, masses or extra-axial collections have
an appropriate structure to allow information from the
negative article No to be propagated through the group so
that all three observation entities (haemorrhage, masses,
extra-axial collections) are marked as negative.
Relation Extraction is the final stage of the text min-
ing part of the system. In this component some pairs
of entities are linked in relations held as structures in
standoff XML mark-up as illustrated in Fig. 6. There
are two possible relations, location and time, which hold
between stroke entities (ischaemic, haemorrhagic
or unknown type) and modifiers. In addition, a
microbleed entity can be in a relation with a location
modifier.
Negation arising from the verb particle not, for exam-
ple in Very acute infarction may not be visible on CT, is
handled as part of the relation extraction module because
Table 2 Annotations in the data sets
Annotated by Positive
entities
Negative
entities
Relations Labels
dev1 Both: reconciled 197 85 68 46
dev2 Both: reconciled 242 116 85 62
dev3 Both: reconciled 670 324 230 192
dev4 Annotator 1 600 284 195 167
dev5 Annotator 2 708 302 212 174
dev6 Annotator 1 524 280 169 151
Total 2941 1391 959 792
test1 Annotator 1 605 291 203 159
test2 Annotator 1 786 337 278 192
test3 Annotator 1 572 333 206 167
Total 1963 961 687 518
test1 Annotator 2 614 304 220 160
test2 Annotator 2 792 361 281 199
test3 Annotator 2 574 355 200 176
Total 1980 1020 701 535
rules linking not with the entities it scopes over are simi-
lar to the other relation rules. The result, however, is not
an explicit relation but an attribute on the negated entities
(acute and infarction, in this case). This is the same format
as for noun group negation detected during chunking.
Table 3 Inter-annotator agreement on the test data
Precision Recall F1
Entities
test1 96.41 98.77 97.57
test2 95.84 98.40 97.10
test3 94.94 97.46 96.18
Total 95.73 98.22 96.96
Negation
test1 95.90 98.19 97.03
test2 95.07 97.70 96.36
test3 94.73 97.29 96.00
Total 95.22 97.72 96.46
Relations
test1 92.99 98.03 95.44
test2 97.47 97.47 97.47
test3 96.39 91.67 93.97
Total 95.77 95.91 95.84
Labels
test1 92.50 93.08 92.79
test2 90.95 94.27 92.58
test3 94.32 99.40 96.79
Total 92.52 95.56 94.02
Alex et al. Journal of Biomedical Semantics 2019, 10(Suppl 1):23 Page 8 of 11
Table 4 IAA precision, recall and F1 for entities including
numbers of true positives (TP), false positives (FP) and false
negatives (FN)
Type TP FP FN Precision Recall F1
Entities
ischaemic stroke 453 9 2 98.05 99.56 98.80
haemorrhagic stroke 264 20 3 92.96 98.88 95.83
stroke (unknown type) 25 0 1 100.00 96.15 98.04
tumour:meningioma 8 0 0 100.00 100.00 100.00
tumour:metastasis 12 0 0 100.00 100.00 100.00
tumour 165 2 1 98.80 99.40 99.10
subdural haematoma 109 32 0 77.30 100.00 87.20
small vessel disease 269 15 7 94.72 97.46 96.07
atrophy 147 14 6 91.30 96.08 93.63
microhaemorrhage 10 0 0 100.00 100.00 100.00
subarachnoid haemorrhage 9 3 1 75.00 90.00 81.82
haemorrhagic transformation 2 2 0 50.00 100.00 66.67
time:old 314 9 7 97.21 97.82 97.52
time:recent 354 0 0 100.00 100.00 100.00
loc:cortical 410 5 2 98.80 99.51 99.15
loc:deep 321 17 22 94.97 93.59 94.27
TOTAL 2872 128 52 95.73 98.22 96.96
The final labelling step of the pipeline uses the infor-
mation from the previous steps to compute which labels
should be associated with a record. Because the mark-up
coming from the text mining is very detailed, the label-
ing rules can be fairly simple. For example, to choose
the Small vessel disease label the rules need only
to check that there is a non-negative small vessel
disease entity in either the report or conclusions
part of the report. To choose the label Ischaemic
stroke, cortical, recent there needs to be a
non-negative ischaemic stroke entity which is in
a location relation (mod:loc) with a cortical loca-
tion entity (loc:cortical) and in a time relation
(mod:time) with a time:recent entity. There are
a few added complexities to these rules, for exam-
ple, a deep ischaemic stroke which is not in an
explicit relationship with a time modifier is assumed to
be old.
Table 5 IAA precision, recall and F1 for relations including
numbers of TPs, FPs and FNs
Type TP FP FN Precision Recall F1
Relations
mod-loc 235 17 25 93.25 90.38 91.80
mod-time 421 12 3 97.23 99.29 98.25
TOTAL 656 29 28 95.77 95.91 95.84
Table 6 IAA precision, recall and F1 for labels including numbers
of TPs, FPs and FNs
Type TP FP FN Precision Recall F1
Labels
Ischaemic stroke,
deep, recent
4 0 0 100 100 100
Ischaemic stroke,
deep, old
81 4 4 95.29 95.29 95.29
Ischaemic stroke,
cortical, recent
13 3 1 81.25 92.86 86.67
Ischaemic stroke,
cortical, old
58 6 3 90.62 95.08 92.8
Ischaemic stroke,
underspecified
6 6 6 50 50 50
Haemorrhagic
stroke, deep, recent
2 1 0 66.67 100 80
Haemorrhagic
stroke, deep, old
4 0 0 100 100 100
Haemorrhagic
stroke, lobar, recent
4 0 0 100 100 100
Haemorrhagic
stroke, lobar, old
3 0 0 100 100 100
Haemorrhagic
stroke, underspecified
9 0 1 100 90 94.74
Stroke,
underspecified
14 1 1 93.33 93.33 93.33
Tumour,
meningioma
4 0 0 100 100 100
Tumour, metastasis 0 0 0 - - -
Tumour, glioma 0 0 0 - - -
Tumour, other 2 3 1 40 66.67 50
Small vessel disease 158 3 1 98.14 99.37 98.75
Atrophy 119 9 3 92.97 97.54 95.2
Subdural
haematoma
6 0 0 100 100 100
Subarachnoid
haemorrhage,
aneurysmal
0 0 0 - - -
Subarachnoid
haemorrhage, other
5 2 1 71.43 83.33 76.92
Microbleed, deep 1 1 0 50 100 66.67
Microbleed, lobar 1 0 0 100 100 100
Microbleed,
underspecified
0 0 1 NaN 0 NaN
Haemorrhagic
transformation
1 1 0 50 100 66.67
TOTAL 495 40 23 92.52 95.56 94.02
Evaluation
In order to evaluate system performance, we anno-
tated development and test data as discussed in the
Annotation section. For this we used 1168 reports from
the Edinburgh Stroke Study (ESS) [22]. We reserved the
Alex et al. Journal of Biomedical Semantics 2019, 10(Suppl 1):23 Page 9 of 11
Table 7 Evaluation of the system on the two annotators test
sets. We reproduce IAA from Table 3 for comparison
Precision Recall F1 IAA F1
Entities
Annotator 1 test set 94.63 96.37 95.49 96.96
Annotator 2 test set 97.21 96.50 96.86
Negation
Annotator 1 test set 93.54 95.30 94.41 96.46
Annotator 2 test set 96.35 95.66 96.01
Relations
Annotator 1 test set 97.32 99.24 98.27 95.84
Annotator 2 test set 95.47 97.61 96.53
Labels
Annotator 1 test set 94.94 97.88 96.39 94.02
Annotator 2 test set 92.70 92.52 92.61
first 500 reports as the development set and the remain-
der as the test set. ESS contains MRI, CT and Doppler
Ultrasound reports but we used only the CT and MRI
reports. We also discarded a few reports which contained
non-brain results, e.g. combined brain and neck, chest, or
abdomen scans. In total the annotated development set
contains 322 CT and 42 MRI reports. We have annotated
a random subset of the test set containing 238 CT and 28
MRI reports.
Manual annotation of the development data was accom-
plished in six tranches, where annotation was correc-
tion of the system output. The system was modified and
improved between the tranches. Table 1 provides infor-
mation on the sizes of the data subsets. The first three
tranches were doubly annotated by the radiology experts
so that IAA could be monitored. For these three tranches
only, disagreements between the annotators were recon-
ciled to produce an agreed gold standard. The remaining
development data was singly annotated. The test data was
doubly annotated in three tranches but not reconciled.
Table 2 provides details of the annotators and annotations
in all the data sets.
Results
Following standard practice we measure both IAA and
system performance using precision, recall and F1. Note
that IAA represents an upper bound for system perfor-
mance as an automatic method would not be expected
to out-perform human capabilities. The overall results
for IAA on the test data are shown in Table 3. Note
that IAA measures for relations are only computed for
those relations where the two annotators agree on both
entities linked by the relation. Overall the IAA results
are very high which indicates that the annotation task is
well-defined.
Table 8 Detailed evaluation of system labelling compared to
Annotator 2 showing numbers of true positives (TP), false
positives (FP) and false negatives (FP), as well as precision, recall
and F1
Type TP FP FN Precision Recall F1
Ischaemic stroke,
deep, recent
4 1 0 80.00 100.00 88.89
Ischaemic stroke,
deep, old
81 5 4 94.19 95.29 94.74
Ischaemic stroke,
cortical, recent
14 1 2 93.33 87.50 90.32
Ischaemic stroke,
cortical, old
56 5 8 91.80 87.50 89.60
Ischaemic stroke,
underspecified
6 8 6 42.86 50.00 46.15
Haemorrhagic
stroke, deep,
recent
3 0 0 100.00 100.00 100.00
Haemorrhagic
stroke, deep, old
4 1 0 80.00 100.00 88.89
Haemorrhagic
stroke, lobar,
recent
4 1 0 80.00 100.00 88.89
Haemorrhagic
stroke, lobar, old
3 1 0 75.00 100.00 85.71
Haemorrhagic
stroke,
underspecified
9 3 0 75.00 100.00 85.71
Stroke,
underspecified
13 1 2 92.86 86.67 89.66
Tumour,
meningioma
4 1 0 80.00 100.00 88.89
Tumour,
metastasis
0 3 0 0.00 - -
Tumour, glioma 0 0 0 - - -
Tumour, other 4 2 1 66.67 80.00 72.73
Small vessel
disease
158 0 3 100.00 98.14 99.06
Atrophy 120 3 8 97.56 93.75 95.62
Subdural
haematoma
5 0 1 100.00 83.33 90.91
Subarachnoid
haemorrhage,
aneurysmal
0 0 0 - - -
Subarachnoid
haemorrhage,
other
4 1 3 80.00 57.14 66.67
Microbleed, deep 1 0 1 100.00 50.00 66.67
Microbleed, lobar 1 0 0 100.00 100.00 100.00
Microbleed,
underspecified
0 2 0 0.00 - -
Haemorrhagic
transformation
1 0 1 100.00 50.00 66.67
TOTAL 495 39 40 92.70 92.52 92.61
Alex et al. Journal of Biomedical Semantics 2019, 10(Suppl 1):23 Page 10 of 11
Tables 4, 5 and 6 provide a more detailed breakdown
of the IAA results per type on the entities, relations and
labels across the three test sets. The majority of lower
IAA scores for entity types are for low frequency ones,
for example subarachnoid haemorrhage. This pat-
tern is mirrored in the IAA scores for labels, for
example for Haemorrhagic transformation and
Microbleed. However, since these types are very infre-
quent their low IAA scores do not have a serious effect on
the overall figures.
Table 7 shows evaluation results for the EdIE-R system
on the two annotators versions of the test set. For labels
and relations, the system agrees more with Annotator 1
than with Annotator 2, while the pattern is reversed for
entities and negation. We would expect system scores to
be lower than IAA (see final column), which is the case
for entities and negation for Annotator 1, and for all but
relations for Annotator 2. We speculate that these differ-
ences indicate that Annotator 1 focused more on entity
mark-up and spotted and corrected more system entity
errors while Annotator 2 focused more on the labels and
made more corrections there. To improve the accuracy of
the evaluation we would ideally arbitrate the annotators
disagreements and produce a consensus test set. Nev-
ertheless, the overall evaluation results are reassuringly
high, indicating that this method of labelling radiology
reports is highly effective.
In Table 8 we provide a breakdown of system perfor-
mance for the labelling task as compared with Annotator
2. This shows the comparative frequency of the dif-
ferent labels. Small vessel disease and Atrophy
are the most frequent and the system performs well
on both. The presence of these labels boosts the
total precision, recall and F1 into the low 90s. With
the exception of Ischaemic stroke, deep, old
and Haemorrhagic stroke, deep, recent, per-
formance is generally slightly lower for both Ischaemic
andHaemorrhagic stroke labels than the total entity score.
The comparative frequency of these labels (Ischaemic
more frequent than Haemorrhagic) does not appear to
make a difference in Table 8, but it may be that the
number of Haemorrhagic stroke instances is too low for
the sample to be representative. Similarly, other labels
are so infrequent that their results may not be inter-
pretable and it would be useful to acquire and annotate
more data to improve the robustness of the evaluation
results.
Conclusion
We have described the development and evaluation of the
EdIE-R system on brain imaging radiology reports from
the Edinburgh Stroke Study. The evaluation results are
encouraging and the system is sufficiently accurate that
we believe it can be used for its intended purpose of data
provision for epidemiological studies. To that end, we are
currently testing and revising the system on a dataset of
over 150,000 routine brain scans from NHS Tayside col-
lected between 1994 and 2015. We are also in the process
of evaluating whether the system can reliably identify
cases of intracerebral haemorrhage in patients in Greater
Manchester.
The evaluation of EdIE-R against these larger datasets
will show how robust it is against new data. The disad-
vantage of a rule-based system such as EdIE-R is that it
takes time to write the rules. However, we found that with
the help of the domain expert input we were able to get a
first prototype running fairly quickly. For a small dataset
such as ESS, we found this to work very well as we did not
have any training data available at the start to test machine
learning methods. Now that we have the annotated data
ready we are evaluating machine learning approaches in
parallel to investigate if we can obtain better results using
them.
Acknowledgements
An initial version of this paper was presented at the Healthcare Text Analytics
Conference 2018 (HealTAC) in Manchester in April 2018 [29].
About this supplement
This article has been published as part of the Journal of Biomedical Semantics
Volume 10 Supplement 1, 2019: HealTAC-2018: Unlocking Evidence Contained
in Healthcare Free-text. The full contents of the supplement are available
online at https://jbiomedsem.biomedcentral.com/articles/supplements/
volume-10-supplement-1.
Authors contributions
Alex and Grover wrote this article. Grover developed the text mining system
and performed the evaluation experiments and Alex assisted in the
annotation, evaluation and discussions of this project. Tobin wrote the XML
processing tools used in the EdIE-R text mining pipeline. Whiteley and Mair
did the manual data annotation, provided expert domain knowledge during
system development and edited the article. Sudlow provided the dataset and
offered domain expertise. All authors edited the paper and approved the final
manuscript.
Funding
Alex and Grover are supported by Turing Fellowships from The Alan Turing
Institute (EPSRC grant EP/N510129/1). Sudlow is Chief Scientist of UK Biobank
and Director of Health Data Research UK Scotland. Mair is supported by a
Stroke Association Edith Murphy Foundation Senior Clinical Lectureship (SA
L-SMP 18\1000). Whiteley was supported by an MRC Clinician Scientist Award
(G0902303) and is supported by a Scottish Senior Clinical Fellowship
(CAF/17/01). Publication costs are funded by the RCUK Open Access Fund.
Availability of data andmaterials
The annotated ESS corpus that we have created as part of this project has
much potential value as a resource for developing text mining algorithms. This
data will be available on application to Prof. Cathie Sudlow (email:
Cathie.Sudlow AT ed.ac.uk) to bona fide researchers with a clear analysis plan,
in line with the Wellcome Trust policy on data-sharing (https://wellcome.ac.uk/
what-we-do/topics/data-sharing). We are in the process of creating a release
of EdIE-R free for research purposes (https://www.ltg.ed.ac.uk/software/edie-r).
For more information contact Dr. Beatrice Alex (email: balex AT ed.ac.uk).
Ethics approval and consent to participate
The Edinburgh Stroke Study received ethical approval from the Lothian
Research Ethics Committee (LREC/2001/4/46). This is a patient-consented
Alex et al. Journal of Biomedical Semantics 2019, 10(Suppl 1):23 Page 11 of 11
dataset. We also received permission from the NHS Tayside Caldicott Guardian
to use the anonymised brain imaging reports for this work.
Competing interests
The authors declare that they have no competing interests.
Author details
1School of Informatics, University of Edinburgh, Informatics Forum, 10 Crichton
Street, Edinburgh, UK. 2Edinburgh Futures Institute, School of Literatures,
Languages and Cultures, University of Edinburgh, 50 George Square,
Edinburgh, UK. 3The Alan Turing Institute, The British Library, 96 Euston Road,
London, UK. 4Centre for Medical Informatics, University of Edinburgh, 9 Little
France Road, Edinburgh, UK. 5Centre for Clinical Brain Sciences, University of
Edinburgh, Chancellors Building, 49 Little France Crescent, Edinburgh, UK.
Published: 12 November 2019
RESEARCH Open Access
Ontology patterns for the representation of
quality changes of cells in time
Patryk Burek2, Nico Scherf3,4,5 and Heinrich Herre1*
Abstract
Background: Cell tracking experiments, based on time-lapse microscopy, have become an important tool in biomedical
research. The goal is the reconstruction of cell migration patterns, shape and state changes, and, comprehensive
genealogical information from these data. This information can be used to develop process models of cellular
dynamics. However, so far there has been no structured, standardized way of annotating and storing the tracking
results, which is critical for comparative analysis and data integration. The key requirement to be satisfied by an
ontology is the representation of a cells change over time. Unfortunately, popular ontology languages, such
as Web Ontology Language (OWL), have limitations for the representation of temporal information. The current
paper addresses the fundamental problem of modeling changes of qualities over time in biomedical ontologies
specified in OWL.
Results: The presented analysis is a result of the lessons learned during the development of an ontology, intended
for the annotation of cell tracking experiments. We present, discuss and evaluate various representation patterns for
specifying cell changes in time. In particular, we discuss two patterns of temporally changing information: n-ary relation
reification and 4d fluents. These representation schemes are formalized within the ontology language OWL and are
aimed at the support for annotation of cell tracking experiments. We analyze the performance of each pattern with
respect to standard criteria used in software engineering and data modeling, i.e. simplicity, scalability, extensibility and
adequacy. We further discuss benefits, drawbacks, and the underlying design choices of each approach.
Conclusions: We demonstrate that patterns perform differently depending on the temporal distribution of modeled
information. The optimal model can be constructed by combining two competitive approaches. Thus, we demonstrate
that both reification and 4d fluents patterns can work hand in hand in a single ontology. Additionally, we have found
that 4d fluents can be reconstructed by two patterns well known in the computer science community, i.e. state
modeling and actor-role pattern.
Keywords: Ontology, Design patterns, Cell tracking, Web ontology language
Background
Life is a complex, hierarchical and dynamic process [1]:
it is a hallmark of all living systems that they change
over time. This is obvious during development, regener-
ation, or disease; but even under homeostatic conditions
living matter is in a dynamic equilibrium; an example is
the constant turnover in the hematopoietic system to
maintain a certain number of blood cells. Thus, a deeper
understanding of basic biological principles requires us to
resolve the systems spatial and temporal structures [2].
Over the past decades, advances in biomedical imaging,
experimental procedures, and computational analysis led
to the establishment of time-lapse microscopy that
allowed us to study the spatio-temporal organization
of tissues, organs, or whole animals at the cellular
level [3, 4].
Time-lapse microscopy has become a fundamental ex-
perimental tool in biomedical research. The goal is to re-
construct migration patterns, shape changes, changes in
protein expression and, eventually, comprehensive ge-
nealogical information [5, 6] from the data. However,
the analysis of the resulting videos has become a major
bottleneck: manual analysis can be done on short se-
quences with few cells, but it is practically infeasible for
© The Author(s). 2019 Open Access This article is distributed under the terms of the Creative Commons Attribution 4.0
International License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and
reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to
the Creative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver
(http://creativecommons.org/publicdomain/zero/1.0/) applies to the data made available in this article, unless otherwise stated.
* Correspondence: heinrich.herre@imise.uni-leipzig.de
1Institute for Medical Informatics, Statistics and Epidemiology, University of
Leipzig, Haertelstr. 16-18, 04107 Leipzig, Germany
Full list of author information is available at the end of the article
Burek et al. Journal of Biomedical Semantics           (2019) 10:16 
https://doi.org/10.1186/s13326-019-0206-4
large-scale, systematic experiments. Consequently, the
development of computational tools for cell tracking, ei-
ther fully or partly automated, is a vital field of research
in image analysis [79]. However, what is still largely
missing is a structured, standardized way of annotating
and storing the tracking results. But this is exactly what
we need in the future to build systematic databases of
cell tracking experiments and to mine, infer and com-
pare the inherent biological information.
A few steps have been taken in this direction: in [1012]
we reported on our work in progress on the framework
for annotating results of experiments and simulations in
stem cell biology. The core component of the framework
is a Cell Tracking Ontology (CTO) formalized in the Web
Ontology Language (OWL) [13], which enables the anno-
tation of time-lapse experiments.
Typically, the information about a cells history is or-
ganized into pedigree-like data structures called cellular
genealogies [14]. In such a genealogy the root represents
the founder cell and its progeny is arranged in the
branches of the tree, with branching events representing
cell division. Here, a cell is perceived as a spatially and
temporally extended object. The existence of a cell is
temporally restricted by its birth (the division of the
mother cell) and either its death (apoptosis) or terminal
division (mitosis), yielding two daughter cells of the next
generation [10]. The observed cells themselves are dy-
namic entities, i.e. they can change their shape, their
position (migration), or their internal state (differenti-
ation). Therefore, the key requirement for an ontology
of cellular genealogies is the representation of changes
over time in individual cells, such as, for instance, the
change of a cell from a round to an elongated shape.
Unfortunately, representing temporal information is a
serious problem appearing across numerous areas of in-
formation modeling, including data modeling and rela-
tional database design [15] as well as the semantic web
languages typically used for ontology modeling, such as
Resource Description Framework (RDF) [16], Web
Ontology Language (OWL), or the Description Logics
underlying OWL. One problem originates from the
lack of direct support for n-ary relationships, which
in turn limits the capabilities for representing tempor-
ally indexed information.
One possible approach to overcoming this limitation is
the extension of these languages so that they can express
temporal information. For instance, in the area of de-
scription logics numerous approaches have been pro-
posed to incorporate time into the logic model [1719].
Unfortunately, as discussed in [20], temporal logics still
have problems with representing temporally changing
information, as they are geared towards synchronic rela-
tionships, not diachronic ones. In the field of RDF the
incorporation of temporal information and temporal
reasoning has been proposed by [21] using the so-called
temporal RDF graphs or a query and storage syntax [22].
For OWL, [23] proposed an extension for representing
dynamic entities using a four-dimensional (4d) model.
An alternative to language extensions, and one more
relevant for the development of CTO, is a solution on
the user level without any need to modify the language
itself. Along these lines, numerous patterns have been
proposed [24], and two strategies are of particular inter-
est: reification of n-ary relations and 4d fluents.
The former strategy is rather straightforward: an n-ary
relationship is represented by introducing an additional
model element, the so-called reified entity. This ap-
proach is well known in many areas of information mod-
eling, e.g. Associative Entities in Entity-Relationship-
Diagrams (ERD)[25], Intersection Tables in SQL [26], or
Association Classes in Unified Modeling Language
(UML) [27]. This strategy has also been suggested for
OWL [28].
The alternative approach originates from the philo-
sophical theory of four-dimensionalism [29], where en-
tities are considered as the so-called 4d worms, which
can be sliced into temporal parts. Different variants of
the 4d fluents pattern have been introduced in literature,
among others by [24, 3032], yet all have in common
the same underlying principle, which, analogously to the
reification strategy, introduces to the model an add-
itional entity (or entities) representing temporal informa-
tion. However, in contrast to reification, the introduced
entity does not represent a reified relationship but a
temporal part/slice of a modeled entity.
In the current paper we take a closer look at both pat-
terns and their relevance to modeling the dynamic
change of information in biomedical ontologies such as
CTO. We focus primarily on the application of these
patterns for constructing new ontologies from scratch. It
should be noted that our goal is neither to address other
related issues, such as time representation and temporal
reasoning, nor the extension of existent OWL domain
ontologies, as it has been presented e.g. in [33, 34].
Although we focus on the use-case of cell tracking ex-
periments, the problem is generic and has to be ad-
dressed by ontology engineers in different domains of
the biomedical field. In contrast to many overviews of
the discussed problem, which typically conduct their
analyses on single isolated temporal information, we
focus on a dynamically changing web of information.
We demonstrate that the patterns perform differently
depending on the temporal distribution of the informa-
tion. We further demonstrate that a 4d approach can be
re-constructed using other well known patterns not re-
quiring the introduction of 4-dimensionalism. We con-
duct our analysis discussing the benefits and drawbacks
of each pattern with respect to common criteria for
Burek et al. Journal of Biomedical Semantics           (2019) 10:16 Page 2 of 18
software systems and information modeling, i.e. scalabil-
ity, extensibility and adequacy.
Cell tracking
To get an idea of the Cell Tracking Ontology, it is useful
to sketch some aspects of typical cell tracking experi-
ments. Figure 1 demonstrates examples from the variety
of image sequence data acquired via time-lapse micros-
copy, which can be either two-dimensional (e.g. in vitro
experiments using traditional wide-field microscopy) or
three-dimensional volumes (e.g. in vivo imaging using
fluorescence microscopy) over time. The data are cor-
rected, annotated and analyzed with the help of software
tools such as [11, 3537]. The tool from [11] is shown as
an example in Fig. 2. A single experiment can span from a
few hours [38] to several days or even weeks [39, 40], de-
pending on the frame rate (i.e. the time between two con-
secutive snapshots). This yields a few hundreds up to
thousands of images (or image volumes) per experiment.
The number of cells observed in each image varies with
biological applications: from tens of cells in in vitro stem
cell assays [39] to tens of thousands of cells in develop-
mental studies [4, 8, 41]. That is, the total number of indi-
vidual observations (snapshots of a cell in time) in a
database will lie somewhere between 10,000 and 500,000
for typical studies but can easily reach a few million.
For biological studies, a number of cellular features
should be recorded and properly stored in the database.
There are various qualities of interest which are associ-
ated with a snapshot of a single cell; these can be classi-
fied and systematized within a top level ontology of data,
being a part of GFO [42]. Examples of such snapshot
qualities are:
 Cell position: typically given as the centroid of the
cell in Cartesian coordinates as a vector [x, y] in 2D
or [x, y, z] in 3D,
 Cell shape: either given as a mask (a set of spatial
grid elements (voxels) occupied by the cell), as a
polygonal outline, or in an abstract representation
(e.g. as an oriented ellipsoid),
 Cell dimensions: e.g. the area or volume occupied by
the cell,
 Cell state: usually measured as the concentration, or
the presence/absence of certain gene products (RNA
or protein) found in particular cell types,
 Depending on the research question additional
features could be of interest, e.g. cell polarity,
orientation, or intracellular features.
At the level of cell trajectories, the following features
would be of interest:
 Migration: the speed and direction of cell movement,
 Deformation: changes in cell shape,
 Mitosis: occurrence of cell division,
 Apoptosis: occurrence of cell death,
 Differentiation: changes in cell type reflected by
changes of other features, such as genetic markers.
Finally, using the information gathered in complete ge-
nealogies a number of aspects can be analyzed:
 Topology: overall structure of the pedigree and its
sub-trees,
 Cell cycle kinetics: distribution of cellular life-times,
 Fate maps: the identification of sub-populations of
cells that give rise to certain structures of interest
(e.g. tracing the origins of specific organs),
 General structure of sub-populations: the distribution
of different features (e.g. cell fate) within the
genealogy,
 Inter-cellular communication: the influence of cell
behavior by other cells within its spatial and
temporal neighborhood.
Preliminaries: terminological clarifications and problem
statement
We do not make many ontological restrictions on the
top level categories used for the development of an
ontology. The broad spectrum of top level categories,
which can be utilized for knowledge representation in
Fig. 1 Examples of cell tracking data: (a) In vitro tracking of an initially small number of cells. (b) In vitro tracking of a fast expanding culture of
pancreatic cells (200 images, 4600 cells in total). Resulting trajectories and genealogies are shown in a space-time plot. (c) In vivo tracking of early
zebrafish development over several hours (400 images, 10,000 cells per image)
Burek et al. Journal of Biomedical Semantics           (2019) 10:16 Page 3 of 18
general and for ontology development in particular, can
be found in literature [43, 44].
We do not want to limit the analysis to any of those
ontologies, instead we only make a few common-sense
assumptions, keeping in mind that even those presup-
pose some ontological commitments, hence ontology
cannot be escaped:
 Entities such as cells endure through time spans
called their lifetimes. We call these Objects (Obj).
 Objects such as cells possess certain characteristics
describing them. Those characteristics, called in the
current paper Qualities (Q), are expressed in natural
and artificial languages by means of syntactic
elements such as adjectives/adverbs or attributes/
properties, respectively (p. 30, [45]). Typical qualities
of cells are e.g. round shape or a specific location.
 A quality such as an oval shape can be predicated
upon an object in a sense that we can say that the
object has that quality as e.g. a cell has an oval
shape. In the current paper we will call such
assignments Quality Assignments (QA).
 A particular QA can change over time. For instance,
the shape of a cell can change, i.e. shape quality at
two different time points may differ. We refer to all
types of entities as Time Entities (TE). Those are e.g.
intervals and time points.1 A complete analysis of
the current time-ontologies is presented in [46],
which also includes a comparison between GFO-
Time and Allens theory of temporal intervals
[47]. Allens theory can be reconstructed within
GFO-Time, though the converse is not possible.
GFO-Time provides a coincidence-relation between
time-boundaries which allows to model discrete
changes, if needed..
Putting the above together allows us to interpret the
sentence a cell has an oval shape at time t1  as follows:
a cell c is an object, a round shape o is a quality and t1 is
a time entity indicating the time-extent of quality assign-
ment of o to c.
Based on the above assumptions and terminological
clarifications the problem addressed in the current paper
can now be formulated as follows: How to model the
Fig. 2 Screenshot: An example showing a software for manual correction and annotation of cell tracking experiments as described in [11]
1For the purpose of the current paper the class Time is considered as
an abstraction of the time parameter and no specific time ontology is
assumed.
Burek et al. Journal of Biomedical Semantics           (2019) 10:16 Page 4 of 18
change of an objects quality assignments over time in
OWL? E.g. how to represent a change of a cells shape
from round at time t1 to elongated at time t2 ?
We believe that in ontology development, as it is rec-
ognized in software engineering [48], there is no
uniquely determined approach which is optimal in all
contexts. For this reason, the goal of the current paper is
not to provide some ultimate template for modeling a
change of an objects qualities, but instead to review pos-
sible patterns and verify them against our specific use
case of developing CTO.
Problem statement exemplified
Figure 3 presents a straightforward approach to model-
ing qualities in OWL: objects are modeled as OWL
Classes, Qualities as OWL Classes or Datatypes and
Quality Ascriptions - as Object Properties or Datatype
Properties, respectively. The upper part of Fig. 3 presents
a UML diagram depicting the pattern itself. The applica-
tion of the pattern to our use-case is shown in the
bottom part of Fig. 3. For instance, a shape of a cell is
modeled by owl:ObjectProperty named has_shape, link-
ing an owl:Class Cell with an owl:Class Shape.2
Utilizing this pattern, an individual cell and its shape
can be defined in turtle notation [49] as follows:
The major advantage of pattern 1 is its simplicity,
the limited number of entities and the ease of exten-
sion. Unfortunately, this pattern does not allow for
representing the change of qualities over time, e.g.
the change of a cells shape from round to elongated.
In order to overcome the limitations of pattern 1 and
to model the change of an objects qualities over time
one can extend pattern 1 by adding a temporal index to
the Quality Assignment property as presented on Fig. 4.
For instance, a class Cell linked with a class Shape by
means of two distinct OWL properties: has_shape_at_t1
and has_shape_at_t2, denotes that a cell has a different
shape at time t1 and t2, respectively.
With the help of that pattern one can easily model the
change of cell shape:
This approach is simple and works well in situations
where the number of time indexes is limited or when there
is some idiosyncratic time index, as for instance the G2
checkpoint and Meta-phase checkpoint in the cell cycle.
Then, the change of shape can be modeled simply by means
of two distinct OWL properties: has_quality_at_G2_check-
point and has_quality_at_Metaphase_checkpoint. Unfortu-
nately, this pattern is not applicable to our use case, since in
cell tracking experiments the number of observations can
be very large for a single experiment. Additionally, time in-
dices are not known a priori. Therefore, the application of
pattern 2 would require the adjustment of the T-box for
each experiment. Moreover, it would result in hundreds of
quality assignment properties, which is hardly maintainable.
Methods
To find an optimal pattern for representing change in
biomedical ontologies encoded in OWL we base our
2For the sake of simplicity in the examples given here we model all
qualities as OWL classes and their values as instances. Clearly, in real
life systems different means can be utilized for that purpose, e.g. OWL
Enumerated Datatypes or RDF Literals.
Fig. 3 Pattern 1: Quality assignment modeled as OWL property. The upper part of the figure presents a semi-UML diagram depicting the categories
used in the pattern. The bottom part presents the application of the pattern to our domain of interest
Burek et al. Journal of Biomedical Semantics           (2019) 10:16 Page 5 of 18
analysis on three common criteria for software sys-
tems, i.e. scalability, extensibility and adequacy. The
first is a common criterion for benchmarking system
performance with respect to a growing amount of
work. The question to be posed in the context of an
ontology is: How does it scale to accommodate an in-
creasing amount of data and, in particular, is the
number of entities kept to the minimum even in situ-
ations when the amount of information increases?
This corresponds to Ockhams razor [50], a principle
broadly adopted to data modelling according to which
the number of entities must not be multiplied beyond
necessity. That principle entails two rules of database
design, i.e. avoidance of data redundancy and simpli-
city [26].
Extensibility is the second measurement of soft-
ware architecture anticipating the future growth of
the software. In the context of ontology engineering
it can be judged by analysing if and how new infor-
mation can be incorporated into the ontology, with-
out or with a minimal need of reorganizing the
existing knowledge base.
Adequacy is a well know criterion of data model-
ling, also called faithfulness [26], which boils down to
the rule that model elements should reflect reality.
The principle can be verified by examining the fol-
lowing questions: How far do the constructs of the
ontology reflect the elements of the domain and is
the ontology comprehensible to domain experts (who
are often non-technicians)? Although the last criterion
is subjective in nature, it works well in practice, espe-
cially in situations where ontology constructs reflect
tangible elements of the domain. It should be noted
that the criterion of adequacy in the current paper is
understood and applied in purely engineering terms;
we do not aim to contribute to the philosophically-
oriented discussion on the nature of the elements of
the modeled domain, i.e. on realism vs. idealism vs.
conceptualism [51, 52].
Results
Patterns for modeling qualities
In the current section we review two patterns fre-
quently proposed for modeling temporal information,
i.e. reification of n-ary relations and 4d fluents. First,
we present the patterns and then discuss their appli-
cation in three scenarios of distinct temporal distribu-
tion of qualities.
Reification
The reification of n-ary relations is a popular strat-
egy for modeling temporally changing information.
It interprets a time-indexed quality as a 3-ary rela-
tionship linking an object, its quality and the time
at which the quality is assigned to the object. Next,
the relation is reified and introduced to the model
as a class.
Pattern 3 depicted in Fig. 5 presents the application
of this reification strategy to our use case. In contrast
to patterns 1 and 2, a Quality Assignment is not
modeled as owl:ObjectProperty but instead as a re-
ified owl:Class acting as a proxy between an Object
and its Quality.
A reified QA represents a specific assignment of a
Quality to a particular Object and as such is
dependent on both the Object and the Quality. That
means that each Quality Assignment is inherent in
exactly one Object and is the assignment of exactly
Fig. 4 Pattern 2: Quality assignment modeled as time-indexed OWL property
Burek et al. Journal of Biomedical Semantics           (2019) 10:16 Page 6 of 18
one Quality. The former constraint is represented by
the cardinality restriction on the carries link between
Object and Quality Assignment and the latter - by
the cardinality restriction on the of_quality link be-
tween Quality Assignment and Quality. Time-index is at-
tributed directly to QA by means of the at_time property
linking QA with the Time class.
The bottom part of Fig. 5 illustrates the applica-
tion of pattern 3 to the CTO use-case. The object
property carries links the Cell class with the
ShapeAssignment class, which is a subclass of Quality
Assignment. ShapeAssignment represents a quality assign-
ment at a given time and has two OWL properties: of_
quality and at_time. The former specifies the value of a
quality, i.e. a specific shape, whereas the latter - the time
index of the parameter.3
This pattern can be applied to annotate a single cell
with two distinct shapes at two different time points:
In many situations it is not the time index of quality
assignments that is relevant but only their t8emporal
order. This may also be true for some cell tracking ex-
periments. In such cases pattern 3 can be simplified: in
the upper part of Fig. 6 the property at_time and the
class Time can be replaced with the property is_next, es-
tablishing the temporal order of quality assignments.
Fig. 5 Pattern 3: Quality assignment modeled as time-indexed OWL class
3In a slightly different variant of the pattern a generic
QualityAssignment class could be used instead of class
ShapeAssignment. This generalization of handling qualities minimizes
the number of classes required in case of diverse qualities. However, it
does not influence the discussed patterns as such when it comes to
representing the change of quality value over time. Thus, it seems that
for the sake of readability the specific properties are more suitable.
Burek et al. Journal of Biomedical Semantics           (2019) 10:16 Page 7 of 18
The implementation of this pattern to our case is pre-
sented in the bottom part of Fig. 6.
Pattern 3 overcomes the limitations of patterns 1 and
2 reported above, since time-indexed quality value as-
signments are represented as instances only. Thus, even
in situations where many time-indexed value assign-
ments occur, the number of classes and properties in the
ontology remains constant (and is relatively low).
On the other hand, as observed in [31], the model in-
troduces additional OWL classes and OWL properties
for representing time-indexed quality ascriptions, redu-
cing its lucidity.
4d Fluents
An alternative to the n-ary relation reification is the so-
called 4d fluents pattern [30]. It is inspired by four-
dimensionalism [29], a philosophical theory explaining
the persistence of objects through time, called perdur-
ance, in analogy to their extension in space: similarly to
an object occupying some space s having parts occupy-
ing parts of s, an object occupying some time t may have
temporal parts occupying parts of t. In that understand-
ing, time-extended objects are considered as the so-
called 4d worms, which can be sliced into temporal
parts, as 3d objects can be sliced into their spatial parts.
The top-part of Fig. 7 presents a 4d pattern. In contrast
to the reification pattern, the idea behind 4d fluents is
not to reify a temporally indexed relation but instead a
temporal part of an object. For instance, in order to
model the fact that a cell c has a round shape at time t1
one can reify a temporal part of c and then assign a
quality directly to the reified part:
Conceptually, the two patterns seem quite distinct, yet
when comparing Fig. 5 and Fig. 7 one can observe that
structurally they are almost the same and both are based
on introducing an association class. The only structural dif-
ference is the cardinality constraint determining the num-
ber of qualities linked to the reified class. In the reification
pattern it is 1, whereas in the 4d fluents pattern it is 0..n.
Therefore, when modeling an objects single quality assign-
ment, both patterns are in fact equal.
The difference between the patterns can be well illus-
trated when applying the patterns to relations rather
Fig. 6 Pattern 4: Temporally ordered quality assignments
Burek et al. Journal of Biomedical Semantics           (2019) 10:16 Page 8 of 18
than quality assignments. Let us consider the CTO rela-
tion of cell-cell contact, denoting the fact that two
cells touch each other. In order to model a tempor-
ally indexed cell-cell contact, the reification pattern
requires the introduction of a single reified time-
indexed relation, whereas the fluent pattern would
introduce a reified and time-indexed slice for each
cell participating in the contact.
The difference between the patterns can also be ob-
served in cases where numerous quality assignments are
being represented, which is in fact the real challenge of
ontology engineering. Therefore, we will analyze the pat-
terns using three different cases of temporal distribution
of qualities:
 Temporally non-overlapping quality assignments.
For instance, a cell can have an oval shape at one
time and an elongated shape at another, but it can
never have both shapes at the same time.
 Temporally equal quality assignments. Thit is a
typical scenario in time lapse experiments where
at a single time point numerous distinct qualities
are observed, e.g. shape, location, etc.
 Temporally overlapping, but not temporally equal
quality assignments. This is a common situation
when qualities change independently from one
another, as is the case with the location and
shape of a cell.
Temporally non-overlapping quality assignments of a
single quality
As a starting point, we consider the simplest case, in
which no two quality assignments of an object are lo-
cated at the same temporal location. Such a situation is
natural for many qualities when considered separately,
e.g. typically a cell has a single location or a single shape
at any given time. This scenario is often assumed in the
works devoted to the modeling of temporal information,
e.g. in [24, 30, 31]. In such a case it can be easily ob-
served that both patterns behave the same, in fact there
is no difference when applying them. Modeling n quality
assignments of a single quality of a single object we need
to introduce n instances of a reified class in both cases.
Both models are equally extensible, i.e. to introduce a
new characteristic a new instance must be added to the
model. Finally, the adequacy of both solutions seems to
be merely a matter of personal taste since the choice be-
tween the patterns generates no structural differences in
the models.
Temporally equal quality assignments
The above discussion is justified when considering a sin-
gle quality in isolation. Yet, when considering numerous
qualities of an object, it is clear that there can be two or
more quality assignments which overlap temporally, e.g.
a cell at a given time point can have some location and
some shape. This is a typical scenario in cell tracking
Fig. 7 Pattern 5: Reified 4D fluents
Burek et al. Journal of Biomedical Semantics           (2019) 10:16 Page 9 of 18
experiments, where at a single time point more than one
quality is observed. In such cases the application of the
reification pattern results in a model with redundantly
time-indexed Quality Assignments: for each quality ob-
served at a given time point a separate Quality Assign-
ment instance has to be introduced.
It seems that the 4d fluents pattern solves that problem.
Time slices in their simplest form are temporal parts of
objects having an arbitrary temporal extension (usually
considered an interval). An alternative approach, present
e.g. in the General Formal Ontology (GFO), introduces
temporal particles located at discrete time points (the so-
called presentials) which are distinct from time extended
slices [45]. In GFO, a presential is an entity that is wholly
present at a single time point. For instance, a cell observed
at a single time point would be considered a presential
cell. A presential may have multiple assigned qualities, all
present at the same time point as the presential which car-
ries them. Thus, a presential is a snapshot of a time ex-
tended entity, i.e. a cell observed at a single time point can
be considered a snapshot of a time extended cell.
Figure 8 presents the pattern for modeling time slices
and presentials where both are considered temporal par-
ticles of objects. Based on that pattern a modeler can
utilize both time interval slices and/or presentials, de-
pending on the actual needs.
The annotation of an individual cell using the presen-
tial pattern would look as presented below:
In contrast to the reification pattern, the presential
pattern reduces the number of instances introduced
to the model. Instead of reifying each quality assign-
ment at a given time point, all coinciding quality as-
signments are modeled with the help of a single
presential instance.
Fig. 8 Pattern 6: Generalized 4D fluents. Presentials and Slices
Burek et al. Journal of Biomedical Semantics           (2019) 10:16 Page 10 of 18
4d fluents also scales better: each new quality assign-
ment added to the reification-based model requires a
new instance, whereas in the case of the 4d-based model
no additional instance is needed when a time slice with
the same time index already exists in the model.
The frugality of the 4d pattern seems to make it more
intuitive than the reification pattern, especially in the
case of cell tracking experiments where the presential
cells are the entities physically represented in the ac-
quired images. Thus, they can be easily identified and it
seems quite natural to reify them.
Temporally overlapping characteristics
In cell tracking experiments the qualities of enduring
cells are deduced on the basis of a sequence of observed
presential cells and their qualities. For instance, if a cell
is observed to have a round shape over the sequence
taken at time points t1, t2,.., tn, then typically one can de-
duce that the cell has a round shape during the whole
time interval (t1, tn). Clearly, in the case of numerous
mutually independent quality assignments it may turn
out that the temporal extensions of many of them may
overlap. For instance, during a time interval (t1, t5) a cell
may remain in location l1 but its shape may change from
round in (t1, t3) to elongated in (t3, t5). That results in
two shape quality assignments overlapping with the lo-
cation quality assignment. This situation is clearly visible
when the reification pattern is used, as for each observed
quality assignment a reified instance is introduced.
However, when turning to 4d fluents, the first observation
we make is that the adaptation of the pattern to this case is
not as straightforward as in previous cases, when it was
relatively easy to say what the cells time slice is, namely, a
presential cell observable in an image and thus having its
own identity. However, in the current case we want to reify
not the presential (observable) cells but instead the time ex-
tended, temporal parts of cells. This raises the following
question: What is a temporal part of a cell and what rules
drive the slicing of an object (a cell) into its temporal parts?
It seems that at least two strategies for introducing tem-
poral parts could come in handy. The first is based on the
principal idea of 4-dimensionalism, namely that a time ex-
tended entity can be sliced into temporal slices in such a
way that each slice fully represents the sliced object at a
given time. This means that all qualities assigned to an ob-
ject within the time span of a slice are attributed to the
slice directly. We call this type of slicing vertical.
Unfortunately, modeling temporally overlapping qual-
ity assignments with vertical slices easily leads to serious
redundancy and is hardly maintainable. This is due to
the fact that slices are overlapping and each one rep-
resents an object in full at a given time and as such
it carries all qualities attributed to the object during
the slices lifetime.
An intuitive solution to fix this problem would be to
prohibit the overlapping of slices. This results in a model
in which a time extended entity is sliced into non-
overlapping slices so that the sum of all the parts consti-
tutes the full lifespan of the object.
Let us illustrate this strategy with an example, starting
with the model of a cell remaining in location l1 during
the interval (t1, t5):
Now, let us assume that we add to our model a new
observation (fact) that the cell changes its shape from
round in (t1, t3) to elongated in (t3, t5). If we add that
observation to our model, we end up with two additional
time particles depicting the location of the cell: one end-
ing at t3 and the other starting at t3, thus both new parti-
cles are overlapping with:my_cell_slice. In order to fix
this, one could reorganize the time slices into two non-
overlapping slices, the first representing the state of the
cell being round and located in l1 and the second - the
state of the cell being elongated and located in l2.
Unfortunately, this strategy has its problems. As it can
be seen from the above example, the change of any of
Burek et al. Journal of Biomedical Semantics           (2019) 10:16 Page 11 of 18
the qualities may entail the reorganization of the objects
slices. That leads to a proliferation of slices, but more
importantly, it makes the knowledge base strongly
coupled and thus harder to extend, i.e. the addition of
new information entails the reorganization of previous
knowledge.
In addition, despite the fact that the strategy solves the
problem of the models redundancy, it still results in
heavily overloaded models. As presented on the listing
above, each slice carries a full specification of the cell at
a given time, even for those qualities which remain con-
stant across many slices.
In order to overcome those limitations an alternative
interpretation of 4d fluents could be considered: an en-
tity could be sliced not only vertically, i.e. along the time
dimension, but also horizontally, i.e. along its quality as-
signments. That way a slice does not fully represent an
object at a given time but only some of its aspects, e.g.
that a cell is located at l1 at t1 - t2. Thus, a slice is a kind
of temporally indexed reified attribute of an entity.
That interpretation fixes the problem of model redun-
dancy, but it also blurs the difference between the 4d
fluents and the reification pattern, since a time slice now
represents some quality assignment, i.e. some temporally
indexed attribute of an entity. The actual difference be-
tween such an interpretation of time slices and reified
quality assignments is hidden in the cardinality
constraint on the quality role (presented in Fig. 5 and
Fig. 7). While the reified quality assignment links an ob-
ject with a single quality, a slice can link an object with
multiple qualities when quality assignments overlap tem-
porally. Thus, if we add the fact of a cells size, which is
temporally equal to that of its shape, we are not forced
to introduce a new temporal particle but it is sufficient
to add that fact to: my_cell_slice_2:
Discussion
Our analysis shows that there is no single best choice
with respect to simplicity, scalability, extensibility and
adequateness for modeling a change of qualities over
time. Table 1 provides a condensed summary of the dis-
cussed patterns and their flavours. Additionally, as the
ontology of cell tracking experiments is still under devel-
opment and relevant amounts of annotated data are cur-
rently lacking, we provide a synthetic example in Table 2
as a benchmark for the performance of discussed
patterns. We simulated data of a single cell undergoing
a parallel changes of four qualities K, L, M, N over time
t15. Since the size of A-box depends on the distribution
of quality changes we have simulated several schemas of
change as depicted on Fig. 9, i.e. qualities K and L
changes independently from all others, from values k1
to k2 and from l1 throughout l2, l3, l4 to l5, respectively.
M and N, in turn, undergo a change simultaneously.
Below we elaborate in detail on two of the presented
patterns, which are our main focus in the current paper,
i.e. the reification and the 4d fluents patterns. These pat-
terns perform differently depending on the temporal dis-
tribution of quality assignments. However, both patterns
result in the same model in the case where quality as-
signments are not temporally overlapping. This situation
seems, however, merely theoretical and in real life cases
it is to be expected that numerous qualities have to be
modeled (as it is also the case in the cell tracking ontol-
ogy). In fact, the introduction of numerous qualities
which are temporally overlapping or equal is the major
source of modelling complexity.
In cases where quality assignments are temporally
equal, the 4d fluents pattern performs better. Firstly, the
expected size of T-box is smaller in case of the 4d flu-
ents pattern as the number of reified classes is equal to
the number of domain classes/types having the qualities
attributed, whereas, in case of the reification pattern, it
is equal to the number of qualities, which, in turn is typ-
ically much higher than the number of classes/types.4 In
fact, in case of the cell tracking ontology the number of
classes is reduced to one as we are only interested in
cells. The size of A-box is also expected smaller for the
4d fluents pattern as the number of reified instances is
the product of objects and t-indexes and the number of
qualities has no additional influence in contrast to the
reification pattern. The extension and maintainability of
such models is also simpler than of models based on the
reification pattern, since adding new quality assignments
requires no additional (reified) model element. Especially
in cases where temporal slices are tangible objects (as in
cell tracking experiments), the number of reified entities
is lower and the reified presentials are well-grounded
domain concepts, which in turn increases the adequate-
ness of the model.
In cases of temporally overlapping quality assignments
the application of 4d fluents is not straightforward. It
could come in variants (a) vertical 4d fluents: a fully spe-
cified non-overlapping slices, and (b) horizontal 4d flu-
ents: a not fully specified overlapping slices. For both
variants of the pattern the size of T-box is expected to
4In case a reification pattern is applied in its generic form with a single
generic QualityAssignment the amount of T-Box elements for both
patterns would be the same.
Burek et al. Journal of Biomedical Semantics           (2019) 10:16 Page 12 of 18
Ta
b
le
1
O
ve
rv
ie
w
of
pa
tt
er
ns
an
d
th
ei
r
pe
rfo
rm
an
ce
in
re
pr
es
en
ta
tio
n
of
ch
an
ge
of
qu
al
iti
es
Pa
tt
er
n
O
ve
rv
ie
w
T-
bo
x
Si
m
pl
ic
ity
(w
rt
nu
m
be
r
of
t-
bo
x
el
em
en
ts
)
A
-b
ox
si
m
pl
ic
ity
(w
rt
nu
m
be
r
of
A
-b
ox
el
em
en
ts
)
Ex
te
ns
ib
ili
ty
/m
ai
nt
ai
na
bi
lit
y
A
de
qu
at
en
es
s
O
W
L
pr
op
er
ty
A
de
fa
ul
t
O
W
L
ha
nd
lin
g
of
qu
al
iti
es
.
Ve
ry
H
ig
h
-
no
ad
di
tio
na
lc
la
ss
es
or
pr
op
er
tie
s.
Ve
ry
H
ig
h
-
no
re
ifi
ed
in
st
an
ce
s.
H
ig
h
Ve
ry
lo
w
-
no
su
pp
or
t
fo
r
re
pr
es
en
tin
g
ch
an
ge
of
qu
al
ity
as
si
gn
m
en
ts
.
T-
in
de
xe
d
O
W
L
pr
op
er
ty
Th
e
pa
tt
er
n
is
si
m
pl
e
an
d
w
or
ks
w
el
lf
or
lim
ite
d
nu
m
be
r
of
tim
e
in
de
xe
s
or
fo
r
id
io
sy
nc
ra
tic
tim
e
in
de
x.
Lo
w
fo
r
ce
ll
tr
ac
ki
ng
ex
pe
rim
en
ts
-
th
e
nu
m
be
ro
fo
bj
ec
tp
ro
pe
rt
ie
s
is
hi
gh
an
d
pr
op
or
tio
na
lt
o
th
e
nu
m
be
ro
ft
-in
de
xe
s
Lo
w
fo
r
ce
ll
tr
ac
ki
ng
du
e
to
hi
gh
nu
m
be
r
of
t-
in
de
xe
d
pr
op
er
ty
ax
io
m
s.
Lo
w
fo
r
ce
ll
tr
ac
ki
ng
-
re
qu
ire
s
th
e
ad
ju
st
m
en
t
of
th
e
T-
bo
x
fo
r
ea
ch
ex
pe
rim
en
t.
C
om
pl
ex
ity
of
T-
bo
x
im
pl
ie
s
po
or
m
ai
nt
ai
na
bi
lit
y.
H
ig
h
-
no
re
ifi
ed
m
od
el
in
g
ar
tif
ac
t
m
us
t
be
in
tr
od
uc
ed
..
Re
ifi
ca
tio
n
Th
e
pa
tt
er
n
ov
er
co
m
es
th
e
lim
ita
tio
ns
of
pa
tt
er
ns
ab
ov
e
-
tim
e-
in
d
ex
ed
qu
al
ity
va
lu
e
as
si
g
nm
en
ts
ar
e
re
p
re
se
nt
ed
as
re
ifi
ed
in
st
an
ce
s
on
ly
.
Th
er
ef
or
e,
ev
en
in
si
tu
at
io
ns
w
he
re
m
an
y
tim
e-
in
de
xe
d
va
lu
e
as
si
gn
m
en
ts
oc
cu
r,
th
e
siz
e
of
T-
bo
x
is
co
ns
ta
nt
.
M
od
er
at
e
-
th
e
nu
m
be
r
of
re
ifi
ed
qu
al
ity
va
lu
e
as
si
gn
m
en
t
cl
as
se
s
eq
ua
ls
th
e
nu
m
be
r
of
qu
al
iti
es
.
M
od
er
at
e
-
th
e
nu
m
be
r
of
re
ifi
ed
in
st
an
ce
s
eq
ua
ls
th
e
pr
od
uc
t
of
ob
je
ct
s,
qu
al
iti
es
an
d
t-
in
de
xe
s.
Fo
r
te
m
po
ra
lly
eq
ua
lq
ua
lit
y
as
-
si
gn
m
en
ts
it
ca
us
es
re
du
nd
an
cy
,
i.e
.f
or
ea
ch
qu
al
ity
ob
se
rv
ed
at
a
gi
ve
n
tim
e
po
in
t
a
se
pa
ra
te
Q
ua
lit
y
A
ss
ig
nm
en
t
in
st
an
ce
ha
s
to
be
in
tr
od
uc
ed
.
M
od
er
at
e
-
a
ne
w
qu
al
ity
as
si
gn
m
en
t
re
qu
ire
s
a
ne
w
in
st
an
ce
of
a
re
ifi
ed
cl
as
s.
M
od
er
at
e
-
re
ifi
ed
qu
al
ity
as
sig
nm
en
ts
do
no
t
co
rr
es
po
nd
to
an
y
ta
ng
ib
le
ob
je
ct
s
in
a
do
m
ai
n
of
ce
ll
tr
ac
ki
ng
bu
t
ar
e
m
er
e
m
od
el
in
g
co
ns
tr
uc
ts
.
Re
ifi
ca
tio
n
w
/
te
m
po
ra
lly
or
de
re
d
as
si
gn
m
en
ts
Th
e
pa
tt
er
n
si
m
pl
ifi
es
an
d
re
st
ric
ts
th
e
ex
pr
es
si
vi
ty
of
th
e
re
ifi
ca
tio
n
pa
tt
er
n
by
no
ex
pl
ic
it
re
pr
es
en
ta
tio
n
of
tim
e
en
tit
ie
s
bu
t
on
ly
a
te
m
po
ra
lo
rd
er
of
qu
al
ity
va
lu
e
as
si
gn
m
en
ts
.
H
ig
h
-
sa
m
e
as
ab
ov
e
w
rt
qu
al
ity
as
si
gn
m
en
t.
A
dd
iti
on
al
ly
,n
o
cl
as
se
s
fo
r
tim
e
en
tit
ie
s
ar
e
in
tr
od
uc
ed
.
Sa
m
e
as
ab
ov
e
w
rt
qu
al
ity
as
si
gn
m
en
t.
A
dd
iti
on
al
ly
,n
o
in
st
an
ce
s
fo
r
tim
e
en
tit
ie
s
ar
e
in
tr
od
uc
ed
.
M
od
er
at
e
-
sa
m
e
as
ab
ov
e.
M
od
er
at
e
-
sa
m
e
as
ab
ov
e.
4d
flu
en
ts
(v
er
tic
al
)
/
st
at
es
Th
e
pa
tt
er
n,
in
co
nt
ra
st
to
th
e
re
ifi
ca
tio
n
pa
tt
er
n,
re
ifi
es
no
t
a
te
m
po
ra
lly
in
de
xe
d
re
la
tio
n
bu
t
in
st
ea
d
a
te
m
po
ra
lp
ar
t
of
an
ob
je
ct
w
hi
ch
ca
n
be
in
te
rp
re
te
d
as
a
st
at
e
of
an
ob
je
ct
.
H
ig
h
-
nu
m
be
r
of
re
ifi
ed
cl
as
se
s
is
re
du
ce
d
to
th
e
nu
m
be
r
of
ob
je
ct
ty
pe
s
Ve
ry
H
ig
h
fo
r
te
m
po
ra
lly
eq
ua
l
qu
al
iti
es
-
in
st
ea
d
of
re
ify
in
g
ea
ch
qu
al
ity
as
si
gn
m
en
t
at
a
gi
ve
n
tim
e,
al
lc
oi
nc
id
in
g
qu
al
ity
as
si
gn
m
en
ts
ar
e
re
pr
es
en
te
d
as
a
a
si
ng
le
in
st
an
ce
.
M
od
er
at
e
fo
r
te
m
po
ra
lly
ov
er
la
pp
in
g
qu
al
iti
es
-
th
e
nu
m
be
r
of
re
ifi
ed
qu
al
ity
in
st
an
ce
s
is
a
fu
nc
tio
n
of
qu
al
ity
as
si
gn
m
en
t
ch
an
ge
s
an
d
de
pe
nd
s
on
th
e
di
st
rib
ut
io
n
of
ch
an
ge
s.
Ve
ry
H
ig
h
fo
r
te
m
po
ra
lly
eq
ua
l
qu
al
iti
es
-
no
ad
di
tio
na
li
ns
ta
nc
e
is
ne
ed
ed
w
he
n
a
tim
e
sl
ic
e
w
ith
th
e
sa
m
e
tim
e
in
de
x
al
re
ad
y
ex
is
ts
in
th
e
m
od
el
.
Lo
w
fo
r
te
m
po
ra
lly
ov
er
la
pp
in
g
qu
al
iti
es
-
ne
w
qu
al
ity
as
si
gn
m
en
t
re
su
lts
in
pr
ol
ife
ra
tio
n
an
d
re
or
ga
ni
za
tio
n
of
re
ifi
ed
in
st
an
ce
s
(s
lic
es
)
an
d
m
ul
tip
lic
at
io
n
of
pr
op
er
ty
ax
io
m
s
fo
r
no
n-
ch
an
gi
ng
qu
al
iti
es
.
H
ig
h
fo
rc
el
lt
ra
ck
in
g
ex
pe
rim
en
ts
-p
re
se
nt
ia
lc
el
ls
re
pr
es
en
t
th
e
do
m
ai
n
ad
eq
ua
te
ly
-t
he
y
ar
e
th
e
ce
lls
re
pr
es
en
te
d
in
th
e
ac
qu
ire
d
im
ag
es
or
th
e
te
m
po
ra
lly
in
de
xe
d
st
at
es
of
ce
lls
.
4d
flu
en
ts
(h
or
iz
on
ta
l)
Th
e
pa
tt
er
n,
ov
er
co
m
es
th
e
lim
ita
tio
ns
of
th
e
ve
rt
ic
al
4d
flu
en
ts
pa
tt
er
n
in
re
pr
es
en
tin
g
th
e
te
m
po
ra
lly
ov
er
la
pp
in
g
qu
al
iti
es
by
th
e
in
tr
od
uc
tio
n
of
ho
riz
on
ta
l
sl
ic
in
g
su
ch
th
at
a
re
ifi
ed
en
tit
y
re
pr
es
en
ts
so
m
e
qu
al
ity
as
si
gn
m
en
t.
H
ig
h
-
sa
m
e
as
ab
ov
e.
Ve
ry
H
ig
h
fo
r
te
m
po
ra
lly
eq
ua
l
qu
al
iti
es
-
sa
m
e
as
ab
ov
e.
H
ig
h
fo
r
te
m
po
ra
lly
ov
er
la
pp
in
g
qu
al
iti
es
-
in
co
nt
ra
st
to
th
e
re
ifi
ca
tio
n
pa
tt
er
n,
it
en
ab
le
s
th
e
bu
nd
lin
g
of
te
m
po
ra
lly
eq
ua
l
ch
ar
ac
te
ris
tic
s
in
to
a
si
ng
le
en
tit
y,
w
hi
ch
lim
its
th
e
nu
m
be
r
of
re
ifi
ed
en
tit
ie
s
Ve
ry
H
ig
h
fo
r
te
m
po
ra
lly
eq
ua
l
qu
al
iti
es
-
sa
m
e
as
ab
ov
e.
H
ig
h-
fo
r
ce
ll
ov
er
la
pp
in
g
qu
al
iti
es
so
lv
es
th
e
pr
ob
le
m
of
th
e
ve
rt
ic
al
4d
pa
tt
er
n.
A
dd
iti
on
al
ly
,i
n
co
nt
ra
st
to
th
e
re
ifi
ca
tio
n
pa
tt
er
n
a
ne
w
qu
al
ity
as
si
gn
m
en
t
re
qu
ire
s
a
ne
w
in
st
an
ce
on
ly
if
a
tim
e
sl
ic
e
fo
r
a
gi
ve
n
tim
e
do
es
no
t
ex
is
t
ye
t
in
A
-b
ox
.
Lo
w
-
tim
e
sl
ic
es
do
no
t
re
fle
ct
ce
lls
ob
se
rv
ed
on
tim
e
po
in
ts
bu
t
in
st
ea
d
co
lle
ct
io
ns
of
te
m
po
ra
lly
eq
ua
lq
ua
lit
y
as
si
gn
m
en
ts
.A
no
n-
ob
vi
ou
s
in
te
rp
re
ta
tio
n
of
th
e
as
so
ci
at
io
n
en
tit
y
lim
its
th
e
in
tu
iti
ve
ne
ss
of
th
e
m
od
el
.
Burek et al. Journal of Biomedical Semantics           (2019) 10:16 Page 13 of 18
be smaller compared to the reification pattern. The size
of the A-box varies depending on the distribution of the
quality changes over time, yet the total sum of instances
and property axioms is higher for both variants than for
the reification pattern.
Here, the first variant does not work well since it is
hardly extensible, i.e. adding a quality assignment which
is temporally overlapping with existing ones requires the
reorganization of the A-box - it results in proliferation
and reorganization of reified instances (slices) and multi-
plication of property axioms for non-changing qualities.
For instance, the attribution of m2 over t25 must be
split into three axioms, one for each vertical slice.
The second variant solves that problem, as there is no
need of redundant quality assignments for non changing
qualities. Additionally, in contrast to the reification pat-
tern, it enables the bundling of temporally equal charac-
teristics into a single entity, which limits the number of
reified entities. New quality assignment only requires
introduction of a new instance if a time slice for a given
time is not yet present. However, a drawback of such an
approach is the non-obvious interpretation of the associ-
ation entity, which limits the intuitiveness and adequacy
of the model.
From the above considerations, we see that a presen-
tial variant of the 4d fluents pattern is naturally applic-
able to the case of temporally equal quality assignments,
especially in time lapse experiments where the presential
cells are tangible/observable objects. Yet, in cases of
non-equal but overlapping quality assignments, the ap-
plication of 4d fluents is not straightforward, demon-
strating the major weakness of a 4d approach: it is not
common-sense. In [30] the authors observe that it is not
very natural to convert statements such as Joe walked
into the room into their 4d equivalents such as A tem-
poral part of Joe walked into a temporal part of the
room. It seems that four dimensionalism has several
weaknesses, also on the level of philosophical theory
underlying the 4d fluents pattern, and the discussion is
still not settled [53]. One of the open problems is the
identity of four-dimensional entities. For a four-
dimensionalist, the identity of an entity resides in its un-
changing temporal parts, but, on the other hand, one
can argue that an entity has different temporal parts at
different times. In contrast, three-dimensionalism seems
more common-sense in that respect. 3d objects are con-
sidered to be identical over time, and only their proper-
ties change over time with no harm to the criteria
constituting the identity of 3d objects.
Therefore, one may still ask if it is possible to get the
benefits of the 4d-pattern without slipping into the 4-d
interpretation of time extended entities. We believe that
some well known approaches in the area of software en-
gineering permit a modeler to abandon a 4d account of
reality, sticking to the 3d approach and still obtaining a
similar output as the 4d pattern.
For instance, the second variant of the 4d pattern can
be successfully represented using state modeling, a tech-
nique originating from finite-state machines, which, due
to its intuitiveness, is applied far beyond hardware and
software engineering. In state modeling the behaviour of
an object (a system) is modeled with the help of the
states the object can be in. An objects state corresponds
to a phase of the execution of the state machine during
which some invariable condition holds. A state can be
defined by the attributes of the object and their
Table 2 Amount of elements for a fragment of ontology representing the change of qualities of a single cell illustrated in Fig. 9
Classes Object properties Individuals Object Property Expressions
T-indexed OWL property 5 7 11 7
Reification Pattern 10 (7) 3 28 30
4D Vertical 7 3 21 30
4D Horizontal 7 3 25 24
Fig. 9 A fragment of simulated cell tracking experiment results presenting changes of qualities K, L, M, N over time t15
Burek et al. Journal of Biomedical Semantics           (2019) 10:16 Page 14 of 18
respective values. For instance, a state of a cell can be
defined by the cells shape and location.
The change of an objects state is modeled with the
help of a transition, which is a directed arc linking the
source state with the target state. An object can change
its state over time but at any given time an object can
only be in a single state. That corresponds to the second
variant of the 4d pattern, where time slices are non-
overlapping.
Thus, a change of quality assignments over time can
be interpreted in terms of a change in the objects state.
In that sense, a model presenting temporal non-
overlapping slices of a cell can be easily reformulated
with the help of state modeling:
In contrast to the previous model, the new model does
not use the notion of time slices, which requires a 4-d
interpretation of entities. Instead, a collection of quality
assignments constitutes the state of the object.
Another alternative approach is the actor-role pat-
tern, also known as actor-participant pattern [54].
The pattern originates from software engineering, but
can be applied in the context of ontology engineering
as well [55]. In principle, the pattern is used to de-
couple the identity (the actor) from the behavior (the
role). The pattern consists of two entities, an actor
and a role, linked by a one-to-many relationship. An
actor is an entity which has an identity and attributed
non-changing characteristics. A role is existentially
dependent on an actor and bundles all characteristics
attributed to the actor in the context in which he
plays a role. An actor can have many roles both sim-
ultaneously as well as sequentially, whereas a role is
always a role of a single actor. A classical example of
an actor-role pattern are social roles such as e.g. a person
(an actor) having different roles such as a student, a driver
or an employee. A role pattern has been extended by some
authors to an actor-role-context pattern, introducing an
additional entity representing a context in which an actor
plays a given role [55, 56].
The modeling of temporally indexed quality assign-
ments with the role pattern results in a model analogous
to the third variant of the 4d pattern. In that sense, hori-
zontal and vertical slices of an object can be interpreted
as roles of the object in the context of a bundle of qual-
ities. Hence, each bundle of temporally equal quality as-
signments is represented as a separate temporally
indexed role. Thus, each role represents some aspect of
an entity at a given time, but, in contrast to the state
modeling pattern, roles can temporally overlap and a
single role does not provide a full specification of the ob-
jects characteristics at a given time, but only those rele-
vant in its context.
Summing up, the 4d pattern can be successfully recon-
structed with two intuitive and well known patterns, i.e.
state and role modeling. This finding can be helpful to
modelers not familiar with the philosophical account of
4-dimensionalism or those for whom considering time
extended objects in terms of 4d entities could be
counter-intuitive.
Choices adapted to the cell tracking ontology
Our analysis demonstrate that there is no single silver
bullet approach to modeling temporally changing infor-
mation. The key aspects here are the number of time in-
dexes and the actual temporal distribution of the
information to be modeled. Based on our analysis we de-
rive the following guidelines for ontology engineers:
 The default handling of OWL properties is most
performant but provides no means for modeling
changes in quality values and therefore cannot be
used when those changes need to be represented.
 The t-indexed property pattern is suited for cases
with a limited number of time indices or in case of
an idiosyncratic time index.
 The vertical 4d fluents/states pattern is suited for
cases with many time indexes and with temporally
equal quality assignments. That is a typical setting in
domains and applications where states of objects are
observed and documented at particular time windows
as it is the case of time lapse experiments where cells
are imaged at equal time intervals.
 The horizontal 4d fluent and the reification pattern
are best suited for the cases with overlapping but
not equal quality assignments. This is the case for
instance when object qualities change independently
Burek et al. Journal of Biomedical Semantics           (2019) 10:16 Page 15 of 18
one from another, as for instance in situation where
the shape of a cell changes independently from its
location.
Accordingly, we have developed CTO as a combined
approach of n-ary relations and presentials. In CTO,
there are two possible types of temporal particles in-
volved: presentials and interval-based particles. The
former correspond to tangible objects observable in im-
ages and indexed with discrete and, therefore, non-
overlapping time points. This is why we have decided to
reify them. This reduces the number of entities, since we
are not forced to reify each QA on the presential level
but instead we can use a straightforward OWL approach
to model qualities as properties of presentials. On the
other hand, in order to model interval-based, overlap-
ping and dynamically changing quality assignments we
have decided to use reified quality assignments.
The combination of both patterns supports at the
same time the requirements of Ockhams razor (the
number of entities used for representing presential qual-
ity assignments is limited by the usage of presentials)
and the extensibility of the ontology (since we use reified
time extended quality assignments, there is no need to
reorganize the existing ontology after adding new over-
lapping quality assignments).
In the current paper we focus on a specific use case of
modeling the change of an objects qualities. Yet, we
think that the patterns and design choices presented are
not restricted to that case: in the development of CTO
we have followed the very same principles for modeling
the change of relations between cells. One example of
such a relation is cell_cell_contact representing adhesion
of two or more cells. Here, in analogy to the case of
quality assignments (modeling relations indexed with
time points), we have decided to follow the presential
pattern and we have used the reification pattern to
model time-extended relations.
Conclusions
Biomedical systems are dynamic in their nature; the rep-
resentation of change is thus one of the fundamental
challenges for knowledge engineering in the biomedical
domain. The current paper addresses the problem of
modeling the change of quality assignments over time in
biomedical ontologies encoded in OWL. The paper dis-
cusses two patterns for modeling temporally changing
information, i.e. n-ry relation reification and 4d fluents.
In contrast to the rich literature on the topic, we are not
interested in modeling temporally isolated characteristics
but an entire web of characteristics in a dynamically
changing domain. Concerning an ontology of time, we
take a minimal ontological commitment which can be
easily fulfilled by various time ontologies, depending on
intended granularity of the model. In many cases, OWL-
time is sufficient, though there might be situations in
which the modeling of a discrete change is needed. In this
case, OWL-time is not sufficient and we may use GFO-
time (and the corresponding OWL-representation).
We discuss the application of these patterns to the
biomedical ontology dedicated to the annotation of cell
tracking experiments (which is currently under develop-
ment). We have analyzed the performance of each solu-
tion in three different settings with respect to common
criteria of software engineering and data modelling, i.e.
scalability, extensibility and adequacy. We have dis-
cussed the benefits and drawbacks of each approach as
well as the underlying design choices. For each design
choice, we have presented possible options and modeling
variants.
The lesson learned from this analysis is that there is
no single best approach. We demonstrate that the pat-
terns behave differently depending on the temporal dis-
tribution of the information modeled. Thus, the optimal
model can be obtained by combining the two competi-
tive approaches. The example of CTO demonstrates that
both reification and 4d fluents patterns can work hand
in hand in a single ontology.
Additionally, we have found that in the (common) case
of temporally overlapping quality assignments the appli-
cation of the 4d fluents pattern can be reconstructed by
two alternative patterns well-known in computer sci-
ence, i.e. the state modeling pattern and the actor-role
pattern. This finding can be helpful to those users not
familiar with the philosophical discussion on four-
dimensionalism to whom considering entities in terms
of 4d worms may seem awkward.
Although the discussed patterns are dedicated for
OWL, the underlying conceptual choices are generic in
nature and we believe that they can be successfully ap-
plied to other technologies and formalisms, such as, e.g.,
UML or ERD. We also expect that the same patterns
could be helpful for modeling other types of temporal
information, such as temporal relations.
The patterns have been investigated in the context of
developing a biomedical ontology dedicated to the anno-
tation of cell tracking experiments. The ontology is
intended for integration with software used for annota-
tion of cell tracking results [11, 3537] (see also Fig. 2).
Obviously, there are two main tasks to solve: Firstly,
we need a sufficiently expressive annotation ontology
(mainly an ontology describing qualities of cellular ge-
nealogies), secondly, we need a support for the anno-
tation of time lapse experiments (being sequences of
visual frames) by using the concepts of the CTO. The
second step could be supported by machine learning
methods, though the training data must be provided
by experts.
Burek et al. Journal of Biomedical Semantics           (2019) 10:16 Page 16 of 18
The evolution of ontologies is an important research
topic which must be taken into account as existing an-
notations of time lapse experiments would have to be
re-annotated for a new version CTO (1) of the ontology
CTO. Here, we would build on the framework for classi-
fying and realizing ontology- versions in the context of
ontology evolution as presented in [57].
Finally, modeling of quality value change is not limited
to cell tracking experiments, but is a common and non-
trivial task across many domains of interest. The ana-
lysed patterns are domain-independent and, since a
change of quality values is common to many biomedical
domains, we believe that the application of these pat-
terns is important in many related problems. In such a
setting the patterns discussed can be used for the exten-
sion of the existing modeling languages such as e.g.
UML and used for the purpose of ontology engineering
and conceptual modeling in various applications includ-
ing modeling of new ontologies as well as refactoring of
existing ones. We already realized this approach and
proved its utility for a different modeling task of func-
tion representation, firstly by introducing the extension
into the UML [58] and, secondly, by the application of
extended UML for the task of refactoring of the Gene
Ontology [59, 60].
Abbreviations
CTO: Cell Tracking Ontology; GFO: General Formal Otology; OBJ: Object;
OWL: Ontology Web Language; Q: Quality; QA: Quality Assignment;
RDF: Resource description framework; TE: Time Entity; UML: Unified Modeling
Language
Acknowledgements
The paper was presented at the Workshop on Ontologies and Data in Life
Sciences (ODLS) 2014 in Freiburg. We acknowledge support from the
German Research Foundation (DFG) and Universität Leipzig within the
program of Open Access Publishing.
Authors contributions
PB drafted the paper and conceived the initial idea. NS provided the
experimental material and the application to time-lapse experiments. HH
contributed to the ontological foundation of the topic. All the authors
participated in the discussion, elaboration and revision of the paper. HH
supervised the project. All authors read and approved the final manuscript.
Funding
The publication fee is funded by the DFG and the University of Leipzig within
the program of Open Access Publishing.
Availability of data and materials
Not applicable.
Ethics approval and consent to participate
Not applicable.
Consent for publication
Not applicable.
Competing interests
The authors declare that they have no competing interests.
Author details
1Institute for Medical Informatics, Statistics and Epidemiology, University of
Leipzig, Haertelstr. 16-18, 04107 Leipzig, Germany. 2Institute of Computer
Science, Faculty of Mathematics, Physics and Computer Science, Marii
Curie-Sklodowskiej University, pl. Marii Curie-Sklodowskiej 5, 20-031 Lublin,
Poland. 3Max Planck Institute for Human Cognitive and Brain Sciences,
Stephanstr. 1a, 04103 Leipzig, Germany. 4Max Planck Institute of Molecular
Cell Biology and Genetics, Pfotenhauerstr. 108, 01307 Dresden, Germany.
5Carl Gustav Carus Faculty of Medicine, Institute for Medical Informatics and
Biometry, TU Dresden, Fetscherstr. 74, 01307 Dresden, Germany.
Received: 21 July 2018 Accepted: 31 July 2019
RESEARCH Open Access
Organizing phenotypic dataa semantic
data model for anatomy
Lars Vogt
Abstract
Background: Currently, almost all morphological data are published as unstructured free text descriptions. This not
only brings about terminological problems regarding semantic transparency, which hampers their re-use by non-
experts, but the data cannot be parsed by computers either, which in turn hampers their integration across many
fields in the life sciences, including genomics, systems biology, development, medicine, evolution, ecology, and
systematics. With an ever-increasing amount of available ontologies and the development of adequate semantic
technology, however, a solution to this problem becomes available. Instead of free text descriptions, morphological
data can be recorded, stored, and communicated through the Web in the form of highly formalized and structured
directed graphs (semantic graphs) that use ontology terms and URIs as terminology.
Results: After introducing an instance-based approach of recording morphological descriptions as semantic graphs
(i.e., Semantic Instance Anatomy Knowledge Graphs) and discussing accompanying metadata graphs, I propose a
general scheme of how to efficiently organize the resulting graphs in a tuple store framework based on instances
of defined named graph ontology classes. The use of such named graph resources allows meaningful fragmentation of
the data, which in turn enables subsequent specification of all kinds of data views for managing and accessing
morphological data.
Conclusions: Morphological data that comply with the here proposed semantic data model will not only be
computer-parsable but also re-usable by non-experts and could be better integrated with other sources of data in the
life sciences. This would allow morphology as a discipline to further participate in eScience and Big Data.
Keywords: Phenotypic data, Semantic data model for anatomy, Instance anatomy knowledge graph, Anatomy,
ontology, Zoology, Knowledge management, Morphological description, Morphology
Background
Morphological data drives much of the research in the life
sciences [1]. Unfortunately, however, the morphological
record consists for the most part of unstructured text.
This has far-reaching consequences for research based on
morphological data, since conventional morphological free
text descriptions not only bear problems relating to
terminology and lack of semantic transparency, but they
also cannot be parsed by computers. Someone interested
in using morphological data, for instance, for systematic-
ally searching for correlations between phenotypic data
and genotypes over a broad set of non-model organisms,
will soon be discouraged after briefly having delved into
the relevant morphological literature, having not only to
search for relevant data in published morphological de-
scriptions, but also having to deal with morphological
terms, the meaning of which depends on the described
taxon, the describing author and the time when the de-
scription has been conducted. Moreover, while some terms
refer to common spatio-structural properties, others refer
to a common function or a presumed common evolution-
ary origin, or some mixture of those three categories (see
Linguistic Problem of Morphology [2]). As a consequence,
interpreting and analyzing morphological data becomes
unnecessarily difficult for non-experts and integrating
morphological data with other sources of data in the life
sciences very difficult and time-consuming.
This is unfortunate because morphology offers a treas-
ure trove of valuable data that only has to be harvested.
Morphological data remain the primary data source for
© The Author(s). 2019 Open Access This article is distributed under the terms of the Creative Commons Attribution 4.0
International License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and
reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to
the Creative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver
(http://creativecommons.org/publicdomain/zero/1.0/) applies to the data made available in this article, unless otherwise stated.
Correspondence: lars.m.vogt@gmail.com
Institut für Evolutionsbiologie und Ökologie, Rheinische
Friedrich-Wilhelms-Universität Bonn, An der Immenburg 1, 53121 Bonn,
Germany
Vogt Journal of Biomedical Semantics           (2019) 10:12 
https://doi.org/10.1186/s13326-019-0204-6
defining most species and understanding their phylogen-
etic history but are also important for recognizing, defin-
ing, and diagnosing pathological conditions in plants,
animals, and other organisms [1]. Morphological data
also provide insights to questions of development, func-
tion, evolution, and interaction of phenotypes with their
environments, yielding in the discovery of new pharma-
ceutical agents and the development of new materials
and technical solutions. Therefore, if morphological data
would be easily accessible, re-usable by non-experts, and
computer-parsable, they could significantly contribute to
a better understanding in a diverse field of research
areas within the life sciences, ranging from evolution
and ecology to pharmacy, health, engineering, and
material sciences. In an ideal world, this data would be
openly accessible and easily findable through the Web,
they would be stored in online databases in a highly for-
malized and structured syntax and format, they would
be semantically transparent and thus easier to compre-
hend and interpret, and data from different authors and
different taxa could be easily integrated and algorithms
could read and analyze them.
Since we are living in the age of Big Data, Linked-Open-
Data, and the Semantic Web, this ideal world should not
be too far-off for morphology. Efficiently managing and
organizing data has become key to data exploration and
eScience, and developing adequate data and metadata stan-
dards is becoming increasingly important [35]. eScience
is a new driving force for scientific progress in data-rich
fields of empirical research [6] and requires data and meta-
data to be maximally findable, accessible, interoperable,
and reusable (FAIR guiding principle [7]). This can be
achieved by establishing semantic transparency and making
data and metadata computer-parsable [810]. Ontologies
and other controlled vocabularies have taken a central role
in this context because they provide the required standard-
ized semantic structure for data and metadata to become
comparable and computer-parsable (e.g., [1113]).
Ontologies are vocabularies that are used for describing a
certain reality. They consist of terms with commonly ac-
cepted definitions that are formulated in a highly formalized
canonical syntax and standardized format, such as the Web
Ontology Language (OWL) serialized to the Resource De-
scription Framework (RDF), with the goal to yield a lexical
or taxonomic framework for knowledge representation [14].
Unfortunately, in morphology, the use of ontologies is
still very limited. Currently, only a small fraction of mor-
phological data is eScience-compliant and that fraction is
usually restricted to data about model organisms (e.g., [15
19]). However, an increasing amount of taxon-specific on-
tologies is becoming available (e.g., Hymenoptera Anatomy
Ontology [20, 21]; Spider Ontology [22]; Plant Ontology
[23]; Vertebrate Trait Ontology [24]; Uberon multi-species
anatomy ontology [25]; Cell Ontology [26]). A first step
towards increasing the amount of eScience-compliant mor-
phological data is to semantically enrich free text descrip-
tions with ontology terms. This is a step in the right
direction. However, semantic technology would be used to
its full potential only when the entire description is repre-
sented using Uniform Resource Identifiers (URIs) with the
RDFs syntax of Subject, Predicate, and Object and when
storing these triples as semantic graphs in a tuple store. A
semantic graph is a network of RDF/OWL-based triple
statements, in which some URIs take the Object positions
in some triples and the Subject position in other triples,
connecting several triples to form a semantic graph.
Tuple stores are capable of handling large semantic
graphs, and semantic technology facilitates detailed data re-
trieval of RDF/OWL-based data through SPARQL end-
points [27], as well as inferencing over OWL-based data
through semantic reasoners [28]. Some tuple stores such as
the Jena tuple store framework [29] allow for organizing
the store into different physically separate RDF stores, with
each RDF store being structured into different named
graphs. A named graph identifies a set of triple statements
by adding the URI of the named graph to each triple be-
longing to this named graph, thus turning these triples into
quads. The Jena tuple store framework can handle such
quads. The use of named graphs thus enables partitioning
data in an RDF store and enables making statements about
statements comparable to OWL reification, but outper-
forms the latter for more complex queries [30].
In the last decade, progress has been made in semantic-
ally representing phenotypic data. Two alternative basic
approaches have been suggested for documenting the ana-
tomical organization of a given specimen using ontology
terms:
Class-based approach
A particular morphological phenotype is described by
defining an ontology class according to a set of proper-
ties that are characteristic to that phenotype. In other
words, the definition of the ontology class contains the
description of the phenotype. The description itself is
thus contained in class axioms, which in OWL are
expressed as TBox expressions. The morphological
description of a specimen that bears the phenotype then
merely expresses that this specimen instantiates the re-
spective ontology class. Corresponding descriptions have
been called Semantic Phenotypes. In this class-based
approach, Semantic Phenotypes are therefore defined
through TBox expressions that are formally described
following an Entity-Quality (EQ) scheme [3134].
Instance-based approach
A particular morphological phenotype is described by
generating a semantic graph consisting of instances that
instantiate ontology classes, with each instance referring
Vogt Journal of Biomedical Semantics           (2019) 10:12 Page 2 of 14
to a particular part of the structure to be described. The
corresponding descriptions are thus contained in ABox
expressions and are called Semantic Instance Anatomy
Knowledge Graphs (or Semantic Instance Anatomies [2,
12, 3537]; from here on Anatomy Knowledge Graphs).
Contrary to the Semantic Phenotypes approach, the
Anatomy Knowledge Graphs approach follows a more
modular framework that makes use of anatomical entity
terms from existing ontologies and does not necessarily
require the definition of new ontology classes to repre-
sent a given phenotype. Besides the smaller demand for
additional ontology classes, Anatomy Knowledge Graphs,
when compared to Semantic Phenotypes, have usually
better properties regarding retrievability of data, for in-
stance, when attempting to retrieve the numbers out of
measurement data. The reason for that is that querying
TBox expressions is more difficult than querying ABox
expressions. When querying TBox expressions, the basic
graph-pattern-matching of SPARQL has to be defined
using entailment regimes [38], which is more complex
and computationally difficult under full expressivity of
OWL [39, 40]. Therefore, querying Anatomy Knowledge
Graphs is more straightforward and computationally less
difficult than querying Semantic Phenotypes. Moreover,
the instance-based approach allows for identifying and
re-using every individual part and property that the
description mentions because each of them possesses its
own URI. As a consequence, Anatomy Knowledge
Graphs can be easily fragmented into sub-graphs. This is
not possible when applying the class-based approach,
because its TBox expressions treat all described parts
and properties as anonymous resources (for a detailed
comparison of the Semantic Phenotypes approach and
the Anatomy Knowledge Graphs approach see [41]).
In the following, I give a brief introduction to Anatomy
Knowledge Graphs and their accompanying metadata be-
fore I will propose a general scheme of how to efficiently
organize respective morphological data and metadata in a
tuple store.
Methods
Organizing a document as a semantic graph
In RDF, propositions are structured as triple statements
consisting of Subject, Predicate, and Object, with Subject
and Predicate being resources in the form of a Uniform
Resource Identifier (URI) and the Object, depending on
the type of Predicate used in the statement, being either a
resource or some numerical or literal value. A resource al-
ways refers to a real thing or a piece of data (e.g., a Web
page), and the value can be a unique ID, a numerical value,
an arbitrary label, a proper name, a kind name, or a string
of free text. An RDF statement can be modeled as a graph,
with Subject and Object forming nodes that are connected
through a Predicate as a labeled directed arch (edge). Since
a given URI can take the Object position in one statement
and the Subject position in another statement, triple state-
ments can connect to each other and jointly form a
semantic graph. Such semantic graphs can be used for
representing specific properties of a particular anatomical
entity or its relation to other anatomical entities of a given
specimen and thus for describing the anatomical
organization of that specimen.
However, simply storing a large semantic description
graph in a database and making it openly accessible is usu-
ally not an efficient way of organizing morphological data
and does not comply with the FAIR guiding principles.
Additional information must be provided when being pub-
lished in a database. One way would be to treat a semantic
morphological description as a scientific publication, and
thus organize it according to the commonly used general
structure for scientific publications. This would require
modeling semantic morphological descriptions as docu-
ments that consist of several different parts, including ab-
stract, author list, introduction, methods, results,
Conway et al. Journal of Biomedical Semantics            (2019) 10:6 
https://doi.org/10.1186/s13326-019-0198-0
SOFTWARE Open Access
Moonstone: a novel natural language
processing system for inferring social risk
from clinical narratives
Mike Conway1* , Salomeh Keyhani2,3, Lee Christensen1, Brett R. South1,4, Marzieh Vali2,
Louise C. Walter2,3, Danielle L. Mowery1,4, Samir Abdelrahman1 and Wendy W. Chapman1,4
Abstract
Background: Social risk factors are important dimensions of health and are linked to access to care, quality of life,
health outcomes and life expectancy. However, in the Electronic Health Record, data related to many social risk factors
are primarily recorded in free-text clinical notes, rather than as more readily computable structured data, and hence
cannot currently be easily incorporated into automated assessments of health. In this paper, we presentMoonstone, a
new, highly configurable rule-based clinical natural language processing system designed to automatically extract
information that requires inferencing from clinical notes. Our initial use case for the tool is focused on the automatic
extraction of social risk factor information in this case, housing situation, living alone, and social support from
clinical notes. Nursing notes, social work notes, emergency room physician notes, primary care notes, hospital
admission notes, and discharge summaries, all derived from the Veterans Health Administration, were used for
algorithm development and evaluation.
Results: An evaluation of Moonstone demonstrated that the system is highly accurate in extracting and classifying
the three variables of interest (housing situation, living alone, and social support). The system achieved positive
predictive value (i.e. precision) scores ranging from 0.66 (homeless/marginally housed) to 0.98 (lives at home/not
homeless), accuracy scores ranging from 0.63 (lives in facility) to 0.95 (lives alone), and sensitivity (i.e. recall) scores
ranging from 0.75 (lives in facility) to 0.97 (lives alone).
Conclusions: The Moonstone system is  to the best of our knowledge the first freely available, open source
natural language processing system designed to extract social risk factors from clinical text with good (lives in facility)
to excellent (lives alone) performance. Although developed with the social risk factor identification task in mind,
Moonstone provides a powerful tool to address a range of clinical natural language processing tasks, especially those
tasks that require nuanced linguistic processing in conjunction with inference capabilities.
Keywords: Natural language processing, Social determinants of health, Software
Background
Social risk factors are important dimensions of health and
are linked to access to care, quality of life, health out-
comes, life expectancy and health care utilization. Some
social risk factors such as alcohol and drug abuse can
be captured using administrative and laboratory data.
However, data related to measures such as housing, living
*Correspondence: mike.conway@utah.edu
1Department of Biomedical Informatics, 421 Wakara Way, University of Utah,
alt Lake City, UT 84108, USA
Full list of author information is available at the end of the article
situation and social support are primarily recorded in
free-text clinical notes, rather than as computable struc-
tured data, and hence resists easy incorporation into pre-
diction models. In this paper, we present Moonstone, a
new, highly configurable rule-based natural language pro-
cessing (NLP) system designed to automatically extract
information that require inferencing from clinical notes.
The use case to which we applied Moonstone for this
study is extraction of Social Determinants of Health
(SDOH) specifically, housing situation, living alone, and
social support  from clinical notes derived from the
© The Author(s). 2019 Open Access This article is distributed under the terms of the Creative Commons Attribution 4.0
International License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and
reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to the
Creative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver
(http://creativecommons.org/publicdomain/zero/1.0/) applies to the data made available in this article, unless otherwise stated.
Conway et al. Journal of Biomedical Semantics            (2019) 10:6 Page 2 of 10
Veterans Health Administration (VA). We chose these
three variables as our focus as this information is not
captured in structured fields within the VAs administra-
tive data, and because these domains of social risk are
important to health outcomes. Building on previous rule-
based clinical NLP systems [1], the Moonstone system
is designed to be extensible to a range of clinical NLP
tasks, especially those that involves the need for nuanced
linguistic processing and inference.
Use case: social risk factors & health
The relationship between SDOH and health outcomes
is well established [2]. Lack of housing, social isolation
and lack of social support are associated with higher
mortality and poor health outcomes. Despite the clear
relationship between SDOH and health, these metrics
are not routinely used in health services and outcomes
research, mainly because many of these health measures
are not collected as part of routine care. Therefore, most
clinical outcome studies that rely on risk adjustment do
not typically utilize social risk data, and models that do
incorporate SDOH data are limited to demographic infor-
mation derived from structured data (e.g. race, ethnicity,
rural location) [3, 4]. The importance of these metrics
have been recently reinforced by the institution of Afford-
able Care Act penalties on hospitals with higher than
average readmission rates, with the result that hospitals
that care for vulnerable and disadvantaged populations are
placed at financial risk. The models used by the Centers
for Medicare & Medicaid Services to compare hospitals
did not include measures of social risk as these factors
are not available in administrative data. In recognition
of the important role social factors play in health, the
National Quality Forum, National Academy of Medicine,
and the Department of Health and Human Services have
recently emphasized the need for health care systems to
identify and address social risk factors effects on patient
care [5].
Natural language processing
There are numerous NLP systems that attempt to extract
clinically relevant data from unstructured clinical nar-
ratives [6]. For example, MedEx, a rule-based system
designed to extract medication information  drug, dose,
frequency  achieves F-scores1 of greater than 0.93
[7]. Similarly, MedLee (Medical Language Extraction and
Encoding System) uses a rule-based approach to extract
clinically relevant information from radiology reports and
discharge summaries, and has been used successfully for a
number of different clinical information extraction appli-
cations (e.g. [1, 8, 9]). More recently, cTAKES (clinical
Text Analysis and Knowledge Extraction System) uti-
lizes open source technologies and a highly modularized
system architecture in conjunction with both machine
learning and rule-basedmethods to perform clinical infor-
mation extraction tasks. The system has been used for
multiple clinical NLP application domains (e.g. smoking
status identification [10] and cohort identification [11]).
The NLP systems described above are designed to
extract information explicitly stated in clinical text (e.g.
explicit documentation of drug and alcohol use); how-
ever, a significant proportion of information regarding
social context is not explicitly stated in the clinical note,
but can be inferred. For example, from the statement
patient family by bedside, it can be indirectly inferred
that the patient enjoys a degree of social support (i.e. fam-
ily members who visit). This inferencing process requires
a degree of semantic analysis and reasoning that existing
clinical NLP systems, optimized as they are for explicit
information extraction, cannot easily perform. Further-
more, existing clinical NLP systems are not necessarily
well suited for tasks that require the processing of highly
ambiguous everyday words. For example, to process the
sentence patient has to stay at the VA hospital overnight
because he had no one to take him home after the proce-
dure requires identification of everyday words, tasks, and
roles, in addition to inference capabilities to arrive at the
(correct) conclusion that the patient lacks social support.
Our goal with this work is to demonstrate the effective-
ness of the Moonstone systems semantic processing and
inferencing capabilities by extracting and evaluating key
measures of social risk  housing situation, living alone,
and social support  from the clinical notes using NLP.
Implementation
Motivation
The current state of the art in automatic social risk fac-
tor analysis  as exemplified by Chen et al. [12] and
Greenwald et al. [13]  utilizes a dictionary of strings
or regular expressions (e.g. patient lives alone, patient
lacks family support). However, there is a substantial
amount of information relevant to the three variables of
interest that is implicit (i.e. not stated directly) and hence
is not amenable to pattern matching-based information
extraction approaches. For example social support is
often manifested in narrative notes as the interaction of
patients with family members. For example, spouse at
bedside, accompanied to medical appointment by son,
family member visiting regularly to help with the food
and chores, and patient in phone contact with adult chil-
dren, are naturally understood as connoting social sup-
port. Conversely, sentences that suggest that the patient
does not experience regular contact and help from family
and friends imply a lack of social support. For exam-
ple, if an elderly patient requires public transport to get
home from a medical procedure, this can be taken as evi-
dence  but not proof  of lack of social support. The
number of possible textual instantiations of social support
Conway et al. Journal of Biomedical Semantics            (2019) 10:6 Page 3 of 10
interactions is very large, and probably beyond the capa-
bilities of a simple string matching approach to adequately
address. Similar examples can be found for both the hous-
ing and living alone variables. For example, the statement
discharged: home with wife implies that the patient both
lives in a stable home, and does not live alone. Further-
more, the identity of the person with whom the patient
lives can be indicative of whether a housing situation is
stable ormarginal. For example, lives with wife and lives
in ex-wifes basement both indicate that the patient does
not live alone, but the latter suggests a more precarious
living situation.
The effort to identify implicit, indirect meaning is com-
plicated by several factors:
1. Inference. The target variable is often several
inference steps away from what is stated explicitly in
the text. For instance, family at bedside literally
means that family members are with the patient in
the clinical care setting, which in turn implies that
they are involved in the patients care, which
connotes support.
2. Ambiguity. The meaning-bearing words relevant to
social support are typically everyday high frequency
words which, in contrast to medical terminology,
have a high probability of appearing in contexts
irrelevant to social support. For example, the word
bedside can be used in many ways unrelated to
social support (e.g. medical equipment at the
bedside). Although potentially relevant words are
relatively common in clinical text, relevant sentences
appear much more sparsely, with very few
documents in our corpus containing such sentences.
3. Semantic roles. Understanding semantic roles  i.e.
who is the actor and who is the recipient of an action
 is vital to sentence interpretation. For example, in
the sentences the wife helps the patient with
medications and the patient helps the wife with
medications, only the first conveys the fact that the
patient receives social support, as the patient is the
direct object of the verb helps. Similarly, word
placement can affect interpretation. For example, the
sentences he needs no help with ADL (Activities of
Daily Living) and he has no help with ADL needs,
differ in only one word (has), and yet have very
different meanings. NLP systems that do not
consider word order, and which do not analyze the
meaning and placement of modifiers, cannot reliably
make such distinctions.
Corpora & annotation
The clinical document corpus used in this study was
selected with the goal of developing information extrac-
tion methods capable of automatically extracting SDOH
variables relevant to 30-day readmission predictive mod-
els, with a focus on four diseases of interest (congestive
heart failure, acutemyocardial infarction, pneumonia, and
stroke). We selected these conditions as, at the time of
study initiation, they were the four medical conditions for
which hospital readmission rates were publicly recorded.
To create an initial cohort, we identified all VA patients
aged 65 or older admitted with at least one of the four dis-
eases of interest between January 1st 2012 and December
31st 2012. More than 21,000 patients were identified2. We
then randomly sampled 500 patients from this cohort and
extracted their associated documents  353,889 notes
in total  from the VA Corporate Data Warehouse for
a period of one year prior to hospital admission. Two
physicians (SK and LW) then reviewed document titles,
selecting only those documents likely to contain evidence
of SDOH variables. Clinical document types selected
included nursing assessment, social work notes, emer-
gency room physician notes, primary care notes, hospi-
tal admission notes, and discharge summaries. In total,
52,304 documents were selected.
Social risk factors pose a significant challenge to the cre-
ation of reliable annotated reference standards given that
human annotators typically experience extreme difficulty
in identifying and reliably annotating rarely documented
variables. For this reason, using the corpus described
above, we pre-annotated social support instances using
a prototype version of Moonstone. We trained three
annotators who were familiar with VA documentation
practices to review a randomly selected sample of pre-
annotated instances, with all disagreements between the
annotators discussed until consensus was achieved. We
then ran the final, trained version of Moonstone over the
document set and presented disagreements between the
human annotators and Moonstone to a fourth annotator
(again, a nurse familiar with VA documentation practices)
who was blinded as to whether the value was assigned
by Moonstone or by the previous consensus of annota-
tors. The fourth annotator selected the best variable value,
which was then used as the final gold standard value.
System description
Moonstone is an open-source, Java-based NLP system
developed by the Biomedical Language Understanding
Laboratory (BLULab) at the University of Utah and
derived from a lineage of clinical NLP systems (ONYX
[14], TOPAZ [1]) that utilize rule-based semantic analy-
sis. The system consists of a Knowledge Base, which in
turn is made up of a type hierarchy, a semantic gram-
mar, a set of inference rules, and a word dictionary, and
processing modules including a named entity recognition
module, a grammatical analysis module, and an inference
module. In addition, we used a tool called the Evalu-
ation WorkBench [15] to compare two sets of human
Conway et al. Journal of Biomedical Semantics            (2019) 10:6 Page 4 of 10
and/or machine-produced annotations over a set of doc-
uments, and display match statistics (e.g. precision, recall,
accuracy, f-measure). The EvaluationWorkBench allows a
human reviewer to view the annotation schema, and then
view annotations highlighted within the text of the docu-
ments, thus supporting rule development and debugging.
We used theWorkBench to compare Moonstones perfor-
mance against reference standard annotations produced
by human experts using the eHOST annotation tool [16].
The architecture of the Moonstone system is shown in
Fig. 1 , with system features described below.
Moonstones activities are user-controlled through its
graphical control tool. A function in that tool can be used
to apply Moonstone to analyze a corpus of documents.
For each document, Moonstone splits that document into
tokens representing words, numbers, punctuation and
other symbols, attaches a dictionary definition to word
tokens if available, and groups the tokens into named
sections (e.g. "History of Present Illness") and sentences
within those sections.
For each sentence in a document, the Moonstone gram-
matical parser applies the semantic grammar to analyze
the tokens in that sentence, and gathers resulting con-
cepts which are relevent to the current NLP task into a
list for further processing. The grammatical parser also
consults the Moonstone ontology to fire those grammar
RESEARCH Open Access
Integrating terminologies into standard
SQL: a new approach for research on
routine data
André Sander1* and Roland Wauer2
Abstract
Background: Most electronic medical records still contain large amounts of free-text data. Semantic evaluation of
such data requires the data to be encoded with sufficient classifications or transformed into a knowledge-based
database.
Methods: We present an approach that allows databases accessible via SQL (Structured Query Language) to be
searched directly through semantic queries without the need for further transformations. Therefore, we developed
I) an extension to SQL named Ontology-SQL (O-SQL) that allows to use semantic expressions, II) a framework that
uses a standard terminology server to annotate free-text containing database tables and III) a parser that rewrites O-
SQL to SQL, so that such queries can be passed to the database server.
Results: I) We compared several semantic queries published to date and were able to reproduce them in a
reduced, highly condensed form. II) The quality of the annotation process was measured against manual
annotation, and we found a sensitivity of 97.62% and a specificity of 100.00%. III) Different semantic queries were
analyzed, and measured with F-scores between 0.91 and 0.98.
Conclusions: We showed that systematic analysis of free-text-containing medical records is possible with standard
tools. The seamless connection of ontologies and standard technologies from the database field represents an
important constituent of unstructured data analysis. The developed technology can be readily applied to
relationally organized data and supports the increasingly important field of translational research.
Keywords: Ontology-based queries, Terminology server, Translational research, Infant mortality, Data mining
(knowledge discovery)
Background
The launching of a working group on the use of elec-
tronic medical records for clinical research [1] in 2011
by the GMDS (Deutsche Gesellschaft für Medizinische
Informatik, Biometrie und Epidemiologie) is evidence of
the enormous importance of medical records for re-
search; however, it also underlines the difficulties that
arise when trying to analyze these data. In the following,
we therefore explain an approach that addresses the effi-
cient usage of medical records in well-established struc-
tures. We introduce an approach that integrates
free-text-based query terms into standard SQL and thus
allows such queries to be run on existing database
systems. The free text is mapped to a terminology and
semantically interpreted using an ontology provided by a
terminology server.
Related work
Two major problems are addressed with our approach: I)
the semantic structuring and evaluation of free text and
II) the querying of such information from medical
records.
Many research papers have presented different ap-
proaches to the semantic structuring of free text. The
outcomes vary in many aspects; however, in general,
these approaches provide good to excellent results. Re-
cent NLP (natural language processing)-based mapping
© The Author(s). 2019 Open Access This article is distributed under the terms of the Creative Commons Attribution 4.0
International License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and
reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to
the Creative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver
(http://creativecommons.org/publicdomain/zero/1.0/) applies to the data made available in this article, unless otherwise stated.
* Correspondence: asander@id-berlin.de
1ID GmbH & Co. KGaA, Platz vor dem Neuen Tor 2, 10115 Berlin, Germany
Full list of author information is available at the end of the article
Sander and Wauer Journal of Biomedical Semantics            (2019) 10:7 
https://doi.org/10.1186/s13326-019-0199-z
systems were published by Friedman et al. in 2004 [2]
and later by Savova et al. [3], both of which exhibited
high accuracy. Elkin et al. analyzed mapping algo-
rithms with the SNOMED (systematized nomenclature
of medicine) ontology on chest X-ray reports with ex-
cellent results [4]. A similar task for pathology was
recently presented by Allones et al. but required fur-
ther improvement [5]. In the German language, a
2015 paper presented by Toepfer et al. showed very
good results [6]. Some well-established mapping tools
have been used by many groups and were evaluated
in [7, 8]. One of the core challenges of these tools is
the disambiguation of mapping alternatives, which
was currently achieved best by Zwicklbauer et al.,
who developed DoSeR [9].
Many attempts to enable knowledge-based querying
of information from medical records have been de-
scribed; for example, Hogarth et al. suggested the
so-called TQL (terminology query language), which
encompassed SQLs idea of universality [10]. SPARQL
(SPARQL Protocol and RDF Query Language) in par-
ticular has established itself in many areas as the de
facto standard [11]. However, for specific problems,
such as mapping between ontologies, additional in-
ternal query languages have been developed, even in
recent years [12]. There has been an evolution of in-
tegrated frameworks for the implementation of
browser-based knowledge systems since early on [13,
14]. Today, SPARQL- and OWL (Web Ontology Lan-
guage)-based systems are successfully implemented
for defined applications, such as the management of
blood pressure or hypertension [15]. In the area of
infectious diseases, Kama et al. used the concept of a
semantic data warehouse that integrates OLAP (on-
line analytical processing) techniques [16]. Neverthe-
less, in this approach, specific query languages have
remained unaltered in their respective domains. Ep-
stein et al. therefore chose to implement and inte-
grate needed subsystems (e.g., NLP pipelines) into
SQL [17]. One of the most recent and interesting ap-
proaches came from Zheng et al., who have extended
standard SQL with semantic constructs [18]. Never-
theless, for this purpose, numerous algorithms have
been implemented in the middleware instead of con-
sequently outsourcing them to a terminology server.
Recently, the field of OBDA (ontology-based data
access) has been examined as a profound theoretical
basis. However, these approaches are currently limited
to specific types of databases and their querying lan-
guages [19].
Classification-based approaches (e.g., ICD (Inter-
national Classification of Diseases)-encoded data) are
also used in current attempts to integrate heteroge-
neous data sources for cohort formation [20]. This
approach, however, is associated with three major
problems: I) loss of specificity [21], II) low interoper-
ability [22] and III) low stability over time [22].
We present an approach that overcomes many of the
described technical hurdles and still achieves comparable
or even better results.
Materials
In the work presented here, we use epicrises from
1868 patients collected from free-text medical re-
cords. These data were captured in the period from
1973 to 1989 in former East Berlin/East Germany by
the Commission on the Reduction of the Infant Mor-
tality Rate1 [23]. The medical records of all newborns
who died in the first 28 days of life were analyzed,
discussed and evaluated by this Commission and clas-
sified based on their avoidability. Avoidability was cat-
egorized from a medical and social point of view into
non-avoidable, conditionally avoidable and avoid-
able. Subsequently, measures were taken in different
areas, ranging from staff training to structural
changes, such as the centralized treatment of certain
risk groups.
At that time, data from the original medical records
(pregnancy card, birth history logs, all hospital docu-
ments, reports of hospital stay, reports of interventions
and so on) were stored on handwritten index cards in
DIN A5 (see Fig. 1). Apart from some structured proper-
ties, these data mainly included clinical text  as defined
in [24]  addressing anamnesis, course of birth, treat-
ment and postmortem classification. In each case, both
peri- and postnatal care were described in detail, and a
differentiated assessment of the cause of death was car-
ried out. When creating the index cards, color highlight-
ing was used to classify cases into the categories
premature birth (red highlighting) or lethal malforma-
tion (yellow highlighting) (see Fig. 1 which has a red
highlighting).
Digitalization of the cards was performed in two steps:
first, a professional service provider for archiving
paper-based patient records scanned the index cards and
provided high-resolution images of the front and back
sides of the cards. In the second step, the cards were
manually transcribed into an SQL database. Spelling and
grammar, however, were copied exactly. Quality assur-
ance was implemented by a three-stage release process
(involving three independent transcriptionists). In the
final step, all values of the structured data items were
analyzed by A-Z analysis for implausible data.
Methods
The central idea of the approach presented here consists
of integrating a terminology server into an SQL-based
RDBMS (Relational Database Management System) and
Sander and Wauer Journal of Biomedical Semantics            (2019) 10:7 Page 2 of 11
extending the SQL language itself by adding the ability
to formulate semantic criteria within the query with free
text. Hence, the approach comprises two components:
I) Semantic structuring and annotation of the RDBMS
tables, and
II) Syntactic extension of standard SQL (Ontology-
SQL).
Semantic structuring and annotation
We chose to store the semantic annotation by using
additional tables to extend the database schema instead
of changing existing tables. This approach offers the ad-
vantage that the data tables that store the annotations
can be created in their own logical instance of an exist-
ing database server.
First, we created a single table for each source col-
umn that had to be annotated. The results are annota-
tion tables that contain semantic representations of
the content of the source columns. The precondition
is that each table contained a unique primary key,
which held true in practice. For each row of the given
column, we created n rows in the annotation table that
contained the semantic interpretations. These annota-
tions are the specific concept identifiers in the
selected ontology. The records are linked via the pri-
mary unique key. In addition to storing direct annota-
tions, we also stored the respective super classes
(derived from the is a hierarchy from the ontology)
to enable a performance analysis. Figure 2 shows the
designed structure, and Table 1 shows a sample data
set.
The approach of using a generic table with metainforma-
tion for the description of the source table was discarded
in favor of performance or respective costs. The annotation
table schema is fairly simple with four columns (one for the
key, one for the concept identifier, one for the concept label
and one for the semantic distance (level)), and thus, modern
RDBMS are expected to handle such tables extremely well.
As an additional benefit of this solution, semantic data
models can be generated from analysis of the annotations,
especially if the source column contains keyword data [25].
The annotation of free text is accomplished by inte-
grating a CTS2 (common terminology services)-compa-
tible terminology server [26]. The terminology server
used here includes a complete NLP pipeline based on
Gate [27] and Jape in addition to numerous supporting
algorithms, such as an extensive, discipline-specific list
of abbreviations, collocation-based disambiguation, a
typing error corrector, which can break up compounds
and correct them step by step, and a function for
Fig. 1 Original sample of a handwritten index card (anonymized). In preparation for each commission meeting on reducing infant mortality (IM),
the chairman of the commission prepared such an index card (N = 1868). The index cards contain basic demographic data regarding the mother
and child and free text regarding anamnesis, birth, postnatal treatment and course of death. The index cards also contain a color-coding system
denoting a premature birth (a red mark on top of the card) and a (lethal) malformation (a yellow mark). Additionally, the index cards included the
final judgment made by the commission if the case was avoidable, conditionally avoidable or not avoidable. In many cases, the index cards also
contained a revision of the initial judgment and an explanatory statement
Sander and Wauer Journal of Biomedical Semantics            (2019) 10:7 Page 3 of 11
German language-optimized word stemming (for further
information, see Additional file 1: Addendum 1).
Ontology-SQL syntax
We developed an extension to standard SQL that enables
the use of free-text and semantic relations within such a
query. Expressions formulated through this extension can
be transformed into standard SQL syntax using a preproces-
sor. The resulting query contains only standard SQL and
thus can be directly passed on to the database server engine.
A basic O-SQL expression consists of a free-text part that
is surrounded by square brackets and followed by a table
and column name in which the free-text should be searched
for. The latter is surrounded by round brackets. So the
simpliest expression looks like this:
[free-text](tablename.columnname)
Furthermore, the table and column name can be a
comma separated list. Since the free-text is mapped to the
ontology, a semantic role (or in short: relation) can be given
Fig. 2 For each table (aTableName) and each column (aColumnName_x) enabled for semantic queries, an annotation table is created with the
naming scheme [_][aTableName][_][aColumnName_x]. The annotation table is linked to the source table via the unique primary key. Each row
in the annotation table results in n rows in the annotation table, each holding the concept identifier (ConceptID) and a concept label
(ConceptLabel) from the ontology and a level denoting the semantic distance (the super classes of the annotation concepts are also stored)
Fig. 3 Inheritance via depth parameter: in this sample, indications of the concept Analgesic subsum indications of Ibuprofen; thus, a query for
indications of Analgesic will find Pain and Fever if the depth is set to ?2
Sander and Wauer Journal of Biomedical Semantics            (2019) 10:7 Page 4 of 11
that will be applied to the expression. That relation is a key-
word written before the O-SQL expression:
relation[free-text](tablename.columnname)
The default value for the relation is isA, which would
query all concepts subsumed under the concept de-
scribed in the free text.
The generic relation context can be further specified
by a modifier to extent the standard relations like is a
and part of to relations like has indication. This con-
text modifier is a free-text written in curly braces be-
tween the relation and the free-text query:
context{modifier}[free-text](tablena-
me.columnname)
The approach of a context modifier was chosen to allow
a generic, ontology independent syntax of O-SQL
expressions.
As shown in Fig. 3, the attributes of the semantic
roles can be passed on through the isA-hierarchy,
which allows inheritance of these attributes up to a
specific depth. The inheritance depth is specified by a
number separated from the context modifier by a
colon. Finally, a leading prefix can be added to in-
clude the is a relation to the given relation.
Consequently, the complete syntax for O-SQL expres-
sions is as follows:
[prefix][relation][{modifier}][:-
depth][[query]](table.column,)
Its elements and their values are further illustrated in
Additional file 1: Addendum Table S1.
When designing the syntax, we attempted not to focus on
a functional characteristics but rather decided to maintain the
narrative character of a query. A free-text formulation of
the actual query offers enormous advantages as the know-
ledge base is seamlessly integrated and implementation details
of the underlying terminology and ontology are hidden. Lie-
bermann et al. demonstrated early on that SQL-based queries
of annotated databases can provide very high recall values,
but the respective queries required extensive knowledge of
the underlying ontology and manual research on the ontology
concepts [28]. Since the terminology server provides an NLP
engine, the query is tolerant to typing errors, and even com-
plex medical concepts requiring post-coordination can be
used.
Conversion
An efficient conversion of O-SQL into standard SQL is cru-
cial, as this step mainly affects the runtime of given queries.
Fig. 4 Schematic overview of transforming an O-SQL query into a standard SQL query using a standardized terminology server
Sander and Wauer Journal of Biomedical Semantics            (2019) 10:7 Page 5 of 11
First, O-SQL expressions are extracted via regular expressions
and are then converted into SQL subqueries.
We decided to use the IN operator for subqueries because
the source table holds a primary unique key and the sub-
clause can be a simple enumeration of the found annotation
rows. Modern RDBMS use a so-called Clustered Index Scan
to process such queries efficiently.
For each O-SQL statement, we created a subclause by first
mapping the free-text part of the O-SQL expression onto the
terminology and then querying the annotation table for the
found concept identifiers. From the results of these queries,
the values of the column containing the key were used to
build the subclause. Then, the O-SQL expression was re-
placed by that subclause. All other parts of the SQL query
remained untouched. Therefore, all logical operators and lan-
guage components  especially parentheses and the use of
the logical operator NOT  function as usual so that struc-
tured discrete information can be directly linked to semantic
information.
Given an O-SQL query such as the following:
SELECT * FROM table_name WHERE <O-SQL ex-
pression>
We transform the free-text part of the O-SQL expression
with the help of the terminology server to form concept
identifiers and look them up in the annotation table (see
Table 1):
SELECT ID FROM annotation_table WHERE
conceptID = <concept identifier>
We then join all the results together and replace the
O-SQL expression with an IN subquery:
SELECT * FROM table_name WHERE ID in ()
If a query contains multiple O-SQL expressions, each
expression is converted separately. Therefore, one can
use all standard SQL operators to combine O-SQL ex-
pressions. For an example, see Additional file 1: Adden-
dum 2.
Figure 4 illustrates the entire pipeline via which se-
mantic queries can directly be integrated into standard
SQL. The pipeline also provides feedback on the termin-
ology concepts actually used to avoid undetected errors.
Such errors can happen if an abbreviation is not known
and is therefore misinterpreted.
Results
First, we measured the accuracy of the annotation
process to evaluate the results gathered from O-SQL
queries. We then analyzed published knowledge-based
Table 1 Sample of the resulting data structure. The upper table represents a diagnosis table that has a primary unique key
(DiagnosisId), a patient and case key, an ICD code and a description of the diagnosis. The diagnosis cluster headache for two
weeks is annotated with D0009F4 Bing-Horton syndrome Z000002 two GA000F8 week and subsequently stored in the annotation
table (lower table). The semantic distance is 0 here because the concepts directly represent the narrative description of the
diagnosis. Additionally, the parents of all concepts found are stored in the annotation table with the same diagnosis id. Therefore,
cephalea is a parent of the 4th degree of cluster headache. The parent concepts are retrieved with a function call from the
terminology server that returns the taxonomy of a given concept. The tables are linked with the relation DiagnosisId ? Id
Sander and Wauer Journal of Biomedical Semantics            (2019) 10:7 Page 6 of 11
queries from various publications to show whether and
how our approach was applicable and able to simplify
them. Finally, we examined the data with specific queries
and measured the results with respect to precision and
recall. For all statistical calculations, we used MedCalc®
[29].
Annotation accuracy
The annotation algorithm of the terminology server
could recognize abbreviations and had a spell check
function optimized for the German language and a mod-
ule for disambiguation of semantic interpretations. In
particular, the spell check function was urgently needed
since German allows the construction of so-called com-
pound nouns and since many of these compound nouns
had been shortened into their subwords and then recon-
structed again. A typical example was the German term
for pregnancy advisory, which is Schwangerenbera-
tung; this term was often written as Schw.brtg in
many variants.
We did not set up a standardized procedure that in-
cluded a manual annotation and an inter-annotator
agreement to calculate precision and recall for two rea-
sons: I) we were mainly interested in whether the anno-
tation was correct and not whether the annotation was
optimal (focus on precision and not on recall) and II)
the architecture is independent of the terminology server
and uses a standard interface for the integration. Thus,
any CTS compliant terminology server can be easily
used.
We manually analyzed the automated annotation
from 10% (N = 187) of the cards, namely, the section
that contained the postmortem diagnoses. We found
423 diagnoses, 304 of which were unique. Each anno-
tation was classified as completely correct, partly
correct or incorrect. The category partly correct
contained items that could not be mapped better due
to missing precoordinated concepts in the ontology,
and thus, the expert partly disagreed with the inter-
pretation (e.g., aspiration of infected amniotic fluid
was annotated as aspiration of amniotic fluid and
infection). The category incorrect contained all
items that were incorrect. In total, we found that 301
of the 304 (99.0%) items were correctly mapped or
could not be mapped better. Twenty-three of these
items were in the category partly correct and could
be fixed by adding new (precoordinated) concepts to
the terminology. The remaining three were
incorrect.
Furthermore, annotation quality was evaluated using a
single concept from the terminology, namely, the anat-
omy concept tentorium. We analyzed all 1868 cases
with a total of 9080 postmortem descriptions and noted
whether the concept tentorium was present. We found
50 different spellings in 77 cases. For all of these cases,
we verified whether the mapping algorithm used the
correct concept. From these comparisons, we found a
sensitivity of 97.62% (CI 95%: 91.6699.71%) and a spe-
cificity of 100.00% (CI 95%: 98.87100.00%) for the auto-
mated annotation.
Published queries
We analyzed published queries and examined whether
we were able to express them in O-SQL and whether
that expression was more compact and easier to create
and understand. The following section demonstrates that
these expectations held true for all examined samples.
In Lieberman et al., the request for patients with cor-
onary artery disease resulted in the following partial ex-
pression [28]:
concept_id in (
select concept_id from snomed_map
where snmd_cncpt = 8957000 or
snmd_cncpt in (
select snmd_cncpt1 from
snmd_relationship
connect by snmd_cncpt2 = prior
snmd_cncpt1 and
relationship_type = 116680003
Table 2 Statistical results of semantic queries of different complexity (complexity is represented by number of query concepts). All
statistics are calculated with MedCalc® [29]. Raw data can be found in Additional file 1: Table S2 in the addendum
Query Vitium cordis Respiration disorder Lethal malformation
Number of query concepts 1 5 16
Sample size (Percentage of all cards) 1868 (100%) 467 (25%) 1868 (100%)
Sensitivity 93.22% (CI 95%: 89.2296.08%) 97.76% (CI 95%: 95.7998.97%) 92.13% (CI 95%: 89.4894.29%)
Specificity 99.94% (CI 95%: 99.66100.00%) 95.45% (CI 95%: 87.2999.05%) 96.30% (CI 95%: 95.1697.24%)
Positive predictive value 99.55% (CI 95%: 96.8799.94%) 99.24% (CI 95%: 97.7599.75%) 90.57% (CI 95%: 87.7592.92%)
Disease prevalence 12.57% (CI 95%: 11.1014.15%) 85.90% (CI 95%: 82.4188.92%) 27.80% (CI 95%: 25.7829.89%)
F score 0.96 0.98 0.91
Sander and Wauer Journal of Biomedical Semantics            (2019) 10:7 Page 7 of 11
start with snmd_cncpt2 = 8957000 and
relationship_type = 116680003)
)
Its complexity is basically derived from the need to
use nested subqueries to represent relationships within
the ontology. The IDs are from SNOMED CT:
8957000 = Coronary artery disease
(disorder)
116680003 = Is a (attribute)
This query can be represented in O-SQL by the fol-
lowing compact expression using a common abbrevi-
ation:
[chd](diagnosis_column)
The next sample shows that the complexity of
SPARQL can also be greatly reduced. In [30], the filter
criterion Find all patients having a side effect of Prandin
after administration is defined. Pathak et al. trans-
formed this criterion into the following SPARQL query
(abbreviated):
SELECT DISTINCT ?MCLSS_KEY {
{ SERVICE <http://www4.wiwiss.fu-ber-
lin.de/sider/sparql>
{ SELECT ?mySideEffect ?mySideEffec-
tLabel WHERE {
?x rdf:type sider:drugs ;
rdfs:label "Prandin" ;
sider:sideEffect ?mySideEffect .
?mySideEffect rdfs:label ?mySideEffec-
tLabel .
}}}
{ SELECT DISTINCT ?rxnormCode WHERE {
SERVICE <http://link.informatics.-
stonybrook.edu/sparql/> {
?rxAUIUrl rxnorm:hasRXCUI ?rxCUIUrl ;
rdfs:label ?rxnormLabel .
?rxCUIUrl rxnorm:RXCUI ?rxnormCode .
FILTER(regex(str(?rxnormLabel), "Pran-
din", "i")) .
}}}
{ SELECT DISTINCT ?MCLSS_KEY WHERE {
SERVICE <http://edison.mayo.edu/
lss1p#> {
?icd9Url semr:dx_code ?icd9Code ;
semr:dx_abbrev_desc ?diagnosis .
FILTER(regex(str(?diagnosis),
str(?mySideEffectLabel), "i")) .
?patientUrl semr:whkey ?MCLSS_KEY ;
semr:diagnosis ?diagnosisCode ;
semr:concept_id ?rxnormCode .
FILTER(regex(str(?icd9Code),
str(?diagnosisCode), "i")) .
}}}}
This query requires a deep understanding of
SPARQL and the structure of external knowledge
bases. In addition, this query requires that local diag-
noses are encoded in ICD-9, as the medication data-
base uses this classification to structure information
on side effects.
In contrast, the query can be drastically reduced to the
following form using our approach:
select * from tableMed, tableDiag where
tableMed.CID = tableDiag.CID and
+partOf[Prandin](tableMed.Drug) and
hasContext{side effect}
[repaglinide](tableDiag.Diag)
The first partial expression searches the column
Drug in the table tableMed for all occurrences of
Prandin itself (note the +) and for all concepts con-
taining Prandin. In doing so, the agents of Prandin are
also found, and possible generic drugs are included. The
second partial expression simply scans the ontology for
a side effect of the agent and uses these results to
search the column Diag in the table tableDiag. Here,
it must be ensured that specifications are also found in
each case. Therefore, Prandin has hypoglycemia as a
side effect and with the assistance of the ontology, the
query will also identify patients in which hyperinsulin-
ism is recorded because hyperinsulinism is a form of
hypoglycemia.
The last example was published by Leroux and Lefort,
who queried anti-diabetic drugs, such as Metformin,
therefore defining the following request (abbreviated) [31]:
SELECT count (distinct ?subject) as
?count ?mp_med WHERE {
SERVICE <http://wifo5-04.informatik.u-
ni-mannheim.de/drugbank/sparql>
{
?s drugbank:genericName "Metformin" .
?s drugbank:drugCategory ?category .
?drug drugbank:drugCategory ?category .
}
{ SELECT distinct ?drug ?med ?subject
?mp_med WHERE {
GRAPH <http://localhost/dataset/aibl/
lcdc/clinical> {
?obs a lcdcobs:Observation .
?obs cm:medicinalProduct ?cm_mp .
?cm_mp skos:exactMatch ?drug .
Sander and Wauer Journal of Biomedical Semantics            (2019) 10:7 Page 8 of 11
?cm_mp amt:synonym ?mp_med .
?obs lcdccore:subject ?subject .
}}}}
Additionally, in this case, the query can be drastically
reduced when using O-SQL:
select * from tableMed where
hasContext{indication}:5[diabetes](Drug)
The indications for all children are determined recur-
sively from diabetes up to the specified depth of 5
(semantic distance).
Specific queries
We used three typical neonatal complications to verify
the querying capabilities: (I) all of the of the index cards
were manually reviewed to see whether the patient had a
vitium cordis, (II) 25% of the index cards were manu-
ally reviewed for the presence of a sign of respiratory
disorder, and (III) we used the yellow highlighting on
the index cards to carry out a full scope examination of
all 1868 index cards for lethal malformation. We then
created corresponding O-SQL queries to look up these
groups, compared the results and calculated standard
statistics (see Table 2).
Discussion
We developed an approach that enables free-text queries
stored in standard SQL-based RDBMS. Thus, we ex-
tended standard SQL syntax and created an architecture
that allows us to integrate a terminology server into
existing databases.
The usefulness of historical data is becoming clearer
due to the tremendous progress in the development and
availability of medical terminologies and ontologies and
in the field of NLP [32]. However, when comparing the
specific findings of queries in this work with the results
of Epstein [17], it is striking that in certain areas, the
ontology first had to be extended to enable the use of
historical text. This extension was required for the rec-
ognition or annotation of drugs, as trade names that are
no longer in use had been employed.
We overcame the disadvantage of Zhengs approach
[18], which needed an already annotated database, by in-
tegrating a terminology server into the analysis pipeline.
In addition, the user is not required to have any know-
ledge about how the terminology works since the data
annotation and free-text annotation of the query expres-
sions use the same NLP-based terminology server.
The annotation results outperformed the approaches
presented by Allones et al. [5] and Shah et al. [7] and
compared very well to the ones presented by Topfer
et al. [6], who obtained slightly better results, and Elkin
et al. [4], whose results were slightly inferior to ours.
This comparison of final metrics shows that the
employed NLP pipeline and annotation algorithm deliver
state-of-the-art results and provide an objective evalu-
ation of the query results. Since the results come from a
relatively small set of data, they can only be generalised
if the terminology is complete and homogeneous, which
needs to be validated. Maintaining terminology and
ontology was not a specific topic of our research, as we
used a standardized terminology server that can provide
different terminologies and is easily interchangeable.
The slight loss of sensitivity when querying for heart
defects was traced back to 16 cases that were false nega-
tives. The reasons for these false negatives were
unrecognized abbreviations, missing precoordinated ter-
minology concepts, missing ontology links and in one
case, selection of an incorrect term-to-concept combin-
ation by the annotation algorithm. However, the results
compare very well to those of Pakhomov et al. [33].
The imperfect specificity for respiration disorders can
be explained by misinterpreted cases of intrauterine
hypoxia and the reduced sensitivity was mainly due to
cases with a hyaline membrane that were not correctly
classified.
The decreased sensitivity in the cases of malformation
was mainly caused by the inconsistent gold standard. The
original marking was performed under the assumption that
the malformation ultimately led to death, since this malfor-
mation influenced the original judgment of avoidability. This
situation becomes particularly clear in the case of congenital
tumors. Systematic yellow marking in the case of teratomas
showed that these tumors had been generally recognized as
lethal malformations, whereas some neuroblastomas were
not included in this category. The overall quality was still ex-
cellent, as over 90% of the individuals were correctly classi-
fied with this rather difficult medical definition.
When comparing the complexity of SPARQL queries
to O-SQL queries, it became clear that a considerable
advantage was not only the ability to use free text but
also the commonly available knowledge of the SQL syn-
tax. We assume that committed physicians with existing
knowledge of SQL can be trained to use O-SQL without
issue. In particular, clinicians calls for secondary use
have caused big software companies to open up their da-
tabases to clients. The use of routine systems, however,
bears certain limits, as the data must not be changed,
and the stability of the database models is not provided
per se. The first limit is completely circumvented by the
framework presented here, as all annotations are stored
in their own tables and the original tables remain un-
touched. Changes in the database schema with respect
to the data model can be represented quite easily by
re-generating the annotations. Also, when evaluating the
differences, it is important to note that SPARQL is
Sander and Wauer Journal of Biomedical Semantics            (2019) 10:7 Page 9 of 11
designed to query RDF data and SQL is designed to
query relational data. Thus, the advantages of both lan-
guages directly reflect the data models on which they
work [34].
Physician training on the use of O-SQL expressions
must be conducted in two steps: first, learning the ac-
tual syntax, which was rather unproblematic, and sec-
ond, learning how to use the mechanics of an
ontology. The latter could be addressed by providing
a detailed demonstration with examples, which could
later be adopted, of what an ontology is and how it
can be used. Without such a demonstration, physi-
cians tend to use rather simple queries, which do not
exploit the full power of the ontology.
Conclusions and future work
Many of the difficulties in using ontologies for the se-
mantic analysis of free text that were described in the
introduction of this paper were overcome by the ap-
proach presented here. The overall concept of integrat-
ing an NLP-based terminology server into SQL syntax
has been proven to be extremely viable.
In particular, the high complexity and diversity of
the German language were processed at a quality that
meets the requirements of medicine. The terminology
server used here is multilingual, so the O-SQL syntax
simply had to be extended to specify the language
used. With this approach, it is now possible to com-
pare databases on an international level, and
country-specific annotations with only one uniform
query language, such as German or English, could be
implemented. A first application, in which neotalogic
epicrises were analysed with regard to avoidable in-
fant mortality, has already proved successful [35].
The ontology-SQL syntax will be extended to allow for
nested expressions. For this purpose, the extent to which
these expressions are relevant and whether they cannot
perhaps be represented by concatenated expressions will
have to be evaluated. One example would be a query for
patients showing symptoms of diseases that can be
treated with specific agents.
From a medical point of view, queries for rare diseases
should be investigated. Here, selection will have to be
carried out via O-SQL and will be followed by concrete
case-by-case examinations.
In addition, the ontologies themselves (especially
the standard ontologies) will become increasingly ex-
tensive as more and more omics data are repre-
sented. Genetic information that was unknown at the
time of data collection can thus be considered in
queries using the approach presented here. Deriving
quality factors from historic data is of growing inter-
est because it enables a comparison of historic
procedures and treatments to the current medical
state-of-the-art.
The approach presented here is independent of a
specific ontology, on the contrary it allows access to
any number of ontologies. However, also controlled
vocabularies can be made applicable through this sys-
tem. Therefore, physicians can access and explore
data with specially developed ontologies that go be-
yond the spectrum of standard ontologies. This
removes one of the typical limitations of standard on-
tologies, which cover a broad spectrum of knowledge
but usually have a limited depth. This should signifi-
cantly increase the acceptance of the system. The fact
that routine data from many sources  as long as it
is stored in SQL based databases - can be immedi-
ately used at an ontology-driven level without further
transformation or integration demonstrates that the
presented work makes an important contribution to
translational research of routine data.
Endnotes
1Infant mortality rate (IMR) = the number of deaths of
children under 1 year of age per 1000 live births
Additional file
Additional file 1: Addendum 1. Detailed description on the specific
used terminology and ontology. Explaines some of the advanced
features possible. Addendum 2. Further details on O-SQL expressions,
namely on the rewriting process. Also contains a structured documenta-
tion of the parts of an O-SQL expression. (DOCX 57 kb)
Abbreviations
CI: Confidence interval; CTS: Common terminology services; GMDS: Deutsche
Gesellschaft für Medizinische Informatik, Biometrie und Epidemiologie;
ICD: International classification of diseases; NLP: Natural language processing;
OCR: Optical character recognition; OLAP: Online analytical processing;
OWL: Web Ontology Language; RDBMS: Relational database management
system; RDF: Resource Description Framework; SEP: Structure Entity Part;
SPARQL: SPARQL Protocol and RDF Query Language; SQL: Structured Query
Language
Acknowledgements
The author thanks the Friedrich Wingert Foundation for its permission to
apply the terminology and ontology used in this study. The author thanks
the company ID Information and Dokumentation im Gesundheitswesen
GmbH & Co KGaA for its permission to work with their product ID LOGIK®.
The author is especially thankful to Prof. Rapoport for providing the original
index cards.
Funding
No funding. The author was allowed to use ID LOGIK®.
Availability of data and materials
The dataset analyzed in the current study is not publicly available due to
obligations by the Department of Data Protection in Berlin/Germany but is
available from the corresponding author upon reasonable request.
Authors contributions
AS transcribed the index cards (and developed an application to support
that process), developed the O-SQL syntax and implemented all parts of the
software for processing O-SQL queries (including the transformation into
Sander and Wauer Journal of Biomedical Semantics            (2019) 10:7 Page 10 of 11
standard SQL) and processing to RDBMS to enable O-SQL queries. AS also
analyzed the data for the medical examples (including the gold standard)
and conducted all statistical measurements. RW reviewed the index card
transcriptions, advised the medical examples and reviewed the gold stand-
ard. Both authors read and approved the final manuscript.
Ethics approval and consent to participate
Ethics approval is not required for historical data over 30 years old.
Consent for publication
Not applicable.
Competing interests
The author works for the company ID Information und Dokumentation im
Gesundheitswesen GmbH & Co KGaA and has contributed to the
development of the product ID LOGIK®.
Publishers Note
Springer Nature remains neutral with regard to jurisdictional claims in
published maps and institutional affiliations.
Author details
1ID GmbH & Co. KGaA, Platz vor dem Neuen Tor 2, 10115 Berlin, Germany.
2Klinik für Neonatologie, Charité-Universitätsmedizin Berlin, 10098 Berlin,
Germany.
Received: 23 July 2018 Accepted: 26 March 2019
Arguello-Casteleiro et al. Journal of Biomedical Semantics 2019, 10(Suppl 1):22
https://doi.org/10.1186/s13326-019-0212-6RESEARCH Open AccessExploring semantic deep learning for
building reliable and reusable one health
knowledge from PubMed systematic
reviews and veterinary clinical notes
Mercedes Arguello-Casteleiro1*, Robert Stevens1, Julio Des-Diz2, Chris Wroe3, Maria Jesus Fernandez-Prieto4,
Nava Maroto5, Diego Maseda-Fernandez6,7, George Demetriou1, Simon Peters8, Peter-John M. Noble9,
Phil H. Jones9, Jo Dukes-McEwan10, Alan D. Radford9, John Keane1,11 and Goran Nenadic1,11,12From UK Healthcare Text Analysis Conference (HealTAC 2018)
Manchester, UK. 18-19 April 2018Abstract
Background: Deep Learning opens up opportunities for routinely scanning large bodies of biomedical literature
and clinical narratives to represent the meaning of biomedical and clinical terms. However, the validation and
integration of this knowledge on a scale requires cross checking with ground truths (i.e. evidence-based resources)
that are unavailable in an actionable or computable form. In this paper we explore how to turn information about
diagnoses, prognoses, therapies and other clinical concepts into computable knowledge using free-text data about
human and animal health. We used a Semantic Deep Learning approach that combines the Semantic Web
technologies and Deep Learning to acquire and validate knowledge about 11 well-known medical conditions
mined from two sets of unstructured free-text data: 300 K PubMed Systematic Review articles (the PMSB dataset)
and 2.5 M veterinary clinical notes (the VetCN dataset). For each target condition we obtained 20 related clinical
concepts using two deep learning methods applied separately on the two datasets, resulting in 880 term pairs
(target term, candidate term). Each concept, represented by an n-gram, is mapped to UMLS using MetaMap; we
also developed a bespoke method for mapping short forms (e.g. abbreviations and acronyms). Existing ontologies
were used to formally represent associations. We also create ontological modules and illustrate how the extracted
knowledge can be queried. The evaluation was performed using the content within BMJ Best Practice.
Results: MetaMap achieves an F measure of 88% (precision 85%, recall 91%) when applied directly to the total of
613 unique candidate terms for the 880 term pairs. When the processing of short forms is included, MetaMap
achieves an F measure of 94% (precision 92%, recall 96%). Validation of the term pairs with BMJ Best Practice yields
precision between 98 and 99%.
Conclusions: The Semantic Deep Learning approach can transform neural embeddings built from unstructured free-
text data into reliable and reusable One Health knowledge using ontologies and content from BMJ Best Practice.
Keywords: Semantic deep learning, Ontology, Deep learning, CBOW, Skip-gram, One health, SNOMED CT, PubMed,
Veterinary clinical narratives, Module extraction© The Author(s). 2019 Open Access This article is distributed under the terms of the Creative Commons Attribution 4.0
International License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and
reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to
the Creative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver
(http://creativecommons.org/publicdomain/zero/1.0/) applies to the data made available in this article, unless otherwise stated.
* Correspondence: m.arguello@manchester.ac.uk
1School of Computer Science, University of Manchester, Manchester, UK
Full list of author information is available at the end of the article
Arguello-Casteleiro et al. Journal of Biomedical Semantics 2019, 10(Suppl 1):22 Page 2 of 28Background
One Health is an approach to achieve better public
health outcomes by combining efforts from different dis-
ciplines and domains [1]. It entails the recognition that
the health of animals and the environment are essential
for human health, and  specifically  that human medi-
cine can benefit from veterinary medicine, as animals
develop many of the same diseases as humans do [2].
Zoonotic infections and anti-microbial resistance are ex-
amples that have received much of the attention re-
cently. A recent study by Stroud et al. [3] compiled
several examples of One Health cases where human
medicine can benefit from veterinary studies. However,
while both biomedical and clinical knowledge about hu-
man and animal health are growing, they remain isolated
silos. This paper investigates to what extent it is possible
to acquire One Health knowledge from the evidence-
based biomedical literature and veterinary clinical
narratives.
We focus on using Semantic Deep Learning (Sem-
Deep) [4, 5]  an emerging area combining the Semantic
Web resources and technologies and Deep Learning for
this task. Deep Learning is an area of machine learning
that applies neural networks to learn representations of
data with multiple levels of abstraction [6]. The Seman-
tic Web embodies standards and tools for publishing
and processing meta-data, with ontologies at its core.
This paper proposes the use of ontologies as a way of
specifying the meaning of semantically related terms de-
rived from neural language models obtained via Deep
Learning. We explore how to turn information about
diagnoses, prognoses, therapies, as well as other clinical/
healthcare entities into computable knowledge integrat-
ing individual clinical expertise and best external evi-
dence [7].
There are two main challenges to achieving actionable
or computable knowledge about human diseases or
syndromes:
Multiple evidence-based resources  such as BMJ Best
Practice [8], DynaMed Plus [9] or UptoDate [10]  are
consulted by clinicians on a daily basis to assist clinical
decision making at point-of-care. Healthcare profes-
sionals need to provide effective and safe patient care,
and this also implies complying with Clinical Practice
Guidelines (CPGs) like those provided by the UK Na-
tional Institute for Health and Care Excellence (NICE)
[11]. CPGs tend to be evidence-based and have been de-
fined as systematically developed statements to assist
practitioners and patient decisions about appropriate
health care for specific circumstances [12]. Typically,
evidence-based resources, such as the NICE CPGs or
BMJ Best Practice, consist of human-readable text that
is updated periodically and is intended only for expert-
to-expert communication. A fundamental obstacle forachieving interoperability between evidence-based re-
sources is lack of grounding or normalisation [13],
i.e. the fact that biomedical/clinical terms appearing in
the NICE CPGs or BMJ Best Practice are not mapped to
specific terminological entries like the Unified Medical
Language System (UMLS) [14] Metathesaurus. Normal-
isation may help with periodic updates of evidence-
based resources from the biomedical literature, as
PubMed/MEDLINE articles are indexed with Medical
Subject Headings (MeSH) [15], which is included in the
UMLS Metathesaurus. Unfortunately, annotating bio-
medical articles with MeSH terms is difficult and expen-
sive [16] and normalisation of evidence-based resources
is not being carried out.
World-leading terminologies, such as the Systematized
Nomenclature of Medicine Clinical Terms (SNOMED
CT) [17], are included within the UMLS Metathesaurus
and provide multiple terms for expressing a biomedical
concept. However, SNOMED CT does not contain for-
mal or semi-formal descriptions that help understand
how a disease develops and which treatment approaches
can be considered. For example, medication statements
that state which drugs treat a disease or syndrome are
not included in SNOMED CT. Hence, even automatic
acquisition of a partial set of SNOMED CT concepts
relevant for a disease or syndrome (e.g. medications/
drugs and clinical findings) remains an unmet need.
This paper investigates whether a SemDeep approach
can help address both challenges. On the one hand, the
neural language models can be applied to PubMed Sys-
tematic Reviews [17], which is a large collection of
evidence-based articles (e.g. clinical trials, systematic re-
views, and CPGs) available in PubMed/MEDLINE. Vec-
tor representations of the terms (word embeddings or
neural embeddings) can be learnt from this unstruc-
tured text corpus, where semantically related terms will
end up close in the representational space. On the other
hand, if the terms that participate in the associations de-
rived from these distributional similarities are normal-
ised (i.e. terms with vector representations are mapped
to UMLS Metathesaurus concepts and SNOMED CT
concepts), that would allow: a) the expansion of the
knowledge that exists in SNOMED CT; and b) auto-
matic derivation of SNOMED CT subsets of semantic-
ally related concepts that can be reused and shared.
In this paper we focus on 11 well-known medical con-
ditions that affect both humans and animals: heart fail-
ure, asthma, epilepsy, glaucoma, chronic kidney disease,
osteoarthritis, anaemia, arthritis, diabetes mellitus,
hypertension, and obesity. We adhere to comparative/
translational medicine [18] and investigate the added
value of One Health by combining: a) the Systematic Re-
views Subset of PubMed, and b) a large set of veterinary
clinical narratives collected by the Small Animal
Arguello-Casteleiro et al. Journal of Biomedical Semantics 2019, 10(Suppl 1):22 Page 3 of 28Veterinary Surveillance Network (SAVSNET) [19]. We
rely on existing ontologies (lemon (Lexicon Model for
Ontologies) [20] and OBAN (Open Biomedical Associa-
tioNs) [21]) to formally represent associations (semantic-
ally related term pairs) derived from neural embeddings.
However, as Deep Learning algorithms have a black-
box representation [22], their wider acceptance and
adoption in the biomedical and clinical domain requires
confidence and trust. To build such confidence (through
transparency and interpretability), we use evidence-
based resources (namely BMJ Best Practice) to verify if
the associations (the semantic relatedness) captured by
neural embeddings are reliable for human medicine. We
note that clinicians consult multiple evidence-based re-
sources, so BMJ Best Practice cannot be taken as the
only gold standard that provides ground-truth. However,
in practical terms, when there is a lack of external evi-
dence from systematic research about the meaningful as-
sociation of two terms (e.g. a medical condition and a
treatment), the term pair should be considered as
unrelated.
Related work
Neural embeddings learnt from the biomedical litera-
ture or clinical narrative corpora have been widely
used from many tasks, but they pose a challenge
when measuring their quality. On the one hand, the
biomedical/clinical domain requires background
knowledge that makes crowd-worker evaluation (e.g.
users of Amazon Mechanical Turk) unsuitable. On
the other hand, there are no similarity and related-
ness benchmarks developed for well-known medical
conditions per se. Currently, there are four main
standard benchmarks that are specific to the medical/
clinical domain and suitable for a semantic similarity
and relatedness task: Caviedes and Cimino [23] with
10 medical term pairs; Pedersen et al. [24] with 30
medical term pairs; Pakhomov et al. [25] with 101
clinical term pairs; and Pakhomov et al. [26] with 724
medical term pairs (the last two available at [27]). In
total, these standard benchmarks provide less than 1
K term pairs. It should be noted that similarity and
relatedness benchmarks were used to evaluate trad-
itional distributional semantic models [28]  e.g. La-
tent Semantic Analysis (LSA) [29] or Latent Dirichlet
Allocation (LDA) [30]. Faruqui et al. [31] emphasise
that the lack of standard evaluation methods for
neural embeddings was the trigger to create new
benchmark datasets (e.g. Simlex-999 [32] and
SimVerb-3500 [33] that are outside of the biomedical/
clinical domain) and highlight that the use of word
similarity tasks for evaluation of word vectors is not
sustainable and calls for further research on evalu-
ation methods.A common characteristic of biomedical/clinical docu-
ments is that longer words and phrases are frequently
mapped onto a shorter form such as abbreviations or ac-
ronyms for efficiency of communication [34]. For ex-
ample, heart failure (long form) can appear as HF
(short form). Another issue is that the number of abbre-
viations and the average number of definitions per abbre-
viation is ever growing [34]. For example, HF (short
form) can have multiple meanings, and therefore, refer
to multiple senses besides heart failure, such as His-
panic female or high-fat or Hartree-Fock or hemo-
filtration. Although short forms (abbreviations and
acronyms) are present in UMLS, several studies [3537]
have shown UMLS to have shortcomings when mapping
short forms to long forms. Sense inventories have been
created such as SaRAD [38], ADAM [39], and more re-
cently Allie [40]  in May 2018, Allie contained 840 K of
short forms. These sense inventories and their algo-
rithms assume that the short and long form co-occur in
the biomedical literature, such as MEDLINE/PubMed
abstracts; however, they rarely co-occur in clinical
narratives [41, 42]. Sense inventories from clinical
documents are fewer in number than sense inventor-
ies from the biomedical literature and contain fewer
short forms. Wu et al. [43] highlight that accurate
identification of clinical abbreviations is a challenging
task and advanced abbreviation recognition modules
are needed for existing clinical NLP systems. Dealing
with short forms is therefore a challenge that requires
an approach to deal with terms appearing in both
biomedical and clinical documents.
The paper is organised as follows. In the next section,
we present a SemDeep approach that builds on our pre-
vious work [4447]. We first introduce the datasets, and
then present the approach that deals with two NLP
tasks: a semantic similarity and relatedness task, and a
named-entity recognition (NER) task. As part of the
SemDeep pipeline, we show how to reuse existing ontol-
ogies to formally represent the associations derived from
neural embeddings in OWL. We also create ontological
modules with the SNOMED CT ontology and illustrate
how to query the extracted knowledge using the
SPARQL query language [48], which exploit the under-
lying ontological representations and can be executed
using Jena ARQ [49].
Materials and methods
Data
The PubMed Systematic Reviews dataset (the PMSB
dataset): we downloaded the MEDLINE/PubMed base-
line files for 2015 and up-to-date files through 8th June
2016. Applying the PubMed Systematic Reviews filter
[17], a subset of 301,201 PubMed publications published
between 2000 and 2016 was obtained. We extracted
Arguello-Casteleiro et al. Journal of Biomedical Semantics 2019, 10(Suppl 1):22 Page 4 of 28titles and available abstracts. We note that this dataset
was also used in our previous study on sepsis [46].
The SAVSNET dataset (the VetCN dataset): a col-
lection of 2,465,420 de-identified and non-empty vet-
erinary clinical narratives was obtained from
SAVSNET on 20th October 2017. SAVSNET is an
initiative by the British Small Animal Veterinary As-
sociation and the University of Liverpool that collects
free-text consultations notes across around 500 UK
veterinary premises in real-time.
We used the UMLS Metathesaurus with close to 3.7
M biomedical/clinical concepts with 203 sources con-
tributing to concept names (as of May 2018), including
SNOMED CT and the Veterinary Extension for
SNOMED CT (VetSCT) [50]. We used MetaMap 2016v2
(released September 2016) and the SNOMED CT ver-
sion released in January 2017 in OWL to maximise com-
patibility among versions. When using the UMLS
Terminology Services [14] to access the UMLS Metathe-
saurus online, we select the UMLS2016AB version. As
we cannot release a subset of the UMLS Metathesaurus
or SNOMED CT, to replicate the results obtained with
our method it is necessary to use the UMLS API [51]
and the OWL API [52].
SemDeep pipeline
Below we describe each step of the pipeline intended to
acquire and validate knowledge about medical condi-
tions from the unstructured text datasets.
Step 1: computing n-grams from unstructured text
We employed word2phrase within the word2vec soft-
ware package [53] to compute n-grams from the un-
structured text datasets (e.g. PMSB or VetCN). It
should be noted that text within consultation notes
(e.g. today pain++) contains a significant number of
misspellings, local abbreviations and short forms, and
lacks the grammatical correctness found within bio-
medical literature. After applying word2phrase, the
character _ appears within tokens that co-occur re-
peatedly together (e.g. heart_failure is a bigram with
two tokens). Each n-gram has a frequency count. We
note that an n-gram captures words or tokens that
appear together in a textual corpus with a certain fre-
quency. Therefore, an n-gram can capture words and
phrases as well as combinations of tokens that may
not correspond exactly to meaningful unit when
looked in isolation phrase, e.g. (COPD)_is_a.
Step 2: creation of neural embeddings
We create neural embeddings with CBOW (Continuous
Bag-of-Words) and Skip-gram [54] using the word2vec
software. The input for CBOW and Skip-gram is the un-
structured text with n-grams, where the character _typically denotes the presence of an n-gram of size
greater than one (e.g. a bigram or a trigram). The output
for CBOW and Skip-gram is typically: 1) a lexicon (i.e. a
list of n-grams) that is present in the unstructured text
and for which the vector representations have been
learnt; and 2) a binary file that contains neural embed-
dings, i.e. real-number representations for the terms in
the lexicon. When producing neural embeddings, there
are a small number of hyperparameters that need to be
tuned  we used the hyperparameters configuration de-
scribed in our previous work [55].
Step 3: obtaining term pairs for the semantic similarity and
relatedness task
Taking the vector for a specific target term (e.g. a disease
or syndrome) and applying the cosine similarity, a list of
top ranked terms (highest cosine values) can be obtained
from the created neural embeddings. These top ranked
terms are candidate terms, i.e. terms that need to be
judged as semantically similar or related to the target
term. Some authors agree that semantic similarity rep-
resents a special case of semantic relatedness [24]; Hill
et al. [32] interpret relatedness as association, where
the strongest similarity relation is synonymy; this inter-
pretation is applied in this study.
Target terms selection: to choose the target terms, we
first select the n-grams that pass the threshold of 1 K
frequency count and MetaMap has assigned them
UMLS Metathesaurus concepts with the Semantic
Type T047|Disease or Syndrome. The final selection
of target terms needs to be done manually as: a)
MetaMap may erroneously assign a UMLS Metathe-
saurus concept to an n-gram, particularly if the n-
gram is a short form such as HF; and b) the well-
known medical conditions selected as target terms
should be covered by BMJ Best Practice  the pre-
ferred gold standard in this study.
Number of top ranked candidate terms per target term:
to the best of our knowledge, no published study justifies
the number of terms selected with the highest cosine
value. Different studies used different numbers: from
three [56], ten [57, 58], 40 [59] to a range of numbers
(e.g. 5, 10, 20, 40, and 100) [60]. We limit the list of can-
didate terms to the 20 n-grams with the highest cosine
value.
Step 4: named entity recognition
Named Entity Recognition (NER) consists of identifying
specific words or phrases (entities) and categorizing
them [61]. We use MetaMap to categorise the n-grams
into one or more of 133 broad categories (Semantic
Types) from the UMLS Metathesaurus. To determine if
MetaMap supplies a correct CUI for an n-gram, detailed
guidelines were developed that intend to favour
Arguello-Casteleiro et al. Journal of Biomedical Semantics 2019, 10(Suppl 1):22 Page 5 of 28compatibility with the SNOMED CT Compositional
Grammar [62]:
 Single Map (SM)  MetaMap provides a single CUI
that captures the full meaning of the n-gram. This
case corresponds to Simple Expression [62], i.e. a
single concept identifier. For example, the n-gram
septic_shock is mapped only to UMLS CUI =
C0036983.
 Multiple Maps (MM)  MetaMap provides
multiple CUIs that capture the meaning of the n-
gram, and one or more focus concepts may ap-
pear among the CUIs provided. This case may
also correspond to Simple Expression [62], al-
though it more often corresponds to Expression
with Refinements or Multiple Focus Concepts
[62]. Selection of focus concept(s) is guided by six
principles described in the Additional file 2.
 Incorrectly Mapped (IM)  MetaMap provides one
or more CUIs, however, none captures the meaning
of the n-gram. For example, the n-gram HF is not
mapped to C0018801|Failure, Heart (Heart
failure).
 Not Mapped (NM)  MetaMap does not provide
any CUI. For example, the n-gram HFpEF is not
mapped to C3889077|Heart failure with preserved
ejection fraction.
Three domain experts (two biomedical terminologists
and a medical consultant) inspected the results of Meta-
Map considering the above-mentioned guidelines and
assigned to each candidate term (n-gram) one of the
above values {SM, MM, IM, NM}. Beside the candidate
term (n-gram), we also provide the target terms (n-
grams) in lower case to provide local context. When an
n-gram is incorrectly mapped or not mapped, a CUI for
the n-gram is manually assigned. On the one hand, the
guidelines presented aim to reduce the number of CUIs
assigned to each n-gram. On the other hand, the n-
grams are the result of statistical NLP and may contain
short forms, and therefore, decomposing the n-grams
into lexico-semantic units of meaning has proved de-
manding in our previous work [4547] (even with years
of experience doing clinical coding). Hence, the three
domain experts worked together to identify the minimal
semantic constituents of the n-grams according to the
guidelines, i.e. determining systematically the focus
concept(s).
Dealing with short forms
We created a short form detector to identify n-grams
with or without one or more clinically meaningful short
forms. The detector is based on a hybrid approach: it
contains if-then-else heuristic rules and utilises two listsof terms, i.e. a list of measurement units compiled from
three resources [6365] and the rank frequency list of
the British National Corpus of written and spoken Eng-
lish [66] with 7726 words. The underlying assumption is
that a measurement unit can have one or more short
forms. For example, mmHg is a short form for the
long form millimetre of mercury.
Figure 1 depicts a flowchart outlining how the short
form detector that assigns one of the following labels to
an n-gram:
 SF-U when an n-gram contains a unit of measure-
ment. The n-gram is mapped to the UMLS
Metathesaurus concept C1519795|Unit of
Measure.
 SF-NU when an n-gram contains a number with a
unit of measurement. The n-gram is mapped to the
UMLS Metathesaurus concept
C0242485|Measurement.
 SF when an n-gram contains a short form token
that is not a measurement unit or a measurement
unit and a number.
 No label when an n-gram does not contain a short
form.
For those n-grams with a short form that is not a
measurement unit or a measurement unit and a number,
the domain experts manually utilised Allie as the pre-
ferred sense inventory, for expanding short forms into
long forms. The reasons for using Allie are: a) it contains
a much larger number of short forms than the UMLS
SPECIALIST Lexicon; b) it has long forms for a short
form ranked based on appearance frequency in
PubMed/MEDLINE abstracts; and c) for each long form
the research area and co-occurring abbreviations are
provided, thus aiding disambiguation.
The short form detector can make two errors, and the
domain experts will assign the following labels to an n-
gram:
 SF-I denotes that a short form identified in an n-
gram was assessed as not clinically meaningful, i.e.
incorrect.
 SF-NF denotes that a clinically meaningful short
form was not identified in an n-gram, i.e. not
found.
Experiment set-up and performance measures
We investigate the impact of the short forms on the per-
formance of MetaMap via two experiments:
 Experiment 1 (EXP1): we expose the candidate
terms directly to MetaMap, i.e. the lists with the 20
top-ranked n-grams (i.e. the 20 n-grams with the
Fig. 1 Flowchart of the short form detector introduced  a diagrammatic representation outlining how the short form detector assigns the labels
{SF-U, SF-NU, SF}. If no label is assigned, this means that the n-gram has no clinically meaningful short form(s)
Arguello-Casteleiro et al. Journal of Biomedical Semantics 2019, 10(Suppl 1):22 Page 6 of 28highest cosine value) are taken as input for
MetaMap.
 Experiment 2 (EXP2): we expose firstly the
candidate terms (n-grams) to the short form
detector described above, and for those n-grams
with one or more short forms, we expand each
short form into the corresponding long form by
utilising Allie. Once the short forms are replaced
with the long forms, we take the modified/ex-
panded candidate terms (n-grams) as input for
MetaMap.
For both experiments, we assume that the candidate
terms are biomedical or clinical terms, and thus, there
should be no True Negatives (TNs). We use the con-
ventional evaluation measures of Precision, Recall,
and F measure [67] to calculate the MetaMap per-
formance. As Pratt and Yetisgen-Yildiz [68], we have
weaker MetaMap precision and recall where exact
matches (typically Single Map) and partial matches
(typically Multiple Maps) are equally counted, i.e. SM
and MM are considered as True Positives (TPs). An
Incorrectly Mapped (IM) is interpreted as False Posi-
tive (FP). A Not Mapped (NM) is interpreted as a
False Negative (FN). Hence, we calculate precision as
TP/(TP + FP) [67] and recall as TP/(TP + FN) [67]. To
calculate F measure, we use equal weighting ofprecision and recall, calculating F measure as (2 x
Precision x Recall)/(Recall + Precision) [67]. We com-
pute precision, recall, and F measure for each well-
known medical condition under study (i.e. target
term), and then, average each evaluation measure over
all to obtain an overall measure of performance (a.k.a.
macro-averaging) [67]. We also report micro-
averaging, i.e. making a single contingency table for
all data [67]  all lists of the 20 n-grams with highest
cosine value that are the input to MetaMap.
Following Smucker et al. [69], we measure statistical
significance of the difference in the mean average
precision, recall, and F measure to judge if there is a
statistically significant improvement in performance
for EXP2 (short form detection and expansion into
long form before applying MetaMap to the unique
candidate terms) when compared with the perform-
ance for EXP1 (applying MetaMap to the unique can-
didate terms). We use the Students paired t-test [70]
as implemented in scikit-learn [71] to compare per-
formance of EXP1 and EXP2.
All unique candidate terms (n-grams) are exposed to the
short form detector. We also compute precision, recall,
and F measure for the short form detector considering all
candidate terms (micro-averaging) and the capability of
the short form detector to identify n-grams with or with-
out one or more clinically meaningful short forms.
Arguello-Casteleiro et al. Journal of Biomedical Semantics 2019, 10(Suppl 1):22 Page 7 of 28Step 5: validation of the term pairs mapped to UMLS
Metathesaurus concept pairs using BMJ best practice
This step validates the candidate terms obtained in Step
3 for the semantic similarity and relatedness task using
BMJ Best Practice, which covers prevention, diagnosis,
treatment and prognosis for well-known medical condi-
tions. It contains top down knowledge manually ex-
tracted by medical experts and is based both on the
latest clinical practice guidelines and underlying research
evidence. Hence, BMJ Best Practice can be considered
an evidence-based gold standard, supporting frontline
clinicians.
The validation involves four domain experts. The three
experts from the previous step (two terminologists and a
medical consultant) together validate the concept pairs
considering BMJ Best Practice and external resources
(whenever necessary). A health informatician  who
works with the content of BMJ Best Practice  contrib-
utes to the final stages of validation of the concept pairs
and (additionally) provides feedback to the editors of
BMJ Best Practice. To avoid bias, the domain experts
validate the concept pairs without knowing: a) the data-
set from which the concept pairs were derived; and b)
the neural language models applied to the dataset. To
avoid further hints about the underlying dataset, the tar-
get terms (n-grams) are presented in lower case.
The outcome of this step is a set of 3-tuples (target
concept, candidate concept, validation label). The target
and candidate concepts are UMLS Metathesaurus con-
cepts representing the focus concept(s) of the n-grams
for the term pairs (target term, candidate term). The val-
idation label indicates how the matching between a can-
didate concept and a term from BMJ Best Practice is
performed and reflects the amount of domain knowledge
required to perform such a match. We distinguish six
cases when matching a candidate concept name from
the UMLS Metathesaurus to a term appearing in BMJ
Best Practice:
1. Itself  a candidate term may have as its focus
concept(s) the same UMLS Metathesaurus concept
as the target term (i.e. the well-known medical con-
dition), and therefore, they will not be matched to
terms appearing in BMJ Best Practice. This case de-
notes synonymy (i.e. the strongest similarity
relation).
2. Relatedness by exact/approximate match 
candidate concept names as they appear in the
UMLS Metathesaurus may match exactly or
approximately terms appearing in BMJ Best
Practice, where the biomedical/clinical meaning is
the same. This typically denotes a similarity relation
between the candidate concept and the BMJ term.
This case can be interpreted as normalising BMJBest Practice terms. For example, pyrexic
(adjective) when used to refer to patients with
pyrexia (noun) can be interpreted as pyrexia.
From a linguistic point of view, pyrexic is a
morphological variant of pyrexia, and thus, this is
an example of an approximate match where the
biomedical/clinical meaning is the same. Some
implicit knowledge may be needed for this case.
3. Relatedness by inexact match (hypernym/hyponym)
or (hyponym/hypernym)  candidate concept names
as they appear in the UMLS Metathesaurus may
have is-a relations with the terms appearing in BMJ
Best Practice or vice versa. An is-a relation is also
similar to a hypernym/hyponym relation or general-
isation/specialisation relation and it denotes a simi-
larity relationship. For example, bacterial sepsis is-
a type of sepsis, where bacterial sepsis is the
hyponym (specialisation) and sepsis is the hyper-
nym (generalisation). Hypernym/hyponym relations
can be used to build semantic taxonomies (a.k.a.
hierarchies). Some implicit knowledge may be
needed for this case.
4. Relatedness by inexact match (background
knowledge)  candidate concept names as they
appear in the UMLS Metathesaurus may have
similarity (similar meaning or is-a relations) or re-
latedness (association) relations with the terms
appearing in BMJ Best Practice, although the rela-
tions are not obvious for someone lacking biomed-
ical/clinical knowledge. To make the implicit
knowledge explicit, one or more excerpts of exter-
nal evidence from systematic research or termino-
logical resources are provided. This case may apply
transitivity, i.e. if A is related to B and B is related
to C, then A is related to C. Therefore, by making
known one or more terms (call them B) it is feasible
to make transparent how a UMLS Metathesaurus
concept A related to a term C appearing in BMJ
Best Practice. In other words, by making B known,
and how A and C relate to B, implicit knowledge
becomes explicit.
5. Unrelated: not clinically meaningful  An n-gram
can capture combinations of words or tokens that
can be mapped to a focus UMLS Metathesaurus
concept(s), although it may not be interpreted per
se as clinically meaningful in connection with a
given medical condition. For example, guided is a
unigram for which alternative UMLS Metathe-
saurus concepts are available to represent multiple
meanings or senses: C0181090|Guide (Professional
guide); C0302614|Guide (Guide device); and
C1706050|Guide (Guide Device Component).
However, for sepsis, any sense for the n-gram
guided per se is not clinically meaningful.
Fig. 2 Overview of the extended version of the lemon core ontology (called here the lemonEXT) used for this study
Arguello-Casteleiro et al. Journal of Biomedical Semantics 2019, 10(Suppl 1):22 Page 8 of 286. Unrelated: excluded  candidate concept names as
they appear in the UMLS Metathesaurus may not
have up-to-date clinically meaningful association
(relatedness) relations with the terms appearing in
BMJ Best Practice, even if there is implicit know-
ledge that can justify the association. A typical ex-
ample of this case are treatments or therapies that
became known as ineffective or have adverse effects.
For example: The only novel anti-sepsis agent to
successfully complete a phase 3 sepsis trial, human
recombinant activated protein C, was recently taken
off the market after a follow up placebo-controlled
trial (PROWESS SHOCK) failed to replicate the re-
sults of the initial registration trial (PROWESS) per-
formed 10 yr earlier. [72]
The process of assigning the six validation labels intro-
duced above is iterative. A focus concept for a candidate
term and a term from BMJ Best Practice may have been
allocated the Relatedness by Inexact match (background
knowledge) label to indicate that one or more excerpts
of external evidence from systematic research or ter-
minological resources are needed to establish related-
ness. However, a closer inspection of the implicit
knowledge that has become explicit may change the
label into: Relatedness by exact/approximate match, or
Relatedness by Inexact match (hypernym/hyponym) or
(hyponym/hypernym), or Unrelated: Excluded. The
cases under the Relatedness by Inexact match (back-
ground knowledge) label may be further refined, for ex-
ample, by considering the relationship between cause
and effect.
The six validation labels introduced can be used for
calculating precision by considering: a) the last two un-
related labels representing False Positives (FPs); and b)
the itself and the labels starting with Relatedness by
representing True Positives (TPs).Step 6: formal representation of the knowledge acquired
and validated
We use OWL-DL to formally represent concept names,
concept expressions, and terminological axioms. Figures
2 and 3 overview the two core ontologies that will be
populated, i.e. the extended lemon core ontology (called
here the lemonEXT) [73] and the modified OBAN core
ontology (called here the OBANmod) [74]. Both core
ontologies reused the USTG (UMLS Semantic Types
and Groups) core ontology in OWL-DL that we created
programmatically and utilised in [45, 46]. The USTG
core ontology represents in OWL the information publi-
cally available at [75].
The USTG core ontology represents formally the
UMLS Semantic Types and Groups as well as the part-
whole relations among them by reusing the OWL object
properties part_of (obo:BFO_0000050) and has_part
(obo:BFO_0000051) from the Basic Formal Ontology
(BFO) [76]. The USTG core ontology also contains the
UMLS Metathesaurus concept, an OWL class we cre-
ated that can have as a subclass any Metathesaurus con-
cept from the UMLS. A new addition to the USTG core
ontology is the OWL annotation property hasDbXre-
fInSCT to create annotation assertion axioms that act
as cross-reference between the UMLS Metathesaurus
and SNOMED CT. The annotation property hasDbXre-
fInSCT is a sub-annotation property of the annotation
property database_cross_reference (oboInOwl:hasDbX-
ref) from the oboInOwl meta-model [77]. The USTG
core ontology has a total of 593 axioms (class count:
151; individual count: 0) and its Description Logic (DL)
expressivity is ALEI.
Table 1 shows the axiom patterns in Manchester
OWL Syntax [78] for populating programmatically the
main OWL Classes of lemonEXT and OBANmod core
ontologies. In this study, a pattern (a.k.a. axiom pattern)
can represent a set of OWL axioms.
Fig. 3 Overview of the modified version of the OBAN core ontology (called here the OBANmod) used for this study
Arguello-Casteleiro et al. Journal of Biomedical Semantics 2019, 10(Suppl 1):22 Page 9 of 28The extended lemon core ontology (lemonEXT)
In Fig. 2, the concept Lexical Topic represents the tar-
get term (i.e. an n-gram corresponding to a given med-
ical condition); the concept Lexicon represents the
lexicon, i.e. a list of the 20 top-ranked terms (n-grams
with the highest cosine value for the target term) ob-
tained with CBOW and Skip-gram; and the concept
Lexical Entry represents an n-gram in the lexicon. We
reuse two concepts from MeSH: D064886|Data Set
and D016571|Neural Networks (Computer). The latter
is a MeSH heading that has the entry term Neural Net-
work Models, which is the term that appears in Fig. 2.
The two MeSH concepts are represented as OWL clas-
ses and they are connected with the lemon concept
Lexicon by reusing the OWL object property corre-
lated with (obo:RO_0002610) from the Relations Ontol-
ogy (RO) [79] .
As depicted in Fig. 2, the concept Lexical entry from
lemon is connected to the UMLS Metathesaurus con-
cept from the USTG core ontology with the OWL object
property denotes from the Ontology Lexicon (Ontolex)
ontology [80]. We made the OWL Class Lexical sense
from lemon a superclass of the OWL Class UMLS Se-
mantic Type from the USTG core ontology. As one or
more UMLS Metathesaurus concept(s) is the focusconcept(s) for each n-gram, one or more UMLS
Metathesaurus concept(s) from the UTSG ontology cap-
tures the senses or meanings of a lexical entry. Taking
into account the UMLS Semantic Type(s) assigned to
each UMLS Metathesaurus concept, it is possible to
categorised the n-grams based on the OWL class de-
scriptions within the USTG ontology  e.g.
C0036983|Septic Shock is a subclass of T046|Patho-
logic Function  and therefore, we follow the seman-
tics by reference principle from [81] that says: the
expressivity and the granularity at which the meaning of
words can be expressed depend on the meaning distinc-
tions made in the ontology.
The lemonEXT core ontology has a total of 643 ax-
ioms (class count: 158; individual count: 0) and its DL
expressivity is ALEI. Once the lemonEXT is populated,
it is possible to create SPARQL SELECT queries retriev-
ing for each target term (i.e. n-gram) the candidate con-
cepts, i.e. the UMLS Metathesaurus concepts that are
the focus concepts of candidate terms (n-grams). We
built three queries (see the Additional file 4 for details)
that retrieve candidate concepts based on few UMLS Se-
mantic Types and a UMLS Semantic Group. The UMLS
Semantic Types and Group chosen intend to bring for-
ward candidate concepts related to the diagnoses and
Ta
b
le
1
Th
e
ax
io
m
pa
tt
er
ns
in
M
an
ch
es
te
r
O
W
L
Sy
nt
ax
fo
r
po
pu
la
tin
g
th
e
m
ai
n
cl
as
se
s
of
th
e
tw
o
co
re
on
to
lo
gi
es
:t
he
ex
te
nd
ed
le
m
on
co
re
on
to
lo
gy
(le
m
on
EX
T)
;a
nd
th
e
m
od
ifi
ed
O
BA
N
co
re
on
to
lo
gy
(O
BA
M
m
od
).
Ea
ch
ax
io
m
pa
tt
er
n
in
th
e
se
co
nd
co
lu
m
n
co
nt
ai
ns
va
ria
bl
es
,w
hi
ch
ca
n
be
ea
si
ly
id
en
tif
ie
d
as
th
ey
st
ar
t
w
ith
th
e
ch
ar
ac
te
r
?
.
Th
e
th
ird
co
lu
m
n
ex
em
pl
ifi
es
O
W
L
in
di
vi
du
al
s
th
at
ar
e
th
e
re
su
lt
of
po
pu
la
tin
g
th
e
ax
io
m
pa
tt
er
ns
in
tr
od
uc
ed
in
th
e
se
co
nd
co
lu
m
n
Br
ie
fd
es
cr
ip
tio
n
of
ax
io
m
pa
tt
er
n
A
xi
om
pa
tt
er
n
in
M
an
ch
es
te
r
O
W
L
Sy
nt
ax
Ex
am
pl
e
of
po
pu
la
tin
g
th
e
A
xi
om
pa
tt
er
n
in
M
an
ch
es
te
r
O
W
L
Sy
nt
ax
In
di
vi
du
al
of
th
e
O
W
L
cl
as
s
le
m
on
:L
ex
ic
al
To
pi
c
In
di
vi
du
al
:?
x
A
nn
ot
at
io
ns
:l
ab
el
?
lb
x@
en
Ty
pe
s:
L
ex
ic
al
to
pi
c
In
di
vi
du
al
:h
ea
rt
_f
ai
lu
re
A
nn
ot
at
io
ns
:l
ab
el
h
ea
rt
_f
ai
lu
re
@
en
Ty
pe
s:
L
ex
ic
al
to
pi
c
In
di
vi
du
al
of
th
e
O
W
L
cl
as
s
le
m
on
:L
ex
ic
al
En
tr
y
In
di
vi
du
al
:?
y
A
nn
ot
at
io
ns
:l
ab
el
?
lb
y@
en
Ty
pe
s:
L
ex
ic
al
en
tr
y
Fa
ct
s:
de
no
te
s?
C
U
I
In
di
vi
du
al
:b
et
a-
bl
oc
ke
rs
A
nn
ot
at
io
ns
:l
ab
el
b
et
a-
bl
oc
ke
rs
@
en
Ty
pe
s:
L
ex
ic
al
en
tr
y
Fa
ct
s:
de
no
te
s
A
dr
en
er
gi
c
be
ta
-A
nt
ag
on
is
ts

In
di
vi
du
al
of
th
e
O
W
L
cl
as
s
le
m
on
:L
ex
ic
on
In
di
vi
du
al
:?
z
A
nn
ot
at
io
ns
:l
ab
el
?
lb
z@
en
Ty
pe
s:
Le
xi
co
n
Fa
ct
s: c
or
re
la
te
d
w
ith
?
da
ta
se
t,
c
or
re
la
te
d
w
ith
?
m
od
el
,
en
tr
y?
y1
,



en
tr
y?
y2
0
In
di
vi
du
al
:P
M
SB
_C
BO
W
_h
ea
rt
_f
ai
lu
re
A
nn
ot
at
io
ns
:l
ab
el
P
M
SB
_C
BO
W
_h
ea
rt
_f
ai
lu
re
@
en
Ty
pe
s:
Le
xi
co
n
Fa
ct
s:
'c
or
re
la
te
d
w
ith

PM
SB
da
ta
se
t,
'c
or
re
la
te
d
w
ith
C
BO
W
,
en
tr
y
be
ta
-b
lo
ck
er
s,



en
tr
y
c
ar
di
ac
_r
es
yn
ch
ro
ni
za
tio
n_
th
er
ap
y_
(C
RT
)
In
di
vi
du
al
of
th
e
O
W
L
cl
as
s
ob
an
:a
ss
oc
ia
tio
n
In
di
vi
du
al
:?
C
pa
ir
A
nn
ot
at
io
ns
:r
df
s:l
ab
el
?
lb
Cp
ai
r@
en
Ty
pe
s:
as
so
ci
at
io
n
Fa
ct
s:
ob
an
:a
ss
oc
ia
tio
n_
ha
s_
ob
je
ct
?
C
U
I1
,
ob
an
:a
ss
oc
ia
tio
n_
ha
s_
su
bj
ec
t?
C
U
I2
In
di
vi
du
al
:
(C
00
17
60
1,
C
00
20
58
1)

A
nn
ot
at
io
ns
:l
ab
el
(C
00
17
60
1,
C
00
20
58
1)
@
en
Ty
pe
s:
as
so
ci
at
io
n
Fa
ct
s:
'a
ss
oc
ia
tio
n
ha
s
ob
je
ct
H
yp
he
m
a,
'a
ss
oc
ia
tio
n
ha
s
su
bj
ec
t
G
la
uc
om
a
In
di
vi
du
al
of
th
e
O
W
L
cl
as
s
ob
an
:p
ro
ve
na
nc
e
In
di
vi
du
al
:?
EC
pa
ir
A
nn
ot
at
io
ns
:r
df
s:l
ab
el
?
lb
EC
pa
ir@
en
Ty
pe
s:
pr
ov
en
an
ce
Fa
ct
s:
'h
as
so
ur
ce
?
BM
Jd
oc
,
'h
as
ex
ce
rp
t?
BM
Jt
er
m
,
'h
as
ev
id
en
ce
?
lb
Ev
id
en
ce
,
'h
as
ex
ce
rp
t?
EE
ex
ce
rp
t,
'is
ab
ou
t?
C
pa
ir,
'd
at
e
cr
ea
tio
n
as
so
ci
at
io
n
?
d1
^
^
st
rin
g,
'so
ur
ce
da
te
is
su
ed
?
d2
^
^
st
rin
g
In
di
vi
du
al
:
(C
00
17
60
1,
C
00
20
58
1,
Re
la
te
dn
es
s
by
in
ex
ac
t
m
at
ch
(b
ac
kg
ro
un
d
kn
ow
le
dg
e)
)
A
nn
ot
at
io
ns
:
la
be
l
(C
00
17
60
1,
C
00
20
58
1,
Re
la
te
dn
es
s
by
in
ex
ac
t
m
at
ch
(b
ac
kg
ro
un
d
kn
ow
le
dg
e)
)@
en
Ty
pe
s:
pr
ov
en
an
ce
Fa
ct
s:
'h
as
so
ur
ce

BM
J
Be
st
Pr
ac
tic
e:
O
pe
n-
an
gl
e
gl
au
co
m
a
,
'h
as
ex
ce
rp
t
tr
ab
ec
ul
ot
om
y,
'h
as
ev
id
en
ce

Re
la
te
dn
es
s
by
in
ex
ac
t
m
at
ch
(b
ac
kg
ro
un
d
kn
ow
le
dg
e)
,
'h
as
ex
ce
rp
t
EE
ex
ce
rp
t_
70
,
'is
ab
ou
t
(C
00
17
60
1,
C0
02
05
81
),
'd
at
e
cr
ea
tio
n
as
so
ci
at
io
n
M
ay
-2
01
8?
^
^
st
rin
g,
'so
ur
ce
da
te
is
su
ed

09
-D
ec
-2
01
6?
^
^
st
rin
g
Arguello-Casteleiro et al. Journal of Biomedical Semantics 2019, 10(Suppl 1):22 Page 10 of 28
Arguello-Casteleiro et al. Journal of Biomedical Semantics 2019, 10(Suppl 1):22 Page 11 of 28management of a given medical condition (i.e. the target
term):
 The UMLS Semantic Types T059|Laboratory
Procedure; T060|Diagnostic Procedure; and
T061|Therapeutic or Preventive Procedure. These
are the three subtypes of the UMLS Semantic Type
T058|Health Care Activity [82]. We call the query
q1 and it utilises these four UMLS Semantic Types.
 The UMLS Semantic Types T034|Laboratory or
Test Result; and T184|Sign or Symptom. These
are the two subtypes of the UMLS Semantic Type
T033|Finding [82]. We call the query q2 and it
utilises these three UMLS Semantic Types.
 The UMLS Semantic Group Chemicals & Drugs
(a.k.a. CHEM) that contains UMLS Semantic Types
that are chemicals taking into account their
structural and functional perspective [82]. Some of
the UMLS Metathesaurus concepts belonging to
CHEM are typically drug treatments (medications).
We call the query q3 and it utilises the Semantic
Group CHEM.
The modified version of the OBAN core ontology
(OBANmod)
An OBAN association relates biomedical entities (e.g. X,
Y) without enforcing directionality on the link [21] (i.e.
X is associated with Y or Y is associated with X) and
separating the association between entities from its prov-
enance [21]. Although we can safely state that there is a
clinically meaningful association for the term pair (heart
failure, pulmonary edema) it does not mean that all pa-
tients with heart failure will also have pulmonary
edema. Instead, we should interpret the term pair (heart
failure, pulmonary edema) as a sometimes true associ-
ation relationship [21] that can be represented in OWL
as an OBAN association.
Figure 3 presents a modified version of the OBAN
core ontology for this study considering:
1. The OBAN association is between two UMLS
Metathesaurus concepts represented as OWL
Classes as in [21], and we also use punning. It
should be noted that OWL 2 DL relaxes the
separation between classes and individuals.
2. The validations labels introduced in Step 5 are
represented as OWL Classes that have as super-
classes OWL Classes from the Evidence and
Conclusion Ontology (ECO) [83] (release of 2018-
04-06). A total of five OWL Classes from ECO have
been reused as well as the subclass axioms for them
in the ECO.
3. The provenance that validates the sometimes true
association relationship is BMJ Best Practice. Torepresent a document from BMJ Best Practice, we
first reuse the OWL Class Document from the
Bibliographic Ontology Specification ontology
(BIBO) [84], and then, create a new subclass with
the name BMJ Best Practice document. Therefore,
BMJ Best Practice for chronic congestive heart
failure [85] will be an OWL instance of the OWL
Class BMJ Best Practice document.
4. Excerpts from biomedical or clinical resources are
needed for this study, such as: 1) the term(s)
appearing in BMJ Practice that are key when
validating the concept pairs; or 2) additional
information that make the implicit knowledge
explicit, such as excerpts from the scientific
literature (e.g. PubMed articles or MedlinePlus [86]
Webpages) or from terminologies like SNOMED
CT [62]. To represent an excerpt, we reuse the
OWL Class Excerpt from the BIBO. In the BIBO,
an Excerpt is part of a Document. We create the
annotation property excerpt_text to store terms
from BMJ Best Practice or lines of text that are
considered pertinent when making the implicit
knowledge explicit. Therefore, in this study, every
OBAN association will have at least one instance of
the OWL Class Excerpt, i.e. BMJ term(s) that are
key to validate the focus concept pairs for the term
pairs.
5. The replacement and modification of OWL data
properties from OBAN to better fit the current
study: a) the OWL data property
date_creation_association where we store the
month and year when the association was validated;
b) the OWL data property source_date_issued
where we store the last update of BMJ Best Practice
document used to validate the association; and c)
relax the xsd:dateTime declarations from OBAN as
sometimes it proves difficult to trace the
publication date for a PubMed paper or the release
day for a terminological resource.
The OBANmod core ontology has a total of 779 axioms
(class count: 181; individual count: 6) and its DL expres-
sivity is ALEHI (D). Once the OBANmod is populated, it
is possible to refine the SPARQL queries q1 to q3 into
q1V to q3V (see the Additional file 4 for details), where
the candidate concepts (i.e. UMLS Metathesaurus con-
cepts that are the focus concepts for the candidate terms)
should have an up-to-date clinically meaningful associ-
ation to the target concepts (the selected diseases or syn-
dromes) according to BMJ Best Practice (i.e. human
medicine), and thus, the UMLS Metathesaurus concept
pairs should have the validation labels introduced in Step
5 starting with Relatedness by or the validation label
Itself.
Arguello-Casteleiro et al. Journal of Biomedical Semantics 2019, 10(Suppl 1):22 Page 12 of 28Extracting locality-based modules
Our aim is the extraction of locality-based modules from
the SNOMED CT ontology that are: 1) much smaller in
size (i.e. number of axioms) than the SNOMED CT
ontology; 2) as specific as possible for a given medical
condition while being logically sound according to
OWL-DL; and 3) can be reused and shared among
organisations.
We extract a locality-based module (a.k.a. upper mod-
ule) [87] per target term using as signature all the
SNOMED CT concept identifiers mapped to UMLS CUI
pairs validated with BMJ Best Practice content. We use
the reasoner FaCT++ [88] for the method ModuleType
BOT in the OWL API [52] as we did in [47]. A DL rea-
soner, like FaCT++, can calculate inferred information
(e.g. inferred subsumption hierarchy) from the asserted
information, i.e. the axioms within an ontology. A
locality-based module contains at least all the (entailed)
super-classes of an OWL class included in the signature
[87] as well as all axioms relevant to the meaning of the
OWL Classes in the signature. A SNOMED CT concept
may have one or more attribute-value pairs [62], where
the value of the pair is typically another SNOMED CT
concept. Attribute-value pairs are considered relevant to
the meaning of a SNOMED CT concept.
A locality-based module keeps the SNOMED CT top-
level hierarchies for the OWL Class extracted, which is
expected by the clinicians, and is likely to be smaller
than the SNOMED CT ontology. The SNOMED CT
ontology corresponding to the January 2017 release con-
tains a total of 1.5 M axioms (Class count: 325 K; indi-
vidual count: 0; Object property count: 80; SubClassOf
axioms count: 246 K; and EquivalentClasses axioms
count: 79 K) and its DL expressivity is ALER.
Multiple SPARQL queries can be built seeking to
gain insights into diseases and syndromes of signifi-
cance for both human medical and veterinary health-
care, i.e. One Health knowledge. For this study, the
SPARQL SELECT queries q1V to q3V presented in
Step 6 intend to retrieve reliable knowledge for hu-
man medicine (UMLS CUI pairs validated with BMJ
Best Practice content) about the diagnosis and man-
agement of well-known medical conditions that affect
humans and animals. We created the SPARQL SE-
LECT queries q1VU to q3VU (see the Additional file
4 for details) that combine the results of the queries
q1V to q3V over each dataset VetCN and PMSB.
Hence, we report the number of UMLS Metathe-
saurus concepts pairs with up-to-date clinically mean-
ingful associations for human medicine, although the
source data can be from veterinary medicine (i.e. the
SAVSNET veterinary clinical narratives) or from hu-
man medical science (i.e. the PubMed Systematic
Reviews).The results of the queries q1VU to q3VU as well as
the results of the queries q1V to q3V are quantitative.
Hence, we can quantify to what extent One Health can
provide added value when compared with a conventional
approach that will keep both datasets VetCN and PMSB
separated for being part of either veterinary medicine or
medical science.
A UMLS Metathesaurus concept can be mapped to
none, one or more than one SNOMED CT concepts.
We created the SPARQL SELECT query q1VM to
q3VM (see the Additional file 4 for details) to retrieve
from the OBANmod those UMLS CUI pairs validated
with BMJ Best Practice content, where the candidate
concept is mapped to at least one SNOMED CT con-
cept. Using the OBANmod and the asserted information
within each locality-based module as the default graph,
we created the SPARQL SELECT query q1VS to q1VS
(see the Additional file 4 for details) that retrieves those
SNOMED CT concept pairs (OWL Classes) mapped to
UMLS CUI pairs validated with BMJ Best Practice con-
tent. For these SNOMED CT pairs, it is possible to go
beyond the knowledge captured in the OBAN some-
times true association relationships.
Each locality-based module created for a well-known
medical condition contains asserted as well as inferred
knowledge that can expand/enrich the results from the
queries q1VS to q3VS by exploiting the transitive clos-
ure of rdfs:subClassOf for the SNOMED CT concepts in
OWL. The SPARQL SELECT queries q1VR to q3VR
(see the Additional file 4 for details) use as the default
graph the inferred model obtained with the DL reasoner
FaCT++ for each locality-based module. The queries
q1VR to q3VR retrieve the OWL Classes that are
asserted and inferred descendants of the those
SNOMED CT concepts that are mapped to candidate
concepts of the SNOMED CT pairs retrieved from the
SPARQL SELECT queries q1VS to q3VS.
Results
We start by illustrating and reporting the results ob-
tained for each step of the SemDeep pipeline using the
PMSB and VetCN datasets. Next, we combine the re-
sults from the SemDeep pipeline to investigate to what
extent the One Health approach can provide added
value.
A SemDeep pipeline
Step 1: computing n-grams from unstructured text
As in our previous work [4447], we employ word2-
phrase to obtain n-grams and we preserve numbers and
punctuation marks including parenthesis as they appear
in the unstructured text. However, the original text of
the PMSB dataset is not converted to lower case as in
[4447]. The PMSB dataset contains 447M terms
Arguello-Casteleiro et al. Journal of Biomedical Semantics 2019, 10(Suppl 1):22 Page 13 of 28(words and tokens as they appear in the text), and after
obtaining the n-grams, this number reduces significantly
to 46M. This means that a high number of tokens/
words appear to be repeatedly collocated.
The original text of the VetCN dataset was converted to
lower case before computing n-grams as many examples
were found within the unstructured text of indiscriminate
alternation between lowercase and uppercase. The VetCN
dataset contains 149M terms (words and tokens as they
appear in the text), and after obtaining the n-grams, this
reduces to 103M. A plausible reason for the modest nu-
meric reduction is presence of spelling variations and/or
errors for the same term. To confirm this hypothesis, we
utilise a probabilistic spelling corrector [89] that provides
alternative spellings for a word or token appearing within
a corpus; the hypothesis was confirmed. For example, the
term vomiting appears in VetCN with more than 50
spelling variations such as vomiteting or vomittimng
or vomirtting or vomikting (to mention just a few),
which can be considered spelling errors. Furthermore, by
close inspection of the unstructured text, it can be ob-
served that short forms like v are used instead of the
long form vomiting.
Step 2: creation of neural embeddings
We use the word2vec implementations for CBOW and
Skip-gram and apply the same hyperparameter configur-
ation as our previous study [55]. To compute the neural
embeddings, we use a Dell PowerEdge R430 with 100GB
RAM and 32 virtual CPUs Intel Xeon E52690 v4 at 2.6
GHz. With this, creating the neural embeddings withTable 2 The target terms for PMSB and VetCN datasets
Target terms for this study and their concept identifiers in UMLS and SNOME
UMLS CUI SNOMED CT identifier VetCN dataset
n-gram (frequency count)
C0018801 84,114,007 heart_failure (1292)
C0004096 195,967,001 asthma (1194)
C0014544 84,757,009 epilepsy (1164)
C0017601 23,986,001 glaucoma (1657)
C1561643 709,044,004 ckd (2698)
C0029408 396,275,006 osteoarthritis (1765)
C0002871 271,737,000 anaemia (1414)
C0003864 3,723,001 arthritis (8276)
C0011849 73,211,009 diabetes (3660)
C0020538 38,341,003 hypertension (1132)
C0028754 414,916,001 obesity (1763)
SOFTWARE Open Access
Seeing the whole picture: integrated pre-
surgery reports with PreOptique
Guillermo Vega-Gorgojo1,2, Laura Slaughter1 and Martin Giese1*
Abstract
Background: Information technology has transformed the way healthcare is conducted. There is a deluge of patient
data dispersed in different systems that are commonly not interoperable. As a result, access to patient data has become
a major bottleneck for healthcare professionals that struggle to find the relevant information in a timely way and without
missing critical clinical information.
Results: We implemented PreOptique, a novel hybrid semantic and text-based system that was commissioned by a
large hospital in Norway for providing integrated access to patient health records scattered over several databases and
document repositories.
We use ontology-based data access (OBDA) for the seamless integration of the structured databases at the hospital
through the Optique platform. We employ text analysis techniques to extract vital sign measures and clinical findings
from patient documents.
PreOptique was developed and deployed at the hospital. This solution demonstrates how OBDA technology can
provide integrated data access to disparate structured sources in healthcare, without requiring the replacement
of existing databases. Unstructured clinical texts are also mined to extract patient findings, while the graphical
user interface (GUI) provides a single access point that hides the underlying complexity of the system. We ran a
usability study with 5 target users, obtaining a system usability score (SUS) of 86.0. Further, participants in the study
stressed the simplicity of the GUI and the integration of data sources enabled by the system.
Conclusions: This pilot study showcases the use of OBDA technology and text analysis to enable the integration of
patient data for supporting clinical surgery operations. PreOptique is usable and can be easily employed by medical
personnel to find patient data in a timely way.
Keywords: Electronic health records, Systems integration, Biological ontologies, Ontology-based data access, Text analysis
Background
Medical practice generates a deluge of patient data,
including diagnostic codes, medication orders, labora-
tory test results, and medical imaging. Typically, several
vendors supply systems to document and collect data
related to patient care. Medical professionals use these
systems for care planning and documentation purposes
related to patient encounters with the healthcare system.
When a patient is referred to a unit, the physician may
order tests and imaging prior to seeing a patient. Health-
care professionals often use the system to access pre-
viously recorded clinical notes that can provide relevant
background including diagnosis and even status regarding
previous health-related assessments such as whether the
patient has had a drivers license revoked for medical
reasons. Tracking all the data and relating it to the
patients current status involves accessing the right system,
evaluating the data that is there, checking date/time of
documentation, assessing whether this is the same or
different incident of a certain condition, and also con-
textual information like the type of medical encounter,
e.g. a routine examination, or even the role of the reporter.
Despite the wealth of patient data and the omnipre-
sence of healthcare systems, use of these systems does
not necessarily equate to an increase of efficiency or
improvements in quality of care [1]. One key issue is the
lack of information exchange between systems which
results in healthcare professionals using a great deal of
time jumping between multiple different information
* Correspondence: martingi@ifi.uio.no
1Department of Informatics, University of Oslo, Oslo, Norway
Full list of author information is available at the end of the article
© The Author(s). 2019 Open Access This article is distributed under the terms of the Creative Commons Attribution 4.0
International License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and
reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to
the Creative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver
(http://creativecommons.org/publicdomain/zero/1.0/) applies to the data made available in this article, unless otherwise stated.
Vega-Gorgojo et al. Journal of Biomedical Semantics            (2019) 10:5 
https://doi.org/10.1186/s13326-019-0197-1
technology (IT) systems in an attempt to tie together
patient information. In this regard, [2] reports physicians
frustration and professional dissatisfaction with electronic
health record (EHR) systems due to insufficient health
information exchange.
The interoperability of hospital IT systems is impacted
by the many underlying policies, organizational con-
straints and culture, and understanding of hospital work-
flow reflected in the architecture and design of each
system in use. To address this challenge, ontology-based
data access (OBDA) technology can be used to seamlessly
integrate structured data and information from these
systems [3]. The role of an ontology is to define the princi-
ples ruling real-world entities and their interrelations,
describing a domains inherent structure and behavior [4].
Semantic data integration involves the use of such a repre-
sentation of entities and relationships to eliminate possible
heterogeneities. The Optique project [5] has developed a
number of tools and methods to support OBDA, inclu-
ding tools for enabling users to formulate queries using
familiar vocabularies and conceptualizations, and inte-
grating data spread across multiple distributed data sources.
Ahus case study
Access to patient data is the chief complaint of the
healthcare personnel at the day surgery unit in Akershus
University Hospital (Ahus). Medical staff described an
environment where they were allocated 20 min to check
all patient information before surgery, but they were
actually investing much longer times to prevent missing
relevant information. We reproduce here some of their
quotes:
«We use too much time to search for information»
«We are not sure that we have checked all»
«We should rather spend the time on patients than on
the computer systems»
The underlying problem is that patient data is scat-
tered across different hospital IT systems, i.e. the registry
of medical encounters, the archive of clinical notes, the
repository of patient measures, the registry of laboratory
tests, and the pharmacy system. Furthermore, some of
these systems lack the necessary functionalities to facili-
tate data access. As an example, Ahus staff can browse
the clinical notes of a particular patient, but text search
is not provided.
In this paper we present a novel hybrid semantic and
text-based system that was commissioned by Ahus for
providing integrated access to patient health records
scattered in several databases and document reposito-
ries. The system makes use of the results from the
Optique project and is based on reuse and extension of
the OBDA tools available. The test case was the surgery
planning process that involves surgeons, anesthesiolo-
gists, and nurses. The proposed system is named PreOp-
tique (Pre-Op support with Optique). We showcase the
benefits of this solution and present the results of a
preliminary usability study.
Implementation
Ahus requirements
Ahus provides healthcare services to approximately
500,000 inhabitants in the county of Akershus, east of
Oslo, Norway. Ahus is a mid-size/large hospital with 953
beds, 62,489 admitted patients, and 28,300 day patients
registered in 2015. Patient data at Ahus is scattered
across several systems  the main information systems
employed by the day surgery unit are shown in Table 1.
However, these systems are not integrated and access to
patient data is not easy; for instance, there is no search
facility for the DIPS document archive (DIPS stands for
Distributed Information and Patient Data System in
Hospital). As a result, medical professionals at Ahus
complain about too much time spent searching patient
information, and they fear missing critical information
related to surgical preparation.
We started a pilot project with the day surgery unit at
Ahus aiming to improve the access to existing patient
information. More specifically, Ahus requested support
for the surgery planning process in which surgeons,
anesthesiologists, and nurses collaboratively fill in a
paper form with the operation plan. In a first stage, sur-
geon and patient agree on the surgery to be performed.
Resources are then allocated and the preparations for
the operation begin. There is a patient safety procedure
before and after the operation to assess that the
operation plan has been followed.
To complete the form, patient data has to be collected
manually from the systems in Table 1, requiring a
significant effort to find patient information and with
concerns about missing critical pieces of information for
Table 1 Main information systems employed by the day surgery unit at Ahus
System Provider Type Data description
DIPS DIPS Electronic health record system SQL database with administrative data, medical encounters and patient measures
Metavision Evry Physician order entry system SQL database with administrative data and patient measures
Document archive of laboratory tests and medical images
DIPS archive DIPS Document repository Document archive of unstructured clinical notes
Vega-Gorgojo et al. Journal of Biomedical Semantics            (2019) 10:5 Page 2 of 15
the planned operation, e.g. an allergy. Therefore, the goal
of the project was to provide an IT solution for suppor-
ting the surgery planning process with the following
requirements:
 Integrate patient data coming from structured
sources, i.e. the SQL databases of DIPS and
Metavision.
 Perform text analysis of the DIPS document archive
and provide access for the operation planning.
 Offer a single easy-to-use access point to patient data.
 Provide provenance information for every piece of
patient data.
 Design a non-invasive solution, i.e. no replacement
of the existing IT systems at Ahus.
 Provide adaptation to emerging user needs and new
data sources such as the laboratory tests and medical
images in Metavision that were not part of this pilot.
The Optique platform
Optique is a solution for unlocking access to corporate
data sources by enabling end users to formulate their
information needs through an intuitive visual query
interface [5]. The platform is based on OBDA techno-
logy [3] that provides an automated connection between
complex information requirements and relational data
stores. More specifically, an ontology is employed to
describe the end users domain with familiar and com-
prehensible terms that are translated into queries over
the data sources through a set of mappings.
Optique provides access to data in a non-invasive way,
since the data sources do not need to be replaced or
converted to another format. Instead, the platform
manages the ontology and mappings, giving the illusion
of a virtual integrated semantic store. In this way, a
query formulation component such as OptiqueVQS [6]
or PepeSearch [7] can directly plug in, enabling end
users to pose ad hoc queries without requiring special-
ized IT skills.
Optique relies on open standards such as SPARQL [8] for
querying the virtual triple store, OWL [9] for ontology spe-
cification, and R2RML [10] for the definition of mappings.
Open standards avoid vendor lock-in situations and
facilitate adaptation to diverse scenarios. For instance,
Optique has been successfully deployed on Statoils
corporate exploration and production data store [11],
as well as on Siemens service centers for monitoring
power plants [12, 13].
Text analysis
While the Optique platform can be used to provide
flexible access to structured data sources, it cannot be
directly used with unstructured data. Instead, natural
language processing (NLP) can be applied to analyze
clinical text, the most common and abundant data type
in the healthcare domain.
Text search engines [14] have become prevalent for
dealing with unstructured data, e.g. Web search. Search
engines maintain an index of the document corpus.
Queries are evaluated against the index and results are
then returned to the user. A query is typically composed
of one or more keywords, although explicit phrases can
also be supported. Potential answers are ranked using a
similarity measure to estimate the relevance of a docu-
ment for a query. The index is a data structure that
maps terms to the documents that contain them, thus
enabling fast query evaluation. Several parsing tech-
niques are commonly applied in the construction of the
index and in query evaluation, such as stemming
(removal of variant endings from words), case folding
(conversion to lowercase), or stopping (removal of common
words such as the).
Besides regular text search, clinical documents can be
mined to extract structured information about patients.
This is typically done using NLP tools, which combine a
range of linguistic, statistical and heuristic methods [15].
Deriving structured information from clinical text
involves entity extraction algorithms that commonly
employ medical vocabularies and ontologies such as
SNOMED CT [16] to drive the entity extraction task.
Difficulties in entity extraction include the presence of
negating terms such as no or never [15]. cTAKES [17]
is an example of an NLP tool for entity extraction from
clinical text.
PreOptique, integrated access to patient data
We aimed to support the surgery planning process by
offering a single easy-to-use access point to patient data
without replacing the existing IT systems at Ahus. In
order to comply with the requirements, we developed a
hybrid semantic and text-based system named Pre-
Optique. The logical architecture is sketched in Fig. 1
and has three main parts: the semantic backbone (teal
color), the text search engine (pink), and the graphical
user interface (GUI) that glues all the components and
serves as entry point to the medical personnel (blue).
The semantic backbone is based on the Optique plat-
form and deals with the integration of patient data
coming from structured sources. The key artefact is the
ontology that was developed to support this setting. The
development of the ontology was thus driven by the
database schemata of the structured sources employed
at Ahus, i.e. DIPS and Metavision. We also used ano-
nymized screenshots of the DIPS user interface to
inform the design. In addition, we interviewed members
of the medical staff at Ahus in order to gather the main
limitations of the existing solution (see the reproduced
Vega-Gorgojo et al. Journal of Biomedical Semantics            (2019) 10:5 Page 3 of 15
quotes in Section 1.1). With these inputs, we identified
that the main components the ontology should include:
administrative patient data, medical diagnoses and
diseases, healthcare encounters, data items such as
documents, and measurements of vital signs.
For constructing the ontology we decided to reuse
existing medical ontologies in the OBO Foundry suite
[18]. OBO Foundrys Basic Formal Ontology (BFO) [19]
is an upper-level ontology that provides a common
top-level structure to support the interoperability of the
multiple domain ontologies. BFO forms the basis of
numerous medical ontologies such as the NCBI organis-
mal classification (NCBItaxon), Ontology of Medically
Related Social Entities (OMRSE), Disease Ontology (DO),
Ontology for General Medical Science (OGMS), Clinical
Measurement Ontology (CMO), and the Information
Artifact Ontology (IAO), or Relation Ontology (RO)  we
reused classes from all these OFO Foundry ontologies.
The starting point was the definition of patient as a sub-
class of human being (NCBItaxon) that has a patient role
(OMRSE). We borrowed properties from the FOAF vo-
cabulary [20] to model basic patient data such as names,
gender or image, while we defined local properties to rep-
resent the Norwegian social security number and the date
of birth. We were therefore able to describe all the admin-
istrative patient data coming from DIPS and Metavision.
In Norway, medical diagnoses in the source DIPS EHR
dataset are tagged using version 10 of the standard
International Statistical Classification of Diseases and
Related Health Problems diagnostic coding schema
(ICD-10) [21]. DO is a domain ontology of human
diseases based on BFO and organized from a clinical
perspective of disease etiology and location [22]. DO is
thus more closely aligned with how medical personnel
work and think than ICD-10, so we decided to employ
this ontology using disease from OGMS as the top con-
Holderness et al. Journal of Biomedical Semantics           (2019) 10:19 
https://doi.org/10.1186/s13326-019-0210-8
RESEARCH Open Access
Analysis of risk factor domains in
psychosis patient health records
Eben Holderness1,1, Nicholas Miller1, Philip Cawkwell1, Kirsten Bolton1, Marie Meteer2, James Pustejovsky2
and Mei-Hua Hall1*
Abstract
Background: Readmission after discharge from a hospital is disruptive and costly, regardless of the reason. However,
it can be particularly problematic for psychiatric patients, so predicting which patients may be readmitted is critically
important but also very difficult. Clinical narratives in psychiatric electronic health records (EHRs) span a wide range of
topics and vocabulary; therefore, a psychiatric readmission prediction model must begin with a robust and
interpretable topic extraction component.
Results: We designed and evaluated multiple multilayer perceptron and radial basis function neural networks to
predict the sentences in a patients EHR that are associated with one or more of seven readmission risk factor domains
that we identified. In contrast to our baseline cosine similarity model that is based on the methodologies of prior
works, our deep learning approaches achieved considerably better F1 scores (0.83 vs 0.66) while also being more
scalable and computationally efficient with large volumes of data. Additionally, we found that integrating clinically
relevant multiword expressions during preprocessing improves the accuracy of our models and allows for identifying
a wider scope of training data in a semi-supervised setting.
Conclusion: We created a data pipeline for using document vector similarity metrics to perform topic extraction on
psychiatric EHR data in service of our long-term goal of creating a readmission risk classifier. We show results for our
topic extraction model and identify additional features we will be incorporating in the future.
Keywords: Natural language processing, Risk prediction, Machine learning, Electronic health record, Psychotic
disorders
Background
Psychotic disorders typically emerge in late adolescence
or early adulthood [1, 2] and affect approximately 2.5-
4% of the population [3, 4], making them one of the
leading causes of disability worldwide [5]. A substantial
proportion of psychiatric inpatients are readmitted after
discharge [6]. Readmissions are disruptive for patients
and families, and are a key driver of rising healthcare
costs [7, 8]. Reducing readmission risk is therefore a
major unmet need of psychiatric care. Developing clin-
ically implementable machine learning tools to enable
accurate assessment of risk factors associated with read-
mission offers opportunities to inform the selection of
*Correspondence: mhall@mclean.harvard.edu
1Psychosis Neurobiology Laboratory, McLean Hospital, Harvard Medical
School, Mill St, Belmont, MA, USA
Full list of author information is available at the end of the article
treatment interventions and implement appropriate pre-
ventive measures.
In psychiatry, traditional strategies to study readmission
risk factors rely on clinical observation and manual ret-
rospective chart review [9, 10]. This approach, although
benefitting from clinical expertise, does not scale well
for large data sets, is effort-intensive, and lacks automa-
tion. An efficient, more robust, and cheaper alternative
approach based on Natural Language Processing (NLP)
has been developed and met with some success in other
medical fields [11]. However, this approach has seldom
been applied in psychiatry because of the unique charac-
teristics of psychiatric medical record content.
There are several challenges for topic extraction when
dealing with clinical narratives in psychiatric EHRs. First,
the vocabulary used is highly varied and context-sensitive.
A patient may report feeling really great and excited
 symptoms of mania  without any explicit mention
© The Author(s). 2019 Open Access This article is distributed under the terms of the Creative Commons Attribution 4.0
International License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and
reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to the
Creative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver
(http://creativecommons.org/publicdomain/zero/1.0/) applies to the data made available in this article, unless otherwise stated.
Holderness et al. Journal of Biomedical Semantics           (2019) 10:19 Page 2 of 10
of keywords that differ from everyday vocabulary. Also,
many technical terms in clinical narratives are multiword
expressions (MWEs) such as obsessive body image, lin-
ear thinking, short attention span, or panic attack. These
phrasemes are comprised of words that in isolation do not
impart much information in determining relatedness to a
given topic but do in the context of the expression.
Second, the narrative structure in psychiatric clini-
cal narratives varies considerably in how the same phe-
nomenon can be described. Hallucinations, for example,
could be described as the patient reports auditory hal-
lucinations, or the patient has been hearing voices for
several months, amongst many other possibilities.
Third, phenomena can be directly mentioned with-
out necessarily being relevant to the patient specifically.
Psychosis patient discharge summaries, for instance, can
include future treatment plans (e.g. Prevent relapse of a
manic or major depressive episode., Prevent recurrence
of psychosis.) containing vocabulary that at the word-
level seem strongly correlated with readmission risk. Yet
at the sentence-level these do not indicate the presence
of a readmission risk factor in the patient and in fact
indicate the absence of a risk factor that was formerly
present.
Lastly, given the complexity of phenotypic assessment
in psychiatric illnesses, patients with psychosis exhibit
considerable differences in terms of illness and symp-
tom presentation. The constellation of symptoms leads
to various diagnoses and comorbidities that can change
over time, including schizophrenia, schizoaffective disor-
der, bipolar disorder with psychosis, and substance use
induced psychosis. Thus, the lexicon of words and phrases
used in EHRs differs not only across diagnoses but also
across patients and time.
Taken together, these factors make topic extraction a
difficult task that cannot be accomplished by keyword
search or other simple text-mining techniques.
To identify specific risk factors to focus on, we not
only reviewed clinical literature of risk factors associated
with readmission [12, 13], but also considered research
related to functional remission [14], forensic risk factors
[15], and consulted clinicians involved with this project.
Seven risk factor domains  Appearance, Mood, Interper-
sonal, Occupation, Thought Content, Thought Process,
and Substance  were chosen because they are clini-
cally relevant, consistent with literature, replicable across
data sets, explainable, and implementable in NLP algo-
rithms. These seven risk factor domains collectively cover
the essential clinical aspects of a patients symptoms and
functioning. Although hospitals may differ in terms of
narrative structure, all of a patients admission notes and
discharge summaries typically include text of these seven
domains. Many hospitals in the US include each of these
risk factors as a heading or subheading.
In our present study, we evaluate multiple approaches to
automatically identify which risk factor domains are asso-
ciated with which sentences in psychotic patient EHRs1.
We perform this study in support of our long-term goal of
creating a readmission risk classifier that can aid clinicians
in targeting individual treatment interventions and assess-
ing patient risk of harm (e.g. suicidal risk, homicidal risk).
Unlike other contemporary approaches in machine learn-
ing, we intend to create a model that is clinically explain-
able and flexible across training data while maintaining
consistent performance.
To incorporate clinical expertise in the identification of
risk factor domains, we undertake an annotation project,
detailed in the Annotation task subsection of the
Methods section. We identify a test set of over 5000
EHR sentences which a team of three domain-expert
clinicians annotate sentence-by-sentence for relevant risk
factor domains. The Inter-Annotator agreement sub-
section of the Methods section describes the results of
this annotation task. We then use the gold standard from
the annotation project to assess the performance of mul-
tiple neural classification models trained exclusively on
institutional EHR data, described in the Results section.
To further improve the performance of our model, we
incorporate domain-relevant MWEs identified using all
in-house data.
Related work
McCoy et al. [16] constructed a corpus of web data based
on the Research Domain Criteria (RDoC)[17], and used
this corpus to create a vector space document similarity
model for topic extraction. They found that the negative
valence and social RDoC domains were associated with
readmission. Using web data (in this case data retrieved
from the Bing API) to train a similarity model for EHR
texts is problematic since it differs from the target data
in both structure and content. Based on reconstruction of
the procedure, we conclude that many of the informative
MWEs critical to understanding the topics of sentences
in EHRs are not captured in the web data. Additionally,
RDoC is by design a generalized research construct to
describe the entire spectrum of mental disorders and does
not include domains that are based on observation or
causes of symptoms. Important indicators within EHRs
of patient health, like appearance or occupation, are not
included in the RDoC constructs.
Rumshisky et al. [18] used a corpus of EHRs from
patients with a primary diagnosis of major depressive
disorder to create a 75-topic Latent Dirichlet Allocation
(LDA) topic model that they then used in a readmission
prediction classifier pipeline. Like with McCoy et al. [16],
the data used to train the LDA model was not ideal as
1This study has received IRB approval.
Holderness et al. Journal of Biomedical Semantics           (2019) 10:19 Page 3 of 10
the generalizability of the data was narrow, focusing on
only one disorder. Their model achieved readmission pre-
diction performance with an area under the curve of .784
compared to a baseline of .618. To perform clinical valida-
tion of the topics derived from the LDAmodel, they man-
ually evaluated and annotated the topics, identifying the
most informative vocabulary for the top ten topics. With
their training data, they found the strongest coherence
occurred in topics involving substance use, suicidality, and
anxiety disorders. But given the unsupervised nature of
the LDA clustering algorithm, the topic coherence they
observed is not guaranteed across data sets.
Methods
Data
Two non-overlapping but highly compatible datasets were
used for training (Research Patient Data Registry, RPDR)
and for testing (McLean Meditech) of our models. Our
test set (McLean) consists of a corpus of discharge sum-
maries, admission notes, individual encounter notes, and
other clinical notes from 220 patients in the OnTrackTM
program at McLean Hospital. OnTrackTM is an outpa-
tient program, focusing on treating adults ages 18 to 30
who are experiencing their first episodes of psychosis. The
length of time in the program varies depending on patient
improvement and insurance coverage, with an average of
two to three years. The program focuses primarily on
early intervention via individual therapy, group therapy,
medication evaluation, and medication management. See
Table 1 for a demographic breakdown of the 220 patients,
for which we have so far extracted approximately 240,000
total EHR sentences spanning from 2011 to 2014 using
Meditech, the software employed by McLean for storing
and organizing EHR data.
These patients are part of a larger research cohort of
approximately 1800 psychosis patients, which will allow
us to connect the results of this EHR study with other
ongoing research studies incorporating genetic, cognitive,
neurobiological, and functional outcome data from this
cohort.
Table 1 Demographic breakdown of the target cohort
Mean Age (2014) 20.7
Gender (Male) 79%
Race
Asian 6%
Black 7%
Caucasian 77%
Latino 5%
Multiracial 5%
Insurance (Public)2 5.5%
30-day Inpatient Readmission Rate 14%
We also use an independent, non-overlapping data set
for identifying training data for our vector space model,
comprised of EHR texts queried from the RPDR, a cen-
tralized regional data repository of clinical data from
all institutions in the Partners HealthCare network (e.g.,
Massachusetts General Hospital, Brigham and Womens
Hospital). These records are highly comparable in style
and vocabulary to the McLean data set. The corpus con-
sists of discharge summaries, encounter notes, and visit
notes of patients admitted to the systems hospitals with
psychiatric diagnoses and symptoms, totaling approxi-
mately 8,000,000 EHR sentences consisting of 340,000,000
tokens. This breadth of data captures a wide range of clin-
ical narratives, creating a comprehensive foundation for
topic extraction.
After using the RPDR query tool to extract EHR sen-
tences from the RPDR database, we created a training
corpus by categorizing the extracted sentences according
to their risk factor domain using a lexicon of 120 key-
words that were identified by the clinicians involved in this
project. Certain domains  particularly those involving
thoughts and other abstract concepts  are often iden-
tifiable by MWEs rather than single words. The same
clinicians who identified the keywords manually exam-
ined the bigrams and trigrams with the highest Term Fre-
quency  Inverse Document Frequency scores (TF-IDF)
for each domain in the categorized sentences, identifying
those which are conceptually related to the given domain.
We then used this lexicon of 775 keyphrases to iden-
tify more relevant training sentences in RPDR and treat
them as (non-stemmed) unigrams when generating the
matrix (see supplementary data). By converting MWEs
such as shortened attention span, unusual motor activity,
wide-ranging affect, or linear thinking to non-stemmed
unigrams, the predictive value of these terms is magnified.
In total, we constructed a corpus of roughly 85,000,000
tokens across 2,100,000 EHR sentences for training our
model.
Annotation task
In order to evaluate our models, we created an anno-
tated test corpus McLean-specific EHR data extracted
from Meditech. 5154 sentences were annotated by three
licensed clinicians for the clinically relevant domains
described in Table 2. The corpus was selected by clinicians
(P. C. and K. B.) who treat patients at McLlean OnTrack
program and M.H.H who conducts clinical research at
the McLean Psychotic Disorders Division. It is comprised
entirely of McLean-specific EHR data, which are disjoint
from the RPDR but are highly compatible in style and
vocabularies with the RPDR dataset.
All sentences were removed from the surrounding
EHR context to ensure annotators were not influenced
by the additional contextual information. Our domain
Holderness et al. Journal of Biomedical Semantics           (2019) 10:19 Page 4 of 10
Table 2 Annotation scheme for the domain classification task
Domain Description Example Example Keywords
Appearance Physical appearance, gestures,
and mannerisms
A well-appearing, clean
young woman appearing
her stated age, pleasant and cooperative. Eye contact
was good."
Disheveled, clothing,
groomed, wearing, clean
Thought Content Suicidal/homicidal ideation,
obsessions, phobias, delusions,
hallucinations
No SI, No HI, No hallucinations, Ideas of reference, Paranoid
delusions"
Obsession, delusion,
grandiose, ideation, suicidal,
paranoid
Interpersonal Family situation, friendships,
and other social relationships
Pt. overall appears to be functioning very well despite this
conflict with a romantic interest of hers."
Boyfriend, relationship, peers,
family, parents, social
Mood Feelings and overall disposition Pt. indicates that his mood is becoming more depressed." Anxious, calm, depressed,
labile, confused, cooperative
Occupation School and/or employment Pt. followed through with decision to leave college at this
point in time."
Boss, employed, job, school,
class, homework, work
Thought Process Pace and coherence of
thoughts. Includes linear,
goal-directed, perseverative,
tangential, and flight of ideas
Disorganized (Difficult to communicate with patient.), Paucity
of thought, Thought-blocking."
Linear, tangential, prosody,
blocking, goal-directed,
perseverant
Substance Drug and/or alcohol use Patient used marijuana once which he believes triggered the
current episode."
Cocaine, marijuana, ETOH,
addiction, narcotic
Other Any example that does not fall
into any of the other seven
domains
Maintain mood stabilization, prevent future episodes of
mania, improve self-monitoring skills."

classification models consider each sentence indepen-
dently and thus we designed the annotation task to mirror
the information available to the models.
The annotators were instructed to label each sentence
with one or more of the seven risk factor domains. In
instances where more than one domain was applicable,
annotators assigned the domains in order of prevalence
within the sentence. An eighth label, Other, was included
if a sentence did not align with any of the seven risk factor
domains. The annotations were then reviewed by a team
of two clinicians who adjudicated collaboratively to create
a gold standard. Basic statistics on the corpus, including
the number of sentences labeled for greater than one risk
factor domain are listed in Table 3. The gold standard
and the clinician-identified keywords and MWEs have
Table 3 Distribution of gold standard sentences and tokens
across risk factor domains
Total Sentences Total Tokens
Appearance 670 11648
Mood 793 17672
Interpersonal 574 11674
Occupation 664 14166
Thought Content 756 18785
Thought Process 663 11203
Substance Use 727 14793
Totals 4847 99941
Sentences With >1 Domain 222 8912
received IRB approval for release to the community. They
are available as supplementary data to this paper.
Inter-Annotator agreement
Inter-annotator agreement (IAA) was assessed using a
combination of Fleisss Kappa (a variant of Scotts Pi that
measures pairwise agreement for annotation tasks involv-
ing more than two annotators) [19] and Cohens Multi-
Kappa as proposed by Davies and Fleiss [20]. Table 4
shows IAA calculations for both overall agreement and
agreement on the first (most important) domain only. Fol-
lowing adjudication, accuracy scores were calculated for
each annotator by evaluating their annotations against the
gold standard.
Overall agreement was generally good and aligned
almost exactly with the IAA on the first domain only.
Out of the 1654 annotated sentences, 671 (41%) had
total agreement across all three annotators. We defined
total agreement for the task as a set-theoretic complete
intersection of domains for a sentence identified by all
annotators.
98% of sentences in total agreement involved one
domain. Only 35 sentences had total disagreement, which
we defined as a set-theoretic null intersection between
Table 4 Inter-annotator agreement
Labels Fleisss Kappa Cohens Multi-Kappa Mean Accuracy
Overall 0.575 0.571 0.746
First Domain Only 0.536 0.528 0.805
Holderness et al. Journal of Biomedical Semantics           (2019) 10:19 Page 5 of 10
the three annotators. An analysis of the 35 sentences with
total disagreement showed that nearly 30% included the
term blunted/restricted. In clinical terminology, these
terms can be used to refer to appearance, affect, mood,
or emotion. Because the sentences being annotated were
extracted from larger clinical narratives and examined
independently of any surrounding context, it was diffi-
cult for the annotators to determine the most appropriate
domain. This lack of contextual information resulted in
each annotator using a different default label: Appear-
ance, Mood, and Other. During adjudication, Other was
decided as the most appropriate label unless the sentence
contained additional content that encompassed other
domains, as it avoids making unnecessary assumptions.
A Fleisss Kappa of 0.575 lies on the boundary between
Moderate and Substantial agreement as proposed by
Landis and Koch [21]. This is a promising indication
that our risk factor domains are adequately defined by
our present guidelines and can be employed by clinicians
involved in similar work at other institutions.
The fourth column in Table 4, Mean Accuracy, was cal-
culated by averaging the three annotator accuracies as
evaluated against the gold standard. This provides us with
an informative baseline of human parity on the domain
classification task.
Topic extraction
Figure 1 illustrates the data pipeline for generating our
training and testing corpora, and applying them to our
classification models.
We use the Universal Sentence Encoder (USE) [22], a
deep averaging neural network that is pretrained on a
very large volume of general-domain web data, to convert
sentences to 512-dimensional embedding vectors, stem-
ming tokens with the Porter Stemmer tool provided by
the NLTK library [23]. USE has the advantage of being
sensitive to word ordering and can encode sequences of
variable lengths, in addition to being integrated directly
into TensorFlow. We have found in previous unpub-
lished observations performed by Holderness, Meteer,
Pustejovsky, and Hall that despite being pretrained on
general-domain web data, USE outperforms other state-
of-the-art embedding models such as ELMo, FastText, or
Doc2Vec.
Starting with the approach taken by McCoy et al. [16],
who used aggregate cosine similarity scores to compute
domain similarity directly from a TF-IDF vector space
model, we extend this method by training a suite of
three-layer multilayer perceptron (MLP) and radial basis
function (RBF) neural networks using a variety of param-
eters to compare performance. We employ the Keras deep
learning library [24] using a TensorFlow backend [25] for
this task. The architectures of our highest performing
MLP and RBF models are summarized in Table 5. Pro-
totype vectors for the nodes in the hidden layer of our
RBF model are selected via k-means clustering [26] on
each domain megadocument individually. The RBF trans-
fer function for each hidden layer node is assigned the
same width, which is based off the maximum Euclidean
distance between the centroids that were computed using
k-means.
To prevent overfitting to the training data, we utilize a
dropout rate [27] of 0.2 on the input layer of all models
and 0.5 on the MLP hidden layer.
Since our classification problem is multiclass, multil-
abel, and open-world, we employ seven nodes with sig-
moid activations in the output layer, one for each risk
factor domain. This allows us to identify sentences that fall
into more than one of the seven domains, as well as deter-
mine sentences that should be classified as Other. Unlike
the traditionally used softmax activation function, which
is ideal for single-label, closed-world classification tasks,
sigmoid nodes output class likelihoods for each node inde-
pendently without the normalization across all classes that
occurs in softmax.
We find that the risk factor domains vary in the degree
of homogeneity of language used, and as such certain
domains produce higher similarity scores, on average,
than others. To account for this, we calculate thresh-
old similarity scores for each domain using the formula
min=avg(sim)+?*? (sim), where ? is standard deviation
and ? is a constant, which we set to 0.5 for our P model
Fig. 1 Data pipeline for training and evaluating our risk factor domain classifiers
Holderness et al. Journal of Biomedical Semantics           (2019) 10:19 Page 6 of 10
Table 5 Architectures of our highest-performing MLP and RBF
networks
Network MLP RBF
Input Layer
Nodes 512 512
Dropout 0.2 0.2
Activation ReLU ReLU
Hidden Layer
Nodes 250 700
Dropout 0.5 0.0
Activation ReLU RBF
Output Layer
Nodes 7 7
Activation Sigmoid Linear
Optimizer Adam Adam
Loss Function Categorical Cross Entropy Mean Squared Error
Training Epochs 60 50
Batch Size 128 128
and 1.25 for our RBF model through trial-and-error.
Employing a generalized formula as opposed to manually
identifying threshold similarity scores for each domain
has the advantage of flexibility in regards to the target
data, which may vary in average similarity scores depend-
ing on its similarity to the training data. If a sentence does
not meet threshold on any domain, it is classified as Other.
Results
Table 6 shows the performance of ourMLP and RBFmod-
els on classifying the sentences in our gold standard. To
assess relative performance of feature representations, we
also include performance metrics of our models without
MWEs. Because this is a multilabel classification task we
compute precision, recall, and F1 scores for each sentence
in the test set usingmacro-averaging, where performances
are calculated for each risk factor domain individually and
then averaged. In identifying the seven risk factor domains
individually, our models achieved the highest per-domain
scores on Substance (F1 ? 0.9) and the lowest score on
Mood (F1 ? 0.75).
Despite prior research indicating that similar classifica-
tion tasks to ours are more effectively performed by RBF
networks [2830], we find that our MLP model performs
marginally better with significantly less computational
complexity (i.e. k-means and width calculations). Figure 2
illustrates the distribution of sentences in vector space
using 2-component Linear Discriminant Analysis (LDA)
[31], and shows that Thought Process, Appearance, Sub-
stance, and  to a certain extent  Occupation clearly
occupy specific regions, whereas Interpersonal, Mood,
Table 6 Overall and domain-specific Precision, Recall, and F1
scores for our models
Precision Recall F1
Aggregate Cosine Similarity Scores 0.626 0.692 0.657
MLP Baseline (No MWEs) 0.816 0.830 0.823
RBF Baseline (No MWEs) 0.795 0.808 0.801
MLP (w/ MWEs) 0.821 0.835 0.828
Appearance 0.953 0.825 0.884
Interpersonal 0.843 0.897 0.869
Mood 0.723 0.816 0.767
Occupation 0.945 0.834 0.886
Substance 0.898 0.946 0.921
Thought Content 0.830 0.685 0.751
Thought Process 0.792 0.878 0.833
Other 0.509 0.614 0.557
RBF (w/ MWEs) 0.814 0.799 0.806
Appearance 0.952 0.803 0.871
Interpersonal 0.929 0.882 0.905
Mood 0.748 0.759 0.754
Occupation 0.956 0.847 0.898
Substance 0.826 0.927 0.874
Thought Content 0.866 0.685 0.765
Thought Process 0.958 0.818 0.883
Other 0.405 0.411 0.408
and Thought Content occupy the same noisy region where
multiple domains overlap. In RBF networks, the magni-
tude of activation for a given hidden layer neuron is based
on the Euclidean distance from the input vector to the
prototype centroid associated with that neuron. Smaller
distances lead to more robust activations. To identify
these prototype centroids, we apply the k-Means cluster-
ing algorithm to identify the training examples for each
class that most closely describe the distribution of the
examples in vector space. With large training sets such as
ours, the RBF prototype centroids will be more precise
and therefore the RBF model is more powerful in differ-
entiating between classes in crowded regions of vector
space. This is reflected by the results in Table 6, where
the RBF network performs as well as or stronger than the
MLP network in the four overlapping domains (0.905 vs
0.869 for Interpersonal, 0.754 vs 0.767 for Mood, 0.898
vs 0.886 for Occupation, and 0.765 vs 0.751 for Thought
Content) whereas the MLP network  with the exception
of Thought Process  performs as well as or stronger than
the RBF network when predicting the non-overlapping
domains (0.874 vs 0.921 for Substance, 0.871 vs 0.884
for Appearance, and 0.883 vs 0.833 for Thought Process).
We also observe a similarity in the words and phrases
Holderness et al. Journal of Biomedical Semantics           (2019) 10:19 Page 7 of 10
Fig. 2 2-component linear discriminant analysis of the RPDR training data
with the highest Term Frequency  TF-IDF scores across
the overlapping domains: many of the Thought Content
words and phrases with the highest TF-IDF scores involve
interpersonal relations (e.g. fear surrounding daughter,
father, family history, familial conflict) and there is a
high degree of similarity between high-scoring words for
Mood (e.g. meets anxiety criteria, cope with mania, ocd)
and Thought Content (e.g. mania, feels anxious, feels
exhausted). Please refer to the Methods section of this
paper for more information on our TF-IDF analysis and
its implications in building our training corpus.
The most significant discrepancy in model perfor-
mances is in classifying sentences that do not involve any
of the seven risk factor domains. While both are fairly
inaccurate at identifying these Other sentences, ourMLP
model has a markedly higher F-score (0.557) compared to
our RBF model (0.408).
Discussion
Results clearly indicate that our MLP and RBF deep
learning models outperform the cosine similarity base-
line. Additionally, our models are more scalable and
computationally efficient to handle large volumes of data.
In our initial work on risk factor domain topic extrac-
tion with a training data set of only 100,000 sentences,
we found performance to increase by 15% when factor-
ing in MWEs, a marked improvement over our models
that did not incorporate them. However, with our cur-
rent training data set of 2,100,000 sentences, factoring
MWEs into our models increased classification perfor-
mance by only 1% uniformly across all risk factor domains,
both overlapping and non-overlapping. This aligns with
our expectations that MWEs comprised of a quotidian
vocabulary hold more clinical significance than when
the words in the expressions are treated independently
but that as the amount of training data increases, these
MWEs are captured organically. Even with the larger vol-
ume of training data, the clinician-identified keywords
and MWEs continue to play an important role when gen-
erating the training data set, as training sentences are
identified by regular expression pattern matching of these
keywords and MWEs. Therefore, including MWEs at this
step increases the scope and variety of training sentences,
leading to more robust downstream performance.
Holderness et al. Journal of Biomedical Semantics           (2019) 10:19 Page 8 of 10
The wide variance in per-domain performance is due
to a number of factors. Most notably, the training sen-
tences we extracted from RPDR  while very comparable
in structure and style to our target OnTrackTM data 
may not have an adequate variety of content and range of
vocabulary. Although using keyword and MWE matching
to create our training corpus has the advantage of being
significantly less labor intensive than manually labeling
every sentence in the corpus, it is likely that the homo-
geneity of language used in the training sentences is higher
than it would be otherwise. Additionally, all of the sen-
tences in the training data are assigned exactly one risk
factor domain even if they actually involve multiple risk
factor domains, making the clustering behavior of the
sentences more difficult to define.
Threshold similarity scores also play a large role in
determining the precision and recall of ourmodels: setting
higher classification thresholds leads to a smaller number
of false positives and a greater number of false negatives
for each risk factor domain. Conversely, more sentences
are incorrectly associated with one or more risk factor
domains when thresholds are set lower. Since our classi-
fier will be used in future work as an early step in a data
analysis pipeline for determining readmission risk, mis-
classifying a sentence with an incorrect risk factor domain
at this stage can lead to greater inaccuracies at later stages.
Sentences misclassified as Other, however, will be dis-
carded from the data pipeline. Therefore, we intentionally
set a conservative threshold where only the most confi-
dently labeled sentences are assigned membership in a
particular domain. In addition to the challenges associ-
ated with fine-tuning threshold similarity scores, Other as
a domain is much broader in scope than the seven risk fac-
tor domains, encompassingmost of the space surrounding
the clusters in Fig. 2. Because the function describing this
space is more complex than the functions delineating the
regions of vector space occupied by the specific risk fac-
tor domains, model accuracy is predictably lower when
classifying these out-of-domain examples.
The IAA that we report on our annotation task falls in
the upper end of Moderate agreement and is only 0.03
away from being considered Substantial agreement as
proposed by Landis and Koch [21]. From a clinical psy-
chiatric perspective, it is in fact satisfactory and the first
of its kind in the psychosis clinical NLP literature. As
described in the Background Section, dealing with clinical
narratives in psychotic EHRs are challenging for a num-
ber of reasons. Also, our annotation task is multiclass,
multilabel, and open-world (i.e., 7 risk factor domains
plus other for sentences that are not relevant to those
domains), making high IAA very difficult to achieve. The
degree of difficulties specific to each domain also affect
the overall IAA. Some domains such as Substance pro-
duced high IAA because it is easy for annotators to agree
on sentences involving substance (e.g., cocaine, cannabis).
Whereas other domains with a larger vocabulary over-
lap, such as Mood, Thought Content, and Interpersonal
are more challenging (see Fig. 2). For example, Pt is a 32
year old single Caucasian male with a history of Schizoaf-
fective Disorder, two prior psychiatric hospitalizations,
with increasing disorganized thought process, paranoia,
and command auditory hallucinations in the context of
discontinuing his psychiatric medications was annotated
to be Thought Process & Thought Content by two
annotators and Appearance & Thought Content &
Thought Process by the third annotator, resulting in
partial agreement among annotators. For each sentence,
the gold standard was created by a majority agreement
among annotators when two or more annotators were in
total agreement. For the remaining sentences, high qual-
ity, domain-expert adjudications were made by a team of
two clinicians who worked collaboratively. Therefore, we
believe that the resulting corpus can be used as a gold
standard.
In terms of computational complexity, our MLP model
significantly outperforms our RBF model during training
and outperforms both the RBF model and the cosine sim-
ilarity baseline at evaluation. Whereas our MLP model
trains in O(n) time, requiring only one pass through each
datapoint for each epoch of training, our RBF model
trains in O(nw) time, where w is equivalent to the num-
ber of prototype centroids in the hidden layer, as each
training example is evaluated against each prototype cen-
troid in the network. In addition, the k-Means clustering
that must be performed before training the RBF network
to identify the prototype centroids runs in O(n) time.
Although the cosine similarity baseline model does not
have a training phase, it runs in O(n2) at evaluation since
the distance between each element in the test corpus and
each element in the training corpus must be computed.
Although both the RBP and MLP models performed
roughly equivalently, the MLP is a simpler model and is
faster to train and evaluate compared to an RBF network.
Given the intention of implementing this model in a larger
clinical NLP pipeline, the lower latency MLP model is
preferred.
Conclusions
To achieve our goal of creating a framework for a readmis-
sion risk classifier, the present study performed necessary
evaluation steps by updating and adding to our model
iteratively. In the first stage of the project, we focused
on collecting the data necessary for training and testing,
and on the domain classification annotation task. At the
same time, we began creating the tools necessary for auto-
matically extracting domain relevance scores at the sen-
tence and document level from patient EHRs using sev-
eral forms of vectorization and topic modeling. In future
Holderness et al. Journal of Biomedical Semantics           (2019) 10:19 Page 9 of 10
versions of our risk factor domain classification model
we will explore increasing robustness through sequence
modeling that considers more contextual information.
Our current feature set for training a machine learn-
ing classifier is relatively small, consisting of sentence
domain scores, bag-of-words, length of stay, and number
of previous admissions, but we intend to factor in many
additional features that extend beyond the scope of the
present study. These include a deeper analysis of clini-
cal narratives in EHRs: in a different line of development,
we have extended our EHR data pipeline by distinguish-
ing between clinically positive and negative phenomena
within each risk factor domain [32]. This involved a
series of annotation tasks that allowed us to generate
lexicon-based and corpus-based sentiment analysis tools.
In future work, we intend to use these clinical sentiment
scores to generate gradients of patient improvement or
deterioration over time with respect to each of the seven
risk factor domains for readmission.
We will also take into account structured data that
have been collected on the target cohort throughout the
course of this study such as brain based electrophysiologi-
cal (EEG) biomarkers, structural brain anatomy fromMRI
scans, social and role functioning assessments, personal-
ity assessments (NEO-FFI), and various symptom scales
(PANSS, MADRS, YMRS). For each feature we consider
adding, we will evaluate the performance of the classifier
with and without the feature to determine its contribution
as a predictor of readmission.
Abbreviations
Adam: Adaptive Moment Estimation [33]; EHR: Electronic Health Record; ETOH:
Ethyl alcohol and ethanol; HI: Homicidal ideation; IAA: Inter-Annotator
Agreement; MADRS: Montgomery-Asperg Depression Rating Scale [34]; MLP:
Multi-Layer Perceptron; MWE: Multi Word Expression; NEO-FFI: NEO
Five-Factor Inventory [35]; NLTK: Natural Language Toolkit; OCD:
Obsessive-compulsive disorder; PANSS: Positive and Negative Syndrome Scale
[36]; RBF: Radial Basis Function; ReLU: Rectified Linear Units, f (x) = max(0, x)
[37]; RPDR: Research Patient Data Registry; SI: Suicidal ideation; TF-IDF: Term
Frequency  Inverse Document Frequency; USE: Universal Sentence Encoder
YMRS: Young Mania Rating Scale [38]
Acknowledgments
Not applicable.
Authors contributions
EH and Nicholas Miller and M-HH prepared this manuscript and wrote the
code for data extraction, model training, and algorithm evaluation. KB and PC
annotated the sentences in our test corpus. MM and JP consulted on
methodologies in computational linguistic analysis of the data. M-HH worked
on all aspects of the project, is the principal investigator of this project, and is
director of the Psychosis Neurobiology Laboratory at McLean Hospital, where
this research was undertaken. All authors read and approved the final
manuscript.
Funding
This work was supported by a grant from the National Institute of Mental
Health (grant no. 5R01MH109687 to Mei-Hua Hall).
Availability of data andmaterial
All data generated or analyzed during this study are included in this published
article and its Additional files.
Ethics approval and consent to participate
Not applicable.
Consent for publication
Not applicable.
Competing interests
The authors declare that they have no competing interests.
Author details
1Psychosis Neurobiology Laboratory, McLean Hospital, Harvard Medical
School, Mill St, Belmont, MA, USA. 2Brandeis University Department of
Computer Science, South St, Waltham, MA, USA.
Received: 1 May 2019 Accepted: 9 September 2019
DATABASE Open Access
Comprehensive anatomic ontologies for
lung development: A comparison of
alveolar formation and maturation within
mouse and human lung
Huaqin Pan1, Gail H. Deutsch2, Susan E. Wert3* , On behalf of the Ontology Subcommittee and NHLBI
Molecular Atlas of Lung Development Program Consortium
Abstract
Background: Although the mouse is widely used to model human lung development, function, and disease, our
understanding of the molecular mechanisms involved in alveolarization of the peripheral lung is incomplete.
Recently, the Molecular Atlas of Lung Development Program (LungMAP) was funded by the National Heart, Lung,
and Blood Institute to develop an integrated open access database (known as BREATH) to characterize the
molecular and cellular anatomy of the developing lung. To support this effort, we designed detailed anatomic and
cellular ontologies describing alveolar formation and maturation in both mouse and human lung.
Description: While the general anatomic organization of the lung is similar for these two species, there are
significant variations in the lungs architectural organization, distribution of connective tissue, and cellular
composition along the respiratory tract. Anatomic ontologies for both species were constructed as partonomic
hierarchies and organized along the lungs proximal-distal axis into respiratory, vascular, neural, and immunologic
components. Terms for developmental and adult lung structures, tissues, and cells were included, providing
comprehensive ontologies for application at varying levels of resolution. Using established scientific resources,
multiple rounds of comparison were performed to identify common, analogous, and unique terms that describe
the lungs of these two species. Existing biological and biomedical ontologies were examined and cross-referenced
to facilitate integration at a later time, while additional terms were drawn from the scientific literature as needed.
This comparative approach eliminated redundancy and inconsistent terminology, enabling us to differentiate true
anatomic variations between mouse and human lungs. As a result, approximately 300 terms for fetal and postnatal
lung structures, tissues, and cells were identified for each species.
(Continued on next page)
© The Author(s). 2019 Open Access This article is distributed under the terms of the Creative Commons Attribution 4.0
International License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and
reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to
the Creative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver
(http://creativecommons.org/publicdomain/zero/1.0/) applies to the data made available in this article, unless otherwise stated.
* Correspondence: susan.wert@cchmc.org
Huaqin Pan, Gail H. Deutsch and Susan E. Wert contributed equally to this
work.
3Department of Pediatrics, Perinatal Institute, Section of Neonatology,
Perinatal and Pulmonary Biology, Cincinnati Childrens Hospital Medical
Center/Research Foundation, University of Cincinnati College of Medicine,
3333 Burnet Ave, MLC7029, Cincinnati, OH 45229, USA
Full list of author information is available at the end of the article
Pan et al. Journal of Biomedical Semantics           (2019) 10:18 
https://doi.org/10.1186/s13326-019-0209-1
(Continued from previous page)
Conclusion: These ontologies standardize and expand current terminology for fetal and adult lungs, providing a
qualitative framework for data annotation, retrieval, and integration across a wide variety of datasets in the BREATH
database. To our knowledge, these are the first ontologies designed to include terminology specific for
developmental structures in the lung, as well as to compare common anatomic features and variations between
mouse and human lungs. These ontologies provide a unique resource for the LungMAP, as well as for the broader
scientific community.
Keywords: Alveolarization, Biomedical ontology, Data annotation, Database, Lung-specific cell types, Molecular
anatomy, LungMAP, OWL, Single-cell analysis, Web-based atlas,
Background
Ontologies are formal representations of knowledge used
to handle big data sets and information retrieval. Ontol-
ogies consist of standardized vocabularies of terms for
individual entities (or objects) that are associated with a
specific domain or field of knowledge. Anatomy ontol-
ogies are designed to capture biological concepts and de-
scriptions in a way that can be easily categorized and
analyzed with computer technology. The most visible
biological application today is the Gene Ontology project
[1], which provides a controlled vocabulary for cross-
species comparisons of genes and gene products that are
associated with biological processes, molecular func-
tions, and cellular components. In recent years, ontol-
ogies have become indispensable tools for various
molecular anatomy and atlas projects, including GUD-
MAP, molecular anatomy of genitourinary tract develop-
ment in the mouse [2, 3]; Brain Maps 4.0, neuroanatomy
of the rat brain [4]; Xenbase, Xenopus anatomy and de-
velopment [5]; and FaceBase, craniofacial anatomy, de-
velopment and malformations in a variety of species [6].
Ontologies also extend our ability to access prior know-
ledge from other model organisms, using cross-
referenced linkages to existing ontologies or databases.
Together, these ontologies provide innovative tools for
knowledge representation and modeling of biologic and
developmental relationships, as well as cellular and mo-
lecular processes.
While extensive research has been published on the
molecular regulation of early lung formation and
branching morphogenesis of the conducting airways
(reviewed in [710]), less is known about the molecular
mechanisms regulating expansion and maturation of the
alveolar parenchyma during the later stages of lung de-
velopment (reviewed in [1116]). This period of lung de-
velopment is critical for the formation of the distal gas-
exchange region of the lung, which is marked by the
generation of millions of highly vascularized alveoli that
are the lungs primary gas-exchange units (reviewed in
[17, 18]). This process, termed alveolarization (or alveo-
logenesis), increases the surface area and diffusion cap-
acity of the lung, which are required for efficient
exchange of oxygen and carbon dioxide after birth. Dis-
ruption of this process has significant clinical relevance
for managing neonatal lung disease related to prematur-
ity, neonatal respiratory distress, and abnormal lung
growth [1921].
The mouse is an important animal model for investi-
gating human lung development, function, and disease
[2226]. Although there are many anatomic, histologic,
and developmental similarities between these two spe-
cies, significant variations exist in the architectural
organization, connective tissue elements, and cellular
composition of their lungs [2729]. Lung development
in both species proceeds in an orderly fashion in re-
sponse to molecular mechanisms that control the initial
formation and subsequent proliferation, differentiation,
growth and maturation of the lung (reviewed [710]).
Development of the lung is divided into several stages
that extend throughout the fetal and postnatal periods of
life [17, 30]. These stages include the embryonic, pseudo-
glandular, canalicular, saccular, and alveolar stages,
which describe the histologic changes observed during
development of the lung [17, 3035]. Vascular matur-
ation of the alveolar capillary bed in both species takes
place during the last stage of lung development and is
coincident with alveolar septation [17, 3638]. Although
lung development is similar in all mammalian species,
the relative timing and/or length of each developmental
stage varies from one species to another [17, 39, 40].
While maturation of the peripheral alveoli is initiated
prior to birth in the human lung [30, 34, 41, 42],
similar histological changes in the mouse do not
begin until after birth [17, 43]. In both species, on-
going formation of additional alveoli continues into
young adulthood [36, 37, 41, 43, 44].
Recently, a cooperative research project, the Molecular
Atlas of Lung Development Program (LungMAP), was
initiated by the National Heart, Lung, and Blood Insti-
tute to characterize and compare the molecular anatomy
of mouse and human lungs, focusing on the later stages
of lung development and maturation [45, 46]. LungMAP
is a consortium composed of four research centers, a
mouse hub, a human tissue repository, a central
Pan et al. Journal of Biomedical Semantics           (2019) 10:18 Page 2 of 21
database termed Bioinformatics REsource ATlas for the
Healthy lung (BREATH), and a data-coordinating center
with a public web site (www.lungmap.net) [45, 46]. The
BREATH database is an integrated open-access database
that contains multiple datasets generated by a variety of
analytical approaches to detect temporal-spatial changes
in the developing lung. These include changes in 1)
mRNA and microRNA expression, using microarrays
and mRNA sequencing; 2) epigenetic control of gene ex-
pression, based on DNA methylation patterns; 3)
protein, lipid and metabolite expression, using mass
spectrometry imaging; 4) protein and mRNA expression,
using high-resolution immunofluorescence confocal mi-
croscopy and high-throughput in situ hybridization; and
5) structural features, using three-dimensional (3-D) im-
aging [4751]. Annotation and retrieval of information
from these diverse datasets require a standardized vo-
cabulary to integrate the molecular data with anatomic,
histologic, and cellular imaging, in order to identify
functionally and/or anatomically defined cell types in the
developing lung.
To support this effort, we developed a comprehensive,
high-resolution ontology, incorporating terms for well-
defined anatomic structures, tissues, and cells found in
the late fetal and postnatal mouse lung. Likewise, a de-
tailed anatomic ontology for the late fetal and postnatal
human lung was constructed and then harmonized with
the mouse ontology in order to compare normal devel-
opmental processes between the two species. To our
knowledge, this is the first ontology to include termin-
ology specific for developmental structures in the mouse
and human lung, including pulmonary, vascular, neural
and immunologic components critical for lung function.
It is also the first time that specific cell types have been
incorporated into an anatomic ontology for the lung.
Content and construction
Methods
The abstract version of these anatomic ontologies was
constructed using Protégé1 version 5.0.0 [52, 53]
(https://protege.stanford.edu/about.php) and Web
Ontology Language (OWL 2). This approach supports
integration with other biological and biomedical ontol-
ogies. Scientific content was informed by review of the
published literature (peer-reviewed research, reviews,
textbooks, atlases, and medical dictionaries), by the au-
thors expertise in lung development, anatomy, histo-
pathology, and cell biology, and by annotation
requirements for the BREATH database. Terminology
and definitions already in use were adopted from exist-
ing ontologies, including the Mouse Gross Anatomy and
Development Ontology (EMAP) [54] (https://bioportal.
bioontology.org/ontologies/EMAP); the Mouse Adult
Gross Anatomy Ontology (MA) [55, 56] (http://
bioportal.bioontology.org/ontologies/MA); the Founda-
tional Model of Anatomy (FMA) [57] (http://bioportal.
bioontology.org/ontologies/FMA); the Uber Anatomy
Ontology (UBERON) [58] (http://bioportal.bioontology.
org/ontologies/UBERON); and the Cell Ontology (CL)
[59, 60] (http://bioportal.bioontology.org/ontologies/CL).
Additional resources for terms and definitions included
the National Cancer Institute Thesaurus (NCIT)
(https://ncit.nci.nih.gov/ncitbrowser/) and National
Institute of Health (NIH) Medical Subject Headings
(MeSH) (https://www.nlm.nih.gov/mesh/). Definitions
derived from existing ontologies and resources were
often modified to reflect lung-specific knowledge and ex-
pertise. Synonyms commonly used in the literature and
in other ontologies were included to improve query
searching. Where additional terms were required (i.e.,
terms that could not be drawn from existing ontologies),
the published literature was reviewed for the most
widely accepted terms, synonyms, and definitions. Mul-
tiple revisions were performed to refine both existing
and newly introduced terms, as well as term definitions
and synonyms. Construction of these ontologies is open-
ended, so that additional anatomic terms and newly
defined or molecularly distinct cell types can be incorpo-
rated as needed for annotation and linkage at a later
date.
Design of the ontology framework for the mouse lung
A review of existing anatomic ontologies for the mouse,
including UBERON, MA and EMAP, demonstrated that
these ontologies had limited coverage of the fetal and
postnatal mouse lung, especially for the later stages of
lung development when alveolar growth, vascularization,
septation, and maturation are initiated. In addition, devel-
opmental staging, specific terminology, and definitions for
fetal lung structures and cells were often lacking in these
established ontologies. As a result, we decided initially to
organize the anatomic ontology for the mouse lung into
four separate developmental time periods, or age_range(s)
(Fig. 1), beginning with the canalicular stage, embryonic
day (E) 16.5-E17.5, and ending with the alveolar stage,
postnatal day (P) 436, of lung development. Since the
intervening saccular stage (E17.5-P3) of lung development
spans the perinatal period in the mouse, this stage is sub-
divided into two age_range(s), i.e., a prenatal (or early)
saccular stage (E17.5-E19.5) and a postnatal (or late) sac-
cular stage (P0-P3) (Fig. 1). During these periods, terms
associated with the formation and maturation of the al-
veolar parenchyma differ as this region evolves over time
(enclosed boxes, Fig. 1).
Within each age_range, anatomic structures, tissues,
and cells were organized into six major classes: trachea,
bronchi, lung, vascular structures (including the pul-
monary, bronchial, and lymphatic circulations), the
Pan et al. Journal of Biomedical Semantics           (2019) 10:18 Page 3 of 21
autonomic nervous system, and the immune system (see
https://www.lungmap.net/breath-ontology-browser/). As
a rule, fetal lung development proceeds both spatially
and temporally along the proximal-distal axis of the
lung, so that formation, growth and differentiation of the
proximal conducting airways, vasculature and nerves
precede that of the distal alveolar parenchyma [6166].
Therefore, each system was organized along the
proximal-distal axis of the lung with increasing levels of
granularity, i.e., from larger, lower resolution, extra-
pulmonary structures (trachea, bronchi and pulmonary
vessels) to smaller, higher resolution, intra-pulmonary
structures (bronchioles, alveoli and alveolar capillaries),
tissues, and cells. Microvascular structures of the
alveolar-capillary bed were integrated into the alveolar
parenchyma of the lung, since close apposition of the
alveolar epithelium and adjacent capillary endothelium
is critical for gas-exchange.
Considering the lung has over 40 different cell types
that have been classified primarily by location, histology,
function, and ultrastructural features [6771], we inte-
grated both general (e.g., epithelial, endothelial, intersti-
tial cells) and specific (e.g., basal, ciliated, mucous,
alveolar type II cells) cell types into the anatomic ontol-
ogy. Recently, the availability of cell-specific markers,
such as antibodies to transcription factors, intracellular
proteins, and cell surface markers [7], has augmented
our ability to detect and isolate lung-specific cell types
and subpopulations, while advances in single-cell tech-
nology have identified molecularly distinct cells previ-
ously classified together as a single, specific, cell type
[51, 7275]. In order to improve data linkage and
Fig. 1 Terms associated with prenatal and postnatal development of the alveolar parenchyma organized by age_range. Development of the
alveolar parenchyma is organized into 4 developmental stages, or age_range(s), each with unique terminology for pre- and post-natal alveolar
structures. These age_range(s) are E16.6-E17.5 (canalicular stage); E18.5-E19.5/birth (saccular stage, prenatal period); P0-P3 (saccular stage, postnatal
period); P4-P36 (alveolar stage). Terms for the alveolar parenchyma (enclosed in boxes) differ with developmental stage as these structures evolve
over time
Pan et al. Journal of Biomedical Semantics           (2019) 10:18 Page 4 of 21
website queries based on single-cell data, a class termed
isolated lung cell types was created for experimental cell
types, i.e., newly defined cell types identified by single-
cell RNA sequencing (scRNA-seq) analysis of isolated
cells. The inclusion of general, specific, and isolated cell
types is a major feature of this ontology that is not com-
monly found in many traditional anatomic and histo-
logic ontologies.
Construction of the mouse lung ontology
The anatomic ontology for the mouse lung is con-
structed as a partonomic (X is a part of Y, or part_
of) hierarchy with separate trees for the different de-
velopmental stages or corresponding age_range(s) [3,
55, 76]. Age_range is an annotation property that is
assigned to each term in the ontology. Each age_range
is subdivided into separate respiratory, vascular,
neural, and immunologic components that are orga-
nized along the proximal-distal axis of the lung. Each
organ system, in turn, is populated with terms for
well-characterized fetal, postnatal, and adult anatomic
structures, distinct tissue compartments, and specific
cell types. General and specific cell types incorporated
into the anatomic ontology are also organized into a
separate cell ontology, which is constructed using the
is_a (subtype) relation. Within each age_range, cell
types are listed alphabetically by class (major general
cell types) and then by subclass (specific cell types)
(Fig. 2). This strategy provides a comprehensive ana-
tomic ontology that can be used at varying levels of
resolution, i.e., with whole mounts, sectioned material
or isolated tissues and cells.
This ontology for the mouse contains 283 terms, in-
cluding 167 for anatomic structures, 48 for tissues, and
68 for cells, which are distributed by developmental age
and organ system (Table 1). It is displayed in the Lung-
MAPs website browser as a tree structure that can be
expanded and collapsed as desired (see https://www.
lungmap.net/breath-ontology-browser/). Access to term
details is achieved by selecting or highlighting any term
Fig. 2 Cell ontology. General and specific cell types are organized into a separate tree of the ontology by developmental age (age_range) and
then alphabetically. a There are 13 general cell classes for the mouse at P0-P3. The general cell type, epithelial cell, has four major subclasses:
alveolar, bronchial, bronchiolar, and tracheal epithelial cells. b Each of these subclasses can be expanded into specific cell types, illustrating their
distribution in the conducting airway and alveoli. A subclass termed isolated lung cell types was created for experimental cell types/subtypes
identified by scRNA seq analysis
Pan et al. Journal of Biomedical Semantics           (2019) 10:18 Page 5 of 21
in the browser. This brings up the term detail box,
which displays a unique identifier (i.e., a LungMAP
Mouse Anatomy ID: LMMA_00XXX), a name (term or
label), synonyms, and a definition for each individual en-
tity (or object) (Fig. 3). This information, along with an-
notation properties and relations, are then incorporated
into the formal ontology (Additional file 1). Annotation
properties, i.e., specific attributes, features, characteris-
tics or values that are associated with each individual ob-
ject, are displayed in Table 2. The annotation property,
evidence, was created to indicate terms that are either 1)
well-established published terms or 2) experimental
terms based on gene expression profiles generated by
mRNA analysis of isolated cells or by scRNA-seq data.
The special annotation property of display_order en-
abled proximal-distal organization of anatomic struc-
tures and tissues. Relations, or attributes describing how
a class or an individual object relates to other classes
and/or objects in the ontology [77], are displayed in
Table 3. Although the primary relation used to construct
this ontology is part_of, five additional relations are in-
cluded to enrich the terms in the ontology. These in-
cluded both spatial (adjacent_to, continuous_with,
branching_part_of) and developmental (develops_from)
relations, whose inclusion is designed to empower web-
based queries related to complex molecular and cellular
interactions.
Existing terms from relevant ontologies were adopted
where applicable. Terms were classified as existing if they
could be mapped to current ontologies and/or to add-
itional vocabularies (e.g., NCIT or NIH MeSH) found in
the National Center of Biomedical Ontology (NCBO) Bio-
portal (https://www.bioontology.org) [78, 79]. In general,
terms drawn from other ontologies describe well-known
anatomic structures, tissues and cells, but rarely include a
complete description of lung-specific tissues and cells.
Where additional terms were required, the scientific litera-
ture was reviewed for the most widely accepted terms,
synonyms, and definitions. Additional terms most often
included tissue structures and cells specific for the lung,
such as alveolar lumen, alveolar capillary bed, and lipofi-
broblast, or for lung-specific developmental structures and
cells, such as acinar tubule, alveolar septal crest, and im-
mature club cell. Many of these developmental terms have
been used for years in the literature to describe the hist-
ology of the developing lung [30, 34] and were incorpo-
rated into the ontologies, where possible, due to their long
and extensive use in the literature. As a result, there are
159 (56%) terms cross-referenced to existing ontologies
and 124 (44%) additional terms drawn from the literature
for the mouse anatomic ontology (Table 4). This repre-
sents a significant expansion of current anatomic ontol-
ogies for the developing and adult mouse lung.
Development of the human lung ontology
As for the mouse, review of existing human anatomic
and developmental ontologies, such as FMA, UBERON,
and the Human Developmental Anatomy Ontology
(http://bioportal.bioontology.org/ontologies/EHDAA2)
[80], revealed limited coverage of fetal and postnatal hu-
man lung structures, especially those associated with the
late stages of lung development when alveolar growth,
vascularization, septation and maturation are initiated.
In the mouse, the alveolar stage of lung development be-
gins postnatally around P4 and is complete by P36 [32,
36]. In contrast, this stage of human lung development
begins prior to birth, at approximately 36 weeks of gesta-
tional age (GA), and continues after birth into the first
few years of life [41]. The human lung ontology was pat-
terned initially on the alveolar stage of mouse lung de-
velopment and then revised to reflect the unique
differences in architectural organization, anatomic struc-
tures, tissue components, and cellular composition be-
tween the two species. Commonly used synonyms were
included to improve harmonization search capabilities
across the two species. As was done for the mouse, gen-
eral and specific cell types were incorporated in to the
anatomic ontology, and an additional cell ontology was
constructed in which the cells were listed alphabetically
by class (major general cell type) and then by subclass
(specific cell type) using the primary relation, is_a. An-
notation properties (Table 2) and class relations (Table
3) were harmonized with those developed for the mouse
lung ontology.
Table 1 Distribution of terms for the mouse lung by anatomy,
organ system, and developmental stage
Category Number of terms
Domain
Anatomy 167
Tissue 48
Cell 68
Organ system
Trachea 40
Bronchus 44
Lung 94
Vascular system 74
Autonomic nervous system 20
Immune system 41
Developmental stage (age_range)a
Canalicular Stage (E16.5-E17.5) 231
Prenatal (early-mid) Saccular Stage (E17.5-E19.5) 229
Postnatal (mid-late) Saccular Stage (P0-P03) 253
Alveolar Stage (P04-P36) 262
a, includes terms for all organ systems at each developmental stage
Pan et al. Journal of Biomedical Semantics           (2019) 10:18 Page 6 of 21
Comparison of mouse and human lung anatomy
Although the general anatomic organization of the ma-
ture human and mouse lung is similar, there are signifi-
cant variations in the gross architecture, as well as in the
distribution of connective tissue elements and in cellular
composition along the airways (Additional file 2). These
variations are due primarily to differences in size be-
tween the two species and partly to differences in the
Fig. 3 Term Details. Access to the Term Details box is achieved by selecting, or highlighting, any term in the Ontology Browser. The Term Details
box contains the name of the term, a unique identifier (LungMAP ID), age range, Theiler stage, developmental stage, synonyms (if applicable),
definition, developmental relationships (if known), evidence (experimental or published term), and ontology path, known database cross
RESEARCH Open Access
Finding relevant free-text radiology reports
at scale with IBM Watson Content Analytics:
a feasibility study in the UK NHS
Alicja Piotrkowicz1,2*, Owen Johnson3,4 and Geoff Hall2,4
From UK Healthcare Text Analysis Conference (HealTAC 2018)
Manchester, UK. 18-19 April 2018
Abstract
Background: Significant amounts of health data are stored as free-text within clinical reports, letters, discharge
summaries and notes. Busy clinicians have limited time to read such large amounts of free-text and are at risk of
information overload and consequently missing information vital to patient care. Automatically identifying relevant
information at the point of care has the potential to reduce these risks but represents a considerable research
challenge. One software solution that has been proposed in industry is the IBM Watson analytics suite which
includes rule-based analytics capable of processing large document collections at scale.
Results: In this paper we present an overview of IBM Watson Content Analytics and a feasibility study using
Content Analytics with a large-scale corpus of clinical free-text reports within a UK National Health Service (NHS)
context. We created dictionaries and rules for identifying positive incidence of hydronephrosis and brain metastasis
from 5.6 m radiology reports and were able to achieve 94% precision, 95% recall and 89% precision, 94% recall
respectively on a sample of manually annotated reports. With minor changes for US English we applied the same
rule set to an open access corpus of 0.5 m radiology reports from a US hospital and achieved 93% precision, 94%
recall and 84% precision, 88% recall respectively.
Conclusions: We were able to implement IBM Watson within a UK NHS context and demonstrate effective results
that could provide clinicians with an automatic safety net which highlights clinically important information within
free-text documents. Our results suggest that currently available technologies such as IBM Watson Content
Analytics already have the potential to address information overload and improve clinical safety and that solutions
developed in one hospital and country may be transportable to different hospitals and countries. Our study was
limited to exploring technical aspects of the feasibility of one industry solution and we recognise that healthcare
text analytics research is a fast-moving field. That said, we believe our study suggests that text analytics is
sufficiently advanced to be implemented within industry solutions that can improve clinical safety.
Keywords: Information retrieval, Natural language processing, Radiology, Feasibility study, Rule-based system
© The Author(s). 2019 Open Access This article is distributed under the terms of the Creative Commons Attribution 4.0
International License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and
reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to
the Creative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver
(http://creativecommons.org/publicdomain/zero/1.0/) applies to the data made available in this article, unless otherwise stated.
* Correspondence: A.Piotrkowicz@leeds.ac.uk
1Leeds Institute of Medical Education, University of Leeds, Leeds, UK
2Leeds Teaching Hospitals Trust, Leeds, UK
Full list of author information is available at the end of the article
Piotrkowicz et al. Journal of Biomedical Semantics 2019, 10(Suppl 1):21
https://doi.org/10.1186/s13326-019-0213-5
Background
A wealth of healthcare data is stored in unstructured free-
text reports [1]. These include narrative reports from diag-
nostic services such as radiology and pathology, consultants
letters, discharge summaries and clinical notes. For example,
Capurro et al. [2] found that in two US health IT systems
only about 25% of the data required to phenotype patients
was available in a structured and easily extractable format.
Clinicians, researchers, and administrators often need to re-
trieve and read these clinical reports to understand the de-
tails of patient care. For busy clinicians with limited time the
requirement to read large amounts of free-text presents a
risk of information overload and consequently missing infor-
mation vital to the care of their patients. In the past such
documents were often handwritten and stored on paper but
in parallel with advances in electronic health records (EHR)
many of these free text documents are now generated digit-
ally and stored within, or linked to, the EHR [1].
Automatically identifying critical information at the point
of care has the potential to reduce the clinical risks associ-
ated with missing this information but also represents a
considerable challenge [3]. The current range of commer-
cially available tools such as IBM Watson claim to offer
support that will improve clinical outcomes through more
efficient and accurate document search and text analytics.
More generally, there has been considerable research effort
to create systems which can reliably identify and extract
relevant information from clinical text. Implementing such
systems at scale in a clinical environment is difficult. As we
see it, the challenge is twofold. Firstly, from the techno-
logical perspective we need reliable and accurate means of
automatically extracting information using natural language
processing methods, and this automatic extraction needs to
happen at scale and be readily available for querying. Sec-
ondly, from an operational perspective, such a text analytics
system would need to be integrated into clinical practice in
a way that preserves data security and delivers information
in real-time at point of care.
In this paper we present a feasibility study of imple-
menting one specific commercial text processing system,
IBM Watson Content Analytics,1 using data from the
UK National Health Service (NHS). IBM Watson Con-
tent Analytics provides an architectural framework for
loading, querying, and searching free-text documents at
scale. The Content Analytics suite belongs to the family
of IBM Watson products, however unlike some of the
other products such as IBM Watson Developer Cloud,2
this is a system which can be installed locally. Patients
are rightly concerned that their personal medical data
does not leave the security of their healthcare provider
and local installation is seen as crucial to supporting the
data protection policies that safeguard clinical data. In
previous work we have argued that this is especially im-
portant for free text where the risk of disclosure of sen-
sitive information within the text is ever present [4]. We
designed [4] and then implemented the Integrated Re-
search Campus (IRC) [5], a large scale infrastructure for
health data analytics to help address these concerns.
Aim
The aim of our feasibility study was to understand the
potential contributions that a commercial text analytics
system such as IBM Watson Content Analytics could
make within Leeds Teaching Hospitals Trust (LTHT), a
large UK NHS hospital. We adopted a case study ap-
proach and used IBM Watson to find all radiology re-
ports within the hospital database with the incidence of
two conditions: hydronephrosis and brain metastasis, de-
fined as those reports that indicate a positive diagnosis
of one of the two conditions (for example we exclude
positive mentions from clinical history). We hoped to
use this study to identify the range of institutional, tech-
nical, and algorithmic factors which could influence the
implementation of clinical text analytics more widely in
the NHS. To understand the generalisability we used the
same architecture on a similar set of radiology reports
extracted from the MIMIC-III open access dataset which
comes from the Beth Israel Deaconess Hospital in Bos-
ton, USA - a different hospital in a different country
with a very different healthcare system [6]. For this study
we agreed that we would not attempt to benchmark
IBM Watson Content Analytics against alternative tools
or conduct a financial evaluation of its costs and
benefits.
Project setup
This feasibility study took place over a three-month
period in 2016. The person commitment included one
full-time PhD student in computer science with an hon-
orary NHS contract for the duration of the project, an
IBM Watson training expert for 1 week, and part-time
commitment from senior academics, including a clinical
expert. Our IRC information security management infra-
structure is ISO 27001 certified and provides secure data
storage and processing facilities in a research environ-
ment directly connected to LTHT. Datasets were trans-
ferred in anonymised formats under appropriate ethics
and information governance frameworks, and within the
IRC data safe facilities. Access was restricted to NHS
staff located within the secure facilities using a secure
Citrix connection to an audited, secure Virtual Machine
running within the IRC on which we installed IBM Wat-
son Content Analytics.
1https://www.ibm.com/support/knowledgecenter/en/SS5RWK
[Accessed 7th June 2018]
2https://www.ibm.com/smarterplanet/us/en/ibmwatson/
developercloud/ [Accessed 7th June 2018]
Piotrkowicz et al. Journal of Biomedical Semantics 2019, 10(Suppl 1):21 Page 2 of 9
Limitations
There were several limitations to our study. Firstly, we
use a case study in a research environment connected to
clinical systems, instead of directly within a live clinical
system. Secondly, we used historical data, not a live
stream. Thirdly, our case study was limited to a small
number of report types and clinical conditions, whereas
an actual implementation would be a part of a larger
pipeline.
Contributions
Our contributions are as follows: (i) we present an im-
plementation of a large-scale commercial text analytics
system which uses NHS data, (ii) we present an overview
of IBM Watson Content Analytics and the results of a
case study in the radiology domain, and (iii) we show
that a task-specific model generalises across radiology
reports in two different countries (US and UK) for the
two conditions we chose.
Information retrieval (IR) approaches
Some of the existing clinical search systems resemble
commonly used search engines like Google. They share
some traits with most IR systems, such as relying on
string matching and using indexing for quick retrieval of
documents from a large repository. Examples include
STRIDE [7] and CISearch [8]. One issue encountered in
the clinical domain is that the same clinical concept can
be expressed by a wide variety of lexical forms and their
acronyms. In the case of search engines that requires
submitting multiple queries in order to retrieve as many
relevant documents as possible. Hanauer et al. [9] ad-
dressed this by already identifying UMLS concepts in
text (which allows searching concepts, not just lexical
forms), as well as providing the facility to create search
bundles which allow to group appropriate search terms.
The advantage of keyword-based clinical IR systems is
their generalisability  since the indexing works on a
token (i.e. individual word) level (more rarely concept
level), any type of clinical report can be processed by the
system. However, the downside of using keyword match-
ing without looking at the context is that in many cases
irrelevant documents are returned (e.g. when the rele-
vant keyword is negated). Taking context into consider-
ation requires a deeper linguistic analysis, which is why
there is an increasing drive to use and develop NLP
methods with clinical text.
Natural language processing (NLP) approaches
There have been a significant number of research efforts
in the domain of natural language processing of clinical
text. An example of continuing research interest in this
domain is the inclusion of a biomedical and clinical text
analysis task in the i2b2 [3] and SemEval (Semantic
Evaluation) challenges, which are a widely used evalu-
ation and benchmarking systems in the field of natural
language processing.3 The majority of NLP architectures
to date have relied on a combination of lexical dictionar-
ies and rules. More recently, supervised machine learn-
ing approaches have also been used.
Many of these clinical NLP tasks concern themselves
with the automatic annotation of clinical text, which goes
further than simple string matching of relevant lexical
forms from medical ontologies. These approaches need to
address the challenges of clinical text annotation including
misspellings, context-sensitive abbreviations, and neg-
ation. Some of these are already handled by more sophisti-
cated IR systems (e.g. handling of misspellings by Hanauer
et al. [9]). ConText [10] is an example of an NLP system
that employs shallow, surface-based methods to annotate
a variety of linguistic aspects in clinical documents. Specif-
ically, ConText evaluates whether a mention of a clinical
condition is negated, hypothetical, historical, or experi-
enced by someone other than the patient. This is done by
matching certain keywords in text by using dictionaries
and using rules to infer the relation between matched key-
words. This approach of using dictionaries and rules is
quite common for clinical NLP tasks. Unlike machine
learning approaches where patterns are learnt from the
data, rule-based systems are preferred because they pro-
vide decision provenance [11]. Furthermore, training of
supervised machine learning models requires considerable
manual effort to provide annotations [12]. However, an
annotated dataset could be reused for training different
machine learning models, as well as different tasks (e.g.
entity recognition, coreference resolution).
Hybrid (NLP and IR) systems
Hybrid systems combine the strengths of IR and NLP
approaches to allow accurate processing of clinical docu-
ments at scale. One of the most successful being the
caTIES system [13] which employs a query-based archi-
tecture to process pathology reports within a live clinical
setting. cTAKES [14] is an open-source toolkit for anno-
tating clinical documents that can be customised by add-
ing relevant dictionaries.
IBM Watson in healthcare
IBM Watson is one of a number of commercially available
cognitive computing products that are exciting popular
interest in the transformative potential of artificial
intelligence and big data [15], including in the UK NHS
[16]. Despite the interest, there is relatively little academic
literature on IBM Watson and its application to healthcare.
The most widely cited example of IBM Watson in
3See an example here: http://alt.qcri.org/semeval2015/task14/
[Accessed 7th June 2018]
Piotrkowicz et al. Journal of Biomedical Semantics 2019, 10(Suppl 1):21 Page 3 of 9
healthcare is IBM Watson for Oncology [17, 18] developed
with Memorial Sloan Kettering hospital in the USA [19]
and focused on providing clinical decision support by
matching patient conditions to those in scientific oncology
publications using NLP. The more widely available NLP
tool within the IBM Watson product set is IBM Watson
Content Analytics. This has been used for dermatology
[20] and patient safety research and risk management [21].
In the UK, IBMWatson is being used on patient generated
text at Alder Hey NHS Trust [22] but as far as we are
aware this paper is the first to explore the possibility of
implementing IBM Watson on clinical free text in the
NHS. In addition, we extended our work to an open access
corpus from the USA to explore the generalisability of our
rule-based approach to other hospitals and English speak-
ing countries.
Overview of IBM Watson Content Analytics
We present an overview of the IBM Watson Content
Analytics system in Fig. 1.
The system consists of three main components, which
(i) import, (ii) parse and index, and (iii) search documents.
The Unstructured Information Management Architecture
(UIMA) [23] is implemented throughout the system and
allows for adding of further components into the pipeline.
We will now describe each component in more detail.
Import
The importing of documents can be done as a one-off task
(ingestion), or continuously using a crawler in a specified
directory. A variety of data formats are handled, including
flat tables, databases, and XML.
Parse and index
The raw documents are first processed. Built-in methods
separate the documents into smaller chunks (paragraphs,
sentences, tokens). Like in standard IR systems, this system
relies on matching keywords against document text.
Keywords can be grouped into dictionaries. For example,
any words or phrases describing cancer can be grouped into
a Cancer dictionary. Existing dictionaries can also be
uploaded. Dictionary matches in text (optionally with sur-
rounding tokens) can be turned into annotation. Each an-
notations can be tagged with additional information, e.g.
length = n characters, word category = noun. Annotations
can be combined with context information (e.g. tokens or
other annotations) into rules. Rule building uses a syntax
similar to regular expressions, including grouping and re-
peats. The order of annotations or tokens in a group can be
controlled by using ordered or disordered groups. Rules can
also act on different levels of the document, e.g. tokens, sen-
tences, or the whole document. For example, a simple rule
for annotating a mention of cancer location could say that
within a single sentence there should be an annotation for a
body organ and an annotation for a cancer keyword (both
annotations identified using dictionaries) with at most five
tokens in between them. This would match breast cancer,
and cancer has metastasized to the brain. Finally, individual
rules can be combined into rule sets, which perform a spe-
cific language task, e.g. Negation. Finally, any annotations
can be turned into facets, i.e. searchable indices.
Search
Once the documents are processed, they can be searched
using the index. The use of the index allows for a quick and
efficient searching through very large document collections.
Specific annotations (e.g. Age, Gender, Condition) from the
parsing stage can be used as facets. These facets can be
used to search and filter documents. A helpful feature is
the search results view with text snippets with the facets
highlighted in different colors, which allows an at-a-glance
overview of results without having to open every document
separately. Facets can also be combined. For example, first
select all documents which mention a specific condition,
then add the Gender facet. Depending on the contents and
processing of the document some further analytics (e.g.
time series) are also available.
Results
In this section we present the results of our investigation
using IBM Watson Content Analytics for processing the
free-text clinical reports in our case study. We used 5.6
Fig. 1 Overview of IBM Watson Content Analytics
Piotrkowicz et al. Journal of Biomedical Semantics 2019, 10(Suppl 1):21 Page 4 of 9
m radiology reports from LTHT in the UK and repeated
our experiments using 0.5 m radiology reports from
similar set of radiology reports extracted from the
MIMIC-III dataset from the USA [6]. MIMIC-III is an
open access dataset and can therefore be used by other
researchers interested in reproducing or improving on
our approach.
Task definition
Our goal is to identify all clinical reports with a positive
incidence of a particular condition. By positive instance
we mean that the condition is diagnosed or identified in
the report (X is noted), and negated instances (without
X) or historical instances (on admission the patient pre-
sented with X) should be excluded.
Conditions
We chose two conditions for the case study: (i) hydrone-
phrosis (swelling of a kidney), and (ii) brain metastasis
(cancer cells which have spread to the brain from another
primary tumour). By looking at two different conditions
we can investigate to what extent the resources and
models for one condition generalize to another (i.e. which
resources can be reused for different conditions and which
have to be adjusted or developed from scratch).
Data
We used two different radiology datasets. Our primary
dataset were the radiology reports from Leeds Patient Path-
way Manager (Leeds PPM), the EHR system used by LTHT
[24]. We were also interested in using a more widely ac-
cessible clinical dataset, which would allow us to compare
methods. Sharing data in the healthcare domain has been a
longstanding issue due to the highly sensitive nature of
health records and this is especially the case for clinical re-
ports, since removing identifiable patient information from
text is complex and time consuming. The MIMIC-III data-
set4 [6] is therefore a very valuable research resource in that
it provides researchers access (subject to conditions) to a
large number of English language free text clinical docu-
ments linked to a full set of EHR records and already de-
identified and prepared for research use. An overview of
the two datasets is presented in Table 1.
Methods
The following metaprocess was used in our pilot study.
(1) Set up IBM Watson Content Analytics: prepare the
server, training and familiarization
(2) Obtain datasets and prepare overview
(3) Initial processing: segment all documents into
tokens which allows for a simple keyword search
(4) Data exploration: using keyword search find
concordances of a condition and study the context
(5) Create a random sample of 1000 documents for in-
depth analysis and initial development
(6) Iterative development of a model: creation of
dictionaries and rule sets
(7) Initial evaluation: evaluate precision (i.e. are the
annotations and rules correct) using the Watson
analytics and highlights features
(8) Extend model to a bigger sample, and then to the
full dataset
(9) Evaluation against a manually annotated gold
standard
Dictionaries
Dictionaries of clinical terms for the two conditions
(hydronephrosis and brain metastasis) were created by a
medical domain expert. Potential additions found in the
corpus during model development were consulted. We
developed separate dictionaries of negative instance indi-
cators: negation (e.g. no, without), evaluation (e.g. query,
evaluate), clinical history (e.g. admitted, history), reso-
lution (e.g. resolved, cleared). These dictionaries were
considerably expanded during the iterative development
process by analysing the false positive cases.
Rules
The general design behind the rules for this task is that a
condition mention is presumed a positive instance, unless
explicitly negated using a negative instance indicator. We
now present a simplified rule set for hydronephrosis.
Rule set for hydronephrosis (cohesive ConditionKeyword):
(1) Create annotations from dictionaries:
ConditionKeyword, EvaluationIndicator,
NegationIndicator, HistoryIndicator,
ResolutionIndicator. Additional dictionaries (e.g.
Age, Gender, ICD-9 codes) can be added to use for
analytics in data exploration and search stage.
(2) For the ConditionKeyword annotation, create some
indication of condition incidence, e.g. present =
unknown, polarity = unknown4https://mimic.physionet.org/ [Accessed 7th June 2018]
Table 1 Summary of the two radiology data sources
LTHT PPM MIMIC-III
EHR data
source
Leeds Teaching Hospitals NHS
Trust, Leeds, UK
Beth Israel Deaconess,
Boston, MA, USA
Period 19962016 20012012
# Patients ~ 1 million ~ 37,000
#
Documents
~ 5.6 million ~ 0.5 million
Av. report
length
70 tokens 206 tokens
Piotrkowicz et al. Journal of Biomedical Semantics 2019, 10(Suppl 1):21 Page 5 of 9
(3) For each negative instance indicator dictionary
(evaluation, negation, history, resolution), create the
following rules, where [S ] indicates that the
scope of the rule is a sentence:
a. If [S NegIndicator ConditionKeyword] then
ConditionKeyword/Presence = false
b. If using an ordered group then optionally
depending on data: [S ConditionKeyword
FalseInd]
(4) For any other instance of ConditionKeyword,
ConditionKeyword/Presence = true
(5) Optional: add lastOccurrence = unknown to
ConditionKeyword annotation and set to true/false.
In the evaluation consider only true instances if
they are also the last occurrence of the
ConditionKeyword in the document (this helps
with eliminating historical incidence and ambiguous
cases)
Extending the hydronephrosis model to brain metastasis
The main difference between the hydronephrosis and brain
metastasis case studies are the keywords indicating the con-
dition. Firstly, the dictionary of hydronephrosis keywords is
(as far as we know) complete for our case study and these
keywords point unambiguously at this particular condition.
Furthermore, in cases of multiword expressions (e.g. dilated
renal pelvis), the words occur together, so simple string
matching is sufficient to create annotations. However, for
the brain metastasis case the condition keywords are some-
times non-contiguous (e.g. Within the brain multiple ring
enhancing metastatic deposits noted). As they occur separ-
ately, two different dictionaries need to be built (Dict1 =
brain-related keywords, Dict2 =metastasis-indicating
keywords), and what follows is that the annotation needs to
be built on the sentence level. Secondly, both brain metasta-
sis dictionaries have some issues. The brain-indicating key-
words can be ambiguous. Some keywords refer to different
body parts (e.g. parenchymal, lobe) and it is sometimes diffi-
cult to tell definitely just from the report text (however the
report title can be help in disambiguating, e.g. CT Head will
point to brain parenchyma, but CT Abdomen would not).
The metastasis-indicating keywords can be quite generic
(e.g. tumour which can indicate both primary and metastatic
tumours). For example, if brain metastasis is queried expli-
citly, then in the findings section the radiologist might not
say brain mets found, but rather multiple lesions found.
Because of the context a human will be able to tell that this
means metastatic lesions in the brain, but it is challenging to
implement computationally because of the long-range refer-
ence. The long-range reference is also an issue when infer-
ring the location of the tumour (e.g. There are two
enhancing lesions with a moderate degree of surrounding
oedema. The largest measures 2.7 cm and is in the left
frontal lobe. The second measures 1.5 cm and is located in
the right occipital lobe.). While the models for the two con-
ditions differ, some elements (e.g. negative instance diction-
aries) can be effectively reused, saving development time.
Extending the model to a different dataset
While each condition required a customised model, we
found that once models had been developed they were ef-
fective on both the data from the UK and from the USA,
two very different hospitals, countries and healthcare envi-
ronments. We believe this is because there is a significant
overlap in medical training and terminology across the Eng-
lish speaking world, especially in the case of technical clin-
ical reports such as those written in radiology. We
acknowledge that despite similarities in jargon, there are still
country- or institution-specific conventions (e.g. use of cer-
tain acronyms) and differences of spelling between UK Eng-
lish (e.g. tumour) and US English (e.g. tumor). Some
conventions are more localised (e.g. frequent use of assess
for Report Indication in the US dataset), but these were eas-
ily resolved by adding some new terms to the relevant dic-
tionary. This addresses the point made by Pons et al. [25]
that most clinical NLP systems are specific to an institution,
which hinders their wider implementation. We showed that
for the same task our models work across two very different
sources. Moreover, the evaluation using MIMIC-III can lead
to models being more commonly shared and compared.
Results
For this preliminary investigation we report the results
of our models on a small sample of radiology reports.
For each condition we randomly sampled from the train-
ing set 50 reports predicted positive and 50 reports pre-
dicted negative. Without indicating the labels we asked a
clinical oncologist to annotate the reports as a positive/
negative instance. We report the results in Table 2.
Overall, we achieved very high results  at least 84% pre-
cision and 88% recall. The models perform better for
hydronephrosis, which can be due to the challenges we
noted above for the brain metastasis model.
Discussion
Results of this three-month pilot project for the task of
clinical document retrieval were very promising. We
took a simple, shallow NLP approach, which combined
with the IBM Watson Content Analytics architecture
and functionalities allowed us to process millions of doc-
uments in a relatively short period of time (e.g. a subset
of 50,000 documents used to develop initial rule sets
took approx. 30 min to process). We tested our models
on a small manually annotated sample and obtained
high precision and recall values. We made the following
observations during the study.
Piotrkowicz et al. Journal of Biomedical Semantics 2019, 10(Suppl 1):21 Page 6 of 9
Generalisability
We found that the models worked best when they were
task-specific. In the case of hydronephrosis the condition
keywords are both cohesive and specific, which allows us to
accurately identify the condition mentions in text. For the
brain metastasis case study we observed that the condition
keywords are often separated, sometime across sentences.
They are also fairly generic and ambiguous keywords, which
makes finding relevant documents difficult. In terms of ex-
tending our methods to other conditions, we hypothesise
that as long as the new condition follows the same patterns
as an implemented model, then it should be the simple case
of replacing the condition dictionary and running the model
for the same type of report (e.g. a condition with very spe-
cific keywords could reuse the hydronephrosis model). Even
for the more challenging cases like brain metastasis, the
model might be re-implemented for similar conditions (e.g.
lung metastasis), where only the tumour location dictionary
would need to be replaced. More broadly, the negative in-
stance indicators can be reused across conditions. However,
this probably would not hold for more distinct types of clin-
ical reports, e.g. negation in radiology is very explicit (no, no
evidence of, without), but in clinical notes implicit negation
could be present as well (e.g. patient denies feeling numb-
ness). Finally, the dictionaries we used were only developed
and evaluated within a single institution. When applied to
other collections of radiology reports, our dictionaries might
account for the standard set of terms and their spelling, but
there might be some further institution- or country-specific
terms or acronyms which would need to be added.
Handling difficult cases
When conducting the error analysis we noted some
cases which present a significant challenge for the auto-
matic processing of clinical reports (cf. Table 3). The
first case can be ambiguous depending on the task set-
ting  if looking at condition incidence in reports, then
it should be treated as negative according to our defin-
ition, however if looking at patient incidence, then this
would be considered as a positive cases. Clear task defi-
nitions based on requirements are needed to avoid false
positives. The second case is ambiguous due to the radi-
ologists phrasing  without frank hydronephrosis, in
this case a system which values recall over precision (e.g.
if the goal was to find any and all potentially positive
cases for quality assurance) would need to treat this as a
positive case. Although rare, these cases still need to be
accounted for and clinical domain experts should decide
whether such a case should be considered positive or
negative. Finally, the third case shows how modality
(raised the possibility) can lead to false positives. For
such cases we introduced an optional rule, whereby the
last condition mention in a report is treated as the one
to be used for indexing. Overall, we recommend a thor-
ough error analysis, which can point to such cases and
thus help to refine the models.
Technical notes about the system
The processing speeds were monitored throughout the
project, however due to technical problems with the ser-
ver infrastructure, the performance of the system varied.
We noted that on average simple indexing (i.e. tokenisa-
tion which enabled free-text search) of documents was
about 200 documents per second. More sophisticated
indexing which included multiple dictionaries and rule
sets took on average about 30 documents per second.
We also noted that the data ingestion is quite sensitive
to the formatting, which necessitates robust data clean-
ing. This is a considerable issue, since in our experience
clinical text data does not have high-quality formatting.
Similarly, the data export in CSV format failed, because
there was no way to protect the text data, which resulted
in misaligned data. Exports in other formats had no such
issues, so post-processing to derive data in CSV format
is possible. Finally, we noted the advantage of the paral-
lel architecture implemented in the system, which allows
for simultaneous importing, parsing and searching of
documents, resulting in significant time savings.
Limitations
This feasibility study aimed to provide feedback to NHS
stakeholders and IBM about advantages/disadvantages
and issues in implementing a commercial text analytics
system for use with clinical free-text reports. Our focus
was on the technical infrastructure needed to set up a
commercial system that could use NHS data in a way
that preserves best data governance practices. We estab-
lished that this is possible through the use of data safe
facilities between the NHS trust and the IRC however
most hospitals do not have access to such a research
Table 2 Precision and recall results for the preliminary
experiments
Hydronephrosis Brain metastasis
LTHT PPM MIMIC-III LTHT PPM MIMIC-III
Precision 94% 93% 89% 84%
Recall 95% 96% 94% 88%
Table 3 Examples of challenging cases of hydronephrosis
incidence
Reason: Evaluate for effusion; Admitting Diagnosis: HYDRONEPHROSIS
The right kidney is considerably lower in location than the left with
slight pelviectasis but without frank hydronephrosis
FINDINGS: [] Initial images raised the possibility of mild bilateral
hydronephrosis; however, repeat imaging with a different probe and in
different positions suggests that this is likely fat hypertrophy within the
renal sinus bilaterally. [] IMPRESSION: No definite hydronephrosis.
Piotrkowicz et al. Journal of Biomedical Semantics 2019, 10(Suppl 1):21 Page 7 of 9
environment. A limitation of our study is therefore that
we conducted our case study in a research environment
connected to clinical systems rather than in the live clin-
ical system itself. This was for the obvious reason that
we needed to avoid any possibility of the research
impacting on the care of patients within the hospital, for
example by data processing demands slowing down the
live servers. Similarly, we used the full set of available
historical data collected over many years recognising
that there may be temporal drift in the use of language
and terms over the 10 year time period. Our case study
was limited to a small number of report types and clin-
ical conditions, whereas an actual implementation would
be a part of a larger pipeline. In addition to technical
factors of such integration, there are also the significant
issues of acceptability and usability by NHS staff.
Conclusions
In this paper we presented the results and observations
from a feasibility study on implementing a commercial
text analytics system  IBM Watson Content Analytics 
with free-text clinical reports obtained from the NHS. We
first presented an overview of the IBM Watson Content
Analytics architecture. We then described our methods
and results using this architecture for two examples from
radiology: hydronephrosis and brain metastasis. The IBM
Watson Content Analytics system allowed us to build a
rule-based NLP model and apply it to millions of docu-
ments. Although the system scaled up to large datasets, it
still required considerable manual input to create diction-
aries and rule sets. However, we found that although we
need to customise the models for each task, some re-
sources and models could be reused between the two
datasets with only some adjustments. We believe it is sig-
nificant that our task-specific models generalise across
radiology reports from two very different countries (UK
and USA) for the two conditions we chose.
Our approach does allow us to reflect on the remaining
implementation challenges. IBM Watson Content Analyt-
ics has the functionality to continuously ingest new data
as a live data stream and output results through its user
interface or as an output data stream. We therefore envis-
age a live data stream of radiology reports into the text an-
alytics engine which returns a stream of coded results
back into the EHR in the form of coded events and as
alerts. In common with many other EHRs, LTHTs PPM
system has a) the ability to store and display such coded
event data so that it can be reviewed by clinicians at point
of care and b) an alerts system that can be set to notify cli-
nicians of events of concern. Arguably, now that the text
processing rules have been developed there is a case that
they could be implemented directly as programme code
within the EHR itself and this would reduce costs and im-
prove processing speed. However, processing speeds of 30
documents per second suggests that system will already
perform significantly faster than both human interpret-
ation and the rate of production of new reports. In
addition, IBM Watson Content Analytics provides a rich
set of features for the continuous evaluation and improve-
ment of NLP text analytics rules and we envisage a learn-
ing health system [26] where there is an ongoing
requirement for text analytics rules that are extended, re-
fined and improved on to account for temporal drift and
make continuous improvements in patient safety. The im-
plementation of user interface changes and alerts to
achieve this within clinical settings is, in itself, a complex
domain and is beyond the scope of this study.
In our study we found it was feasible to use IBM Wat-
son Content Analytics within the UK NHS but there are
other good large-scale text analytics systems available
such as cTAKES, GATE and other commercial plat-
forms. We note that IBM Watson Content Analytics
uses the UIMA content analytics standards to support
the transfer of dictionaries and models between different
systems and we believe this presents an opportunity to
separate the discussion on tools and rules from the dis-
cussion on implementation. We therefore envisage fur-
ther work along three lines of investigation: a) what
tools and techniques are best for generating and refining
healthcare text analytics dictionaries and models? b)
what are the optimum rules, dictionaries and models for
each clinical condition given the inevitable trade-off be-
tween global generalisability and local language, culture
and custom as clinical text evolves over time? and c)
how best to implement text analytics rules, dictionaries
and models within real time live clinical environments?
Our feasibility study suggests that healthcare text analyt-
ics is sufficiently advanced to be operationalised within
EHR solutions. The biggest challenge ahead is likely to
be the design and implementation of real time process-
ing solutions which will demonstrate the promised step
change in clinical safety.
Abbreviations
EHR: Electronic Health Record; IR: Information Retrieval; IRC: Integrated
Research Campus; LTHT: Leeds Teaching Hospitals Trust; NHS: National
Health Service; NLP: Natural Language Processing; PPM: Patient Pathway
Manager; UIMA: Unstructured Information Management Architecture;
UMLS: Unified Medical Language System
Acknowledgements
The authors would like to thank the Leeds Teaching Hospitals Trust and IBM
UK for their support in this project. An initial version of this paper has been
presented at the Healthcare Text Analytics Conference 2018 (HealTAC) in
April 2018.
About this supplement
This article has been published as part of the Journal of Biomedical
Semantics Volume 10 Supplement 1, 2019: HealTAC-2018: Unlocking Evi-
dence Contained in Healthcare Free-text. The full contents of the supple-
ment are available online at https://jbiomedsem.biomedcentral.com/articles/
supplements/volume-10-supplement-1.
Piotrkowicz et al. Journal of Biomedical Semantics 2019, 10(Suppl 1):21 Page 8 of 9
Authors contributions
AP preprocessed the data, and developed and analysed the models. OJ and
GH made substantial contributions to conception and design, acquisition of
data, and result interpretation. AP and OJ wrote the manuscript. All authors
read and approved the final manuscript.
Funding
The work was commissioned by Leeds Teaching Hospitals Trust (LTHT) as
part of an evaluation of IBM Watson. Funding was provided by Leeds Cares,
a charitable trust that supports research and innovation at LTHT. IBM UK
supported the project with access to software and supporting consultancy
but did not provide or receive any funding. AP is also supported by the
University of Leeds Wellcome Trust Strategic Support Fund. Publication costs
are funded by the Wellcome Trust.
Availability of data and materials
Not applicable.
Ethics approval and consent to participate
The work was conducted by research and informatics staff contracted to
Leeds Teaching Hospitals Trust Informatics Department using anonymised
retrospective data from the Trust. Approval to perform the study was
obtained from Leeds Teaching Hospitals Trust Research and Innovation
Director and the Trusts Information Governance lead.
Consent for publication
Not applicable.
Competing interests
The authors declare that they have no competing interests.
Author details
1Leeds Institute of Medical Education, University of Leeds, Leeds, UK. 2Leeds
Teaching Hospitals Trust, Leeds, UK. 3School of Computing, University of
Leeds, Leeds, UK. 4School of Medicine, University of Leeds, Leeds, UK.
Published: 12 November 2019
RESEARCH Open Access
Phenotype annotation with the ontology of
microbial phenotypes (OMP)
Deborah A. Siegele1, Sandra A. LaBonte2, Peter I-Fan Wu2, Marcus C. Chibucos3, Suvarna Nandendla3,
Michelle G. Giglio3 and James C. Hu2*
Abstract
Background: Microbial genetics has formed a foundation for understanding many aspects of biology. Systematic
annotation that supports computational data mining should reveal further insights for microbes, microbiomes, and
conserved functions beyond microbes. The Ontology of Microbial Phenotypes (OMP) was created to support such
annotation.
Results: We define standards for an OMP-based annotation framework that supports the capture of a variety of
phenotypes and provides flexibility for different levels of detail based on a combination of pre- and post-
composition using OMP and other Open Biomedical Ontology (OBO) projects. A system for entering and viewing
OMP annotations has been added to our online, public, web-based data portal.
Conclusions: The annotation framework described here is ready to support projects to capture phenotypes from
the experimental literature for a variety of microbes. Defining the OMP annotation standard should support the
development of new software tools for data mining and analysis in comparative phenomics.
Keywords: Annotation, Phenotypes, Ontology, Biomedical ontologies, Curation, Microbial phenotypes, Microbial
genetics, Microbiology
Background
Phenotypes are the result of the interaction of a particular
genotype with an environment. An organisms phenotypes
will vary in different environments or life stages. Just as we
see the arctic foxs fur change in color and thickness as
summer warmth changes to winter cold [1], we can also
observe changes in microbes as their environments change.
For example, when faced with nutrient depleted environ-
ments some bacteria will change their phenotype from
vegetative cells and become spores that can survive adverse
environments [2]. Other bacteria switch from swimming to
swarming motility in viscous environments or when mov-
ing across a surface [3, 4]. Likewise, if a change occurs in
the underlying DNA sequence of an organism, creating a
new genotype, a change in the phenotype may be observed.
Linking particular phenotypic changes to changes in spe-
cific genes provides the raw material for understanding the
vast variety in biological form and function and is key to
genetic dissection of biological processes. Microbial genet-
ics has played a central role in the history of molecular biol-
ogy. The unity of biology is reflected in how insights based
on microbial model systems have informed the understand-
ing of the biology of other clades, including humans.
The Ontology of Microbial Phenotypes (OMP) [5] was
created for the systematic annotation of the phenotypes of
microbes (e.g. bacteria, archaea, viruses, protists, etc.) in a
common framework that supports computational data
mining and analysis. The current release of OMP contains
1880 terms describing phenotypes associated with all as-
pects of microbial life (e.g. morphology, growth, metabol-
ism). Each OMP term consists of a term name (or label),
definition, and unique identifier. For example, the term
with id OMP:0000041 has the name increased cell size
and the definition An altered cell size phenotype where
the volume of a cell or cells is increased relative to a desig-
nated control. The association of an OMP term id with a
particular gene variant or allele indicates that the genotype
in question, when found in a particular environment, leads
to the phenotype described by the OMP term.
© The Author(s). 2019 Open Access This article is distributed under the terms of the Creative Commons Attribution 4.0
International License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and
reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to
the Creative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver
(http://creativecommons.org/publicdomain/zero/1.0/) applies to the data made available in this article, unless otherwise stated.
* Correspondence: jimhu@tamu.edu
2Department of Biochemistry and Biophysics, Texas A&M University and
Texas AgriLife Research, College Station, TX, USA
Full list of author information is available at the end of the article
Siegele et al. Journal of Biomedical Semantics           (2019) 10:13 
https://doi.org/10.1186/s13326-019-0205-5
Previously, Chibucos et al. [5] described the ontology de-
sign principles we incorporated into developing OMP. Here,
we provide a formal description of OMP annotations, ex-
tending the concepts initially proposed in Chibucos et al.
[5]. The annotation system to be described here can capture
a broad variety of phenotypes from type strains, mutants,
and genetic suppressors and enhancers in all kinds of micro-
bial systems. The OMP annotation framework and a wiki-
based online interface are being used to collect and display
microbial phenotype annotations using OMP terms.
Results
The elements of an OMP annotation
Figure 1 lists the components of an OMP annotation, each
of which will be discussed below. Specific fields in Fig. 1 will
be referred to in parentheses. We maximize the use of inter-
operable ontologies and computable identifiers in OMP an-
notations, however, for some information types we currently
use free text content if other more systematic solutions are
not yet available.
Annotation ID
All OMP annotations are assigned a unique ID (1.1),
which consists of an OMP_AN prefix followed by an
integer and an optional suffix used for annotations made
by other groups. These are currently created through the
annotation web interface (described below). We assign
stable identifiers to each annotation for two reasons: to
track corrections to an annotation if needed, and to
allow one annotation to make reference to another an-
notation as described in more detail below.
Annotation object
Although phenotypes are often discussed in terms of as-
sociation with genes, in fact phenotypes are manifesta-
tions of the combination of genotype, environment, and
developmental stage or cell type. In an OMP annotation,
genotype and environment information is captured in
the Genotype and Environment fields of the phenotype
descriptors, while life stage or cell type is captured in
the Annotation Extension field.
In this context we need a stable identifier for any
genotype that will be subject to phenotype annotation.
Ideally, we would reuse an existing resource in the way
that GO annotation can reuse identifiers from global re-
sources such as UniProt. A variety of stock centers and
collections such as ATCC associate genotypes with a
stable identifier. Also, genome accessions at GenBank
Fig. 1 Phenotypes in the OMP wiki. a An Annotations table on a Strain page. Two annotations are shown. The interface calculates differences in the
genotype and conditions for each annotation compared to the reference annotation. In the second row, the comparison is to a strain that is not isogenic,
so multiple allele differences are shown where only one is likely to be causative. b Editing interface using TableEdit. This shows how an existing annotation
can be edited. OMP and ECO term names are filled in from the IDs by a database lookup. Conditions are entered as multiple key-value pairs where allowed
keys are selected from a pull-down menu. These include, ENVO term, temperature, pH, medium, and other. Extensions and Notes are entered as free text
Siegele et al. Journal of Biomedical Semantics           (2019) 10:13 Page 2 of 8
are available for microbial genomes that have been se-
quenced. However, these external resources are not suffi-
cient, because a substantial fraction of the literature
involves strains that have not been sequenced or have not
been deposited in any collections. Because there is no ex-
ternal resource that provides unique identifiers to the wide
range genotypes that OMP will be used to annotate, we
built this capability into the OMP annotation infrastruc-
ture. Genotype ID (2.1) is a unique stable ID that has
OMP_ST: as a prefix followed by an integer. Each ID is as-
sociated with information about a particular microbial
substrain, including known alleles, episomes, and ancestry.
If available, a source for obtaining the strain is included,
along with a reference for where the strain was described
in the literature. Where available, stable identifiers from
genomes or other resources can be added.
In many high-throughput microbial phenotype studies,
where the fitness of a large number of mutants are being
compared across a large number of growth conditions,
the fitness of each individual mutant is measured relative
to the average fitness of all the mutants in the collection
rather than to the fitness of the parental strain [68]. To
capture these relative phenotypes in OMP, we have cre-
ated special virtual strains that represent the average be-
havior of the particular collection of mutants used in a
particular study. The virtual strain is used as the refer-
ence strain that each individual mutant is compared to.
For capture of environment (2.2), we prefer to use
ontology-based descriptors such as ENVO terms [9, 10].
However, ENVO does not currently contain the terms
needed for microbial phenotype annotations. While term
development and annotation practice are being worked
out with the ENVO team, we use the placeholder condi-
tions field (2.3) for a free text description of the environ-
mental conditions where the phenotype was observed.
Phenotype
Four fields (OMP term, Relative to, Qualifier, and Exten-
sions) combined together form an ontology-based
phenotype description.
An OMP term (3.1) and Extensions (3.2), if any, de-
scribe the phenotype. Mungall et al. [11] describe how
pre-composition and post-composition of phenotype de-
scriptions are used by different phenotype annotation pro-
jects. Briefly, pre-composition consists of using ontology
terms with sufficient granularity to capture the desired
level of specificity in the annotation system, while in post-
composition curators can extend the specificity of
annotations by combining less specific terms at annota-
tion time from interoperable ontologies.
The OMP term (3.1) is a pre-composed phenotype de-
scription defined by the ontology. Extensions (3.2) is an
optional field that can hold zero to many entries to pro-
vide more information about the phenotype. Each exten-
sion entry is a pairing of a relationship based on the OBO
relations ontology [12] and one or more identifiers.
The Relative to field (3.3) is used in a specific kind of an-
notation. There are two kinds of OMP terms to support
two kinds of phenotype annotations: independent and
dependent [5]. Independent phenotypes are phenotypes of
microbes that can be described without reference to an-
other observation. For example, a microbe either has the
ability to become motile or is nonmotile. By contrast, de-
scription of a dependent phenotype requires reference to
another annotation. For example, increased or decreased
motility might be observed when comparing a mutant vs
wild-type strain or a single strain in different environments.
To capture dependent phenotypes, the optional Relative to
field holds the OMP_AN identifier for the reference pheno-
type used in the comparison. In many instances, the curator
will need to start with creating the annotation for the refer-
ence phenotype.
Qualifier (3.4, optional) can modify the meaning of
the observation. There are currently three allowed values
for qualifiers (Table 1).
Evidence
OMP annotation captures the evidence for a phenotype
observation with two fields. Evidence (4.1) uses terms
from the Evidence and Conclusion Ontology (ECO) [13]
to capture the type of experiment used and Reference
(4.2) provides an identifier for the source of the observa-
tion in the literature, usually in the form of a PubMed ID.
Metadata
History (5.1) records revision history of the annotation,
including a timestamp for when an annotation was cre-
ated or changed and who made the changes.
Finally, the annotation system provides an optional
free text notes (5.2) field for information that could be
of value that does not fit into the fields described above.
For example, notes could be used to explain revisions or
specify where a phenotype is described in a paper. Notes
could include links to term requests at OMP, ENVO,
ECO, or ChEBI needed to refine the annotation.
Table 1 Allowed qualifiers and when to use them
Not Indicates that a phenotype was tested for, but was not observed.
Same phenotype as reference strain Indicates that a change in genotype does not change the observed phenotype.
Same phenotype as in reference condition Indicates that a change in environment does not change the observed phenotype.
Siegele et al. Journal of Biomedical Semantics           (2019) 10:13 Page 3 of 8
Online system for viewing, creating and editing
annotations
OMP annotations have been added to the OMP wiki [14],
which previously focused on pages for OMP and ECO
terms [5]. A system for managing strains and substrains
(unpublished) was developed that creates pages for each
strain/genotype used in OMP annotation. Strain pages are
assigned OMP_ST unique identifiers upon page creation,
and the pages include a table for annotations based on the
TableEdit Mediawiki extension (unpublished) combined
with extra capabilities written specifically for OMP anno-
tation tables. Figure 2 shows an example of an annotation
table in the wiki and the editing interface.
Each row in the table represents one annotation, where
all the annotations in that table share the OMP_ST ID for
the page bearing the table. In addition to the specified an-
notation component fields described above, the user inter-
face fills in the term name for an entered OMP_ID and an
extension to the MediaWiki software calculates differ-
ences in the genotype and conditions relative to the refer-
ence annotation in the relative_to field as described in
Methods. An auto-incremented OMP_AN ID is created
when the annotation is saved.
Discussion
While developing the annotation system for OMP, we
examined the annotation formats used by other species-
specific microbial phenotype projects. The systems used
for Saccharomyces cerevisiae [15], Schizosaccharomyces
pombe [16], and Dictyostelium discoideum [17] appear to
be different from one another. The MicrO project [18]
provides an alternative ontology for bacterial and ar-
chaeal phenotypes and related concepts (e.g. media) but
appears to currently emphasize supporting MicroPIE
[19] natural language processing, and we did not find a
comparable annotation format for use of MicrO. Thus,
we decided that developing a distinct universal system to
unify annotation would be beneficial.
Insofar as we are building OMP to allow data mining
across studies and across microbial species, our annotation
system does not capture quantitative fitness scores or mea-
sures of growth rates, mutation rates, or other numeric data.
Pre vs post-composition in OMP
OMP uses a combination of pre- and post-composed ap-
proaches to describe phenotypes in annotations. The
OMP ontology [5] consists of pre-composed terms that
range from broad classification of phenotypes to terms
of intermediate specificity where groupings are poten-
tially useful. For example, OMP:0000336 beta-lactam re-
sistance phenotype and its child terms are used when
the chemical described in the extension is a beta-lactam,
such as penicillin, ampicillin, methicillin etc. Beta-lactam
antibiotics are defined by the presence of a beta-lactam
ring, which is important for their biological effects on
peptidoglycan synthesis in the Bacteria [20]. Phenotypes
found for a particular beta-lactam are likely to be in-
formative for the effects of other beta-lactams. Retriev-
ing annotations to these intermediate terms would
support analyses that compare and contrast resistance to
different members of the antibiotic class, such as the
substrate specificity of beta-lactamases [21].
The OMP consortium policy is to limit pre-composition
to these intermediate levels, rather than pre-compose a dif-
ferent OMP term for every different beta-lactam antibiotic,
even though differences in antibiotic resistance spectrum are
potentially useful. Similarly, we do not pre-compose OMP
terms for other detailed phenotypes, such as resistance to a
particular species of phage, or utilization of a specific nutri-
ent. In these cases, a pre-composed set of terms for every
phage and every chemical utilized by a microbe would lead
to an astronomical explosion in the size of the ontology.
By contrast, the purpose of the annotation extension
field in the system described here, which is modeled on
the similar extensions used in Gene Ontology Annota-
tion [2224], is to increase our ability to express specific
phenotypes at annotation time without creating new
pre-composed OMP terms. Extensions can be used to
specify the drug used in an antibiotic resistance pheno-
type, the cell type where a phenotype is observed (e.g. le-
thal during spore germination), or other relevant
information such as penetrance.
For example, to describe phenotypes relating to resist-
ance or sensitivity to a chemical, OMP contains a variety
of pre-composed terms including those shown in Fig. 3a.
To identify the specific chemical used in a study, the an-
notator would add to the annotation extension field a
CHEBI ID (or other stable identifier for the chemical), and
link the OMP term to the chemical with a towards rela-
tionship (RO:0002503) from the Relationship Ontology
(RO) [12] (Fig. 3b). Figure 3c shows additional examples
of how the annotation extension field is used in OMP.
Many microbial phenotypes can be described with
pre-composed terms, and some species-specific pheno-
type annotation systems, such as FYPO [16], are based
on extensive pre-composition. The availability of pre-
composed terms facilitates community annotation, but
can lead to the creation of large numbers of highly spe-
cific terms, which can make the ontology unwieldy, es-
pecially in an ontology like OMP that coordinates
annotation across many taxa.
Post-composition with extensions does not alter the
ontology itself. Editing the OMP ontology itself is done
as described in Chibucos et al. [5]: term-related requests
are gathered via a GitHub issue tracker and changes in
the ontology are done using standard ontology editing
tools to generate .obo and .owl files, which are periodic-
ally released.
Siegele et al. Journal of Biomedical Semantics           (2019) 10:13 Page 4 of 8
Fig. 2 (See legend on next page.)
Siegele et al. Journal of Biomedical Semantics           (2019) 10:13 Page 5 of 8
Future directions
Populating the corpus of microbial phenotype data
Although we expect that collaborations with other
ontology projects and other work in our group will lead
to refinements that decrease the use of free text, the
annotation system described here should be sufficient to
support curation of microbial phenotypes from the lit-
erature. Curation projects are ongoing to add pheno-
types from high-throughput studies from E. coli, B.
subtilis, S. pombe, and S. cerevisiae. As each of these
(See figure on previous page.)
Fig. 2 Phenotypes in the OMP wiki. a An Annotations table on a Strain page. Two annotations are shown. The interface calculates differences in
the genotype and conditions for each annotation compared to the reference annotation. In the second row, the comparison is to a strain that is
not isogenic, so multiple allele differences are shown where only one is likely to be causative. b Editing interface using TableEdit. This shows how
an existing annotation can be edited. OMP and ECO term names are filled in from the IDs by a database lookup. Conditions are entered as
multiple key-value pairs where allowed keys are selected from a pull-down menu. These include, ENVO term, temperature, pH, medium, and
other. Extensions and Notes are entered as free text.
A
B
C
Fig. 3 Post-composition with the extensions field. a Example of OMP terms with pre-composed groupings at the level of resistance to chemicals.
b Use of an extension to specify increased resistance to acriflavine hydrochloride using the Relations Ontology term RO:0002503 (towards) to link
the ChEBI term CHEBI:74728 (acriflavine hydrochloride) to the OMP term for increased resistance to a chemical. c Other uses of the RO:0002503
(towards) relationship include specifying increased resistance to a beta-lactam (ampicillin), decreased organic carbon source utilization (lactose),
and decreased sensitivity to a bacteriophage (bacteriophage Chi)
Siegele et al. Journal of Biomedical Semantics           (2019) 10:13 Page 6 of 8
presents specific challenges and issues, the details of
these contributions to the overall corpus will be de-
scribed elsewhere.
Export formats
A goal for OMP is to provide phenotype data consistent
with FAIR principles [25]. Toward the goal of improving
interoperability and reuse, we are working on a system
for regular releases of the corpus of OMP annotations.
We are modeling our first data release specification on
the GPAD+GPI system used by GO [22, 26]. For OMP,
we would generate a pair of tab-delimited files. One of
these would contain the annotation fields specified here,
while the second would include information associated
with the genotype in the annotation object. The geno-
type representation system is under development.
As an alternative to tab-delimited text, it should be
possible to export OMP annotations and the associated
genotype information as JSON or JSON-LD [27].
Conclusions
We describe a framework for the use of OMP to make
phenotype annotations. This system is in active use for
the annotation of phenotypes for Escherichia coli, Bacil-
lus subtilis, Saccharomyces cerevisiae, Schizosaccharo-
myces pombe,and other microbes.. A wiki-based online
interface allows viewing of annotations and community/
collaborative curation of phenotype annotations.
The OMP annotation standard, as defined here, will
support the development of new software tools for data
mining and analysis in comparative phenomics.
Methods
The annotation system as described here is a platform-
independent specification.
The OMP wiki [14] implementation of the annotation
system is based on the open source Mediawiki software
platform [28]. The OMP wiki is currently running on
Mediawiki 1.31 using php7.2 and MySQL 5.7 with cus-
tomized extensions to support biological wikis and
ontology projects [29] and additional software exten-
sions developed specifically to support OMP projects.
The OMP wiki is currently a virtual host on a single
Linux server at Texas A&M shared with other projects.
Extension code is open source and available at our
GitHub repository [30].
The OMP and ECO ontologies are downloaded from
our central repositories daily and parsed into a local
mysql database, obo_archive, with a custom schema that
incorporates version history for every ontology term.
The annotation system within the wiki is controlled by
a custom extension for the OMP project, which in turn
builds on TableEdit [31], an extension for managing
structured tabular data in MediaWiki, and TableEdit-
based code modules developed for ontology wiki pro-
jects [29]. The template for the annotation form is
defined by a page in the wiki, Template:OMP_annota-
tion_table, which controls formatting and callbacks for
the displays in Fig. 2a (viewing mode) and b (editing
mode). The annotation editing form (Fig. 2b) uses obo_
archive to look up current term names when a curator
enters OMP or ECO ids.
Each phenotype annotation is stored as a TableEdit
row associated with a specific TableEdit table on a
genotype page. Each genotype page also contains a
TableEdit table with genotype information defined by
a different TableEdit template: Template: Strain_
info_table. To calculate possibly relevant differences
in genotype and conditions, the extension uses the
unique annotation id in the Relative to field to find
the content of the conditions field in the reference
annotation, and the genotype on the page where the
reference annotation is stored. The genotype and
conditions fields for the reference and dependent an-
notation are then tokenized with a regular expres-
sion and the differences are calculated by comparing
arrays of unique tokens for each field.
Abbreviations
ChEBI: Chemical Entities of Biological Interest; ECO: Evidence and Conclusions
Ontology; ENVO: Environment Ontology; FYPO: Fission Yeast Phenotype Ontology;
GO: Gene Ontology; OBO: Open Biomedical Ontologies; OMP: Ontology of
Microbial Phenotypes; RO: Relations Ontology
Acknowledgements
The authors thank Oliver He for encouraging us to submit to this special issue, and
Suzi Lewis for including us in the Phenotype RCN conferences, and participants in
the Phenotype RCN for many helpful discussions.
Authors contributions
JH, MG, and DS oversee the OMP project. JH, DS, and SL wrote the manuscript with
input from the other authors. JH, DS, SL, and PW worked on annotation standards
and examples. DS, MC, SN, and MG manage OMP ontology development. MC, SN,
and MG coordinate with the ECO project for evidence capture in the annotation
system. JH and SL performed mediawiki extension development. All authors read
and approved the final manuscript.
Funding
This work was supported by a grants from the National Science Foundation
Division of Biological Infrastructure [1458400] and the National Institutes of
Health [R01GM089636, U41HG008735].
Availability of data and materials
Data sharing is not applicable to this article as no primary datasets were
generated or analyzed during the current study. Individual annotations can be
viewed at the OMP wiki [14]. Plans for dissemination of the annotation sets
generated using the annotation system described here are discussed in the text.
Software developed for the work described in this article (Mediawiki
extensions) are available from our GitHub repository [14].
Ethics approval and consent to participate
Not applicable.
Consent for publication
Not applicable.
Competing interests
The authors declare that they have no competing interests.
Siegele et al. Journal of Biomedical Semantics           (2019) 10:13 Page 7 of 8
Author details
1Department of Biology, Texas A&M University, College Station, TX, USA.
2Department of Biochemistry and Biophysics, Texas A&M University and
Texas AgriLife Research, College Station, TX, USA. 3Institute for Genome
Sciences, University of Maryland School of Medicine, Baltimore, MD, USA.
Received: 18 September 2018 Accepted: 19 June 2019
